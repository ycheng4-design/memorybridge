'use client';

import { useState, useEffect, useRef, useCallback, Suspense } from 'react';
import { useSearchParams } from 'next/navigation';
import Link from 'next/link';
import DashboardNav from '@/components/DashboardNav';
import DrillCard from '@/components/DrillCard';
import { TabbedDrillAnimation } from '@/components/Skeleton3D';
import PlayerSelectionModal from '@/components/PlayerSelectionModal';
import { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';
import {
  drawSkeleton,
  extractMetrics,
  POSE_CONNECTIONS,
  POSE_LANDMARKS
} from '@/lib/pose-utils';
import {
  DRILLS,
  FORM_RULES,
  evaluateForm,
  findViolationTimestamps,
  type EvaluationResult
} from '@/lib/rules-engine';
import {
  evaluateWithBands,
  SCORING_LEGEND,
  SKILL_LEVEL_DESCRIPTIONS,
} from '@/lib/scoring-rules';
import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData } from '@/lib/types';

// MediaPipe Types
type PoseLandmarker = any;

interface FrameAnalysis {
  timestamp: number;
  landmarks: PoseLandmark[] | null;
  evaluation: EvaluationResult | null;
  metrics: PoseMetrics | null;
}

interface DetectedIssue {
  code: string;
  title: string;
  severity: 'low' | 'medium' | 'high';
  description?: string;
  timestamps: number[];
  drill?: any;
}

function AnalyticsContent() {
  const searchParams = useSearchParams();
  const sessionId = searchParams.get('session');

  // State
  const [uploading, setUploading] = useState(false);
  const [analyzing, setAnalyzing] = useState(false);
  const [analyzeProgress, setAnalyzeProgress] = useState(0);
  const [analysisId, setAnalysisId] = useState<string | null>(null);
  const [result, setResult] = useState<AnalysisResultJson | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);
  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);

  // Multi-pose and player selection state
  const [showPlayerSelection, setShowPlayerSelection] = useState(false);
  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);
  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);
  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);
  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');
  const [eventType, setEventType] = useState<string>('');

  // Banded scoring state
  const [skillLevel, setSkillLevel] = useState<'beginner' | 'intermediate' | 'advanced'>('intermediate');
  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);

  // Video playback state
  const [videoUrl, setVideoUrl] = useState<string | null>(null);
  const [videoFile, setVideoFile] = useState<File | null>(null);
  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);
  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);
  const [issues, setIssues] = useState<DetectedIssue[]>([]);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  const [isPlaying, setIsPlaying] = useState(false);
  const [showSkeleton, setShowSkeleton] = useState(true);
  const [fps, setFps] = useState(30);

  // Pose detection
  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);
  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);

  // Refs
  const fileInputRef = useRef<HTMLInputElement>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const processVideoRef = useRef<HTMLVideoElement | null>(null);
  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const animationRef = useRef<number | null>(null);

  // Initialize MediaPipe Pose Landmarker
  useEffect(() => {
    initializePoseLandmarker();
    return () => {
      cleanup();
    };
  }, []);

  // Load session if ID provided
  useEffect(() => {
    if (sessionId) {
      loadSession(sessionId);
    }
  }, [sessionId]);

  const initializePoseLandmarker = async () => {
    try {
      const vision = await import('@mediapipe/tasks-vision');
      const { PoseLandmarker, FilesetResolver } = vision;

      const filesetResolver = await FilesetResolver.forVisionTasks(
        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
      );

      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',
          delegate: 'GPU',
        },
        runningMode: 'VIDEO',
        numPoses: 4, // Support up to 4 players for doubles
        minPoseDetectionConfidence: 0.5,
        minPosePresenceConfidence: 0.5,
        minTrackingConfidence: 0.5,
      });

      setPoseLandmarkerReady(true);
    } catch (error) {
      console.error('Failed to load MediaPipe Pose:', error);
      // Continue without pose detection - will use fallback
    }
  };

  const cleanup = () => {
    if (pollIntervalRef.current) {
      clearInterval(pollIntervalRef.current);
    }
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
    }
    if (poseLandmarkerRef.current) {
      poseLandmarkerRef.current.close();
    }
  };

  const loadSession = async (id: string) => {
    try {
      setAnalyzing(true);

      // Try new sessions table first
      const { data: sessionData, error: sessionError } = await supabase
        .from('sessions')
        .select('*')
        .eq('id', id)
        .single();

      if (sessionError) {
        // Try legacy table
        const { data: legacyData, error: legacyError } = await supabase
          .from('analysis_results')
          .select('*')
          .eq('id', id)
          .single();

        if (legacyError) throw legacyError;
        if (legacyData?.result_json) {
          setResult(legacyData.result_json);
          if (legacyData.result_json.video_url) {
            setVideoUrl(legacyData.result_json.video_url);
          }
        }
      } else if (sessionData) {
        // New session format
        setVideoUrl(sessionData.video_url);

        if (sessionData.pose_data) {
          setPoseData(sessionData.pose_data);
        }

        // Fetch issues
        const { data: issuesData } = await supabase
          .from('issues')
          .select('*')
          .eq('session_id', id);

        if (issuesData && issuesData.length > 0) {
          setIssues(issuesData.map((issue: any) => ({
            code: issue.code,
            title: issue.title,
            severity: issue.severity,
            description: issue.description,
            timestamps: issue.timestamps || [],
            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],
          })));
        }

        // Build result from session summary
        const summary = sessionData.summary || {};
        setResult({
          top_issues: issuesData?.map((i: any) => ({
            id: i.id,
            title: i.title,
            severity: i.severity,
            description: i.description,
            affected_metrics: [],
          })) || [],
          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({
            id: d.id,
            name: d.name,
            description: d.description,
            duration_minutes: d.durationMinutes,
            target_metrics: d.targetMetrics,
            instructions: d.steps,
          })) || [],
          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',
          strategy_summary: summary.feedback?.strategy_summary || '',
          training_plan: [],
        });
      }
    } catch (err) {
      console.error('Error loading session:', err);
      setError('Failed to load session');
    } finally {
      setAnalyzing(false);
    }
  };

  // Process uploaded video with MediaPipe
  // PHASE 1 FIX: Ensure timestamps are strictly monotonically increasing to prevent
  // "Packet timestamp mismatch" and "CalculatorGraph::Run() failed" errors
  const processVideoWithPose = async (
    videoElement: HTMLVideoElement,
    selectedTracks: number[] = [0]
  ): Promise<FrameAnalysis[]> => {
    if (!poseLandmarkerRef.current) {
      console.warn('Pose landmarker not ready');
      return [];
    }

    const analyses: FrameAnalysis[] = [];
    const videoDuration = videoElement.duration;
    const sampleRate = 10; // Process 10 frames per second
    const totalFrames = Math.floor(videoDuration * sampleRate);

    // PHASE 1: Track last timestamp to ensure strictly increasing timestamps
    let lastTimestampMs = -1;
    let validPoseFrames = 0;
    let lowConfidenceFrames = 0;
    let noPoseFrames = 0;

    setAnalyzeProgress(10); // Start at 10% after track detection

    for (let i = 0; i <= totalFrames; i++) {
      const timestamp = i / sampleRate;
      videoElement.currentTime = timestamp;

      // Wait for video to seek
      await new Promise<void>((resolve) => {
        const onSeeked = () => {
          videoElement.removeEventListener('seeked', onSeeked);
          resolve();
        };
        videoElement.addEventListener('seeked', onSeeked);
      });

      // Give the video a moment to render the frame
      await new Promise(resolve => setTimeout(resolve, 50));

      try {
        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp
        // MediaPipe requires strictly monotonically increasing timestamps
        const rawTimestampMs = Math.floor(timestamp * 1000);
        const timestampMs = Math.max(lastTimestampMs + 1, rawTimestampMs);
        lastTimestampMs = timestampMs;

        const results = poseLandmarkerRef.current.detectForVideo(
          videoElement,
          timestampMs
        );

        let landmarks: PoseLandmark[] | null = null;
        let evaluation: EvaluationResult | null = null;
        let metrics: PoseMetrics | null = null;

        if (results.landmarks && results.landmarks.length > 0) {
          // Only use the selected player's landmarks
          // For doubles, we could merge/average but for now take the first selected
          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length
            ? selectedTracks[0]
            : 0;

          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({
            x: lm.x,
            y: lm.y,
            z: lm.z,
            visibility: lm.visibility ?? 1.0,
          }));

          if (landmarks && landmarks.length > 0) {
            // PHASE 1: Check average visibility/confidence
            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;

            if (avgVisibility < 0.5) {
              // Low confidence pose detection
              lowConfidenceFrames++;
              console.debug(`Frame ${i}: Low confidence pose (avg visibility: ${avgVisibility.toFixed(2)})`);
            } else {
              validPoseFrames++;
            }
            metrics = extractMetrics(landmarks);
            // Use banded evaluation for more realistic scoring
            const bandedResult = evaluateWithBands(landmarks, skillLevel);
            evaluation = {
              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',
              score: bandedResult.overall_score,
              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({
                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,
                value: 0,
                feedback: f,
              })) : [],
              passedRules: [],
              highlightJoints: bandedResult.highlight_joints,
              recommendedDrills: [],
            };
          }
        } else {
          // PHASE 1: Track frames with no pose detected
          noPoseFrames++;
          if (i % 10 === 0) {
            console.debug(`Frame ${i}: No pose detected`);
          }
        }

        analyses.push({
          timestamp,
          landmarks,
          evaluation,
          metrics,
        });
      } catch (err) {
        // PHASE 1: Better error logging for MediaPipe failures
        const errorMsg = err instanceof Error ? err.message : String(err);
        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {
          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);
        } else {
          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);
        }
        analyses.push({
          timestamp,
          landmarks: null,
          evaluation: null,
          metrics: null,
        });
      }

      // Update progress (10-95%)
      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 85));
    }

    // PHASE 1: Log pose detection statistics
    const totalProcessed = totalFrames + 1;
    const validRatio = validPoseFrames / totalProcessed;
    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);

    if (validRatio < 0.3) {
      console.warn('Low pose detection rate - video may have poor lighting or player not visible');
    }

    return analyses;
  };

  // Detect issues from frame analyses
  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {
    const issueMap: Map<string, {
      rule: any;
      timestamps: number[];
      count: number;
    }> = new Map();

    for (const frame of analyses) {
      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {
        for (const failed of frame.evaluation.failedRules) {
          const code = failed.rule.code;
          if (!issueMap.has(code)) {
            issueMap.set(code, {
              rule: failed.rule,
              timestamps: [],
              count: 0,
            });
          }
          const issue = issueMap.get(code)!;
          issue.timestamps.push(frame.timestamp);
          issue.count++;
        }
      }
    }

    // Convert to array and sort by count
    const issues: DetectedIssue[] = Array.from(issueMap.entries())
      .map(([code, data]) => ({
        code,
        title: data.rule.name,
        severity: data.rule.severity,
        description: data.rule.description,
        timestamps: data.timestamps,
        drill: DRILLS[data.rule.drillId],
      }))
      .sort((a, b) => b.timestamps.length - a.timestamps.length)
      .slice(0, 5); // Top 5 issues

    return issues;
  };

  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file) return;

    if (!file.type.startsWith('video/')) {
      setError('Please select a video file');
      return;
    }

    if (file.size > 100 * 1024 * 1024) {
      setError('File size must be less than 100MB. Please compress your video before uploading.');
      return;
    }

    setError(null);
    setVideoFile(file);
    setResult(null);
    setIssues([]);
    setPoseData([]);
    setFrameAnalyses([]);

    // Create object URL for video preview
    const objectUrl = URL.createObjectURL(file);
    setVideoUrl(objectUrl);

    // Start analysis
    await analyzeVideo(file, objectUrl);
  };

  // Detect player tracks in the video
  // PHASE 1 FIX: Ensure timestamps are strictly monotonically increasing
  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {
    if (!poseLandmarkerRef.current) return [];

    const tracks: Map<number, PlayerTrackData> = new Map();
    const sampleFrames = 5; // Sample 5 frames to detect players
    const duration = videoElement.duration;

    // PHASE 1: Track last timestamp to ensure strictly increasing
    let lastTimestampMs = -1;

    for (let i = 0; i < sampleFrames; i++) {
      const timestamp = (i / sampleFrames) * duration;
      videoElement.currentTime = timestamp;

      await new Promise<void>((resolve) => {
        const onSeeked = () => {
          videoElement.removeEventListener('seeked', onSeeked);
          resolve();
        };
        videoElement.addEventListener('seeked', onSeeked);
      });

      await new Promise(resolve => setTimeout(resolve, 50));

      try {
        // PHASE 1 FIX: Ensure timestamp is strictly greater than last
        const rawTimestampMs = Math.floor(timestamp * 1000);
        const timestampMs = Math.max(lastTimestampMs + 1, rawTimestampMs);
        lastTimestampMs = timestampMs;

        const results = poseLandmarkerRef.current.detectForVideo(
          videoElement,
          timestampMs
        );

        if (results.landmarks && results.landmarks.length > 0) {
          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {
            const landmarks = results.landmarks[poseIdx];
            const bbox = calculateBoundingBox(landmarks);

            if (!tracks.has(poseIdx)) {
              tracks.set(poseIdx, {
                track_id: poseIdx,
                bbox_samples: [],
                is_selected: false,
                confidence_avg: 0,
                frame_count: 0,
                side: bbox.y < 0.5 ? 'far' : 'near',
              });
            }

            const track = tracks.get(poseIdx)!;
            track.bbox_samples.push({
              frame: i,
              x: bbox.x,
              y: bbox.y,
              w: bbox.w,
              h: bbox.h,
              confidence: landmarks[0].visibility || 0.5,
            });
            track.frame_count++;
            track.confidence_avg =
              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /
              track.frame_count;
          }
        }
      } catch (err) {
        console.warn('Error detecting poses in frame:', err);
      }
    }

    // PHASE 2: Generate thumbnails for detected tracks
    // Seek to a frame where we have good detections (e.g., 0.5s or first detection)
    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);

    // Find best frame for thumbnails (frame with most detections)
    const bestFrameIdx = tracksArray.length > 0 && tracksArray[0].bbox_samples.length > 0
      ? tracksArray[0].bbox_samples[0].frame
      : 0;
    const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;

    // Seek to best frame for thumbnail capture
    if (tracksArray.length > 0) {
      videoElement.currentTime = Math.max(0.5, bestTimestamp);
      await new Promise<void>((resolve) => {
        const onSeeked = () => {
          videoElement.removeEventListener('seeked', onSeeked);
          resolve();
        };
        videoElement.addEventListener('seeked', onSeeked);
      });
      await new Promise(resolve => setTimeout(resolve, 100));

      // Generate thumbnail for each track
      for (const track of tracksArray) {
        if (track.bbox_samples.length > 0) {
          // Use the best bounding box (highest confidence)
          const bestBbox = track.bbox_samples.reduce((best, current) =>
            (current.confidence || 0) > (best.confidence || 0) ? current : best
          );

          const thumbnail = generateThumbnail(videoElement, {
            x: bestBbox.x,
            y: bestBbox.y,
            w: bestBbox.w,
            h: bestBbox.h,
          });

          if (thumbnail) {
            track.thumbnail_url = thumbnail;
            console.log(`Generated thumbnail for track ${track.track_id}`);
          }
        }
      }
    }

    return tracksArray;
  };

  // Calculate bounding box from landmarks
  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {
    let minX = 1, minY = 1, maxX = 0, maxY = 0;
    for (const lm of landmarks) {
      if (lm.visibility > 0.5) {
        minX = Math.min(minX, lm.x);
        minY = Math.min(minY, lm.y);
        maxX = Math.max(maxX, lm.x);
        maxY = Math.max(maxY, lm.y);
      }
    }
    return {
      x: minX,
      y: minY,
      w: maxX - minX,
      h: maxY - minY,
    };
  };

  // PHASE 2: Generate thumbnail from video at specific bounding box
  const generateThumbnail = (
    video: HTMLVideoElement,
    bbox: { x: number; y: number; w: number; h: number },
    padding: number = 0.1
  ): string | null => {
    try {
      // Create canvas for thumbnail
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      if (!ctx) return null;

      // Calculate crop region with padding
      const vw = video.videoWidth;
      const vh = video.videoHeight;

      // Add padding and ensure bounds are valid
      const padX = bbox.w * padding;
      const padY = bbox.h * padding;

      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));
      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));
      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));
      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));

      if (cropW <= 0 || cropH <= 0) return null;

      // Set thumbnail size (maintain aspect ratio, max 150px)
      const maxSize = 150;
      const scale = Math.min(maxSize / cropW, maxSize / cropH);
      canvas.width = Math.floor(cropW * scale);
      canvas.height = Math.floor(cropH * scale);

      // Draw cropped region
      ctx.drawImage(
        video,
        cropX, cropY, cropW, cropH, // Source
        0, 0, canvas.width, canvas.height // Destination
      );

      // Return as base64 data URL
      return canvas.toDataURL('image/jpeg', 0.8);
    } catch (err) {
      console.warn('Error generating thumbnail:', err);
      return null;
    }
  };

  // Handle player selection confirmation
  const handlePlayerSelectionConfirm = (
    selectedTracks: number[],
    format: 'singles' | 'doubles',
    event: string
  ) => {
    setSelectedTrackIds(selectedTracks);
    setMatchFormat(format);
    setEventType(event);
    setShowPlayerSelection(false);

    // Continue with analysis using selected tracks
    if (processVideoRef.current && videoFile) {
      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);
    }
  };

  // Continue analysis after player selection
  const continueAnalysisWithSelection = async (
    processVideo: HTMLVideoElement,
    selectedTracks: number[]
  ) => {
    const analyses = await processVideoWithPose(processVideo, selectedTracks);
    setFrameAnalyses(analyses);

    const poseArray = analyses.map(a => a.landmarks);
    setPoseData(poseArray);

    const detectedIssues = detectIssuesFromAnalyses(analyses);
    setIssues(detectedIssues);

    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;
    const totalFrames = analyses.filter(a => a.evaluation).length;
    const avgScore = totalFrames > 0
      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames
      : 0;

    setResult({
      top_issues: detectedIssues.map(issue => ({
        id: issue.code,
        title: issue.title,
        severity: issue.severity,
        description: issue.description || '',
        affected_metrics: [],
      })),
      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({
        id: d.id,
        name: d.name,
        description: d.description,
        duration_minutes: d.durationMinutes,
        target_metrics: d.targetMetrics,
        instructions: d.steps,
      })),
      technique_summary: `Analysis complete. Found ${detectedIssues.length} areas to improve. Overall form score: ${avgScore.toFixed(0)}%`,
      strategy_summary: passedFrames > totalFrames * 0.7
        ? 'Your form is generally good. Focus on the specific issues identified.'
        : 'Work on maintaining consistent form throughout your movements.',
      training_plan: [],
    });

    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore);
    if (!saveResult.success) {
      setError(saveResult.error || 'Failed to save analysis');
    }
    setAnalyzing(false);
    setAnalyzeProgress(100);
  };

  const analyzeVideo = async (file: File, videoObjectUrl: string) => {
    setAnalyzing(true);
    setAnalyzeProgress(0);

    try {
      // Create a hidden video element for processing
      const processVideo = document.createElement('video');
      processVideo.src = videoObjectUrl;
      processVideo.muted = true;
      processVideo.playsInline = true;
      processVideoRef.current = processVideo;

      // Wait for video to load metadata
      await new Promise<void>((resolve, reject) => {
        processVideo.onloadedmetadata = () => {
          setDuration(processVideo.duration);
          setFps(30); // Assume 30fps
          resolve();
        };
        processVideo.onerror = () => reject(new Error('Failed to load video'));
      });

      // Wait for video to be fully loaded
      await new Promise<void>((resolve) => {
        if (processVideo.readyState >= 2) {
          resolve();
        } else {
          processVideo.oncanplay = () => resolve();
        }
      });

      // Detect player tracks first
      setAnalyzeProgress(5);
      const tracks = await detectPlayerTracks(processVideo);
      setDetectedTracks(tracks);

      // Auto-detect singles/doubles
      const uniquePlayers = tracks.length;
      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';
      setDetectedMatchFormat(detectedFormat);

      // If multiple players detected, show selection modal
      if (tracks.length > 1) {
        setShowPlayerSelection(true);
        return; // Wait for user selection before continuing
      }

      // If single player, auto-select and continue
      if (tracks.length === 1) {
        setSelectedTrackIds([tracks[0].track_id]);
      }

      // Process video with pose detection
      let analyses: FrameAnalysis[] = [];

      if (poseLandmarkerReady && poseLandmarkerRef.current) {
        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);
        setFrameAnalyses(analyses);

        // Extract pose data array for rendering
        const poseArray = analyses.map(a => a.landmarks);
        setPoseData(poseArray);

        // Detect issues
        const detectedIssues = detectIssuesFromAnalyses(analyses);
        setIssues(detectedIssues);

        // Calculate overall stats
        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;
        const totalFrames = analyses.filter(a => a.evaluation).length;
        const avgScore = totalFrames > 0
          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames
          : 0;

        // Build result
        setResult({
          top_issues: detectedIssues.map(issue => ({
            id: issue.code,
            title: issue.title,
            severity: issue.severity,
            description: issue.description || '',
            affected_metrics: [],
          })),
          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({
            id: d.id,
            name: d.name,
            description: d.description,
            duration_minutes: d.durationMinutes,
            target_metrics: d.targetMetrics,
            instructions: d.steps,
          })),
          technique_summary: `Analysis complete. Found ${detectedIssues.length} areas to improve. Overall form score: ${avgScore.toFixed(0)}%`,
          strategy_summary: passedFrames > totalFrames * 0.7
            ? 'Your form is generally good. Focus on the specific issues identified.'
            : 'Work on maintaining consistent form throughout your movements.',
          training_plan: [],
        });

        // Save to database - only create session if upload succeeds
        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore);
        if (!saveResult.success) {
          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');
        }
      } else {
        // Fallback: Use backend API or show message
        setError('Pose detection not available. Using demo mode.');

        // Generate demo data
        const demoIssues: DetectedIssue[] = [
          {
            code: 'ELBOW_ANGLE_OVERHEAD',
            title: 'Elbow Extension (Overhead)',
            severity: 'high',
            description: 'Elbow should be nearly straight at contact point',
            timestamps: [1.2, 3.5, 7.8],
            drill: DRILLS['elbow-extension'],
          },
          {
            code: 'KNEE_BEND',
            title: 'Knee Bend',
            severity: 'medium',
            description: 'Bend knees more for power',
            timestamps: [2.1, 5.3],
            drill: DRILLS['lunge-practice'],
          },
        ];
        setIssues(demoIssues);
        setResult({
          top_issues: demoIssues.map(i => ({
            id: i.code,
            title: i.title,
            severity: i.severity,
            description: i.description || '',
            affected_metrics: [],
          })),
          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({
            id: d!.id,
            name: d!.name,
            description: d!.description,
            duration_minutes: d!.durationMinutes,
            target_metrics: d!.targetMetrics,
            instructions: d!.steps,
          })),
          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',
          strategy_summary: '',
          training_plan: [],
        });
      }

    } catch (err) {
      console.error('Analysis error:', err);
      setError('Failed to analyze video. Please try again.');
    } finally {
      setAnalyzing(false);
      setAnalyzeProgress(100);
    }
  };

  const saveAnalysisToDatabase = async (
    file: File,
    analyses: FrameAnalysis[],
    detectedIssues: DetectedIssue[],
    avgScore: number
  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {
    try {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) {
        return { success: false, error: 'Not authenticated' };
      }

      // Upload video with progress tracking
      // This is critical - do NOT create session if upload fails
      let videoPath: string | null = null;
      let publicVideoUrl = '';

      try {
        videoPath = await uploadVideo(file, user.id, (progress) => {
          // Update progress: first 60% is analysis, last 40% is upload
          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));
        });

        if (!videoPath) {
          throw new Error('Upload returned empty path');
        }

        // Get video URL - try public URL first, fall back to signed URL
        publicVideoUrl = getVideoUrl(videoPath);

        // Verify the URL is valid by checking if it's accessible
        // This helps catch cases where bucket might be private
        console.log('Video uploaded successfully:', videoPath);
        console.log('Public URL:', publicVideoUrl);

      } catch (uploadError) {
        console.error('Video upload failed:', uploadError);
        const errorMessage = uploadError instanceof Error
          ? uploadError.message
          : 'Failed to upload video. Please try again.';
        setError(errorMessage);
        return { success: false, error: errorMessage };
      }

      // Calculate stats
      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;
      const totalFrames = analyses.filter(a => a.evaluation).length;

      // Create session with enhanced fields
      // Only create session AFTER successful upload
      const { data: session, error: sessionError } = await supabase
        .from('sessions')
        .insert({
          user_id: user.id,
          type: 'analytics',
          video_path: videoPath,
          video_url: publicVideoUrl,
          filename: file.name,
          frame_count: analyses.length,
          overall_score: Math.round(avgScore),
          pose_data: analyses.map(a => a.landmarks),
          // Enhanced v3 fields
          status: 'ready',
          match_format: matchFormat,
          event_type: eventType || null,
          selected_tracks: selectedTrackIds,
          skill_level: skillLevel,
          rules_version: 'v1',
          summary: {
            total_frames: totalFrames,
            green_frames: passedFrames,
            red_frames: totalFrames - passedFrames,
            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,
            average_score: avgScore,
            duration_seconds: duration,
          },
        })
        .select()
        .single();

      if (sessionError) {
        console.error('Session save error:', sessionError);
        return { success: false, error: 'Failed to save session data' };
      }

      // Save issues
      if (session && detectedIssues.length > 0) {
        const issueInserts = detectedIssues.map(issue => ({
          session_id: session.id,
          code: issue.code,
          title: issue.title,
          severity: issue.severity,
          description: issue.description,
          timestamps: issue.timestamps,
          drill: issue.drill,
        }));

        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);
        if (issuesError) {
          console.warn('Issues save warning:', issuesError);
          // Non-fatal - session was created successfully
        }
      }

      setAnalyzeProgress(100);
      return { success: true, sessionId: session.id };

    } catch (err) {
      console.error('Error saving to database:', err);
      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';
      return { success: false, error: errorMessage };
    }
  };

  // Video frame rendering with skeleton overlay
  const renderFrame = useCallback(() => {
    if (!videoRef.current || !canvasRef.current) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // Resize canvas to match video
    if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
      canvas.width = video.videoWidth || 640;
      canvas.height = video.videoHeight || 480;
    }

    // Clear canvas
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    if (!showSkeleton) return;

    // Find the closest frame analysis
    let closestFrame: FrameAnalysis | null = null;
    let minDiff = Infinity;

    for (const frame of frameAnalyses) {
      const diff = Math.abs(frame.timestamp - video.currentTime);
      if (diff < minDiff) {
        minDiff = diff;
        closestFrame = frame;
      }
    }

    // Also check raw poseData array (for loaded sessions)
    if (!closestFrame && poseData.length > 0) {
      const frameIndex = Math.floor(video.currentTime * 10); // Assuming 10fps sample rate
      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];
      if (landmarks) {
        closestFrame = {
          timestamp: video.currentTime,
          landmarks,
          evaluation: evaluateForm(landmarks, 'general'),
          metrics: extractMetrics(landmarks),
        };
      }
    }

    if (closestFrame?.landmarks) {
      // Use banded scoring for more nuanced feedback
      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);
      setCurrentBandedScore(bandedResult);

      // Determine color based on band
      const isGreen = bandedResult.overall_band === 'green';
      const isYellow = bandedResult.overall_band === 'yellow';

      // Draw with appropriate color
      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';

      // Custom draw with banded colors
      ctx.strokeStyle = color;
      ctx.lineWidth = 3;
      ctx.fillStyle = color;

      // Draw skeleton connections
      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {
        const start = closestFrame.landmarks[startIdx];
        const end = closestFrame.landmarks[endIdx];
        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {
          ctx.beginPath();
          ctx.moveTo(start.x * canvas.width, start.y * canvas.height);
          ctx.lineTo(end.x * canvas.width, end.y * canvas.height);
          ctx.stroke();
        }
      }

      // Draw joints
      for (const landmark of closestFrame.landmarks) {
        if (landmark.visibility > 0.5) {
          ctx.beginPath();
          ctx.arc(
            landmark.x * canvas.width,
            landmark.y * canvas.height,
            5,
            0,
            2 * Math.PI
          );
          ctx.fill();
        }
      }
    }

    if (!video.paused) {
      animationRef.current = requestAnimationFrame(renderFrame);
    }
  }, [frameAnalyses, poseData, showSkeleton]);

  // Trigger skeleton render when poseData is loaded
  useEffect(() => {
    if (poseData.length > 0 && videoRef.current) {
      // Wait for video to be ready then render
      const tryRender = () => {
        if (videoRef.current && videoRef.current.readyState >= 2) {
          renderFrame();
        } else {
          setTimeout(tryRender, 100);
        }
      };
      tryRender();
    }
  }, [poseData, renderFrame]);

  // Handle video time updates
  const handleTimeUpdate = useCallback(() => {
    if (videoRef.current) {
      setCurrentTime(videoRef.current.currentTime);
      renderFrame();
    }
  }, [renderFrame]);

  // Handle video play/pause
  const togglePlayPause = useCallback(() => {
    if (videoRef.current) {
      if (videoRef.current.paused) {
        videoRef.current.play();
        setIsPlaying(true);
        animationRef.current = requestAnimationFrame(renderFrame);
      } else {
        videoRef.current.pause();
        setIsPlaying(false);
        if (animationRef.current) {
          cancelAnimationFrame(animationRef.current);
        }
      }
    }
  }, [renderFrame]);

  // Jump to timestamp
  const jumpToTimestamp = useCallback((timestamp: number) => {
    if (videoRef.current) {
      videoRef.current.currentTime = timestamp;
      videoRef.current.pause();
      setIsPlaying(false);
      setCurrentTime(timestamp);
      // Force render frame at new position
      setTimeout(renderFrame, 50);
    }
  }, [renderFrame]);

  // Find next mistake
  const goToNextMistake = useCallback(() => {
    const allTimestamps = issues
      .flatMap((i) => i.timestamps || [])
      .sort((a, b) => a - b);

    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);
    if (nextTimestamp !== undefined) {
      jumpToTimestamp(nextTimestamp);
    } else if (allTimestamps.length > 0) {
      // Wrap around to first
      jumpToTimestamp(allTimestamps[0]);
    }
  }, [issues, currentTime, jumpToTimestamp]);

  // Handle video metadata loaded
  const handleLoadedMetadata = useCallback(() => {
    if (videoRef.current) {
      setDuration(videoRef.current.duration);
      // Initial render
      setTimeout(renderFrame, 100);
    }
  }, [renderFrame]);

  const getSeverityColor = (severity: string) => {
    switch (severity) {
      case 'high':
        return 'bg-red-50 border-red-200 text-red-800';
      case 'medium':
        return 'bg-yellow-50 border-yellow-200 text-yellow-800';
      case 'low':
        return 'bg-green-50 border-green-200 text-green-800';
      default:
        return 'bg-gray-50 border-gray-200 text-gray-800';
    }
  };

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  // Get current frame info for display
  const getCurrentFrameInfo = () => {
    if (frameAnalyses.length === 0) return null;

    let closestFrame: FrameAnalysis | null = null;
    let minDiff = Infinity;

    for (const frame of frameAnalyses) {
      const diff = Math.abs(frame.timestamp - currentTime);
      if (diff < minDiff) {
        minDiff = diff;
        closestFrame = frame;
      }
    }

    return closestFrame;
  };

  const currentFrameInfo = getCurrentFrameInfo();

  return (
    <div className="min-h-screen bg-gray-50">
      <DashboardNav />

      <main className="ml-64 p-8">
        <div className="max-w-7xl mx-auto">
          {/* Header */}
          <div className="mb-8">
            <h1 className="text-3xl font-bold text-gray-900">Video Analytics</h1>
            <p className="text-gray-600 mt-1">
              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}
            </p>
          </div>

          {/* Upload Section */}
          {!result && !videoUrl && (
            <div className="bg-white rounded-xl p-8 shadow-sm mb-8">
              <div
                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${
                  uploading || analyzing
                    ? 'border-primary-300 bg-primary-50'
                    : 'border-gray-300 hover:border-primary-400'
                }`}
              >
                {uploading ? (
                  <div className="space-y-4">
                    <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto"></div>
                    <p className="text-gray-600">Uploading video...</p>
                  </div>
                ) : analyzing ? (
                  <div className="space-y-4">
                    <div className="w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto">
                      <svg className="w-8 h-8 text-primary-500 animate-pulse" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z" />
                      </svg>
                    </div>
                    <p className="text-gray-900 font-medium">Analyzing your technique...</p>
                    <p className="text-gray-500 text-sm">Processing pose detection frame by frame</p>
                    <div className="w-64 mx-auto bg-gray-200 rounded-full h-2">
                      <div
                        className="bg-primary-500 h-2 rounded-full transition-all duration-300"
                        style={{ width: `${analyzeProgress}%` }}
                      ></div>
                    </div>
                    <p className="text-sm text-gray-500">{analyzeProgress}% complete</p>
                  </div>
                ) : (
                  <>
                    <div className="w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4">
                      <svg className="w-8 h-8 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12" />
                      </svg>
                    </div>
                    <h3 className="text-lg font-medium text-gray-900 mb-2">Upload your badminton video</h3>
                    <p className="text-gray-500 mb-4">MP4, MOV, or WebM up to 100MB</p>
                    {poseLandmarkerReady && (
                      <p className="text-sm text-green-600 mb-4">Pose detection ready</p>
                    )}
                    <input ref={fileInputRef} type="file" accept="video/*" onChange={handleFileSelect} className="hidden" />
                    <button onClick={() => fileInputRef.current?.click()} className="px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition">
                      Select Video
                    </button>
                  </>
                )}
              </div>

              {error && (
                <div className="mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700">{error}</div>
              )}
            </div>
          )}

          {/* Video Player with Overlay */}
          {videoUrl && (
            <div className="grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8">
              <div className="lg:col-span-2">
                <div className="bg-gray-900 rounded-xl overflow-hidden">
                  <div className="relative aspect-video">
                    <video
                      ref={videoRef}
                      src={videoUrl}
                      className="absolute inset-0 w-full h-full object-contain"
                      onTimeUpdate={handleTimeUpdate}
                      onLoadedMetadata={handleLoadedMetadata}
                      onEnded={() => setIsPlaying(false)}
                      playsInline
                    />
                    <canvas
                      ref={canvasRef}
                      className={`absolute inset-0 w-full h-full object-contain pointer-events-none ${
                        showSkeleton ? '' : 'hidden'
                      }`}
                    />

                    {/* Status indicator with banded scoring */}
                    {currentBandedScore && (
                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${
                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :
                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :
                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :
                        'bg-gray-500 text-white'
                      }`}>
                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}
                        <span className="ml-2 opacity-75">
                          {Math.round(currentBandedScore.overall_score)}%
                        </span>
                      </div>
                    )}

                    {/* Time display */}
                    <div className="absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm">
                      {formatTime(currentTime)} / {formatTime(duration)}
                    </div>

                    {/* Current metrics display */}
                    {currentFrameInfo?.metrics && (
                      <div className="absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs">
                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>
                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>
                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>
                      </div>
                    )}
                  </div>

                  {/* Controls */}
                  <div className="p-4 flex items-center justify-between">
                    <div className="flex items-center gap-2">
                      <button
                        onClick={togglePlayPause}
                        className="p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition"
                      >
                        {isPlaying ? (
                          <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z" />
                          </svg>
                        ) : (
                          <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z" />
                            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
                          </svg>
                        )}
                      </button>

                      <button
                        onClick={goToNextMistake}
                        disabled={issues.length === 0}
                        className="px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50"
                      >
                        Next Mistake
                      </button>
                    </div>

                    <div className="flex items-center gap-4">
                      {/* Skill level selector */}
                      <select
                        value={skillLevel}
                        onChange={(e) => setSkillLevel(e.target.value as any)}
                        className="text-sm bg-gray-800 text-white border-gray-700 rounded-lg px-2 py-1"
                        title="Adjust scoring sensitivity"
                      >
                        <option value="beginner">Beginner</option>
                        <option value="intermediate">Intermediate</option>
                        <option value="advanced">Advanced</option>
                      </select>

                      <label className="flex items-center gap-2 text-white text-sm">
                        <input
                          type="checkbox"
                          checked={showSkeleton}
                          onChange={(e) => {
                            setShowSkeleton(e.target.checked);
                            if (e.target.checked) {
                              setTimeout(renderFrame, 50);
                            }
                          }}
                          className="rounded"
                        />
                        Show Skeleton
                      </label>
                    </div>
                  </div>

                  {/* Timeline scrubber */}
                  <div className="px-4 pb-4">
                    <input
                      type="range"
                      min={0}
                      max={duration || 100}
                      step={0.1}
                      value={currentTime}
                      onChange={(e) => {
                        const time = parseFloat(e.target.value);
                        if (videoRef.current) {
                          videoRef.current.currentTime = time;
                          setCurrentTime(time);
                          // Force render skeleton at new position
                          setTimeout(renderFrame, 50);
                        }
                      }}
                      className="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer"
                    />
                  </div>
                </div>

                {/* Analysis Summary */}
                {result && (
                  <div className="mt-6 bg-white rounded-xl p-6 shadow-sm">
                    <h3 className="font-semibold text-gray-900 mb-3">Analysis Summary</h3>
                    <p className="text-gray-600">{result.technique_summary}</p>
                    {result.strategy_summary && (
                      <p className="text-gray-500 mt-2 text-sm">{result.strategy_summary}</p>
                    )}
                  </div>
                )}
              </div>

              {/* Issues Panel */}
              <div className="space-y-4">
                <h3 className="font-semibold text-gray-900">Detected Issues</h3>
                {analyzing ? (
                  <div className="bg-white rounded-xl p-6 shadow-sm animate-pulse">
                    <div className="h-4 bg-gray-200 rounded w-3/4 mb-3"></div>
                    <div className="h-4 bg-gray-200 rounded w-1/2"></div>
                  </div>
                ) : issues.length > 0 ? (
                  <div className="space-y-4 max-h-[600px] overflow-y-auto">
                    {issues.map((issue, index) => (
                      <DrillCard
                        key={index}
                        issue={issue}
                        onTimestampClick={jumpToTimestamp}
                        currentTime={currentTime}
                      />
                    ))}
                  </div>
                ) : (
                  <div className="bg-green-50 border border-green-200 rounded-xl p-4 text-green-800">
                    <p className="font-medium">Great form!</p>
                    <p className="text-sm">No major issues detected in this video.</p>
                  </div>
                )}

                {/* Reset button */}
                {videoUrl && !analyzing && (
                  <button
                    onClick={() => {
                      setResult(null);
                      setVideoUrl(null);
                      setVideoFile(null);
                      setIssues([]);
                      setPoseData([]);
                      setFrameAnalyses([]);
                      setCurrentTime(0);
                      setDuration(0);
                    }}
                    className="w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition"
                  >
                    Analyze Another Video
                  </button>
                )}
              </div>
            </div>
          )}

          {/* Results Section (legacy format without video) */}
          {result && !videoUrl && (
            <div className="grid grid-cols-1 lg:grid-cols-2 gap-8">
              {/* Left Column - Issues */}
              <div className="space-y-6">
                <div className="bg-white rounded-xl p-6 shadow-sm">
                  <h2 className="text-lg font-semibold text-gray-900 mb-4">Areas to Improve</h2>
                  <div className="space-y-3">
                    {result.top_issues.map((issue) => (
                      <button
                        key={issue.id}
                        onClick={() => setSelectedIssue(issue)}
                        className={`w-full text-left p-4 rounded-lg border transition ${
                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''
                        } ${getSeverityColor(issue.severity)}`}
                      >
                        <div className="flex items-center justify-between mb-1">
                          <span className="font-medium">{issue.title}</span>
                          <span className="text-xs uppercase font-semibold">{issue.severity}</span>
                        </div>
                        <p className="text-sm opacity-80">{issue.description}</p>
                      </button>
                    ))}
                  </div>
                </div>

                <div className="bg-white rounded-xl p-6 shadow-sm">
                  <h2 className="text-lg font-semibold text-gray-900 mb-3">Technique Summary</h2>
                  <p className="text-gray-600">{result.technique_summary}</p>
                </div>
              </div>

              {/* Right Column - Drills */}
              <div className="space-y-6">
                <div className="bg-white rounded-xl p-6 shadow-sm">
                  <h2 className="text-lg font-semibold text-gray-900 mb-4">Recommended Drills</h2>
                  <div className="space-y-3">
                    {result.drills.map((drill) => (
                      <button
                        key={drill.id}
                        onClick={() => setSelectedDrill(drill)}
                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${
                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''
                        }`}
                      >
                        <div className="flex items-center justify-between mb-1">
                          <span className="font-medium text-gray-900">{drill.name}</span>
                          <span className="text-sm text-gray-500">{drill.duration_minutes} min</span>
                        </div>
                        <p className="text-sm text-gray-600">{drill.description}</p>
                      </button>
                    ))}
                  </div>
                </div>

                {selectedDrill && (
                  <div className="bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6">
                    <div className="flex items-center justify-between mb-4">
                      <h3 className="text-lg font-semibold text-gray-900">{selectedDrill.name}</h3>
                      <Link
                        href={`/practice?drill=${selectedDrill.id}`}
                        className="px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition"
                      >
                        Let&apos;s Practice
                      </Link>
                    </div>
                    <div className="space-y-3">
                      <p className="text-gray-700">{selectedDrill.description}</p>
                      <div>
                        <p className="font-medium text-gray-900 mb-2">Instructions:</p>
                        <ol className="list-decimal list-inside space-y-1 text-gray-700">
                          {selectedDrill.instructions.map((instruction, i) => (
                            <li key={i}>{instruction}</li>
                          ))}
                        </ol>
                      </div>
                    </div>
                  </div>
                )}

                <button
                  onClick={() => {
                    setResult(null);
                    setSelectedIssue(null);
                    setSelectedDrill(null);
                    setVideoUrl(null);
                    setPoseData([]);
                    setIssues([]);
                  }}
                  className="w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition"
                >
                  Analyze Another Video
                </button>
              </div>
            </div>
          )}
        </div>
      </main>

      {/* Player Selection Modal */}
      <PlayerSelectionModal
        isOpen={showPlayerSelection}
        onClose={() => {
          setShowPlayerSelection(false);
          // Reset if user cancels
          setAnalyzing(false);
          setVideoUrl(null);
          setVideoFile(null);
        }}
        onConfirm={handlePlayerSelectionConfirm}
        tracks={detectedTracks}
        detectedFormat={detectedMatchFormat}
      />
    </div>
  );
}

function AnalyticsLoading() {
  return (
    <div className="min-h-screen bg-gray-50">
      <DashboardNav />
      <main className="ml-64 p-8">
        <div className="max-w-7xl mx-auto">
          <div className="animate-pulse">
            <div className="h-8 bg-gray-200 rounded w-48 mb-4"></div>
            <div className="h-4 bg-gray-200 rounded w-96 mb-8"></div>
            <div className="bg-gray-200 rounded-xl h-96"></div>
          </div>
        </div>
      </main>
    </div>
  );
}

export default function AnalyticsPage() {
  return (
    <Suspense fallback={<AnalyticsLoading />}>
      <AnalyticsContent />
    </Suspense>
  );
}
