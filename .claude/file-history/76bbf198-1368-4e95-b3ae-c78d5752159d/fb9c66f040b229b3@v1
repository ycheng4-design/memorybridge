'use client';

import { useState, useEffect, useRef, useCallback, useMemo, Suspense } from 'react';
import { useSearchParams } from 'next/navigation';
import Link from 'next/link';
import DashboardNav from '@/components/DashboardNav';
import DrillCard from '@/components/DrillCard';
import { TabbedDrillAnimation } from '@/components/Skeleton3D';
import PlayerSelectionModal from '@/components/PlayerSelectionModal';
import GuidanceAnimation from '@/components/GuidanceAnimation';
import MovementGuidance, { TrajectoryPreview } from '@/components/MovementGuidance';
import { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';
import {
  drawSkeleton,
  extractMetrics,
  POSE_CONNECTIONS,
  POSE_LANDMARKS
} from '@/lib/pose-utils';
import {
  createSubjectLock,
  findLockedSubjectPose,
  setManualLock,
  clearManualLock,
  findPoseAtClick,
  type SubjectLock
} from '@/lib/subject-lock';
import {
  drawUserSkeleton,
  drawGhostSkeleton,
  drawMotionPath,
  extractRacketTrajectory,
  drawSelectionIndicator,
  SKELETON_COLORS,
  type RenderOptions,
} from '@/lib/skeleton-renderer';
import {
  DRILLS,
  FORM_RULES,
  evaluateForm,
  findViolationTimestamps,
  type EvaluationResult
} from '@/lib/rules-engine';
import {
  evaluateWithBands,
  SCORING_LEGEND,
  SKILL_LEVEL_DESCRIPTIONS,
  validateSessionPoseData,
} from '@/lib/scoring-rules';
import { computeSkillScore } from '@/lib/skill-scoring';
import { initializeGhostRival, getGhostPoseAtTime, createContextAwareGhost } from '@/lib/ghost-overlay';
import { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';
import MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';
import FixItCard from '@/components/FixItCard';
import SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';
import CompareMode from '@/components/CompareMode';
import PoseSandbox3D from '@/components/PoseSandbox3D';
import type {
  AnalysisResultJson,
  Issue,
  Drill,
  PoseLandmark,
  Session,
  PoseMetrics,
  PlayerTrackData,
  ComputedSkillScore,
  MistakeEvent,
  GhostPoseFrame,
  GhostRivalData,
  TrackingFrame,
  TrackingResult,
  TrackSummary,
  LockedPlayerContext,
} from '@/lib/types';

// MediaPipe Types
type PoseLandmarker = any;

interface FrameAnalysis {
  timestamp: number;
  landmarks: PoseLandmark[] | null;
  evaluation: EvaluationResult | null;
  metrics: PoseMetrics | null;
}

interface DetectedIssue {
  code: string;
  title: string;
  severity: 'low' | 'medium' | 'high';
  description?: string;
  timestamps: number[];
  drill?: any;
}

// PHASE 5: Analysis state machine
type AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';

// PHASE 3: Auto-level detection result from Gemini
interface AutoLevelResult {
  level: 'Beginner' | 'Intermediate' | 'Advanced';
  confidence: number;
  rationaleBullets: string[];
  guidanceKeyframes?: GuidanceKeyframe[];
}

// PHASE 4: Guidance keyframe for animation
interface GuidanceKeyframe {
  name: string;
  description: string;
  landmarks: PoseLandmark[] | null;
  targetLandmarks?: PoseLandmark[] | null;
  correction?: string;
}

function AnalyticsContent() {
  const searchParams = useSearchParams();
  const sessionId = searchParams.get('session');

  // State
  const [uploading, setUploading] = useState(false);
  const [analyzing, setAnalyzing] = useState(false);
  const [analyzeProgress, setAnalyzeProgress] = useState(0);
  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');
  const [analysisId, setAnalysisId] = useState<string | null>(null);
  const [result, setResult] = useState<AnalysisResultJson | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);
  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);

  // Multi-pose and player selection state
  const [showPlayerSelection, setShowPlayerSelection] = useState(false);
  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);
  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);
  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);
  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');
  const [eventType, setEventType] = useState<string>('');

  // V5: Backend YOLO+ByteTrack tracking state
  const [backendTrackingData, setBackendTrackingData] = useState<TrackingFrame[] | null>(null);
  const [backendTrackSummaries, setBackendTrackSummaries] = useState<TrackSummary[] | null>(null);
  const [useBackendTracking, setUseBackendTracking] = useState(false);
  const [lockedPlayerContext, setLockedPlayerContext] = useState<LockedPlayerContext | null>(null);
  const [showDebugOverlay, setShowDebugOverlay] = useState(false);

  // PHASE 3: Auto-level detection state (replaces manual skill level selector)
  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);
  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);

  // PHASE 4: Guidance animation state
  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);
  const [showGuidance, setShowGuidance] = useState(false);

  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline
  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);
  const [showGhost, setShowGhost] = useState(false);
  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);
  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);
  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);

  // V5: Compare Mode state
  const [showCompareMode, setShowCompareMode] = useState(false);
  const [compareMistake, setCompareMistake] = useState<MistakeEvent | null>(null);

  // V5: 3D Pose Sandbox state
  const [show3DSandbox, setShow3DSandbox] = useState(false);

  // TASK 2: Store original ghost data to switch back to when no mistake is selected
  const originalGhostDataRef = useRef<GhostRivalData | null>(null);

  // Video playback state
  const [videoUrl, setVideoUrl] = useState<string | null>(null);
  const [videoFile, setVideoFile] = useState<File | null>(null);
  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);
  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);
  const [issues, setIssues] = useState<DetectedIssue[]>([]);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  const [isPlaying, setIsPlaying] = useState(false);
  const [showSkeleton, setShowSkeleton] = useState(true);
  const [fps, setFps] = useState(30);

  // PHASE 2: Canvas overlay alignment state
  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);

  // Pose detection
  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);
  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);

  // PHASE 1: Timestamp tracking for monotonic enforcement
  const lastTimestampMsRef = useRef<number>(-1);
  const timestampBaseOffsetRef = useRef<number>(0);
  const isProcessingRef = useRef<boolean>(false);

  // FIX 1: Subject Lock for skeleton tracking persistence
  const subjectLockRef = useRef<SubjectLock>(createSubjectLock());
  const [showMotionPath, setShowMotionPath] = useState(false);
  const ghostPulseRef = useRef<number>(0);

  // TASK 1: User-initiated subject selection mode
  const [isSubjectSelectionMode, setIsSubjectSelectionMode] = useState(false);
  const [manuallyLockedSubject, setManuallyLockedSubject] = useState<number | null>(null);
  const lastDetectedPosesRef = useRef<PoseLandmark[][]>([]);

  // Refs
  const fileInputRef = useRef<HTMLInputElement>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const videoContainerRef = useRef<HTMLDivElement>(null);
  const processVideoRef = useRef<HTMLVideoElement | null>(null);
  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const animationRef = useRef<number | null>(null);

  // Initialize MediaPipe Pose Landmarker
  useEffect(() => {
    initializePoseLandmarker();
    return () => {
      cleanup();
    };
  }, []);

  // Load session if ID provided
  useEffect(() => {
    if (sessionId) {
      loadSession(sessionId);
    }
  }, [sessionId]);

  // PHASE 2: Update canvas size on video resize
  useEffect(() => {
    const updateVideoRect = () => {
      if (videoRef.current && videoContainerRef.current) {
        const video = videoRef.current;
        const container = videoContainerRef.current;

        // Calculate the actual rendered video rectangle (accounting for object-contain)
        const containerRect = container.getBoundingClientRect();
        const videoAspect = video.videoWidth / video.videoHeight;
        const containerAspect = containerRect.width / containerRect.height;

        let renderWidth, renderHeight, offsetX, offsetY;

        if (videoAspect > containerAspect) {
          // Video is wider - letterbox top/bottom
          renderWidth = containerRect.width;
          renderHeight = containerRect.width / videoAspect;
          offsetX = 0;
          offsetY = (containerRect.height - renderHeight) / 2;
        } else {
          // Video is taller - letterbox left/right
          renderHeight = containerRect.height;
          renderWidth = containerRect.height * videoAspect;
          offsetX = (containerRect.width - renderWidth) / 2;
          offsetY = 0;
        }

        setVideoRect({
          x: offsetX,
          y: offsetY,
          width: renderWidth,
          height: renderHeight,
          top: offsetY,
          left: offsetX,
          right: offsetX + renderWidth,
          bottom: offsetY + renderHeight,
          toJSON: () => ({})
        } as DOMRect);
      }
    };

    updateVideoRect();
    window.addEventListener('resize', updateVideoRect);

    return () => window.removeEventListener('resize', updateVideoRect);
  }, [videoUrl]);

  const initializePoseLandmarker = async () => {
    try {
      const vision = await import('@mediapipe/tasks-vision');
      const { PoseLandmarker, FilesetResolver } = vision;

      const filesetResolver = await FilesetResolver.forVisionTasks(
        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
      );

      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',
          delegate: 'GPU',
        },
        runningMode: 'VIDEO',
        numPoses: 4, // Support up to 4 players for doubles
        minPoseDetectionConfidence: 0.5,
        minPosePresenceConfidence: 0.5,
        minTrackingConfidence: 0.5,
      });

      setPoseLandmarkerReady(true);
    } catch (error) {
      console.error('Failed to load MediaPipe Pose:', error);
      // Continue without pose detection - will use fallback
    }
  };

  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking
  const recreatePoseLandmarker = async () => {
    if (poseLandmarkerRef.current) {
      poseLandmarkerRef.current.close();
    }
    lastTimestampMsRef.current = -1;
    timestampBaseOffsetRef.current = 0;
    await initializePoseLandmarker();
  };

  const cleanup = () => {
    if (pollIntervalRef.current) {
      clearInterval(pollIntervalRef.current);
    }
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
    }
    if (poseLandmarkerRef.current) {
      poseLandmarkerRef.current.close();
    }
  };

  // V5: Backend API call for YOLO+ByteTrack tracking
  const fetchBackendTracking = async (file: File): Promise<{
    tracking_data: TrackingFrame[] | null;
    detected_players: TrackSummary[];
    detected_match_format: 'singles' | 'doubles';
    fps: number;
    tracking_available: boolean;
  }> => {
    try {
      const formData = new FormData();
      formData.append('file', file);
      formData.append('user_id', 'guest'); // TODO: Get actual user ID

      const response = await fetch('http://localhost:8000/api/analyze', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        throw new Error(`Backend API error: ${response.status}`);
      }

      const data = await response.json();

      return {
        tracking_data: data.tracking_data || null,
        detected_players: data.detected_players || [],
        detected_match_format: data.detected_match_format || 'singles',
        fps: data.fps || 30,
        tracking_available: data.tracking_available || false,
      };
    } catch (error) {
      console.warn('[V5] Backend tracking not available, using browser-side detection:', error);
      return {
        tracking_data: null,
        detected_players: [],
        detected_match_format: 'singles',
        fps: 30,
        tracking_available: false,
      };
    }
  };

  // V5: Get filtered pose data for the selected track_id
  const getFilteredPoseDataForFrame = useCallback((frameIndex: number): PoseLandmark[] | null => {
    if (!backendTrackingData || selectedTrackIds.length === 0) {
      // Fallback to regular pose data if no backend tracking
      return poseData[frameIndex] || null;
    }

    const frame = backendTrackingData[frameIndex];
    if (!frame) return null;

    // Find the track matching the first selected track_id
    const selectedTrack = frame.tracks.find(t => t.track_id === selectedTrackIds[0]);
    if (!selectedTrack || !selectedTrack.landmarks) return null;

    // Convert backend landmarks format to PoseLandmark[]
    return selectedTrack.landmarks.map(lm => ({
      x: lm.x,
      y: lm.y,
      z: lm.z,
      visibility: lm.visibility,
    }));
  }, [backendTrackingData, selectedTrackIds, poseData]);

  // V5: Get all poses for current frame (for debug overlay)
  const getAllPosesForFrame = useCallback((frameIndex: number): Array<{
    track_id: number;
    landmarks: PoseLandmark[] | null;
    bbox: { x: number; y: number; w: number; h: number };
    isSelected: boolean;
  }> => {
    if (!backendTrackingData) return [];

    const frame = backendTrackingData[frameIndex];
    if (!frame) return [];

    return frame.tracks.map(track => ({
      track_id: track.track_id,
      landmarks: track.landmarks?.map(lm => ({
        x: lm.x,
        y: lm.y,
        z: lm.z,
        visibility: lm.visibility,
      })) || null,
      bbox: track.bbox,
      isSelected: selectedTrackIds.includes(track.track_id),
    }));
  }, [backendTrackingData, selectedTrackIds]);

  // V5: Lock player by track_id
  const lockPlayerByTrackId = useCallback((trackId: number) => {
    setSelectedTrackIds([trackId]);
    setLockedPlayerContext({
      trackId,
      lockTime: Date.now(),
      thumbnailUrl: backendTrackSummaries?.find(s => s.track_id === trackId)?.thumbnail_base64,
      side: backendTrackSummaries?.find(s => s.track_id === trackId)?.side,
    });

    // Recompute ghost/mistakes for new player
    if (backendTrackingData) {
      const filteredPoses: (PoseLandmark[] | null)[] = backendTrackingData.map(frame => {
        const track = frame.tracks.find(t => t.track_id === trackId);
        if (!track?.landmarks) return null;
        return track.landmarks.map(lm => ({
          x: lm.x,
          y: lm.y,
          z: lm.z,
          visibility: lm.visibility,
        }));
      });

      setPoseData(filteredPoses);

      // Recompute V4 features for the new player
      const mistakes = detectMistakes(filteredPoses, fps);
      setMistakeEvents(mistakes);

      const metricsHistory = filteredPoses.map(pose =>
        pose ? extractMetrics(pose) : null
      );
      const ghost = initializeGhostRival(filteredPoses, metricsHistory, fps);
      setGhostData(ghost);
      originalGhostDataRef.current = ghost;

      const skillResult = computeSkillScore(filteredPoses, metricsHistory, mistakes);
      setComputedSkill(skillResult);
    }
  }, [backendTrackingData, backendTrackSummaries, fps]);

  const loadSession = async (id: string) => {
    try {
      setAnalyzing(true);
      setAnalysisState('EXTRACTING_POSE');

      // Try new sessions table first
      const { data: sessionData, error: sessionError } = await supabase
        .from('sessions')
        .select('*')
        .eq('id', id)
        .single();

      if (sessionError) {
        // Try legacy table
        const { data: legacyData, error: legacyError } = await supabase
          .from('analysis_results')
          .select('*')
          .eq('id', id)
          .single();

        if (legacyError) throw legacyError;
        if (legacyData?.result_json) {
          setResult(legacyData.result_json);
          if (legacyData.result_json.video_url) {
            setVideoUrl(legacyData.result_json.video_url);
          }
        }
      } else if (sessionData) {
        // New session format
        setVideoUrl(sessionData.video_url);

        if (sessionData.pose_data) {
          setPoseData(sessionData.pose_data);
        }

        // Fetch issues
        const { data: issuesData } = await supabase
          .from('issues')
          .select('*')
          .eq('session_id', id);

        if (issuesData && issuesData.length > 0) {
          setIssues(issuesData.map((issue: any) => ({
            code: issue.code,
            title: issue.title,
            severity: issue.severity,
            description: issue.description,
            timestamps: issue.timestamps || [],
            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],
          })));
        }

        // Build result from session summary
        const summary = sessionData.summary || {};
        setResult({
          top_issues: issuesData?.map((i: any) => ({
            id: i.id,
            title: i.title,
            severity: i.severity,
            description: i.description,
            affected_metrics: [],
          })) || [],
          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({
            id: d.id,
            name: d.name,
            description: d.description,
            duration_minutes: d.durationMinutes,
            target_metrics: d.targetMetrics,
            instructions: d.steps,
          })) || [],
          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',
          strategy_summary: summary.feedback?.strategy_summary || '',
          training_plan: [],
        });
      }
      setAnalysisState('DONE');
    } catch (err) {
      console.error('Error loading session:', err);
      setError('Failed to load session');
      setAnalysisState('ERROR');
    } finally {
      setAnalyzing(false);
    }
  };

  // TASK 2: Update ghost data when a mistake is selected for context-aware ghost
  useEffect(() => {
    if (!poseData.length || !frameAnalyses.length) return;

    const metricsHistory = frameAnalyses.map(a => a.metrics);

    if (selectedMistake) {
      // Store original ghost data if not already stored
      if (!originalGhostDataRef.current && ghostData) {
        originalGhostDataRef.current = ghostData;
      }

      // Create context-aware ghost for the selected mistake type
      const contextGhost = createContextAwareGhost(
        poseData,
        metricsHistory,
        selectedMistake.type,
        10
      );

      if (contextGhost.poseSequence.length > 0) {
        setGhostData(contextGhost);
        // Auto-enable ghost when selecting a mistake to show correct form
        setShowGhost(true);
      }
    } else {
      // Restore original ghost data when no mistake is selected
      if (originalGhostDataRef.current) {
        setGhostData(originalGhostDataRef.current);
      }
    }
  }, [selectedMistake, poseData, frameAnalyses]);

  // PHASE 1 FIX: Process video with strictly monotonic timestamps
  // Uses base offset approach to handle seeks without recreating PoseLandmarker
  const processVideoWithPose = async (
    videoElement: HTMLVideoElement,
    selectedTracks: number[] = [0]
  ): Promise<FrameAnalysis[]> => {
    if (!poseLandmarkerRef.current) {
      console.warn('Pose landmarker not ready');
      return [];
    }

    // Prevent concurrent processing
    if (isProcessingRef.current) {
      console.warn('Already processing video, skipping');
      return [];
    }
    isProcessingRef.current = true;

    const analyses: FrameAnalysis[] = [];
    const videoDuration = videoElement.duration;
    const sampleRate = 10; // Process 10 frames per second
    const totalFrames = Math.floor(videoDuration * sampleRate);

    // PHASE 1: Reset timestamp tracking for fresh processing
    // Use base offset approach so timestamps always increase even if we restart
    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer
    let localLastTimestamp = timestampBaseOffsetRef.current;

    let validPoseFrames = 0;
    let lowConfidenceFrames = 0;
    let noPoseFrames = 0;

    setAnalyzeProgress(10); // Start at 10% after track detection

    for (let i = 0; i <= totalFrames; i++) {
      const timestamp = i / sampleRate;
      videoElement.currentTime = timestamp;

      // Wait for video to seek
      await new Promise<void>((resolve) => {
        const onSeeked = () => {
          videoElement.removeEventListener('seeked', onSeeked);
          resolve();
        };
        videoElement.addEventListener('seeked', onSeeked);
      });

      // Give the video a moment to render the frame
      await new Promise(resolve => setTimeout(resolve, 50));

      try {
        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp
        // Use base offset + local timestamp to guarantee monotonic increase
        const rawTimestampMs = Math.floor(timestamp * 1000);
        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;

        // Double-check monotonicity
        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);
        localLastTimestamp = safeTimestampMs;
        lastTimestampMsRef.current = safeTimestampMs;

        const results = poseLandmarkerRef.current.detectForVideo(
          videoElement,
          safeTimestampMs
        );

        let landmarks: PoseLandmark[] | null = null;
        let evaluation: EvaluationResult | null = null;
        let metrics: PoseMetrics | null = null;

        if (results.landmarks && results.landmarks.length > 0) {
          // FIX 1: Use Subject Lock to maintain consistent tracking
          // Convert MediaPipe results to our format
          const allPoses: PoseLandmark[][] = results.landmarks.map((poseLandmarks: any) =>
            poseLandmarks.map((lm: any) => ({
              x: lm.x,
              y: lm.y,
              z: lm.z,
              visibility: lm.visibility ?? 1.0,
            }))
          );

          // Find the locked subject pose (prevents jumping between people)
          const { poseIndex, updatedLock } = findLockedSubjectPose(
            allPoses,
            subjectLockRef.current,
            i
          );
          subjectLockRef.current = updatedLock;

          // Use locked pose or fall back to selected track
          const selectedPoseIdx = poseIndex >= 0 ? poseIndex :
            (selectedTracks[0] < results.landmarks.length ? selectedTracks[0] : 0);

          landmarks = allPoses[selectedPoseIdx];

          if (landmarks && landmarks.length > 0) {
            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;

            if (avgVisibility < 0.5) {
              lowConfidenceFrames++;
            } else {
              validPoseFrames++;
            }
            metrics = extractMetrics(landmarks);

            // Use intermediate level for initial processing (auto-level will adjust later)
            const bandedResult = evaluateWithBands(landmarks, 'intermediate');
            evaluation = {
              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',
              score: bandedResult.overall_score,
              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({
                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,
                value: 0,
                feedback: f,
              })) : [],
              passedRules: [],
              highlightJoints: bandedResult.highlight_joints,
              recommendedDrills: [],
            };
          }
        } else {
          noPoseFrames++;
        }

        analyses.push({
          timestamp,
          landmarks,
          evaluation,
          metrics,
        });
      } catch (err) {
        const errorMsg = err instanceof Error ? err.message : String(err);
        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {
          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);
          // PHASE 1 FIX: On timestamp error, bump the base offset significantly
          timestampBaseOffsetRef.current += 10000; // Add 10 seconds
          localLastTimestamp = timestampBaseOffsetRef.current;
        } else {
          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);
        }
        analyses.push({
          timestamp,
          landmarks: null,
          evaluation: null,
          metrics: null,
        });
      }

      // Update progress (10-70%)
      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));
    }

    // PHASE 1: Log pose detection statistics
    const totalProcessed = totalFrames + 1;
    const validRatio = validPoseFrames / totalProcessed;
    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);

    if (validRatio < 0.3) {
      console.warn('Low pose detection rate - video may have poor lighting or player not visible');
    }

    isProcessingRef.current = false;
    return analyses;
  };

  // Detect issues from frame analyses
  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {
    const issueMap: Map<string, {
      rule: any;
      timestamps: number[];
      count: number;
    }> = new Map();

    for (const frame of analyses) {
      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {
        for (const failed of frame.evaluation.failedRules) {
          const code = failed.rule.code;
          if (!issueMap.has(code)) {
            issueMap.set(code, {
              rule: failed.rule,
              timestamps: [],
              count: 0,
            });
          }
          const issue = issueMap.get(code)!;
          issue.timestamps.push(frame.timestamp);
          issue.count++;
        }
      }
    }

    // Convert to array and sort by count
    const issues: DetectedIssue[] = Array.from(issueMap.entries())
      .map(([code, data]) => ({
        code,
        title: data.rule.name,
        severity: data.rule.severity,
        description: data.rule.description,
        timestamps: data.timestamps,
        drill: DRILLS[data.rule.drillId],
      }))
      .sort((a, b) => b.timestamps.length - a.timestamps.length)
      .slice(0, 5); // Top 5 issues

    return issues;
  };

  // PHASE 3: Auto-detect skill level using Gemini
  const detectSkillLevelWithGemini = async (
    analyses: FrameAnalysis[],
    detectedIssues: DetectedIssue[]
  ): Promise<AutoLevelResult> => {
    setAnalysisState('GEMINI_SCORING');
    setAnalyzeProgress(75);

    try {
      // Extract features for Gemini analysis
      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);

      if (validAnalyses.length < 5) {
        // Fallback if not enough data
        return {
          level: 'Intermediate',
          confidence: 0.5,
          rationaleBullets: ['Insufficient pose data for accurate assessment'],
        };
      }

      // Calculate aggregate metrics
      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;
      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;
      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;
      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;

      // Calculate consistency (standard deviation proxy)
      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;
      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;

      // Calculate movement intensity (velocity proxy from position changes)
      let totalMovement = 0;
      for (let i = 1; i < validAnalyses.length; i++) {
        const prev = validAnalyses[i - 1].landmarks;
        const curr = validAnalyses[i].landmarks;
        if (prev && curr) {
          const hipMovement = Math.sqrt(
            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +
            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)
          );
          totalMovement += hipMovement;
        }
      }
      const avgMovement = totalMovement / (validAnalyses.length - 1);

      // Issue frequency
      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;

      // Call Gemini API for skill level detection
      const response = await fetch('/api/analysis/auto-level', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          metrics: {
            avgElbowAngle,
            avgKneeAngle,
            avgStanceWidth,
            avgRotation,
            elbowConsistency: Math.sqrt(elbowVariance),
            kneeConsistency: Math.sqrt(kneeVariance),
            movementIntensity: avgMovement,
            issueFrequency,
            totalFrames: validAnalyses.length,
            issueCount: detectedIssues.length,
          },
          issues: detectedIssues.map(i => ({
            code: i.code,
            title: i.title,
            frequency: i.timestamps.length / validAnalyses.length,
          })),
        }),
      });

      if (response.ok) {
        const result = await response.json();
        setAnalyzeProgress(90);
        return {
          level: result.level || 'Intermediate',
          confidence: result.confidence || 0.7,
          rationaleBullets: result.rationaleBullets || [],
          guidanceKeyframes: result.guidanceKeyframes,
        };
      }
    } catch (err) {
      console.error('Gemini auto-level detection failed:', err);
    }

    // Fallback rule-based detection
    setAnalyzeProgress(90);
    return fallbackSkillLevelDetection(analyses, detectedIssues);
  };

  // Fallback rule-based skill level detection
  const fallbackSkillLevelDetection = (
    analyses: FrameAnalysis[],
    detectedIssues: DetectedIssue[]
  ): AutoLevelResult => {
    const validAnalyses = analyses.filter(a => a.evaluation);
    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;
    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;
    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;

    if (passRatio >= 0.7 && highSeverityIssues === 0) {
      return {
        level: 'Advanced',
        confidence: 0.75,
        rationaleBullets: [
          'Consistent form across frames',
          'No major technique issues detected',
          'Good body mechanics observed',
        ],
      };
    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {
      return {
        level: 'Intermediate',
        confidence: 0.7,
        rationaleBullets: [
          'Moderate consistency in technique',
          `${highSeverityIssues} area(s) need focused improvement`,
          'Foundations are solid with room to refine',
        ],
      };
    } else {
      return {
        level: 'Beginner',
        confidence: 0.8,
        rationaleBullets: [
          'Multiple technique areas need development',
          'Focus on fundamentals before advancing',
          'Regular practice will show rapid improvement',
        ],
      };
    }
  };

  // PHASE 4: Generate guidance keyframes from analysis
  const generateGuidanceKeyframes = (
    analyses: FrameAnalysis[],
    detectedIssues: DetectedIssue[]
  ): GuidanceKeyframe[] => {
    const keyframes: GuidanceKeyframe[] = [];
    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);

    if (validAnalyses.length < 3) return keyframes;

    // Find key moments: Setup, Contact/Action, Recovery
    // Setup: Early stable frame
    const setupIdx = Math.floor(validAnalyses.length * 0.1);
    const contactIdx = Math.floor(validAnalyses.length * 0.5);
    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);

    const setupFrame = validAnalyses[setupIdx];
    const contactFrame = validAnalyses[contactIdx];
    const recoveryFrame = validAnalyses[recoveryIdx];

    // Determine primary issue for corrections
    const primaryIssue = detectedIssues[0];
    let correction = '';
    if (primaryIssue) {
      if (primaryIssue.code.includes('ELBOW')) {
        correction = 'Extend elbow more at contact';
      } else if (primaryIssue.code.includes('KNEE')) {
        correction = 'Maintain athletic knee bend';
      } else if (primaryIssue.code.includes('STANCE')) {
        correction = 'Widen stance for stability';
      } else if (primaryIssue.code.includes('ROTATION')) {
        correction = 'Rotate hips before shoulders';
      }
    }

    keyframes.push({
      name: 'Setup',
      description: 'Preparation phase',
      landmarks: setupFrame?.landmarks || null,
      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',
    });

    keyframes.push({
      name: 'Contact',
      description: 'Point of contact',
      landmarks: contactFrame?.landmarks || null,
      correction: correction || undefined,
    });

    keyframes.push({
      name: 'Recovery',
      description: 'Return to ready',
      landmarks: recoveryFrame?.landmarks || null,
      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',
    });

    return keyframes;
  };

  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file) return;

    if (!file.type.startsWith('video/')) {
      setError('Please select a video file');
      return;
    }

    if (file.size > 100 * 1024 * 1024) {
      setError('File size must be less than 100MB. Please compress your video before uploading.');
      return;
    }

    setError(null);
    setVideoFile(file);
    setResult(null);
    setIssues([]);
    setPoseData([]);
    setFrameAnalyses([]);
    setAutoLevelResult(null);
    setGuidanceKeyframes([]);
    // V4 state reset
    setGhostData(null);
    setShowGhost(false);
    setComputedSkill(null);
    setMistakeEvents([]);
    setSelectedMistake(null);

    // Create object URL for video preview
    const objectUrl = URL.createObjectURL(file);
    setVideoUrl(objectUrl);

    // Start analysis
    await analyzeVideo(file, objectUrl);
  };

  // PHASE 1 FIX: Detect player tracks with monotonic timestamps
  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {
    if (!poseLandmarkerRef.current) return [];

    const tracks: Map<number, PlayerTrackData> = new Map();
    const sampleFrames = 5;
    const duration = videoElement.duration;

    // Use separate timestamp tracking for track detection
    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;

    for (let i = 0; i < sampleFrames; i++) {
      const timestamp = (i / sampleFrames) * duration;
      videoElement.currentTime = timestamp;

      await new Promise<void>((resolve) => {
        const onSeeked = () => {
          videoElement.removeEventListener('seeked', onSeeked);
          resolve();
        };
        videoElement.addEventListener('seeked', onSeeked);
      });

      await new Promise(resolve => setTimeout(resolve, 50));

      try {
        // PHASE 1 FIX: Ensure monotonic timestamp
        trackDetectionTimestamp += 100; // 100ms between samples
        const safeTimestamp = trackDetectionTimestamp;
        lastTimestampMsRef.current = safeTimestamp;

        const results = poseLandmarkerRef.current.detectForVideo(
          videoElement,
          safeTimestamp
        );

        if (results.landmarks && results.landmarks.length > 0) {
          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {
            const landmarks = results.landmarks[poseIdx];
            const bbox = calculateBoundingBox(landmarks);

            if (!tracks.has(poseIdx)) {
              tracks.set(poseIdx, {
                track_id: poseIdx,
                bbox_samples: [],
                is_selected: false,
                confidence_avg: 0,
                frame_count: 0,
                side: bbox.y < 0.5 ? 'far' : 'near',
              });
            }

            const track = tracks.get(poseIdx)!;
            track.bbox_samples.push({
              frame: i,
              x: bbox.x,
              y: bbox.y,
              w: bbox.w,
              h: bbox.h,
              confidence: landmarks[0].visibility || 0.5,
            });
            track.frame_count++;
            track.confidence_avg =
              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /
              track.frame_count;
          }
        }
      } catch (err) {
        console.warn('Error detecting poses in frame:', err);
      }
    }

    // Generate thumbnails
    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);

    if (tracksArray.length > 0) {
      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;
      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;
      videoElement.currentTime = Math.max(0.5, bestTimestamp);

      await new Promise<void>((resolve) => {
        const onSeeked = () => {
          videoElement.removeEventListener('seeked', onSeeked);
          resolve();
        };
        videoElement.addEventListener('seeked', onSeeked);
      });
      await new Promise(resolve => setTimeout(resolve, 100));

      for (const track of tracksArray) {
        if (track.bbox_samples.length > 0) {
          const bestBbox = track.bbox_samples.reduce((best, current) =>
            (current.confidence || 0) > (best.confidence || 0) ? current : best
          );

          const thumbnail = generateThumbnail(videoElement, {
            x: bestBbox.x,
            y: bestBbox.y,
            w: bestBbox.w,
            h: bestBbox.h,
          });

          if (thumbnail) {
            track.thumbnail_url = thumbnail;
          }
        }
      }
    }

    return tracksArray;
  };

  // Calculate bounding box from landmarks
  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {
    let minX = 1, minY = 1, maxX = 0, maxY = 0;
    for (const lm of landmarks) {
      if (lm.visibility > 0.5) {
        minX = Math.min(minX, lm.x);
        minY = Math.min(minY, lm.y);
        maxX = Math.max(maxX, lm.x);
        maxY = Math.max(maxY, lm.y);
      }
    }
    return {
      x: minX,
      y: minY,
      w: maxX - minX,
      h: maxY - minY,
    };
  };

  // Generate thumbnail from video at specific bounding box
  const generateThumbnail = (
    video: HTMLVideoElement,
    bbox: { x: number; y: number; w: number; h: number },
    padding: number = 0.1
  ): string | null => {
    try {
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      if (!ctx) return null;

      const vw = video.videoWidth;
      const vh = video.videoHeight;

      const padX = bbox.w * padding;
      const padY = bbox.h * padding;

      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));
      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));
      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));
      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));

      if (cropW <= 0 || cropH <= 0) return null;

      const maxSize = 150;
      const scale = Math.min(maxSize / cropW, maxSize / cropH);
      canvas.width = Math.floor(cropW * scale);
      canvas.height = Math.floor(cropH * scale);

      ctx.drawImage(
        video,
        cropX, cropY, cropW, cropH,
        0, 0, canvas.width, canvas.height
      );

      return canvas.toDataURL('image/jpeg', 0.8);
    } catch (err) {
      console.warn('Error generating thumbnail:', err);
      return null;
    }
  };

  // Handle player selection confirmation
  const handlePlayerSelectionConfirm = (
    selectedTracks: number[],
    format: 'singles' | 'doubles',
    event: string
  ) => {
    setSelectedTrackIds(selectedTracks);
    setMatchFormat(format);
    setEventType(event);
    setShowPlayerSelection(false);

    if (processVideoRef.current && videoFile) {
      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);
    }
  };

  // Continue analysis after player selection
  const continueAnalysisWithSelection = async (
    processVideo: HTMLVideoElement,
    selectedTracks: number[]
  ) => {
    setAnalysisState('EXTRACTING_POSE');
    const analyses = await processVideoWithPose(processVideo, selectedTracks);
    setFrameAnalyses(analyses);

    const poseArray = analyses.map(a => a.landmarks);
    setPoseData(poseArray);

    const detectedIssues = detectIssuesFromAnalyses(analyses);
    setIssues(detectedIssues);

    // V4 FEATURE: Detect mistake events for timeline
    const mistakes = detectMistakes(poseArray, 10);
    setMistakeEvents(mistakes);

    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)
    const metricsHistory = analyses.map(a => a.metrics);
    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);
    setComputedSkill(skillResult);

    // V4 FEATURE: Initialize ghost rival data
    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);
    setGhostData(ghost);
    // TASK 2: Store original ghost data for restoration
    originalGhostDataRef.current = ghost;

    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)
    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);
    // Override level with computed score
    const finalLevel = {
      ...levelResult,
      level: skillResult.levelLabel,
      confidence: skillResult.confidencePercent / 100,
    };
    setAutoLevelResult(finalLevel);

    // PHASE 4: Generate guidance keyframes
    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);
    setGuidanceKeyframes(guidance);

    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;
    const totalFrames = analyses.filter(a => a.evaluation).length;

    setResult({
      top_issues: detectedIssues.map(issue => ({
        id: issue.code,
        title: issue.title,
        severity: issue.severity,
        description: issue.description || '',
        affected_metrics: [],
      })),
      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({
        id: d.id,
        name: d.name,
        description: d.description,
        duration_minutes: d.durationMinutes,
        target_metrics: d.targetMetrics,
        instructions: d.steps,
      })),
      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,
      strategy_summary: passedFrames > totalFrames * 0.7
        ? 'Your form is generally good. Focus on the specific issues identified.'
        : 'Work on maintaining consistent form throughout your movements.',
      training_plan: [],
    });

    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);
    if (!saveResult.success) {
      setError(saveResult.error || 'Failed to save analysis');
    }
    setAnalyzing(false);
    setAnalysisState('DONE');
    setAnalyzeProgress(100);
  };

  const analyzeVideo = async (file: File, videoObjectUrl: string) => {
    setAnalyzing(true);
    setAnalyzeProgress(0);
    setAnalysisState('DETECTING_PLAYERS');

    try {
      const processVideo = document.createElement('video');
      processVideo.src = videoObjectUrl;
      processVideo.muted = true;
      processVideo.playsInline = true;
      processVideoRef.current = processVideo;

      await new Promise<void>((resolve, reject) => {
        processVideo.onloadedmetadata = () => {
          setDuration(processVideo.duration);
          setFps(30);
          resolve();
        };
        processVideo.onerror = () => reject(new Error('Failed to load video'));
      });

      await new Promise<void>((resolve) => {
        if (processVideo.readyState >= 2) {
          resolve();
        } else {
          processVideo.oncanplay = () => resolve();
        }
      });

      // V5: Try backend YOLO+ByteTrack tracking first
      setAnalyzeProgress(5);
      let tracks: PlayerTrackData[] = [];
      let backendAvailable = false;
      let backendTrackingDataLocal: TrackingFrame[] | null = null;

      try {
        console.log('[V5] Attempting backend YOLO+ByteTrack tracking...');
        const backendResult = await fetchBackendTracking(file);

        if (backendResult.tracking_available && backendResult.tracking_data) {
          console.log('[V5] Backend tracking available:', {
            frames: backendResult.tracking_data.length,
            players: backendResult.detected_players.length,
            matchFormat: backendResult.detected_match_format,
          });

          backendAvailable = true;
          backendTrackingDataLocal = backendResult.tracking_data;
          setUseBackendTracking(true);
          setBackendTrackingData(backendResult.tracking_data);
          setBackendTrackSummaries(backendResult.detected_players);
          setFps(backendResult.fps);

          // Use backend-detected match format
          setDetectedMatchFormat(backendResult.detected_match_format);

          // Convert backend track summaries to PlayerTrackData format
          tracks = backendResult.detected_players.map((s: TrackSummary) => ({
            track_id: s.track_id,
            bbox_samples: [],
            is_selected: false,
            confidence_avg: s.avg_confidence,
            frame_count: s.frame_count,
            side: s.side,
            thumbnail_url: s.thumbnail_base64 ? `data:image/jpeg;base64,${s.thumbnail_base64}` : undefined,
          }));
        }
      } catch (err) {
        console.warn('[V5] Backend tracking failed, using browser-side detection:', err);
      }

      // Fallback to browser-side detection if backend not available
      if (!backendAvailable) {
        console.log('[V5] Using browser-side MediaPipe detection');
        setUseBackendTracking(false);
        tracks = await detectPlayerTracks(processVideo);
      }

      setDetectedTracks(tracks);

      // Only compute match format from track count if not using backend
      // (backend already set the format above)
      if (!backendAvailable) {
        const uniquePlayers = tracks.length;
        const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';
        setDetectedMatchFormat(detectedFormat);
      }

      if (tracks.length > 1) {
        setShowPlayerSelection(true);
        return;
      }

      if (tracks.length === 1) {
        setSelectedTrackIds([tracks[0].track_id]);

        // V5: If using backend tracking, set the locked player context
        if (backendAvailable) {
          setLockedPlayerContext({
            trackId: tracks[0].track_id,
            lockTime: Date.now(),
            thumbnailUrl: tracks[0].thumbnail_url,
            side: tracks[0].side,
          });
        }
      }

      // Process video with pose detection
      let analyses: FrameAnalysis[] = [];
      let poseArray: (PoseLandmark[] | null)[] = [];

      // V5: If backend tracking is available, use backend pose data
      if (backendAvailable && backendTrackingDataLocal) {
        setAnalysisState('EXTRACTING_POSE');
        console.log('[V5] Using backend tracking data for pose analysis');

        const targetTrackId = selectedTrackIds[0] || tracks[0]?.track_id || 0;
        console.log('[V5] Target track ID:', targetTrackId);

        // Extract filtered poses from backend tracking data
        let validPoseCount = 0;
        let nullPoseCount = 0;

        poseArray = backendTrackingDataLocal.map((frame: TrackingFrame) => {
          const track = frame.tracks.find(t => t.track_id === targetTrackId);
          if (!track?.landmarks || track.landmarks.length === 0) {
            nullPoseCount++;
            return null;
          }
          validPoseCount++;
          return track.landmarks.map(lm => ({
            x: lm.x,
            y: lm.y,
            z: lm.z,
            visibility: lm.visibility ?? 1.0,  // Default visibility to 1.0 if missing
          }));
        });

        console.log(`[V5] Pose extraction: ${validPoseCount} valid, ${nullPoseCount} null (total: ${poseArray.length})`);

        // If too many null poses, warn and check if there's a better track
        if (validPoseCount < poseArray.length * 0.1) {
          console.warn('[V5] Very few valid poses detected! Checking other tracks...');
          // Try to find a track with more poses
          const trackPoseCounts: Record<number, number> = {};
          for (const frame of backendTrackingDataLocal) {
            for (const track of frame.tracks) {
              if (track.landmarks && track.landmarks.length > 0) {
                trackPoseCounts[track.track_id] = (trackPoseCounts[track.track_id] || 0) + 1;
              }
            }
          }
          console.log('[V5] Pose counts per track:', trackPoseCounts);
        }

        setPoseData(poseArray);

        // Build analyses from backend pose data
        analyses = poseArray.map((landmarks, idx) => {
          const metrics = landmarks ? extractMetrics(landmarks) : null;
          const evaluation = landmarks ? evaluateForm(landmarks, 'default') : null;

          return {
            timestamp: idx / fps,
            landmarks,
            evaluation,
            metrics,
          };
        });
        setFrameAnalyses(analyses);

      } else if (poseLandmarkerReady && poseLandmarkerRef.current) {
        // Fallback: Use browser-side MediaPipe
        setAnalysisState('EXTRACTING_POSE');
        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);
        setFrameAnalyses(analyses);
        poseArray = analyses.map(a => a.landmarks);
        setPoseData(poseArray);
      }

      if (poseArray.length > 0) {
        const detectedIssues = detectIssuesFromAnalyses(analyses);
        setIssues(detectedIssues);

        // V4 FEATURE: Detect mistake events for timeline
        const mistakes = detectMistakes(poseArray, fps);
        setMistakeEvents(mistakes);

        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)
        const metricsHistory = analyses.map(a => a.metrics);
        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);
        setComputedSkill(skillResult);

        // V4 FEATURE: Initialize ghost rival data
        const ghost = initializeGhostRival(poseArray, metricsHistory, fps);
        setGhostData(ghost);
        // TASK 2: Store original ghost data for restoration
        originalGhostDataRef.current = ghost;

        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)
        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);
        // Override level with computed score
        const finalLevel = {
          ...levelResult,
          level: skillResult.levelLabel,
          confidence: skillResult.confidencePercent / 100,
        };
        setAutoLevelResult(finalLevel);

        // PHASE 4: Generate guidance keyframes
        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);
        setGuidanceKeyframes(guidance);

        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;
        const totalFrames = analyses.filter(a => a.evaluation).length;

        setResult({
          top_issues: detectedIssues.map(issue => ({
            id: issue.code,
            title: issue.title,
            severity: issue.severity,
            description: issue.description || '',
            affected_metrics: [],
          })),
          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({
            id: d.id,
            name: d.name,
            description: d.description,
            duration_minutes: d.durationMinutes,
            target_metrics: d.targetMetrics,
            instructions: d.steps,
          })),
          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,
          strategy_summary: passedFrames > totalFrames * 0.7
            ? 'Your form is generally good. Focus on the specific issues identified.'
            : 'Work on maintaining consistent form throughout your movements.',
          training_plan: [],
        });

        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);
        if (!saveResult.success) {
          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');
        }
        setAnalysisState('DONE');
      } else {
        setError('Pose detection not available. Using demo mode.');
        setAnalysisState('ERROR');

        const demoIssues: DetectedIssue[] = [
          {
            code: 'ELBOW_ANGLE_OVERHEAD',
            title: 'Elbow Extension (Overhead)',
            severity: 'high',
            description: 'Elbow should be nearly straight at contact point',
            timestamps: [1.2, 3.5, 7.8],
            drill: DRILLS['elbow-extension'],
          },
          {
            code: 'KNEE_BEND',
            title: 'Knee Bend',
            severity: 'medium',
            description: 'Bend knees more for power',
            timestamps: [2.1, 5.3],
            drill: DRILLS['lunge-practice'],
          },
        ];
        setIssues(demoIssues);
        setAutoLevelResult({
          level: 'Intermediate',
          confidence: 0.5,
          rationaleBullets: ['Demo mode - upload video for real analysis'],
        });
        setResult({
          top_issues: demoIssues.map(i => ({
            id: i.code,
            title: i.title,
            severity: i.severity,
            description: i.description || '',
            affected_metrics: [],
          })),
          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({
            id: d!.id,
            name: d!.name,
            description: d!.description,
            duration_minutes: d!.durationMinutes,
            target_metrics: d!.targetMetrics,
            instructions: d!.steps,
          })),
          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',
          strategy_summary: '',
          training_plan: [],
        });
      }

    } catch (err) {
      console.error('Analysis error:', err);
      setError('Failed to analyze video. Please try again.');
      setAnalysisState('ERROR');
    } finally {
      setAnalyzing(false);
      setAnalyzeProgress(100);
    }
  };

  const saveAnalysisToDatabase = async (
    file: File,
    analyses: FrameAnalysis[],
    detectedIssues: DetectedIssue[],
    avgScore: number,
    levelResult?: AutoLevelResult,
    mistakeEventsData?: MistakeEvent[],
    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }
  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {
    try {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) {
        return { success: false, error: 'Not authenticated' };
      }

      let videoPath: string | null = null;
      let publicVideoUrl = '';

      try {
        videoPath = await uploadVideo(file, user.id, (progress) => {
          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));
        });

        if (!videoPath) {
          throw new Error('Upload returned empty path');
        }

        publicVideoUrl = getVideoUrl(videoPath);
        console.log('Video uploaded successfully:', videoPath);

      } catch (uploadError) {
        console.error('Video upload failed:', uploadError);
        const errorMessage = uploadError instanceof Error
          ? uploadError.message
          : 'Failed to upload video. Please try again.';
        setError(errorMessage);
        return { success: false, error: errorMessage };
      }

      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;
      const totalFrames = analyses.filter(a => a.evaluation).length;

      const { data: session, error: sessionError } = await supabase
        .from('sessions')
        .insert({
          user_id: user.id,
          type: 'analytics',
          video_path: videoPath,
          video_url: publicVideoUrl,
          filename: file.name,
          frame_count: analyses.length,
          overall_score: Math.round(avgScore),
          pose_data: analyses.map(a => a.landmarks),
          status: 'ready',
          match_format: matchFormat,
          event_type: eventType || null,
          selected_tracks: selectedTrackIds,
          skill_level: levelResult?.level.toLowerCase() || 'intermediate',
          rules_version: 'v1',
          // V4 FEATURES: Store computed skill metrics
          skill_score: avgScore,
          skill_confidence: levelResult?.confidence || 0.5,
          best_rep_window: bestRepWindowData || null,
          summary: {
            total_frames: totalFrames,
            green_frames: passedFrames,
            red_frames: totalFrames - passedFrames,
            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,
            average_score: avgScore,
            duration_seconds: duration,
            auto_level: levelResult,
          },
        })
        .select()
        .single();

      if (sessionError) {
        console.error('Session save error:', sessionError);
        return { success: false, error: 'Failed to save session data' };
      }

      if (session && detectedIssues.length > 0) {
        const issueInserts = detectedIssues.map(issue => ({
          session_id: session.id,
          code: issue.code,
          title: issue.title,
          severity: issue.severity,
          description: issue.description,
          timestamps: issue.timestamps,
          drill: issue.drill,
        }));

        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);
        if (issuesError) {
          console.warn('Issues save warning:', issuesError);
        }
      }

      // V4 FEATURE: Save mistake events for timeline
      if (session && mistakeEventsData && mistakeEventsData.length > 0) {
        const mistakeInserts = mistakeEventsData.map(mistake => ({
          session_id: session.id,
          type: mistake.type,
          start_time_sec: mistake.startTimeSec,
          end_time_sec: mistake.endTimeSec,
          severity: mistake.severity,
          confidence: mistake.confidence,
          joints: mistake.joints,
          summary_title: mistake.summaryTitle,
        }));

        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);
        if (mistakeError) {
          console.warn('Mistake events save warning:', mistakeError);
        }
      }

      setAnalyzeProgress(100);
      return { success: true, sessionId: session.id };

    } catch (err) {
      console.error('Error saving to database:', err);
      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';
      return { success: false, error: errorMessage };
    }
  };

  // PHASE 2 FIX: Video frame rendering with proper canvas alignment
  const renderFrame = useCallback(() => {
    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)
    const container = videoContainerRef.current;
    const containerRect = container.getBoundingClientRect();

    if (video.videoWidth === 0 || video.videoHeight === 0) return;

    const videoAspect = video.videoWidth / video.videoHeight;
    const containerAspect = containerRect.width / containerRect.height;

    let renderWidth, renderHeight, offsetX, offsetY;

    if (videoAspect > containerAspect) {
      // Video is wider - letterbox top/bottom
      renderWidth = containerRect.width;
      renderHeight = containerRect.width / videoAspect;
      offsetX = 0;
      offsetY = (containerRect.height - renderHeight) / 2;
    } else {
      // Video is taller - letterbox left/right
      renderHeight = containerRect.height;
      renderWidth = containerRect.height * videoAspect;
      offsetX = (containerRect.width - renderWidth) / 2;
      offsetY = 0;
    }

    // Set canvas to match container size
    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {
      canvas.width = containerRect.width;
      canvas.height = containerRect.height;
    }

    // Clear canvas
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    if (!showSkeleton) return;

    // Find the closest frame analysis
    let closestFrame: FrameAnalysis | null = null;
    let minDiff = Infinity;

    for (const frame of frameAnalyses) {
      const diff = Math.abs(frame.timestamp - video.currentTime);
      if (diff < minDiff) {
        minDiff = diff;
        closestFrame = frame;
      }
    }

    // Also check raw poseData array (for loaded sessions)
    if (!closestFrame && poseData.length > 0) {
      const frameIndex = Math.floor(video.currentTime * 10);
      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];
      if (landmarks) {
        closestFrame = {
          timestamp: video.currentTime,
          landmarks,
          evaluation: evaluateForm(landmarks, 'general'),
          metrics: extractMetrics(landmarks),
        };
      }
    }

    if (closestFrame?.landmarks) {
      // Get skill level from auto-detection or default to intermediate
      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';
      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);
      setCurrentBandedScore(bandedResult);

      // FIX 2: Enhanced skeleton rendering with better visuals
      const renderOptions: RenderOptions = {
        offsetX,
        offsetY,
        renderWidth,
        renderHeight,
      };

      // TASK 1: Store current landmarks for click detection
      lastDetectedPosesRef.current = [closestFrame.landmarks];

      // Determine form quality for color coding
      const formQuality: 'excellent' | 'good' | 'needsWork' | 'poor' =
        bandedResult.overall_band === 'green' ? 'excellent' :
        bandedResult.overall_band === 'yellow' ? 'good' :
        bandedResult.overall_score > 40 ? 'needsWork' : 'poor';

      // Draw the user's skeleton with enhanced styling
      drawUserSkeleton(ctx, closestFrame.landmarks, formQuality, renderOptions);

      // TASK 1: Draw selection indicator if in selection mode or subject is locked
      const isLocked = manuallyLockedSubject !== null;
      if (isSubjectSelectionMode || isLocked) {
        drawSelectionIndicator(
          ctx,
          closestFrame.landmarks,
          renderOptions,
          isLocked,
          isSubjectSelectionMode
        );
      }

      // V5 REFACTOR: Ghost overlay REMOVED from main canvas
      // Ghost visualization has been moved to Compare Mode in the Detected Issues panel
      // See CompareMode component for side-by-side User vs Target pose comparison
      // The ghostData is still computed and available for use in Compare Mode

      // FIX 4: Draw motion path if enabled (shows racket trajectory)
      if (showMotionPath && poseData.length > 10) {
        const frameIndex = Math.floor(video.currentTime * 10);
        const startFrame = Math.max(0, frameIndex - 15);
        const endFrame = Math.min(poseData.length - 1, frameIndex);
        const trajectoryPoints = extractRacketTrajectory(poseData, startFrame, endFrame);

        if (trajectoryPoints.length > 2) {
          drawMotionPath(ctx, trajectoryPoints, renderOptions);
        }
      }

      // V5: Debug overlay for tracking visualization
      if (showDebugOverlay && backendTrackingData) {
        const currentFrameIdx = Math.floor(video.currentTime * fps);
        const frame = backendTrackingData[currentFrameIdx];

        if (frame) {
          frame.tracks.forEach((track: any) => {
            const isSelected = selectedTrackIds.includes(track.track_id);
            const bbox = track.bbox;

            // Draw bounding box
            ctx.strokeStyle = isSelected ? '#00ff00' : '#ff6b6b';
            ctx.lineWidth = isSelected ? 3 : 2;
            ctx.setLineDash(isSelected ? [] : [5, 5]);
            ctx.strokeRect(
              renderOptions.offsetX + bbox.x * renderOptions.renderWidth,
              renderOptions.offsetY + bbox.y * renderOptions.renderHeight,
              bbox.w * renderOptions.renderWidth,
              bbox.h * renderOptions.renderHeight
            );
            ctx.setLineDash([]);

            // Draw track ID label
            const labelX = renderOptions.offsetX + bbox.x * renderOptions.renderWidth + 4;
            const labelY = renderOptions.offsetY + bbox.y * renderOptions.renderHeight + 16;

            ctx.fillStyle = isSelected ? 'rgba(0, 255, 0, 0.8)' : 'rgba(255, 107, 107, 0.8)';
            ctx.fillRect(labelX - 2, labelY - 12, 50, 16);

            ctx.fillStyle = '#000000';
            ctx.font = 'bold 11px monospace';
            ctx.fillText(`ID: ${track.track_id}`, labelX, labelY);

            // Draw confidence
            if (track.confidence) {
              ctx.fillStyle = '#ffffff';
              ctx.font = '10px monospace';
              ctx.fillText(`${Math.round(track.confidence * 100)}%`, labelX, labelY + 12);
            }
          });

          // Draw frame info overlay
          ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
          ctx.fillRect(10, 10, 150, 50);
          ctx.fillStyle = '#00ff00';
          ctx.font = 'bold 12px monospace';
          ctx.fillText(`Frame: ${currentFrameIdx}`, 15, 28);
          ctx.fillText(`Tracks: ${frame.tracks.length}`, 15, 44);
          ctx.fillText(`Selected: ${selectedTrackIds.join(', ') || 'None'}`, 15, 58);
        }
      }
    }

    if (!video.paused) {
      animationRef.current = requestAnimationFrame(renderFrame);
    }
  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData, showMotionPath, isSubjectSelectionMode, manuallyLockedSubject, showDebugOverlay, backendTrackingData, selectedTrackIds, fps]);

  // Trigger skeleton render when poseData is loaded
  useEffect(() => {
    if (poseData.length > 0 && videoRef.current) {
      const tryRender = () => {
        if (videoRef.current && videoRef.current.readyState >= 2) {
          renderFrame();
        } else {
          setTimeout(tryRender, 100);
        }
      };
      tryRender();
    }
  }, [poseData, renderFrame]);

  // Handle video time updates
  const handleTimeUpdate = useCallback(() => {
    if (videoRef.current) {
      setCurrentTime(videoRef.current.currentTime);
      renderFrame();
    }
  }, [renderFrame]);

  // Handle video play/pause
  const togglePlayPause = useCallback(() => {
    if (videoRef.current) {
      if (videoRef.current.paused) {
        videoRef.current.play();
        setIsPlaying(true);
        animationRef.current = requestAnimationFrame(renderFrame);
      } else {
        videoRef.current.pause();
        setIsPlaying(false);
        if (animationRef.current) {
          cancelAnimationFrame(animationRef.current);
        }
      }
    }
  }, [renderFrame]);

  // Jump to timestamp
  const jumpToTimestamp = useCallback((timestamp: number) => {
    if (videoRef.current) {
      videoRef.current.currentTime = timestamp;
      videoRef.current.pause();
      setIsPlaying(false);
      setCurrentTime(timestamp);
      setTimeout(renderFrame, 50);
    }
  }, [renderFrame]);

  // Find next mistake
  const goToNextMistake = useCallback(() => {
    const allTimestamps = issues
      .flatMap((i) => i.timestamps || [])
      .sort((a, b) => a - b);

    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);
    if (nextTimestamp !== undefined) {
      jumpToTimestamp(nextTimestamp);
    } else if (allTimestamps.length > 0) {
      jumpToTimestamp(allTimestamps[0]);
    }
  }, [issues, currentTime, jumpToTimestamp]);

  // Handle video metadata loaded
  const handleLoadedMetadata = useCallback(() => {
    if (videoRef.current) {
      setDuration(videoRef.current.duration);
      setTimeout(renderFrame, 100);
    }
  }, [renderFrame]);

  const getSeverityColor = (severity: string) => {
    switch (severity) {
      case 'high':
        return 'bg-red-50 border-red-200 text-red-800';
      case 'medium':
        return 'bg-yellow-50 border-yellow-200 text-yellow-800';
      case 'low':
        return 'bg-green-50 border-green-200 text-green-800';
      default:
        return 'bg-gray-50 border-gray-200 text-gray-800';
    }
  };

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  // TASK 1: Handle canvas click for subject selection
  const handleCanvasClick = useCallback((e: React.MouseEvent<HTMLCanvasElement>) => {
    if (!isSubjectSelectionMode || !canvasRef.current || !videoContainerRef.current) return;

    const canvas = canvasRef.current;
    const rect = canvas.getBoundingClientRect();
    const container = videoContainerRef.current;
    const containerRect = container.getBoundingClientRect();

    // Get click position relative to canvas
    const clickX = e.clientX - rect.left;
    const clickY = e.clientY - rect.top;

    // Calculate video render area (accounting for letterboxing)
    const video = videoRef.current;
    if (!video || video.videoWidth === 0) return;

    const videoAspect = video.videoWidth / video.videoHeight;
    const containerAspect = containerRect.width / containerRect.height;

    let renderWidth, renderHeight, offsetX, offsetY;
    if (videoAspect > containerAspect) {
      renderWidth = containerRect.width;
      renderHeight = containerRect.width / videoAspect;
      offsetX = 0;
      offsetY = (containerRect.height - renderHeight) / 2;
    } else {
      renderHeight = containerRect.height;
      renderWidth = containerRect.height * videoAspect;
      offsetX = (containerRect.width - renderWidth) / 2;
      offsetY = 0;
    }

    // Convert to normalized coordinates (0-1)
    const normalizedX = (clickX - offsetX) / renderWidth;
    const normalizedY = (clickY - offsetY) / renderHeight;

    // Check if click is within video bounds
    if (normalizedX < 0 || normalizedX > 1 || normalizedY < 0 || normalizedY > 1) return;

    // Find which pose was clicked
    const allPoses = lastDetectedPosesRef.current;
    if (allPoses.length === 0) return;

    const clickedPoseIndex = findPoseAtClick(allPoses, normalizedX, normalizedY, 0.1);

    if (clickedPoseIndex >= 0) {
      // Lock to this subject
      subjectLockRef.current = setManualLock(
        subjectLockRef.current,
        clickedPoseIndex,
        allPoses[clickedPoseIndex]
      );
      setManuallyLockedSubject(clickedPoseIndex);
      setIsSubjectSelectionMode(false);
      setTimeout(renderFrame, 50);
    }
  }, [isSubjectSelectionMode, renderFrame]);

  // TASK 1: Clear subject lock and allow re-selection
  const handleClearSubjectLock = useCallback(() => {
    subjectLockRef.current = clearManualLock(subjectLockRef.current);
    setManuallyLockedSubject(null);
    setTimeout(renderFrame, 50);
  }, [renderFrame]);

  // Get current frame info for display
  const getCurrentFrameInfo = () => {
    if (frameAnalyses.length === 0) return null;

    let closestFrame: FrameAnalysis | null = null;
    let minDiff = Infinity;

    for (const frame of frameAnalyses) {
      const diff = Math.abs(frame.timestamp - currentTime);
      if (diff < minDiff) {
        minDiff = diff;
        closestFrame = frame;
      }
    }

    return closestFrame;
  };

  const currentFrameInfo = getCurrentFrameInfo();

  // PHASE 5: Get analysis state message
  const getAnalysisStateMessage = () => {
    switch (analysisState) {
      case 'DETECTING_PLAYERS':
        return 'Detecting players in video...';
      case 'EXTRACTING_POSE':
        return 'Extracting pose data from frames...';
      case 'GEMINI_SCORING':
        return 'AI analyzing skill level...';
      case 'DONE':
        return 'Analysis complete!';
      case 'ERROR':
        return 'Analysis failed';
      default:
        return 'Ready to analyze';
    }
  };

  return (
    <div className="min-h-screen bg-gray-50">
      <DashboardNav />

      <main className="ml-64 p-8">
        <div className="max-w-7xl mx-auto">
          {/* Header */}
          <div className="mb-8">
            <h1 className="text-3xl font-bold text-gray-900">Video Analytics</h1>
            <p className="text-gray-600 mt-1">
              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}
            </p>
          </div>

          {/* Upload Section */}
          {!result && !videoUrl && (
            <div className="bg-white rounded-xl p-8 shadow-sm mb-8">
              <div
                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${
                  uploading || analyzing
                    ? 'border-primary-300 bg-primary-50'
                    : 'border-gray-300 hover:border-primary-400'
                }`}
              >
                {uploading ? (
                  <div className="space-y-4">
                    <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto"></div>
                    <p className="text-gray-600">Uploading video...</p>
                  </div>
                ) : analyzing ? (
                  // PHASE 5: Enhanced loading state with state machine
                  <div className="space-y-4">
                    <div className="w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative">
                      <svg className="w-8 h-8 text-primary-500 animate-pulse" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z" />
                      </svg>
                      {/* Spinning ring */}
                      <div className="absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin"></div>
                    </div>
                    <p className="text-gray-900 font-medium">{getAnalysisStateMessage()}</p>

                    {/* Progress steps */}
                    <div className="flex justify-center gap-2 mt-4">
                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (
                        <div
                          key={state}
                          className={`w-3 h-3 rounded-full transition-colors ${
                            analysisState === state
                              ? 'bg-primary-500 animate-pulse'
                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx
                              ? 'bg-green-500'
                              : 'bg-gray-300'
                          }`}
                        />
                      ))}
                    </div>
                    <p className="text-gray-500 text-sm">
                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}
                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}
                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}
                    </p>

                    <div className="w-64 mx-auto bg-gray-200 rounded-full h-2">
                      <div
                        className="bg-primary-500 h-2 rounded-full transition-all duration-300"
                        style={{ width: `${analyzeProgress}%` }}
                      ></div>
                    </div>
                    <p className="text-sm text-gray-500">{analyzeProgress}% complete</p>
                  </div>
                ) : (
                  <>
                    <div className="w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4">
                      <svg className="w-8 h-8 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12" />
                      </svg>
                    </div>
                    <h3 className="text-lg font-medium text-gray-900 mb-2">Upload your badminton video</h3>
                    <p className="text-gray-500 mb-4">MP4, MOV, or WebM up to 100MB</p>
                    {poseLandmarkerReady && (
                      <p className="text-sm text-green-600 mb-4">Pose detection ready</p>
                    )}
                    <input ref={fileInputRef} type="file" accept="video/*" onChange={handleFileSelect} className="hidden" />
                    <button onClick={() => fileInputRef.current?.click()} className="px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition">
                      Select Video
                    </button>
                  </>
                )}
              </div>

              {error && (
                <div className="mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700">{error}</div>
              )}
            </div>
          )}

          {/* Video Player with Overlay */}
          {videoUrl && (
            <div className="grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8">
              <div className="lg:col-span-2">
                <div className="bg-gray-900 rounded-xl overflow-hidden">
                  {/* TASK 1: Selection Mode Banner */}
                  {isSubjectSelectionMode && (
                    <div className="bg-cyan-600 text-white px-4 py-3 flex items-center justify-between">
                      <div className="flex items-center gap-2">
                        <span className="w-3 h-3 rounded-full bg-white animate-pulse" />
                        <span className="font-medium">Click on a player to track</span>
                      </div>
                      <span className="text-sm opacity-80">
                        The selected player will be tracked throughout the video
                      </span>
                    </div>
                  )}

                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}
                  <div ref={videoContainerRef} className="relative aspect-video">
                    <video
                      ref={videoRef}
                      src={videoUrl}
                      className="absolute inset-0 w-full h-full object-contain"
                      onTimeUpdate={handleTimeUpdate}
                      onLoadedMetadata={handleLoadedMetadata}
                      onEnded={() => setIsPlaying(false)}
                      playsInline
                    />
                    <canvas
                      ref={canvasRef}
                      onClick={handleCanvasClick}
                      className={`absolute inset-0 w-full h-full ${
                        isSubjectSelectionMode ? 'cursor-crosshair' : 'pointer-events-none'
                      } ${showSkeleton ? '' : 'hidden'}`}
                    />

                    {/* Status indicator with auto-detected level */}
                    {currentBandedScore && (
                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${
                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :
                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :
                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :
                        'bg-gray-500 text-white'
                      }`}>
                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}
                        <span className="ml-2 opacity-75">
                          {Math.round(currentBandedScore.overall_score)}%
                        </span>
                      </div>
                    )}

                    {/* Time display */}
                    <div className="absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm">
                      {formatTime(currentTime)} / {formatTime(duration)}
                    </div>

                    {/* Current metrics display */}
                    {currentFrameInfo?.metrics && (
                      <div className="absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs">
                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>
                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>
                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>
                      </div>
                    )}
                  </div>

                  {/* Controls - PHASE 3: Removed skill level dropdown */}
                  <div className="p-4 flex items-center justify-between">
                    <div className="flex items-center gap-2">
                      <button
                        onClick={togglePlayPause}
                        className="p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition"
                      >
                        {isPlaying ? (
                          <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z" />
                          </svg>
                        ) : (
                          <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z" />
                            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
                          </svg>
                        )}
                      </button>

                      <button
                        onClick={goToNextMistake}
                        disabled={issues.length === 0 || analyzing}
                        className="px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50"
                      >
                        Next Mistake
                      </button>

                      {/* TASK 1: Subject Selection Button */}
                      {poseData.length > 0 && (
                        <div className="flex items-center gap-2">
                          {isSubjectSelectionMode ? (
                            <button
                              onClick={() => setIsSubjectSelectionMode(false)}
                              className="px-4 py-2 bg-yellow-500 text-white rounded-lg hover:bg-yellow-600 transition text-sm font-medium animate-pulse"
                            >
                              <span className="flex items-center gap-1">
                                <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                                </svg>
                                Cancel Selection
                              </span>
                            </button>
                          ) : manuallyLockedSubject !== null ? (
                            <>
                              <span className="px-3 py-2 bg-cyan-600/20 text-cyan-400 rounded-lg text-sm flex items-center gap-1">
                                <span className="w-2 h-2 rounded-full bg-cyan-400 animate-pulse" />
                                Player Locked
                              </span>
                              <button
                                onClick={handleClearSubjectLock}
                                className="px-3 py-2 bg-gray-600 text-white rounded-lg hover:bg-gray-500 transition text-sm"
                                title="Clear lock and select another player"
                              >
                                <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15" />
                                </svg>
                              </button>
                            </>
                          ) : (
                            <button
                              onClick={() => setIsSubjectSelectionMode(true)}
                              className="px-4 py-2 bg-cyan-600 text-white rounded-lg hover:bg-cyan-700 transition text-sm font-medium"
                              title="Click on a player in the video to lock tracking"
                            >
                              <span className="flex items-center gap-1">
                                <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z" />
                                </svg>
                                Select Player
                              </span>
                            </button>
                          )}
                        </div>
                      )}
                    </div>

                    <div className="flex items-center gap-4">
                      {/* PHASE 3: Show auto-detected level instead of dropdown */}
                      {autoLevelResult && (
                        <div className="flex items-center gap-2 text-white text-sm">
                          <span className="px-2 py-1 bg-primary-600 rounded text-xs font-medium">
                            {autoLevelResult.level}
                          </span>
                          <span className="text-gray-400 text-xs">
                            {Math.round(autoLevelResult.confidence * 100)}% confidence
                          </span>
                        </div>
                      )}

                      <label className="flex items-center gap-2 text-white text-sm">
                        <input
                          type="checkbox"
                          checked={showSkeleton}
                          onChange={(e) => {
                            setShowSkeleton(e.target.checked);
                            if (e.target.checked) {
                              setTimeout(renderFrame, 50);
                            }
                          }}
                          className="rounded"
                        />
                        Show Skeleton
                      </label>

                      {/* FIX 2 + TASK 2: Enhanced Ghost overlay toggle with context-awareness indicator */}
                      {ghostData && ghostData.poseSequence.length > 0 && (
                        <label className="flex items-center gap-2 text-white text-sm">
                          <input
                            type="checkbox"
                            checked={showGhost}
                            onChange={(e) => {
                              const enabled = e.target.checked;
                              setShowGhost(enabled);
                              // Enable/disable the ghost data
                              if (ghostData) {
                                setGhostData({ ...ghostData, enabled });
                              }
                              if (enabled) {
                                setTimeout(renderFrame, 50);
                              }
                            }}
                            className="rounded accent-cyan-400"
                          />
                          <span className="text-cyan-400 flex items-center gap-1">
                            <span className="w-2 h-2 rounded-full bg-cyan-400 animate-pulse" style={{ boxShadow: '0 0 8px #00d4ff' }} />
                            {selectedMistake ? (
                              <span className="flex items-center gap-1">
                                Ghost <span className="text-xs opacity-75">(Correct {selectedMistake.summaryTitle.split(' ')[0]})</span>
                              </span>
                            ) : (
                              'Ghost (Best Rep)'
                            )}
                          </span>
                        </label>
                      )}

                      {/* FIX 4: Motion Path toggle */}
                      {poseData.length > 10 && (
                        <label className="flex items-center gap-2 text-white text-sm">
                          <input
                            type="checkbox"
                            checked={showMotionPath}
                            onChange={(e) => {
                              setShowMotionPath(e.target.checked);
                              if (e.target.checked) {
                                setTimeout(renderFrame, 50);
                              }
                            }}
                            className="rounded accent-orange-400"
                          />
                          <span className="text-orange-400">Motion Trail</span>
                        </label>
                      )}

                      {/* V5: Debug Overlay toggle (only when backend tracking is available) */}
                      {useBackendTracking && backendTrackingData && (
                        <label className="flex items-center gap-2 text-white text-sm">
                          <input
                            type="checkbox"
                            checked={showDebugOverlay}
                            onChange={(e) => {
                              setShowDebugOverlay(e.target.checked);
                              if (e.target.checked) {
                                setTimeout(renderFrame, 50);
                              }
                            }}
                            className="rounded accent-purple-400"
                          />
                          <span className="text-purple-400">Debug Tracking</span>
                        </label>
                      )}
                    </div>
                  </div>

                  {/* Timeline scrubber */}
                  <div className="px-4 pb-4">
                    <input
                      type="range"
                      min={0}
                      max={duration || 100}
                      step={0.1}
                      value={currentTime}
                      onChange={(e) => {
                        const time = parseFloat(e.target.value);
                        if (videoRef.current) {
                          videoRef.current.currentTime = time;
                          setCurrentTime(time);
                          setTimeout(renderFrame, 50);
                        }
                      }}
                      className="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer"
                    />
                  </div>

                  {/* V4 FEATURE: Mistake Timeline */}
                  {mistakeEvents.length > 0 && duration > 0 && (
                    <div className="px-4 pb-4">
                      <MistakeTimeline
                        mistakes={mistakeEvents}
                        duration={duration}
                        currentTime={currentTime}
                        onSeek={(time) => {
                          if (videoRef.current) {
                            videoRef.current.currentTime = time;
                            setCurrentTime(time);
                            setTimeout(renderFrame, 50);
                          }
                        }}
                        onSelectMistake={(mistake) => {
                          setSelectedMistake(mistake);
                          if (mistake && videoRef.current) {
                            videoRef.current.currentTime = mistake.startTimeSec;
                            setCurrentTime(mistake.startTimeSec);
                            setTimeout(renderFrame, 50);
                          }
                        }}
                        selectedMistakeId={selectedMistake?.id}
                      />
                    </div>
                  )}
                </div>

                {/* V4 FEATURE: SkillMeter with computed metrics */}
                {computedSkill && (
                  <div className="mt-6">
                    <SkillMeter skillData={computedSkill} />
                  </div>
                )}

                {/* V4 FEATURE: FixItCard for selected mistake */}
                {selectedMistake && (
                  <div className="mt-6">
                    <div className="flex items-center justify-between mb-3">
                      <h3 className="font-semibold text-gray-900">Fix This Mistake</h3>
                      <div className="flex items-center gap-2">
                        {/* V5: Compare Mode button */}
                        {ghostData && (
                          <button
                            onClick={() => {
                              setCompareMistake(selectedMistake);
                              setShowCompareMode(true);
                            }}
                            className="px-3 py-1 text-sm bg-cyan-500 hover:bg-cyan-600 text-white rounded-lg flex items-center gap-1 transition-colors"
                          >
                            <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z" />
                            </svg>
                            Compare
                          </button>
                        )}
                        {/* V5: 3D Sandbox button */}
                        {poseData.length > 0 && (
                          <button
                            onClick={() => setShow3DSandbox(!show3DSandbox)}
                            className={`px-3 py-1 text-sm rounded-lg flex items-center gap-1 transition-colors ${
                              show3DSandbox
                                ? 'bg-purple-600 text-white'
                                : 'bg-purple-500 hover:bg-purple-600 text-white'
                            }`}
                          >
                            <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M14 10l-2 1m0 0l-2-1m2 1v2.5M20 7l-2 1m2-1l-2-1m2 1v2.5M14 4l-2-1-2 1M4 7l2-1M4 7l2 1M4 7v2.5M12 21l-2-1m2 1l2-1m-2 1v-2.5M6 18l-2-1v-2.5M18 18l2-1v-2.5" />
                            </svg>
                            3D View
                          </button>
                        )}
                        <button
                          onClick={() => setSelectedMistake(null)}
                          className="text-sm text-gray-500 hover:text-gray-700"
                        >
                          Close
                        </button>
                      </div>
                    </div>
                    <FixItCard
                      mistake={selectedMistake}
                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}
                      onClose={() => setSelectedMistake(null)}
                    />

                    {/* V5: 3D Pose Sandbox */}
                    {show3DSandbox && poseData.length > 0 && (
                      <div className="mt-4">
                        <PoseSandbox3D
                          mistake={selectedMistake}
                          userPose={poseData[Math.floor(selectedMistake.startTimeSec * fps)] || []}
                          correctPose={ghostData?.poseSequence?.[0]?.landmarks}
                          fixKeyframes={generateFixKeyframes(selectedMistake, poseData, fps)}
                          onClose={() => setShow3DSandbox(false)}
                        />
                      </div>
                    )}
                  </div>
                )}

                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}
                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (
                  <div className="mt-6 bg-white rounded-xl p-6 shadow-sm">
                    <div className="flex items-center justify-between mb-4">
                      <h3 className="font-semibold text-gray-900">AI Analysis Notes</h3>
                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${
                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :
                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :
                        'bg-blue-100 text-blue-800'
                      }`}>
                        {autoLevelResult.level}
                      </span>
                    </div>
                    <div className="space-y-2">
                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (
                        <div key={idx} className="flex items-start gap-2 text-sm text-gray-600">
                          <svg className="w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0" fill="currentColor" viewBox="0 0 20 20">
                            <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clipRule="evenodd" />
                          </svg>
                          <span>{bullet}</span>
                        </div>
                      ))}
                    </div>
                  </div>
                )}

                {/* FIX 3 & 4: Enhanced Movement Guidance with Animated Corrections & Motion Paths */}
                {poseData.length > 0 && (
                  <div className="mt-6">
                    <div className="flex items-center justify-between mb-4">
                      <h3 className="font-semibold text-gray-900">Movement Guidance</h3>
                      <button
                        onClick={() => setShowGuidance(!showGuidance)}
                        className="text-sm text-primary-600 hover:text-primary-700"
                      >
                        {showGuidance ? 'Hide' : 'Show'} Analysis
                      </button>
                    </div>
                    {showGuidance && (
                      <MovementGuidance
                        poseHistory={poseData}
                        currentMistake={selectedMistake}
                        width={340}
                        height={280}
                        showTrajectory={true}
                        showCorrection={!!selectedMistake}
                      />
                    )}
                    {/* Compact trajectory preview when guidance is hidden */}
                    {!showGuidance && poseData.length > 10 && (
                      <div className="mt-2">
                        <p className="text-xs text-gray-500 mb-2">Racket Trajectory</p>
                        <TrajectoryPreview poseHistory={poseData} width={200} height={60} />
                      </div>
                    )}
                  </div>
                )}

                {/* Legacy Guidance Animation (fallback) */}
                {guidanceKeyframes.length > 0 && !poseData.length && (
                  <div className="mt-6">
                    <div className="flex items-center justify-between mb-4">
                      <h3 className="font-semibold text-gray-900">Form Guidance</h3>
                    </div>
                    <GuidanceAnimation
                      keyframes={guidanceKeyframes}
                      primaryIssue={issues[0]}
                    />
                  </div>
                )}

                {/* Analysis Summary */}
                {result && (
                  <div className="mt-6 bg-white rounded-xl p-6 shadow-sm">
                    <h3 className="font-semibold text-gray-900 mb-3">Analysis Summary</h3>
                    <p className="text-gray-600">{result.technique_summary}</p>
                    {result.strategy_summary && (
                      <p className="text-gray-500 mt-2 text-sm">{result.strategy_summary}</p>
                    )}
                  </div>
                )}
              </div>

              {/* Issues Panel */}
              <div className="space-y-4">
                <h3 className="font-semibold text-gray-900">Detected Issues</h3>
                {analyzing ? (
                  <div className="bg-white rounded-xl p-6 shadow-sm">
                    {/* Shimmer loading animation */}
                    <div className="animate-pulse space-y-4">
                      <div className="h-4 bg-gray-200 rounded w-3/4"></div>
                      <div className="h-4 bg-gray-200 rounded w-1/2"></div>
                      <div className="h-20 bg-gray-200 rounded"></div>
                      <div className="h-4 bg-gray-200 rounded w-2/3"></div>
                    </div>
                  </div>
                ) : issues.length > 0 ? (
                  <div className="space-y-4 max-h-[600px] overflow-y-auto">
                    {issues.map((issue, index) => (
                      <DrillCard
                        key={index}
                        issue={issue}
                        onTimestampClick={jumpToTimestamp}
                        currentTime={currentTime}
                      />
                    ))}
                  </div>
                ) : (
                  <div className="bg-green-50 border border-green-200 rounded-xl p-4 text-green-800">
                    <p className="font-medium">Great form!</p>
                    <p className="text-sm">No major issues detected in this video.</p>
                  </div>
                )}

                {/* Reset button */}
                {videoUrl && !analyzing && (
                  <button
                    onClick={() => {
                      setResult(null);
                      setVideoUrl(null);
                      setVideoFile(null);
                      setIssues([]);
                      setPoseData([]);
                      setFrameAnalyses([]);
                      setCurrentTime(0);
                      setDuration(0);
                      setAutoLevelResult(null);
                      setGuidanceKeyframes([]);
                      setAnalysisState('IDLE');
                      // V4 state reset
                      setGhostData(null);
                      setShowGhost(false);
                      setComputedSkill(null);
                      setMistakeEvents([]);
                      setSelectedMistake(null);
                    }}
                    className="w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition"
                  >
                    Analyze Another Video
                  </button>
                )}
              </div>
            </div>
          )}

          {/* Results Section (legacy format without video) */}
          {result && !videoUrl && (
            <div className="grid grid-cols-1 lg:grid-cols-2 gap-8">
              {/* Left Column - Issues */}
              <div className="space-y-6">
                <div className="bg-white rounded-xl p-6 shadow-sm">
                  <h2 className="text-lg font-semibold text-gray-900 mb-4">Areas to Improve</h2>
                  <div className="space-y-3">
                    {result.top_issues.map((issue) => (
                      <button
                        key={issue.id}
                        onClick={() => setSelectedIssue(issue)}
                        className={`w-full text-left p-4 rounded-lg border transition ${
                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''
                        } ${getSeverityColor(issue.severity)}`}
                      >
                        <div className="flex items-center justify-between mb-1">
                          <span className="font-medium">{issue.title}</span>
                          <span className="text-xs uppercase font-semibold">{issue.severity}</span>
                        </div>
                        <p className="text-sm opacity-80">{issue.description}</p>
                      </button>
                    ))}
                  </div>
                </div>

                <div className="bg-white rounded-xl p-6 shadow-sm">
                  <h2 className="text-lg font-semibold text-gray-900 mb-3">Technique Summary</h2>
                  <p className="text-gray-600">{result.technique_summary}</p>
                </div>
              </div>

              {/* Right Column - Drills */}
              <div className="space-y-6">
                <div className="bg-white rounded-xl p-6 shadow-sm">
                  <h2 className="text-lg font-semibold text-gray-900 mb-4">Recommended Drills</h2>
                  <div className="space-y-3">
                    {result.drills.map((drill) => (
                      <button
                        key={drill.id}
                        onClick={() => setSelectedDrill(drill)}
                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${
                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''
                        }`}
                      >
                        <div className="flex items-center justify-between mb-1">
                          <span className="font-medium text-gray-900">{drill.name}</span>
                          <span className="text-sm text-gray-500">{drill.duration_minutes} min</span>
                        </div>
                        <p className="text-sm text-gray-600">{drill.description}</p>
                      </button>
                    ))}
                  </div>
                </div>

                {selectedDrill && (
                  <div className="bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6">
                    <div className="flex items-center justify-between mb-4">
                      <h3 className="text-lg font-semibold text-gray-900">{selectedDrill.name}</h3>
                      <Link
                        href={`/practice?drill=${selectedDrill.id}`}
                        className="px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition"
                      >
                        Let&apos;s Practice
                      </Link>
                    </div>
                    <div className="space-y-3">
                      <p className="text-gray-700">{selectedDrill.description}</p>
                      <div>
                        <p className="font-medium text-gray-900 mb-2">Instructions:</p>
                        <ol className="list-decimal list-inside space-y-1 text-gray-700">
                          {selectedDrill.instructions.map((instruction, i) => (
                            <li key={i}>{instruction}</li>
                          ))}
                        </ol>
                      </div>
                    </div>
                  </div>
                )}

                <button
                  onClick={() => {
                    setResult(null);
                    setSelectedIssue(null);
                    setSelectedDrill(null);
                    setVideoUrl(null);
                    setPoseData([]);
                    setIssues([]);
                    setAutoLevelResult(null);
                    setGuidanceKeyframes([]);
                    setAnalysisState('IDLE');
                    // V4 state reset
                    setGhostData(null);
                    setShowGhost(false);
                    setComputedSkill(null);
                    setMistakeEvents([]);
                    setSelectedMistake(null);
                  }}
                  className="w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition"
                >
                  Analyze Another Video
                </button>
              </div>
            </div>
          )}
        </div>
      </main>

      {/* Player Selection Modal */}
      <PlayerSelectionModal
        isOpen={showPlayerSelection}
        onClose={() => {
          setShowPlayerSelection(false);
          setAnalyzing(false);
          setVideoUrl(null);
          setVideoFile(null);
          setAnalysisState('IDLE');
          // V4 state reset
          setGhostData(null);
          setShowGhost(false);
          setComputedSkill(null);
          setMistakeEvents([]);
          setSelectedMistake(null);
        }}
        onConfirm={handlePlayerSelectionConfirm}
        tracks={detectedTracks}
        detectedFormat={detectedMatchFormat}
      />

      {/* V5: Compare Mode Modal */}
      {showCompareMode && compareMistake && ghostData && (
        <CompareMode
          mistake={compareMistake}
          userPoseAtMistake={
            poseData[Math.floor(compareMistake.startTimeSec * fps)] || []
          }
          ghostData={ghostData}
          allPoseData={poseData}
          fps={fps}
          onClose={() => {
            setShowCompareMode(false);
            setCompareMistake(null);
          }}
        />
      )}
    </div>
  );
}

function AnalyticsLoading() {
  return (
    <div className="min-h-screen bg-gray-50">
      <DashboardNav />
      <main className="ml-64 p-8">
        <div className="max-w-7xl mx-auto">
          <div className="animate-pulse">
            <div className="h-8 bg-gray-200 rounded w-48 mb-4"></div>
            <div className="h-4 bg-gray-200 rounded w-96 mb-8"></div>
            <div className="bg-gray-200 rounded-xl h-96"></div>
          </div>
        </div>
      </main>
    </div>
  );
}

export default function AnalyticsPage() {
  return (
    <Suspense fallback={<AnalyticsLoading />}>
      <AnalyticsContent />
    </Suspense>
  );
}
