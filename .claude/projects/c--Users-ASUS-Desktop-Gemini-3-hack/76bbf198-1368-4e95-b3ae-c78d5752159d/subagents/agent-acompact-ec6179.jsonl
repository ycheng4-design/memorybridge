{"parentUuid":"7b3b18de-dcbf-4a93-b8e7-60db722d6605","isSidechain":true,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"76bbf198-1368-4e95-b3ae-c78d5752159d","version":"2.1.29","gitBranch":"","agentId":"acompact-ec6179","slug":"linear-jumping-quill","message":{"model":"claude-opus-4-5-20251101","id":"msg_013gX92bJDrnPLUogzx22p9g","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BXMonaDVgXd3erG6whb8db","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <div className=\"flex items-center gap-2\">\n                        {/* V5: Compare Mode button */}\n                        {ghostData && (\n                          <button\n                            onClick={() => {\n                              setCompareMistake(selectedMistake);\n                              setShowCompareMode(true);\n                            }}\n                            className=\"px-3 py-1 text-sm bg-cyan-500 hover:bg-cyan-600 text-white rounded-lg flex items-center gap-1 transition-colors\"\n                          >\n                            <svg className=\"w-4 h-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z\" />\n                            </svg>\n                            Compare\n                          </button>\n                        )}\n                        {/* V5: 3D Sandbox button */}\n                        {poseData.length > 0 && (\n                          <button\n                            onClick={() => setShow3DSandbox(!show3DSandbox)}\n                            className={`px-3 py-1 text-sm rounded-lg flex items-center gap-1 transition-colors ${\n                              show3DSandbox\n                                ? 'bg-purple-600 text-white'\n                                : 'bg-purple-500 hover:bg-purple-600 text-white'\n                            }`}\n                          >\n                            <svg className=\"w-4 h-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14 10l-2 1m0 0l-2-1m2 1v2.5M20 7l-2 1m2-1l-2-1m2 1v2.5M14 4l-2-1-2 1M4 7l2-1M4 7l2 1M4 7v2.5M12 21l-2-1m2 1l2-1m-2 1v-2.5M6 18l-2-1v-2.5M18 18l2-1v-2.5\" />\n                            </svg>\n                            3D View\n                          </button>\n                        )}\n                        <button\n                          onClick={() => setSelectedMistake(null)}\n                          className=\"text-sm text-gray-500 hover:text-gray-700\"\n                        >\n                          Close\n                        </button>\n                      </div>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n\n                    {/* V5: 3D Pose Sandbox */}\n                    {show3DSandbox && poseData.length > 0 && (\n                      <div className=\"mt-4\">\n                        <PoseSandbox3D\n                          mistake={selectedMistake}\n                          userPose={poseData[Math.floor(selectedMistake.startTimeSec * fps)] || []}\n                          correctPose={ghostData?.poseSequence?.[0]?.landmarks}\n                          fixKeyframes={generateFixKeyframes(selectedMistake, poseData, fps)}\n                          onClose={() => setShow3DSandbox(false)}\n                        />\n                      </div>\n                    )}\n                  </div>\n                )}","new_string":"                {/* V4 FEATURE: 3D Pose View for selected mistake - DIRECTLY SHOWS 3D */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    {/* Show 3D directly - no 2D FixItCard */}\n                    {poseData.length > 0 && (\n                      <PoseSandbox3D\n                        mistake={selectedMistake}\n                        userPose={poseData[Math.floor(selectedMistake.startTimeSec * fps)] || []}\n                        correctPose={ghostData?.poseSequence?.[0]?.landmarks}\n                        fixKeyframes={generateFixKeyframes(selectedMistake, poseData, fps)}\n                        onClose={() => setSelectedMistake(null)}\n                      />\n                    )}\n                  </div>\n                )}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":2049,"cache_read_input_tokens":164965,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2049},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXk1LR4QnQtxrTd7gMLqu","type":"assistant","uuid":"247f3745-7bd9-4f77-b513-bfb8ca3651a7","timestamp":"2026-02-02T22:09:58.596Z"}
{"parentUuid":"247f3745-7bd9-4f77-b513-bfb8ca3651a7","isSidechain":true,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"76bbf198-1368-4e95-b3ae-c78d5752159d","version":"2.1.29","gitBranch":"","agentId":"acompact-ec6179","slug":"linear-jumping-quill","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BXMonaDVgXd3erG6whb8db","type":"tool_result","content":"The file C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"b49d8fe8-9506-4c5a-9ed6-bb8359c9d82f","timestamp":"2026-02-02T22:09:59.167Z","toolUseResult":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <div className=\"flex items-center gap-2\">\n                        {/* V5: Compare Mode button */}\n                        {ghostData && (\n                          <button\n                            onClick={() => {\n                              setCompareMistake(selectedMistake);\n                              setShowCompareMode(true);\n                            }}\n                            className=\"px-3 py-1 text-sm bg-cyan-500 hover:bg-cyan-600 text-white rounded-lg flex items-center gap-1 transition-colors\"\n                          >\n                            <svg className=\"w-4 h-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z\" />\n                            </svg>\n                            Compare\n                          </button>\n                        )}\n                        {/* V5: 3D Sandbox button */}\n                        {poseData.length > 0 && (\n                          <button\n                            onClick={() => setShow3DSandbox(!show3DSandbox)}\n                            className={`px-3 py-1 text-sm rounded-lg flex items-center gap-1 transition-colors ${\n                              show3DSandbox\n                                ? 'bg-purple-600 text-white'\n                                : 'bg-purple-500 hover:bg-purple-600 text-white'\n                            }`}\n                          >\n                            <svg className=\"w-4 h-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14 10l-2 1m0 0l-2-1m2 1v2.5M20 7l-2 1m2-1l-2-1m2 1v2.5M14 4l-2-1-2 1M4 7l2-1M4 7l2 1M4 7v2.5M12 21l-2-1m2 1l2-1m-2 1v-2.5M6 18l-2-1v-2.5M18 18l2-1v-2.5\" />\n                            </svg>\n                            3D View\n                          </button>\n                        )}\n                        <button\n                          onClick={() => setSelectedMistake(null)}\n                          className=\"text-sm text-gray-500 hover:text-gray-700\"\n                        >\n                          Close\n                        </button>\n                      </div>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n\n                    {/* V5: 3D Pose Sandbox */}\n                    {show3DSandbox && poseData.length > 0 && (\n                      <div className=\"mt-4\">\n                        <PoseSandbox3D\n                          mistake={selectedMistake}\n                          userPose={poseData[Math.floor(selectedMistake.startTimeSec * fps)] || []}\n                          correctPose={ghostData?.poseSequence?.[0]?.landmarks}\n                          fixKeyframes={generateFixKeyframes(selectedMistake, poseData, fps)}\n                          onClose={() => setShow3DSandbox(false)}\n                        />\n                      </div>\n                    )}\n                  </div>\n                )}","newString":"                {/* V4 FEATURE: 3D Pose View for selected mistake - DIRECTLY SHOWS 3D */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    {/* Show 3D directly - no 2D FixItCard */}\n                    {poseData.length > 0 && (\n                      <PoseSandbox3D\n                        mistake={selectedMistake}\n                        userPose={poseData[Math.floor(selectedMistake.startTimeSec * fps)] || []}\n                        correctPose={ghostData?.poseSequence?.[0]?.landmarks}\n                        fixKeyframes={generateFixKeyframes(selectedMistake, poseData, fps)}\n                        onClose={() => setSelectedMistake(null)}\n                      />\n                    )}\n                  </div>\n                )}","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, useMemo, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport MovementGuidance, { TrajectoryPreview } from '@/components/MovementGuidance';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  createSubjectLock,\n  findLockedSubjectPose,\n  setManualLock,\n  clearManualLock,\n  findPoseAtClick,\n  type SubjectLock\n} from '@/lib/subject-lock';\nimport {\n  drawUserSkeleton,\n  drawGhostSkeleton,\n  drawMotionPath,\n  extractRacketTrajectory,\n  drawSelectionIndicator,\n  SKELETON_COLORS,\n  type RenderOptions,\n} from '@/lib/skeleton-renderer';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, createContextAwareGhost } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport CompareMode from '@/components/CompareMode';\nimport PoseSandbox3D from '@/components/PoseSandbox3D';\nimport type {\n  AnalysisResultJson,\n  Issue,\n  Drill,\n  PoseLandmark,\n  Session,\n  PoseMetrics,\n  PlayerTrackData,\n  ComputedSkillScore,\n  MistakeEvent,\n  GhostPoseFrame,\n  GhostRivalData,\n  TrackingFrame,\n  TrackingResult,\n  TrackSummary,\n  LockedPlayerContext,\n} from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // V5: Backend YOLO+ByteTrack tracking state\n  const [backendTrackingData, setBackendTrackingData] = useState<TrackingFrame[] | null>(null);\n  const [backendTrackSummaries, setBackendTrackSummaries] = useState<TrackSummary[] | null>(null);\n  const [useBackendTracking, setUseBackendTracking] = useState(false);\n  const [lockedPlayerContext, setLockedPlayerContext] = useState<LockedPlayerContext | null>(null);\n  const [showDebugOverlay, setShowDebugOverlay] = useState(false);\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // V5: Compare Mode state\n  const [showCompareMode, setShowCompareMode] = useState(false);\n  const [compareMistake, setCompareMistake] = useState<MistakeEvent | null>(null);\n\n  // V5: 3D Pose Sandbox state\n  const [show3DSandbox, setShow3DSandbox] = useState(false);\n\n  // TASK 2: Store original ghost data to switch back to when no mistake is selected\n  const originalGhostDataRef = useRef<GhostRivalData | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // FIX 1: Subject Lock for skeleton tracking persistence\n  const subjectLockRef = useRef<SubjectLock>(createSubjectLock());\n  const [showMotionPath, setShowMotionPath] = useState(false);\n  const ghostPulseRef = useRef<number>(0);\n\n  // TASK 1: User-initiated subject selection mode\n  const [isSubjectSelectionMode, setIsSubjectSelectionMode] = useState(false);\n  const [manuallyLockedSubject, setManuallyLockedSubject] = useState<number | null>(null);\n  const lastDetectedPosesRef = useRef<PoseLandmark[][]>([]);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  // V5: Backend API call for YOLO+ByteTrack tracking\n  const fetchBackendTracking = async (file: File): Promise<{\n    tracking_data: TrackingFrame[] | null;\n    detected_players: TrackSummary[];\n    detected_match_format: 'singles' | 'doubles';\n    fps: number;\n    tracking_available: boolean;\n  }> => {\n    try {\n      const formData = new FormData();\n      formData.append('file', file);\n      formData.append('user_id', 'guest'); // TODO: Get actual user ID\n\n      const response = await fetch('http://localhost:8000/api/analyze', {\n        method: 'POST',\n        body: formData,\n      });\n\n      if (!response.ok) {\n        throw new Error(`Backend API error: ${response.status}`);\n      }\n\n      const data = await response.json();\n\n      return {\n        tracking_data: data.tracking_data || null,\n        detected_players: data.detected_players || [],\n        detected_match_format: data.detected_match_format || 'singles',\n        fps: data.fps || 30,\n        tracking_available: data.tracking_available || false,\n      };\n    } catch (error) {\n      console.warn('[V5] Backend tracking not available, using browser-side detection:', error);\n      return {\n        tracking_data: null,\n        detected_players: [],\n        detected_match_format: 'singles',\n        fps: 30,\n        tracking_available: false,\n      };\n    }\n  };\n\n  // V5: Get filtered pose data for the selected track_id\n  const getFilteredPoseDataForFrame = useCallback((frameIndex: number): PoseLandmark[] | null => {\n    if (!backendTrackingData || selectedTrackIds.length === 0) {\n      // Fallback to regular pose data if no backend tracking\n      return poseData[frameIndex] || null;\n    }\n\n    const frame = backendTrackingData[frameIndex];\n    if (!frame) return null;\n\n    // Find the track matching the first selected track_id\n    const selectedTrack = frame.tracks.find(t => t.track_id === selectedTrackIds[0]);\n    if (!selectedTrack || !selectedTrack.landmarks) return null;\n\n    // Convert backend landmarks format to PoseLandmark[]\n    return selectedTrack.landmarks.map(lm => ({\n      x: lm.x,\n      y: lm.y,\n      z: lm.z,\n      visibility: lm.visibility,\n    }));\n  }, [backendTrackingData, selectedTrackIds, poseData]);\n\n  // V5: Get all poses for current frame (for debug overlay)\n  const getAllPosesForFrame = useCallback((frameIndex: number): Array<{\n    track_id: number;\n    landmarks: PoseLandmark[] | null;\n    bbox: { x: number; y: number; w: number; h: number };\n    isSelected: boolean;\n  }> => {\n    if (!backendTrackingData) return [];\n\n    const frame = backendTrackingData[frameIndex];\n    if (!frame) return [];\n\n    return frame.tracks.map(track => ({\n      track_id: track.track_id,\n      landmarks: track.landmarks?.map(lm => ({\n        x: lm.x,\n        y: lm.y,\n        z: lm.z,\n        visibility: lm.visibility,\n      })) || null,\n      bbox: track.bbox,\n      isSelected: selectedTrackIds.includes(track.track_id),\n    }));\n  }, [backendTrackingData, selectedTrackIds]);\n\n  // V5: Lock player by track_id\n  const lockPlayerByTrackId = useCallback((trackId: number) => {\n    setSelectedTrackIds([trackId]);\n    setLockedPlayerContext({\n      trackId,\n      lockTime: Date.now(),\n      thumbnailUrl: backendTrackSummaries?.find(s => s.track_id === trackId)?.thumbnail_base64,\n      side: backendTrackSummaries?.find(s => s.track_id === trackId)?.side,\n    });\n\n    // Recompute ghost/mistakes for new player\n    if (backendTrackingData) {\n      const filteredPoses: (PoseLandmark[] | null)[] = backendTrackingData.map(frame => {\n        const track = frame.tracks.find(t => t.track_id === trackId);\n        if (!track?.landmarks) return null;\n        return track.landmarks.map(lm => ({\n          x: lm.x,\n          y: lm.y,\n          z: lm.z,\n          visibility: lm.visibility,\n        }));\n      });\n\n      setPoseData(filteredPoses);\n\n      // Recompute V4 features for the new player\n      const mistakes = detectMistakes(filteredPoses, fps);\n      setMistakeEvents(mistakes);\n\n      const metricsHistory = filteredPoses.map(pose =>\n        pose ? extractMetrics(pose) : null\n      );\n      const ghost = initializeGhostRival(filteredPoses, metricsHistory, fps);\n      setGhostData(ghost);\n      originalGhostDataRef.current = ghost;\n\n      const skillResult = computeSkillScore(filteredPoses, metricsHistory, mistakes);\n      setComputedSkill(skillResult);\n    }\n  }, [backendTrackingData, backendTrackSummaries, fps]);\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // TASK 2: Update ghost data when a mistake is selected for context-aware ghost\n  useEffect(() => {\n    if (!poseData.length || !frameAnalyses.length) return;\n\n    const metricsHistory = frameAnalyses.map(a => a.metrics);\n\n    if (selectedMistake) {\n      // Store original ghost data if not already stored\n      if (!originalGhostDataRef.current && ghostData) {\n        originalGhostDataRef.current = ghostData;\n      }\n\n      // Create context-aware ghost for the selected mistake type\n      const contextGhost = createContextAwareGhost(\n        poseData,\n        metricsHistory,\n        selectedMistake.type,\n        10\n      );\n\n      if (contextGhost.poseSequence.length > 0) {\n        setGhostData(contextGhost);\n        // Auto-enable ghost when selecting a mistake to show correct form\n        setShowGhost(true);\n      }\n    } else {\n      // Restore original ghost data when no mistake is selected\n      if (originalGhostDataRef.current) {\n        setGhostData(originalGhostDataRef.current);\n      }\n    }\n  }, [selectedMistake, poseData, frameAnalyses]);\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // FIX 1: Use Subject Lock to maintain consistent tracking\n          // Convert MediaPipe results to our format\n          const allPoses: PoseLandmark[][] = results.landmarks.map((poseLandmarks: any) =>\n            poseLandmarks.map((lm: any) => ({\n              x: lm.x,\n              y: lm.y,\n              z: lm.z,\n              visibility: lm.visibility ?? 1.0,\n            }))\n          );\n\n          // Find the locked subject pose (prevents jumping between people)\n          const { poseIndex, updatedLock } = findLockedSubjectPose(\n            allPoses,\n            subjectLockRef.current,\n            i\n          );\n          subjectLockRef.current = updatedLock;\n\n          // Use locked pose or fall back to selected track\n          const selectedPoseIdx = poseIndex >= 0 ? poseIndex :\n            (selectedTracks[0] < results.landmarks.length ? selectedTracks[0] : 0);\n\n          landmarks = allPoses[selectedPoseIdx];\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n    // V4 state reset\n    setGhostData(null);\n    setShowGhost(false);\n    setComputedSkill(null);\n    setMistakeEvents([]);\n    setSelectedMistake(null);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n    // TASK 2: Store original ghost data for restoration\n    originalGhostDataRef.current = ghost;\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // V5: Try backend YOLO+ByteTrack tracking first\n      setAnalyzeProgress(5);\n      let tracks: PlayerTrackData[] = [];\n      let backendAvailable = false;\n      let backendTrackingDataLocal: TrackingFrame[] | null = null;\n\n      try {\n        console.log('[V5] Attempting backend YOLO+ByteTrack tracking...');\n        const backendResult = await fetchBackendTracking(file);\n\n        if (backendResult.tracking_available && backendResult.tracking_data) {\n          console.log('[V5] Backend tracking available:', {\n            frames: backendResult.tracking_data.length,\n            players: backendResult.detected_players.length,\n            matchFormat: backendResult.detected_match_format,\n          });\n\n          backendAvailable = true;\n          backendTrackingDataLocal = backendResult.tracking_data;\n          setUseBackendTracking(true);\n          setBackendTrackingData(backendResult.tracking_data);\n          setBackendTrackSummaries(backendResult.detected_players);\n          setFps(backendResult.fps);\n\n          // Use backend-detected match format\n          setDetectedMatchFormat(backendResult.detected_match_format);\n\n          // Convert backend track summaries to PlayerTrackData format\n          tracks = backendResult.detected_players.map((s: TrackSummary) => ({\n            track_id: s.track_id,\n            bbox_samples: [],\n            is_selected: false,\n            confidence_avg: s.avg_confidence,\n            frame_count: s.frame_count,\n            side: s.side,\n            thumbnail_url: s.thumbnail_base64 ? `data:image/jpeg;base64,${s.thumbnail_base64}` : undefined,\n          }));\n        }\n      } catch (err) {\n        console.warn('[V5] Backend tracking failed, using browser-side detection:', err);\n      }\n\n      // Fallback to browser-side detection if backend not available\n      if (!backendAvailable) {\n        console.log('[V5] Using browser-side MediaPipe detection');\n        setUseBackendTracking(false);\n        tracks = await detectPlayerTracks(processVideo);\n      }\n\n      setDetectedTracks(tracks);\n\n      // Only compute match format from track count if not using backend\n      // (backend already set the format above)\n      if (!backendAvailable) {\n        const uniquePlayers = tracks.length;\n        const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n        setDetectedMatchFormat(detectedFormat);\n      }\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n\n        // V5: If using backend tracking, set the locked player context\n        if (backendAvailable) {\n          setLockedPlayerContext({\n            trackId: tracks[0].track_id,\n            lockTime: Date.now(),\n            thumbnailUrl: tracks[0].thumbnail_url,\n            side: tracks[0].side,\n          });\n        }\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n      let poseArray: (PoseLandmark[] | null)[] = [];\n\n      // V5: If backend tracking is available, use backend pose data\n      if (backendAvailable && backendTrackingDataLocal) {\n        setAnalysisState('EXTRACTING_POSE');\n        console.log('[V5] Using backend tracking data for pose analysis');\n\n        const targetTrackId = selectedTrackIds[0] || tracks[0]?.track_id || 0;\n        console.log('[V5] Target track ID:', targetTrackId);\n\n        // Extract filtered poses from backend tracking data\n        let validPoseCount = 0;\n        let nullPoseCount = 0;\n\n        poseArray = backendTrackingDataLocal.map((frame: TrackingFrame) => {\n          const track = frame.tracks.find(t => t.track_id === targetTrackId);\n          if (!track?.landmarks || track.landmarks.length === 0) {\n            nullPoseCount++;\n            return null;\n          }\n          validPoseCount++;\n          return track.landmarks.map(lm => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,  // Default visibility to 1.0 if missing\n          }));\n        });\n\n        console.log(`[V5] Pose extraction: ${validPoseCount} valid, ${nullPoseCount} null (total: ${poseArray.length})`);\n\n        // If too many null poses, warn and check if there's a better track\n        if (validPoseCount < poseArray.length * 0.1) {\n          console.warn('[V5] Very few valid poses detected! Checking other tracks...');\n          // Try to find a track with more poses\n          const trackPoseCounts: Record<number, number> = {};\n          for (const frame of backendTrackingDataLocal) {\n            for (const track of frame.tracks) {\n              if (track.landmarks && track.landmarks.length > 0) {\n                trackPoseCounts[track.track_id] = (trackPoseCounts[track.track_id] || 0) + 1;\n              }\n            }\n          }\n          console.log('[V5] Pose counts per track:', trackPoseCounts);\n        }\n\n        setPoseData(poseArray);\n\n        // Build analyses from backend pose data\n        analyses = poseArray.map((landmarks, idx) => {\n          const metrics = landmarks ? extractMetrics(landmarks) : null;\n          const evaluation = landmarks ? evaluateForm(landmarks, 'default') : null;\n\n          return {\n            timestamp: idx / fps,\n            landmarks,\n            evaluation,\n            metrics,\n          };\n        });\n        setFrameAnalyses(analyses);\n\n        // PERFORMANCE FIX: Force React to render skeleton immediately\n        // by yielding to the main thread before heavy computations\n        await new Promise(resolve => setTimeout(resolve, 50));\n        console.log('[PERF] Skeleton should now be visible, starting heavy analytics...');\n\n      } else if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        // Fallback: Use browser-side MediaPipe\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n        poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n      }\n\n      if (poseArray.length > 0) {\n        // PERFORMANCE FIX: Progressive rendering - show UI updates between heavy computations\n        console.log('[PERF] Starting analytics computations progressively...');\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // Yield to allow React to render issues\n        await new Promise(resolve => setTimeout(resolve, 10));\n\n        // V4 FEATURE: Detect mistake events for timeline\n        console.log('[PERF] Computing mistake detection...');\n        const mistakes = detectMistakes(poseArray, fps);\n        setMistakeEvents(mistakes);\n\n        // Yield to allow React to render mistake timeline\n        await new Promise(resolve => setTimeout(resolve, 10));\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        console.log('[PERF] Computing skill score...');\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // Yield to allow React to render skill meter\n        await new Promise(resolve => setTimeout(resolve, 10));\n\n        // V4 FEATURE: Initialize ghost rival data\n        console.log('[PERF] Initializing ghost rival...');\n        const ghost = initializeGhostRival(poseArray, metricsHistory, fps);\n        setGhostData(ghost);\n        // TASK 2: Store original ghost data for restoration\n        originalGhostDataRef.current = ghost;\n\n        // PERFORMANCE FIX: Run Gemini API call in background - don't block UI\n        // Start Gemini call but don't await it immediately\n        console.log('[PERF] Starting Gemini API call (non-blocking)...');\n        const geminiPromise = detectSkillLevelWithGemini(analyses, detectedIssues);\n\n        // Show initial result immediately with computed metrics\n        setAutoLevelResult({\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n          rationaleBullets: ['Analyzing form patterns...'],\n        });\n\n        // PHASE 4: Generate guidance keyframes (don't wait for Gemini)\n        const guidance = generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        // Now await Gemini in background and update when ready\n        geminiPromise.then(levelResult => {\n          console.log('[PERF] Gemini analysis complete, updating UI...');\n          const finalLevel = {\n            ...levelResult,\n            level: skillResult.levelLabel,\n            confidence: skillResult.confidencePercent / 100,\n          };\n          setAutoLevelResult(finalLevel);\n\n          // Update guidance if Gemini provided better keyframes\n          if (levelResult.guidanceKeyframes && levelResult.guidanceKeyframes.length > 0) {\n            setGuidanceKeyframes(levelResult.guidanceKeyframes);\n          }\n        }).catch(err => {\n          console.warn('[PERF] Gemini API failed, using computed metrics only:', err);\n        });\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        // PERFORMANCE FIX: Mark as DONE immediately so UI is responsive\n        setAnalysisState('DONE');\n        console.log('[PERF] Analysis UI complete, saving to database in background...');\n\n        // PERFORMANCE FIX: Save to database in background (non-blocking)\n        const initialLevel = {\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n          rationaleBullets: [],\n        };\n        saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, initialLevel, mistakes, ghost.bestRepWindow)\n          .then(saveResult => {\n            if (!saveResult.success) {\n              console.error('[PERF] Database save failed:', saveResult.error);\n              setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n            } else {\n              console.log('[PERF] Database save complete');\n            }\n          })\n          .catch(err => {\n            console.error('[PERF] Database save error:', err);\n          });\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      // FIX 2: Enhanced skeleton rendering with better visuals\n      const renderOptions: RenderOptions = {\n        offsetX,\n        offsetY,\n        renderWidth,\n        renderHeight,\n      };\n\n      // TASK 1: Store current landmarks for click detection\n      lastDetectedPosesRef.current = [closestFrame.landmarks];\n\n      // Determine form quality for color coding\n      const formQuality: 'excellent' | 'good' | 'needsWork' | 'poor' =\n        bandedResult.overall_band === 'green' ? 'excellent' :\n        bandedResult.overall_band === 'yellow' ? 'good' :\n        bandedResult.overall_score > 40 ? 'needsWork' : 'poor';\n\n      // Draw the user's skeleton with enhanced styling\n      drawUserSkeleton(ctx, closestFrame.landmarks, formQuality, renderOptions);\n\n      // TASK 1: Draw selection indicator if in selection mode or subject is locked\n      const isLocked = manuallyLockedSubject !== null;\n      if (isSubjectSelectionMode || isLocked) {\n        drawSelectionIndicator(\n          ctx,\n          closestFrame.landmarks,\n          renderOptions,\n          isLocked,\n          isSubjectSelectionMode\n        );\n      }\n\n      // V5 REFACTOR: Ghost overlay REMOVED from main canvas\n      // Ghost visualization has been moved to Compare Mode in the Detected Issues panel\n      // See CompareMode component for side-by-side User vs Target pose comparison\n      // The ghostData is still computed and available for use in Compare Mode\n\n      // FIX 4: Draw motion path if enabled (shows racket trajectory)\n      if (showMotionPath && poseData.length > 10) {\n        const frameIndex = Math.floor(video.currentTime * 10);\n        const startFrame = Math.max(0, frameIndex - 15);\n        const endFrame = Math.min(poseData.length - 1, frameIndex);\n        const trajectoryPoints = extractRacketTrajectory(poseData, startFrame, endFrame);\n\n        if (trajectoryPoints.length > 2) {\n          drawMotionPath(ctx, trajectoryPoints, renderOptions);\n        }\n      }\n\n      // V5: Debug overlay for tracking visualization\n      if (showDebugOverlay && backendTrackingData) {\n        const currentFrameIdx = Math.floor(video.currentTime * fps);\n        const frame = backendTrackingData[currentFrameIdx];\n\n        if (frame) {\n          frame.tracks.forEach((track: any) => {\n            const isSelected = selectedTrackIds.includes(track.track_id);\n            const bbox = track.bbox;\n\n            // Draw bounding box\n            ctx.strokeStyle = isSelected ? '#00ff00' : '#ff6b6b';\n            ctx.lineWidth = isSelected ? 3 : 2;\n            ctx.setLineDash(isSelected ? [] : [5, 5]);\n            ctx.strokeRect(\n              renderOptions.offsetX + bbox.x * renderOptions.renderWidth,\n              renderOptions.offsetY + bbox.y * renderOptions.renderHeight,\n              bbox.w * renderOptions.renderWidth,\n              bbox.h * renderOptions.renderHeight\n            );\n            ctx.setLineDash([]);\n\n            // Draw track ID label\n            const labelX = renderOptions.offsetX + bbox.x * renderOptions.renderWidth + 4;\n            const labelY = renderOptions.offsetY + bbox.y * renderOptions.renderHeight + 16;\n\n            ctx.fillStyle = isSelected ? 'rgba(0, 255, 0, 0.8)' : 'rgba(255, 107, 107, 0.8)';\n            ctx.fillRect(labelX - 2, labelY - 12, 50, 16);\n\n            ctx.fillStyle = '#000000';\n            ctx.font = 'bold 11px monospace';\n            ctx.fillText(`ID: ${track.track_id}`, labelX, labelY);\n\n            // Draw confidence\n            if (track.confidence) {\n              ctx.fillStyle = '#ffffff';\n              ctx.font = '10px monospace';\n              ctx.fillText(`${Math.round(track.confidence * 100)}%`, labelX, labelY + 12);\n            }\n          });\n\n          // Draw frame info overlay\n          ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';\n          ctx.fillRect(10, 10, 150, 50);\n          ctx.fillStyle = '#00ff00';\n          ctx.font = 'bold 12px monospace';\n          ctx.fillText(`Frame: ${currentFrameIdx}`, 15, 28);\n          ctx.fillText(`Tracks: ${frame.tracks.length}`, 15, 44);\n          ctx.fillText(`Selected: ${selectedTrackIds.join(', ') || 'None'}`, 15, 58);\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData, showMotionPath, isSubjectSelectionMode, manuallyLockedSubject, showDebugOverlay, backendTrackingData, selectedTrackIds, fps]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // TASK 1: Handle canvas click for subject selection\n  const handleCanvasClick = useCallback((e: React.MouseEvent<HTMLCanvasElement>) => {\n    if (!isSubjectSelectionMode || !canvasRef.current || !videoContainerRef.current) return;\n\n    const canvas = canvasRef.current;\n    const rect = canvas.getBoundingClientRect();\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    // Get click position relative to canvas\n    const clickX = e.clientX - rect.left;\n    const clickY = e.clientY - rect.top;\n\n    // Calculate video render area (accounting for letterboxing)\n    const video = videoRef.current;\n    if (!video || video.videoWidth === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n    if (videoAspect > containerAspect) {\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Convert to normalized coordinates (0-1)\n    const normalizedX = (clickX - offsetX) / renderWidth;\n    const normalizedY = (clickY - offsetY) / renderHeight;\n\n    // Check if click is within video bounds\n    if (normalizedX < 0 || normalizedX > 1 || normalizedY < 0 || normalizedY > 1) return;\n\n    // Find which pose was clicked\n    const allPoses = lastDetectedPosesRef.current;\n    if (allPoses.length === 0) return;\n\n    const clickedPoseIndex = findPoseAtClick(allPoses, normalizedX, normalizedY, 0.1);\n\n    if (clickedPoseIndex >= 0) {\n      // Lock to this subject\n      subjectLockRef.current = setManualLock(\n        subjectLockRef.current,\n        clickedPoseIndex,\n        allPoses[clickedPoseIndex]\n      );\n      setManuallyLockedSubject(clickedPoseIndex);\n      setIsSubjectSelectionMode(false);\n      setTimeout(renderFrame, 50);\n    }\n  }, [isSubjectSelectionMode, renderFrame]);\n\n  // TASK 1: Clear subject lock and allow re-selection\n  const handleClearSubjectLock = useCallback(() => {\n    subjectLockRef.current = clearManualLock(subjectLockRef.current);\n    setManuallyLockedSubject(null);\n    setTimeout(renderFrame, 50);\n  }, [renderFrame]);\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* TASK 1: Selection Mode Banner */}\n                  {isSubjectSelectionMode && (\n                    <div className=\"bg-cyan-600 text-white px-4 py-3 flex items-center justify-between\">\n                      <div className=\"flex items-center gap-2\">\n                        <span className=\"w-3 h-3 rounded-full bg-white animate-pulse\" />\n                        <span className=\"font-medium\">Click on a player to track</span>\n                      </div>\n                      <span className=\"text-sm opacity-80\">\n                        The selected player will be tracked throughout the video\n                      </span>\n                    </div>\n                  )}\n\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      onClick={handleCanvasClick}\n                      className={`absolute inset-0 w-full h-full ${\n                        isSubjectSelectionMode ? 'cursor-crosshair' : 'pointer-events-none'\n                      } ${showSkeleton ? '' : 'hidden'}`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n\n                      {/* Player selection removed - player is indicated by green square on video */}\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* FIX 2 + TASK 2: Enhanced Ghost overlay toggle with context-awareness indicator */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              const enabled = e.target.checked;\n                              setShowGhost(enabled);\n                              // Enable/disable the ghost data\n                              if (ghostData) {\n                                setGhostData({ ...ghostData, enabled });\n                              }\n                              if (enabled) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400 flex items-center gap-1\">\n                            <span className=\"w-2 h-2 rounded-full bg-cyan-400 animate-pulse\" style={{ boxShadow: '0 0 8px #00d4ff' }} />\n                            {selectedMistake ? (\n                              <span className=\"flex items-center gap-1\">\n                                Ghost <span className=\"text-xs opacity-75\">(Correct {selectedMistake.summaryTitle.split(' ')[0]})</span>\n                              </span>\n                            ) : (\n                              'Ghost (Best Rep)'\n                            )}\n                          </span>\n                        </label>\n                      )}\n\n                      {/* FIX 4: Motion Path toggle */}\n                      {poseData.length > 10 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showMotionPath}\n                            onChange={(e) => {\n                              setShowMotionPath(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-orange-400\"\n                          />\n                          <span className=\"text-orange-400\">Motion Trail</span>\n                        </label>\n                      )}\n\n                      {/* V5: Debug Overlay toggle (only when backend tracking is available) */}\n                      {useBackendTracking && backendTrackingData && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showDebugOverlay}\n                            onChange={(e) => {\n                              setShowDebugOverlay(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-purple-400\"\n                          />\n                          <span className=\"text-purple-400\">Debug Tracking</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <div className=\"flex items-center gap-2\">\n                        {/* V5: Compare Mode button */}\n                        {ghostData && (\n                          <button\n                            onClick={() => {\n                              setCompareMistake(selectedMistake);\n                              setShowCompareMode(true);\n                            }}\n                            className=\"px-3 py-1 text-sm bg-cyan-500 hover:bg-cyan-600 text-white rounded-lg flex items-center gap-1 transition-colors\"\n                          >\n                            <svg className=\"w-4 h-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z\" />\n                            </svg>\n                            Compare\n                          </button>\n                        )}\n                        {/* V5: 3D Sandbox button */}\n                        {poseData.length > 0 && (\n                          <button\n                            onClick={() => setShow3DSandbox(!show3DSandbox)}\n                            className={`px-3 py-1 text-sm rounded-lg flex items-center gap-1 transition-colors ${\n                              show3DSandbox\n                                ? 'bg-purple-600 text-white'\n                                : 'bg-purple-500 hover:bg-purple-600 text-white'\n                            }`}\n                          >\n                            <svg className=\"w-4 h-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14 10l-2 1m0 0l-2-1m2 1v2.5M20 7l-2 1m2-1l-2-1m2 1v2.5M14 4l-2-1-2 1M4 7l2-1M4 7l2 1M4 7v2.5M12 21l-2-1m2 1l2-1m-2 1v-2.5M6 18l-2-1v-2.5M18 18l2-1v-2.5\" />\n                            </svg>\n                            3D View\n                          </button>\n                        )}\n                        <button\n                          onClick={() => setSelectedMistake(null)}\n                          className=\"text-sm text-gray-500 hover:text-gray-700\"\n                        >\n                          Close\n                        </button>\n                      </div>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n\n                    {/* V5: 3D Pose Sandbox */}\n                    {show3DSandbox && poseData.length > 0 && (\n                      <div className=\"mt-4\">\n                        <PoseSandbox3D\n                          mistake={selectedMistake}\n                          userPose={poseData[Math.floor(selectedMistake.startTimeSec * fps)] || []}\n                          correctPose={ghostData?.poseSequence?.[0]?.landmarks}\n                          fixKeyframes={generateFixKeyframes(selectedMistake, poseData, fps)}\n                          onClose={() => setShow3DSandbox(false)}\n                        />\n                      </div>\n                    )}\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* FIX 3 & 4: Enhanced Movement Guidance with Animated Corrections & Motion Paths */}\n                {poseData.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Analysis\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <MovementGuidance\n                        poseHistory={poseData}\n                        currentMistake={selectedMistake}\n                        width={340}\n                        height={280}\n                        showTrajectory={true}\n                        showCorrection={!!selectedMistake}\n                      />\n                    )}\n                    {/* Compact trajectory preview when guidance is hidden */}\n                    {!showGuidance && poseData.length > 10 && (\n                      <div className=\"mt-2\">\n                        <p className=\"text-xs text-gray-500 mb-2\">Racket Trajectory</p>\n                        <TrajectoryPreview poseHistory={poseData} width={200} height={60} />\n                      </div>\n                    )}\n                  </div>\n                )}\n\n                {/* Legacy Guidance Animation (fallback) */}\n                {guidanceKeyframes.length > 0 && !poseData.length && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Form Guidance</h3>\n                    </div>\n                    <GuidanceAnimation\n                      keyframes={guidanceKeyframes}\n                      primaryIssue={issues[0]}\n                    />\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                      // V4 state reset\n                      setGhostData(null);\n                      setShowGhost(false);\n                      setComputedSkill(null);\n                      setMistakeEvents([]);\n                      setSelectedMistake(null);\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                    // V4 state reset\n                    setGhostData(null);\n                    setShowGhost(false);\n                    setComputedSkill(null);\n                    setMistakeEvents([]);\n                    setSelectedMistake(null);\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n          // V4 state reset\n          setGhostData(null);\n          setShowGhost(false);\n          setComputedSkill(null);\n          setMistakeEvents([]);\n          setSelectedMistake(null);\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n\n      {/* V5: Compare Mode Modal */}\n      {showCompareMode && compareMistake && ghostData && (\n        <CompareMode\n          mistake={compareMistake}\n          userPoseAtMistake={\n            poseData[Math.floor(compareMistake.startTimeSec * fps)] || []\n          }\n          ghostData={ghostData}\n          allPoseData={poseData}\n          fps={fps}\n          onClose={() => {\n            setShowCompareMode(false);\n            setCompareMistake(null);\n          }}\n        />\n      )}\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":2493,"oldLines":68,"newStart":2493,"newLines":27,"lines":["                   </div>","                 )}"," ","-                {/* V4 FEATURE: FixItCard for selected mistake */}","+                {/* V4 FEATURE: 3D Pose View for selected mistake - DIRECTLY SHOWS 3D */}","                 {selectedMistake && (","                   <div className=\"mt-6\">","                     <div className=\"flex items-center justify-between mb-3\">","                       <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>","-                      <div className=\"flex items-center gap-2\">","-                        {/* V5: Compare Mode button */}","-                        {ghostData && (","-                          <button","-                            onClick={() => {","-                              setCompareMistake(selectedMistake);","-                              setShowCompareMode(true);","-                            }}","-                            className=\"px-3 py-1 text-sm bg-cyan-500 hover:bg-cyan-600 text-white rounded-lg flex items-center gap-1 transition-colors\"","-                          >","-                            <svg className=\"w-4 h-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">","-                              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z\" />","-                            </svg>","-                            Compare","-                          </button>","-                        )}","-                        {/* V5: 3D Sandbox button */}","-                        {poseData.length > 0 && (","-                          <button","-                            onClick={() => setShow3DSandbox(!show3DSandbox)}","-                            className={`px-3 py-1 text-sm rounded-lg flex items-center gap-1 transition-colors ${","-                              show3DSandbox","-                                ? 'bg-purple-600 text-white'","-                                : 'bg-purple-500 hover:bg-purple-600 text-white'","-                            }`}","-                          >","-                            <svg className=\"w-4 h-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">","-                              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14 10l-2 1m0 0l-2-1m2 1v2.5M20 7l-2 1m2-1l-2-1m2 1v2.5M14 4l-2-1-2 1M4 7l2-1M4 7l2 1M4 7v2.5M12 21l-2-1m2 1l2-1m-2 1v-2.5M6 18l-2-1v-2.5M18 18l2-1v-2.5\" />","-                            </svg>","-                            3D View","-                          </button>","-                        )}","-                        <button","-                          onClick={() => setSelectedMistake(null)}","-                          className=\"text-sm text-gray-500 hover:text-gray-700\"","-                        >","-                          Close","-                        </button>","-                      </div>","+                      <button","+                        onClick={() => setSelectedMistake(null)}","+                        className=\"text-sm text-gray-500 hover:text-gray-700\"","+                      >","+                        Close","+                      </button>","                     </div>","-                    <FixItCard","-                      mistake={selectedMistake}","-                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}","-                      onClose={() => setSelectedMistake(null)}","-                    />","-","-                    {/* V5: 3D Pose Sandbox */}","-                    {show3DSandbox && poseData.length > 0 && (","-                      <div className=\"mt-4\">","-                        <PoseSandbox3D","-                          mistake={selectedMistake}","-                          userPose={poseData[Math.floor(selectedMistake.startTimeSec * fps)] || []}","-                          correctPose={ghostData?.poseSequence?.[0]?.landmarks}","-                          fixKeyframes={generateFixKeyframes(selectedMistake, poseData, fps)}","-                          onClose={() => setShow3DSandbox(false)}","-                        />","-                      </div>","+                    {/* Show 3D directly - no 2D FixItCard */}","+                    {poseData.length > 0 && (","+                      <PoseSandbox3D","+                        mistake={selectedMistake}","+                        userPose={poseData[Math.floor(selectedMistake.startTimeSec * fps)] || []}","+                        correctPose={ghostData?.poseSequence?.[0]?.landmarks}","+                        fixKeyframes={generateFixKeyframes(selectedMistake, poseData, fps)}","+                        onClose={() => setSelectedMistake(null)}","+                      />","                     )}","                   </div>","                 )}"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"247f3745-7bd9-4f77-b513-bfb8ca3651a7"}
{"parentUuid":"b49d8fe8-9506-4c5a-9ed6-bb8359c9d82f","isSidechain":true,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"76bbf198-1368-4e95-b3ae-c78d5752159d","version":"2.1.29","gitBranch":"","agentId":"acompact-ec6179","slug":"linear-jumping-quill","type":"user","message":{"role":"user","content":"Your task is to create a detailed summary of the conversation so far, paying close attention to the user's explicit requests and your previous actions.\nThis summary should be thorough in capturing technical details, code patterns, and architectural decisions that would be essential for continuing development work without losing context.\n\nBefore providing your final summary, wrap your analysis in <analysis> tags to organize your thoughts and ensure you've covered all necessary points. In your analysis process:\n\n1. Chronologically analyze each message and section of the conversation. For each section thoroughly identify:\n   - The user's explicit requests and intents\n   - Your approach to addressing the user's requests\n   - Key decisions, technical concepts and code patterns\n   - Specific details like:\n     - file names\n     - full code snippets\n     - function signatures\n     - file edits\n  - Errors that you ran into and how you fixed them\n  - Pay special attention to specific user feedback that you received, especially if the user told you to do something differently.\n2. Double-check for technical accuracy and completeness, addressing each required element thoroughly.\n\nYour summary should include the following sections:\n\n1. Primary Request and Intent: Capture all of the user's explicit requests and intents in detail\n2. Key Technical Concepts: List all important technical concepts, technologies, and frameworks discussed.\n3. Files and Code Sections: Enumerate specific files and code sections examined, modified, or created. Pay special attention to the most recent messages and include full code snippets where applicable and include a summary of why this file read or edit is important.\n4. Errors and fixes: List all errors that you ran into, and how you fixed them. Pay special attention to specific user feedback that you received, especially if the user told you to do something differently.\n5. Problem Solving: Document problems solved and any ongoing troubleshooting efforts.\n6. All user messages: List ALL user messages that are not tool results. These are critical for understanding the users' feedback and changing intent.\n6. Pending Tasks: Outline any pending tasks that you have explicitly been asked to work on.\n7. Current Work: Describe in detail precisely what was being worked on immediately before this summary request, paying special attention to the most recent messages from both user and assistant. Include file names and code snippets where applicable.\n8. Optional Next Step: List the next step that you will take that is related to the most recent work you were doing. IMPORTANT: ensure that this step is DIRECTLY in line with the user's most recent explicit requests, and the task you were working on immediately before this summary request. If your last task was concluded, then only list next steps if they are explicitly in line with the users request. Do not start on tangential requests or really old requests that were already completed without confirming with the user first.\n                       If there is a next step, include direct quotes from the most recent conversation showing exactly what task you were working on and where you left off. This should be verbatim to ensure there's no drift in task interpretation.\n\nHere's an example of how your output should be structured:\n\n<example>\n<analysis>\n[Your thought process, ensuring all points are covered thoroughly and accurately]\n</analysis>\n\n<summary>\n1. Primary Request and Intent:\n   [Detailed description]\n\n2. Key Technical Concepts:\n   - [Concept 1]\n   - [Concept 2]\n   - [...]\n\n3. Files and Code Sections:\n   - [File Name 1]\n      - [Summary of why this file is important]\n      - [Summary of the changes made to this file, if any]\n      - [Important Code Snippet]\n   - [File Name 2]\n      - [Important Code Snippet]\n   - [...]\n\n4. Errors and fixes:\n    - [Detailed description of error 1]:\n      - [How you fixed the error]\n      - [User feedback on the error if any]\n    - [...]\n\n5. Problem Solving:\n   [Description of solved problems and ongoing troubleshooting]\n\n6. All user messages: \n    - [Detailed non tool use user message]\n    - [...]\n\n7. Pending Tasks:\n   - [Task 1]\n   - [Task 2]\n   - [...]\n\n8. Current Work:\n   [Precise description of current work]\n\n9. Optional Next Step:\n   [Optional Next step to take]\n\n</summary>\n</example>\n\nPlease provide your summary based on the conversation so far, following this structure and ensuring precision and thoroughness in your response. \n\nThere may be additional summarization instructions provided in the included context. If so, remember to follow these instructions when creating the above summary. Examples of instructions include:\n<example>\n## Compact Instructions\nWhen summarizing the conversation focus on typescript code changes and also remember the mistakes you made and how you fixed them.\n</example>\n\n<example>\n# Summary instructions\nWhen you are using compact - please focus on test output and code changes. Include file reads verbatim.\n</example>\n\n\nIMPORTANT: Do NOT use any tools. You MUST respond with ONLY the <summary>...</summary> block as your text output."},"uuid":"b50771cd-fae4-4997-b1dd-3c2c561b60e4","timestamp":"2026-02-02T22:09:59.373Z"}
{"parentUuid":"b50771cd-fae4-4997-b1dd-3c2c561b60e4","isSidechain":true,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"76bbf198-1368-4e95-b3ae-c78d5752159d","version":"2.1.29","gitBranch":"","agentId":"acompact-ec6179","slug":"linear-jumping-quill","message":{"model":"claude-opus-4-5-20251101","id":"msg_017JtEo9kRE4fp1LpvxW3vUr","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me analyze the conversation chronologically to create a comprehensive summary.\n\n1. Initial Request: The user reported multiple problems with a RallyCoach AI Badminton Coach application:\n   - Problem 1: TUS upload error (413 - file size exceeds limit)\n   - Problem 2: Player Locked button on controller is redundant\n   - Problem 3: 3D Pose View transition animation too fast\n   - Problem 4: Movement Guidance should be 3D (currently 2D)\n   - Problem 5: Detected Issues animation too small\n\n2. I explored the codebase and identified all relevant files.\n\n3. I created tasks and fixed each problem:\n   - Task 1: Fixed file upload 413 error by reducing max size to 50MB and adding better error messages\n   - Task 2: Removed Player Locked button from video controller\n   - Task 3: Slowed down 3D Pose View animation and showed two separate skeletons\n   - Task 4: Converted Movement Guidance to 3D with slower animation\n   - Task 5: Enlarged Detected Issues animation with bigger joints and slower phases\n\n4. User reported UI delay issue - after backend returns 200 OK, there's a delay before skeleton appears.\n\n5. I investigated and found the root cause: synchronous processing chain blocking UI updates. Fixed by:\n   - Adding yield points (setTimeout) after setPoseData\n   - Making Gemini API call non-blocking\n   - Making database save non-blocking\n\n6. User then reported more problems (second set):\n   - Problem 1: \"Fix This Mistake\" shows 2D, should show 3D directly. Remove Compare button.\n   - Problem 2: 3D Pose View skeleton connections wrong, animation too fast, \"Show target pose\" checkbox doesn't work\n   - Problem 3: Movement Guidance shows 2D, should show 3D only\n   - Problem 4: UI delay after \"Subject lock confirmed\" - still too slow\n   - Problem 5: Remove Ghost toggle from video controller\n\n7. I created tasks 6-10 for these new problems and started working on Task 6.\n\n8. I edited the analytics page to remove the Compare button and display PoseSandbox3D directly instead of FixItCard. The remaining tasks involve fixing the 3D Pose View skeleton connections and animation speed, converting Movement Guidance to 3D-only, addressing the UI delay issue, and removing the Ghost toggle from the controller.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":151390,"cache_read_input_tokens":18585,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":151390},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXk1MsoXDwBfcy5n1FRZk","type":"assistant","uuid":"bd3207bb-bcbd-49d9-8eaa-6ca0710c1704","timestamp":"2026-02-02T22:10:22.969Z"}
{"parentUuid":"bd3207bb-bcbd-49d9-8eaa-6ca0710c1704","isSidechain":true,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"76bbf198-1368-4e95-b3ae-c78d5752159d","version":"2.1.29","gitBranch":"","agentId":"acompact-ec6179","slug":"linear-jumping-quill","message":{"model":"claude-opus-4-5-20251101","id":"msg_017JtEo9kRE4fp1LpvxW3vUr","type":"message","role":"assistant","content":[{"type":"text","text":"<summary>\n1. Primary Request and Intent:\n   The user is developing a RallyCoach AI Badminton Coach application and needs multiple bugs and UX issues fixed. The initial request covered 5 problems: file upload 413 error, redundant Player Locked button, 3D Pose View animation too fast, Movement Guidance needs 3D, and Detected Issues animation too small. After initial fixes, the user reported a UI delay issue and then a second batch of problems: \"Fix This Mistake\" section showing 2D instead of 3D, 3D Pose View skeleton connections wrong, Movement Guidance still showing 2D, UI delay after subject lock, and Ghost toggle needing removal.\n\n2. Key Technical Concepts:\n   - React Three Fiber / Three.js for 3D skeleton visualization\n   - MediaPipe pose detection with 33 landmarks\n   - Supabase storage with TUS resumable uploads\n   - Progressive rendering with setTimeout yields to prevent UI blocking\n   - Non-blocking API calls using Promise.then() instead of await\n   - Canvas 2D rendering for pose skeletons\n   - React state management for complex multi-component UI\n\n3. Files and Code Sections:\n\n   - **`rallycoach/src/lib/supabase.ts`** - Video upload handling\n     - Reduced MAX_FILE_SIZE from 100MB to 50MB\n     - Added formatFileSize() helper\n     - Improved error messages for 413 errors\n     ```javascript\n     const MAX_FILE_SIZE = 50 * 1024 * 1024; // 50MB max file size (Supabase free tier limit)\n     \n     function formatFileSize(bytes: number): string {\n       if (bytes < 1024) return bytes + ' B';\n       if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(1) + ' KB';\n       return (bytes / (1024 * 1024)).toFixed(1) + ' MB';\n     }\n     ```\n\n   - **`rallycoach/src/app/analytics/page.tsx`** - Main analytics page\n     - Removed Player Locked button section (lines ~2283-2329)\n     - Added performance yield points after setPoseData\n     - Made Gemini API call non-blocking with .then()\n     - Made database save non-blocking\n     - Most recently: Removed Compare button and FixItCard, replaced with direct PoseSandbox3D:\n     ```javascript\n     {/* V4 FEATURE: 3D Pose View for selected mistake - DIRECTLY SHOWS 3D */}\n     {selectedMistake && (\n       <div className=\"mt-6\">\n         <div className=\"flex items-center justify-between mb-3\">\n           <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n           <button onClick={() => setSelectedMistake(null)} className=\"text-sm text-gray-500 hover:text-gray-700\">\n             Close\n           </button>\n         </div>\n         {poseData.length > 0 && (\n           <PoseSandbox3D\n             mistake={selectedMistake}\n             userPose={poseData[Math.floor(selectedMistake.startTimeSec * fps)] || []}\n             correctPose={ghostData?.poseSequence?.[0]?.landmarks}\n             fixKeyframes={generateFixKeyframes(selectedMistake, poseData, fps)}\n             onClose={() => setSelectedMistake(null)}\n           />\n         )}\n       </div>\n     )}\n     ```\n\n   - **`rallycoach/src/components/PoseSandbox3D.tsx`** - 3D pose visualization\n     - Slowed animation from p + 0.02 to p + 0.005\n     - Changed to side-by-side view with Current Form (left, red) and Target Form (right, green)\n     - Added HTML labels for each skeleton\n     - Increased canvas height from 400px to 450px\n\n   - **`rallycoach/src/components/MovementGuidance.tsx`** - Movement guidance display\n     - Added Three.js imports and 3D components (LowerBodySkeleton3D, Joint3D, Bone3D)\n     - Slowed animation from 2500ms to 6000ms\n     - Added 3D/2D toggle button\n     - Added enable3D prop defaulting to true\n\n   - **`rallycoach/src/components/FixItCard.tsx`** - Detected issues animation\n     - Increased canvas from 200x240 to 320x400\n     - Slowed phase duration from 1500ms to 3500ms\n     - Increased joint radius from 6/5/3 to 12/10/8/5\n     - Thicker bones (lineWidth 57 for arms)\n     - Added glow effect for elbow joints\n\n4. Errors and Fixes:\n   - **413 Upload Error**: File size exceeded Supabase free tier 50MB limit. Fixed by reducing MAX_FILE_SIZE to 50MB and improving error messages.\n   - **UI Delay Issue**: Synchronous processing chain blocked React rendering. Fixed by adding setTimeout yields between heavy computations and making Gemini API/database saves non-blocking.\n   - **User feedback**: Animation speeds still too fast, 2D views should be replaced with 3D entirely, skeleton connections wrong in 3D view.\n\n5. Problem Solving:\n   - Investigated performance delay using systematic debugging approach\n   - Identified bottlenecks: detectMistakes() (13,181 function calls), computeSkillScore() (22,596+ operations), initializeGhostRival(), and blocking Gemini API call\n   - Implemented progressive rendering with yield points\n\n6. All User Messages:\n   - Initial message listing 5 problems: file upload error, redundant Player Locked button, 3D Pose View too fast, Movement Guidance needs 3D, Detected Issues animation too small\n   - Delay issue report: Backend returns 200 OK but UI takes time to show skeleton\n   - Second batch of problems: \"Fix This Mistake\" should show 3D only (delete Compare), 3D Pose View skeleton connections wrong and animation too fast and \"Show target pose\" doesn't work, Movement Guidance shows 2D should be 3D only, UI delay after \"Subject lock confirmed\", remove Ghost toggle from video controller\n\n7. Pending Tasks:\n   - Task #6: Fix FixItCard to show 3D only and remove Compare button (IN PROGRESS - partially done)\n   - Task #7: Fix PoseSandbox3D skeleton connections and slow animation\n   - Task #8: Fix Movement Guidance to show 3D only  \n   - Task #9: Fix UI delay after subject lock confirmed\n   - Task #10: Remove Ghost toggle from video controller\n\n8. Current Work:\n   Working on Task #6 - \"Fix FixItCard to show 3D only and remove Compare button\". Just completed editing `analytics/page.tsx` to remove the Compare button and replace FixItCard (2D) with direct PoseSandbox3D rendering. The edit removed approximately 40 lines of code including the Compare button, 3D View toggle button, and FixItCard component.\n\n9. Optional Next Step:\n   Continue with Task #7: Fix PoseSandbox3D skeleton connections and slow animation. User stated: \"in '3D Pose View' (you can see from Image #5) it does not connect each body tightly, even wrong. I want it to be connected each part right. Moreover, as you can see 'Animate Correction' button. When I click the button, it shows very very fast animation from wrong to correct. I want to be much much slower, slower till people can see what happen. Besides, the 'show target pose' this block does not work and not connected to any function.\"\n\n   This requires fixing POSE_CONNECTIONS in PoseSandbox3D.tsx, further slowing the animation, and making the \"Show target pose\" checkbox functional.\n</summary>"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":151390,"cache_read_input_tokens":18585,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":151390},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXk1MsoXDwBfcy5n1FRZk","type":"assistant","uuid":"bd9c3053-097b-4510-ac1e-46677130d749","timestamp":"2026-02-02T22:10:53.422Z"}
