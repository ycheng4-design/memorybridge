     1→'use client';
     2→
     3→import { useState, useEffect, useRef, useCallback, Suspense } from 'react';
     4→import { useSearchParams } from 'next/navigation';
     5→import Link from 'next/link';
     6→import DashboardNav from '@/components/DashboardNav';
     7→import DrillCard from '@/components/DrillCard';
     8→import { TabbedDrillAnimation } from '@/components/Skeleton3D';
     9→import PlayerSelectionModal from '@/components/PlayerSelectionModal';
    10→import GuidanceAnimation from '@/components/GuidanceAnimation';
    11→import { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';
    12→import {
    13→  drawSkeleton,
    14→  extractMetrics,
    15→  POSE_CONNECTIONS,
    16→  POSE_LANDMARKS
    17→} from '@/lib/pose-utils';
    18→import {
    19→  DRILLS,
    20→  FORM_RULES,
    21→  evaluateForm,
    22→  findViolationTimestamps,
    23→  type EvaluationResult
    24→} from '@/lib/rules-engine';
    25→import {
    26→  evaluateWithBands,
    27→  SCORING_LEGEND,
    28→  SKILL_LEVEL_DESCRIPTIONS,
    29→  validateSessionPoseData,
    30→} from '@/lib/scoring-rules';
    31→import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData } from '@/lib/types';
    32→
    33→// MediaPipe Types
    34→type PoseLandmarker = any;
    35→
    36→interface FrameAnalysis {
    37→  timestamp: number;
    38→  landmarks: PoseLandmark[] | null;
    39→  evaluation: EvaluationResult | null;
    40→  metrics: PoseMetrics | null;
    41→}
    42→
    43→interface DetectedIssue {
    44→  code: string;
    45→  title: string;
    46→  severity: 'low' | 'medium' | 'high';
    47→  description?: string;
    48→  timestamps: number[];
    49→  drill?: any;
    50→}
    51→
    52→// PHASE 5: Analysis state machine
    53→type AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';
    54→
    55→// PHASE 3: Auto-level detection result from Gemini
    56→interface AutoLevelResult {
    57→  level: 'Beginner' | 'Intermediate' | 'Advanced';
    58→  confidence: number;
    59→  rationaleBullets: string[];
    60→  guidanceKeyframes?: GuidanceKeyframe[];
    61→}
    62→
    63→// PHASE 4: Guidance keyframe for animation
    64→interface GuidanceKeyframe {
    65→  name: string;
    66→  description: string;
    67→  landmarks: PoseLandmark[] | null;
    68→  targetLandmarks?: PoseLandmark[] | null;
    69→  correction?: string;
    70→}
    71→
    72→function AnalyticsContent() {
    73→  const searchParams = useSearchParams();
    74→  const sessionId = searchParams.get('session');
    75→
    76→  // State
    77→  const [uploading, setUploading] = useState(false);
    78→  const [analyzing, setAnalyzing] = useState(false);
    79→  const [analyzeProgress, setAnalyzeProgress] = useState(0);
    80→  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');
    81→  const [analysisId, setAnalysisId] = useState<string | null>(null);
    82→  const [result, setResult] = useState<AnalysisResultJson | null>(null);
    83→  const [error, setError] = useState<string | null>(null);
    84→  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);
    85→  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);
    86→
    87→  // Multi-pose and player selection state
    88→  const [showPlayerSelection, setShowPlayerSelection] = useState(false);
    89→  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);
    90→  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);
    91→  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);
    92→  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');
    93→  const [eventType, setEventType] = useState<string>('');
    94→
    95→  // PHASE 3: Auto-level detection state (replaces manual skill level selector)
    96→  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);
    97→  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);
    98→
    99→  // PHASE 4: Guidance animation state
   100→  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);
   101→  const [showGuidance, setShowGuidance] = useState(false);
   102→
   103→  // Video playback state
   104→  const [videoUrl, setVideoUrl] = useState<string | null>(null);
   105→  const [videoFile, setVideoFile] = useState<File | null>(null);
   106→  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);
   107→  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);
   108→  const [issues, setIssues] = useState<DetectedIssue[]>([]);
   109→  const [currentTime, setCurrentTime] = useState(0);
   110→  const [duration, setDuration] = useState(0);
   111→  const [isPlaying, setIsPlaying] = useState(false);
   112→  const [showSkeleton, setShowSkeleton] = useState(true);
   113→  const [fps, setFps] = useState(30);
   114→
   115→  // PHASE 2: Canvas overlay alignment state
   116→  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);
   117→
   118→  // Pose detection
   119→  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);
   120→  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);
   121→
   122→  // PHASE 1: Timestamp tracking for monotonic enforcement
   123→  const lastTimestampMsRef = useRef<number>(-1);
   124→  const timestampBaseOffsetRef = useRef<number>(0);
   125→  const isProcessingRef = useRef<boolean>(false);
   126→
   127→  // Refs
   128→  const fileInputRef = useRef<HTMLInputElement>(null);
   129→  const videoRef = useRef<HTMLVideoElement>(null);
   130→  const canvasRef = useRef<HTMLCanvasElement>(null);
   131→  const videoContainerRef = useRef<HTMLDivElement>(null);
   132→  const processVideoRef = useRef<HTMLVideoElement | null>(null);
   133→  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);
   134→  const animationRef = useRef<number | null>(null);
   135→
   136→  // Initialize MediaPipe Pose Landmarker
   137→  useEffect(() => {
   138→    initializePoseLandmarker();
   139→    return () => {
   140→      cleanup();
   141→    };
   142→  }, []);
   143→
   144→  // Load session if ID provided
   145→  useEffect(() => {
   146→    if (sessionId) {
   147→      loadSession(sessionId);
   148→    }
   149→  }, [sessionId]);
   150→
   151→  // PHASE 2: Update canvas size on video resize
   152→  useEffect(() => {
   153→    const updateVideoRect = () => {
   154→      if (videoRef.current && videoContainerRef.current) {
   155→        const video = videoRef.current;
   156→        const container = videoContainerRef.current;
   157→
   158→        // Calculate the actual rendered video rectangle (accounting for object-contain)
   159→        const containerRect = container.getBoundingClientRect();
   160→        const videoAspect = video.videoWidth / video.videoHeight;
   161→        const containerAspect = containerRect.width / containerRect.height;
   162→
   163→        let renderWidth, renderHeight, offsetX, offsetY;
   164→
   165→        if (videoAspect > containerAspect) {
   166→          // Video is wider - letterbox top/bottom
   167→          renderWidth = containerRect.width;
   168→          renderHeight = containerRect.width / videoAspect;
   169→          offsetX = 0;
   170→          offsetY = (containerRect.height - renderHeight) / 2;
   171→        } else {
   172→          // Video is taller - letterbox left/right
   173→          renderHeight = containerRect.height;
   174→          renderWidth = containerRect.height * videoAspect;
   175→          offsetX = (containerRect.width - renderWidth) / 2;
   176→          offsetY = 0;
   177→        }
   178→
   179→        setVideoRect({
   180→          x: offsetX,
   181→          y: offsetY,
   182→          width: renderWidth,
   183→          height: renderHeight,
   184→          top: offsetY,
   185→          left: offsetX,
   186→          right: offsetX + renderWidth,
   187→          bottom: offsetY + renderHeight,
   188→          toJSON: () => ({})
   189→        } as DOMRect);
   190→      }
   191→    };
   192→
   193→    updateVideoRect();
   194→    window.addEventListener('resize', updateVideoRect);
   195→
   196→    return () => window.removeEventListener('resize', updateVideoRect);
   197→  }, [videoUrl]);
   198→
   199→  const initializePoseLandmarker = async () => {
   200→    try {
   201→      const vision = await import('@mediapipe/tasks-vision');
   202→      const { PoseLandmarker, FilesetResolver } = vision;
   203→
   204→      const filesetResolver = await FilesetResolver.forVisionTasks(
   205→        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
   206→      );
   207→
   208→      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {
   209→        baseOptions: {
   210→          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',
   211→          delegate: 'GPU',
   212→        },
   213→        runningMode: 'VIDEO',
   214→        numPoses: 4, // Support up to 4 players for doubles
   215→        minPoseDetectionConfidence: 0.5,
   216→        minPosePresenceConfidence: 0.5,
   217→        minTrackingConfidence: 0.5,
   218→      });
   219→
   220→      setPoseLandmarkerReady(true);
   221→    } catch (error) {
   222→      console.error('Failed to load MediaPipe Pose:', error);
   223→      // Continue without pose detection - will use fallback
   224→    }
   225→  };
   226→
   227→  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking
   228→  const recreatePoseLandmarker = async () => {
   229→    if (poseLandmarkerRef.current) {
   230→      poseLandmarkerRef.current.close();
   231→    }
   232→    lastTimestampMsRef.current = -1;
   233→    timestampBaseOffsetRef.current = 0;
   234→    await initializePoseLandmarker();
   235→  };
   236→
   237→  const cleanup = () => {
   238→    if (pollIntervalRef.current) {
   239→      clearInterval(pollIntervalRef.current);
   240→    }
   241→    if (animationRef.current) {
   242→      cancelAnimationFrame(animationRef.current);
   243→    }
   244→    if (poseLandmarkerRef.current) {
   245→      poseLandmarkerRef.current.close();
   246→    }
   247→  };
   248→
   249→  const loadSession = async (id: string) => {
   250→    try {
   251→      setAnalyzing(true);
   252→      setAnalysisState('EXTRACTING_POSE');
   253→
   254→      // Try new sessions table first
   255→      const { data: sessionData, error: sessionError } = await supabase
   256→        .from('sessions')
   257→        .select('*')
   258→        .eq('id', id)
   259→        .single();
   260→
   261→      if (sessionError) {
   262→        // Try legacy table
   263→        const { data: legacyData, error: legacyError } = await supabase
   264→          .from('analysis_results')
   265→          .select('*')
   266→          .eq('id', id)
   267→          .single();
   268→
   269→        if (legacyError) throw legacyError;
   270→        if (legacyData?.result_json) {
   271→          setResult(legacyData.result_json);
   272→          if (legacyData.result_json.video_url) {
   273→            setVideoUrl(legacyData.result_json.video_url);
   274→          }
   275→        }
   276→      } else if (sessionData) {
   277→        // New session format
   278→        setVideoUrl(sessionData.video_url);
   279→
   280→        if (sessionData.pose_data) {
   281→          setPoseData(sessionData.pose_data);
   282→        }
   283→
   284→        // Fetch issues
   285→        const { data: issuesData } = await supabase
   286→          .from('issues')
   287→          .select('*')
   288→          .eq('session_id', id);
   289→
   290→        if (issuesData && issuesData.length > 0) {
   291→          setIssues(issuesData.map((issue: any) => ({
   292→            code: issue.code,
   293→            title: issue.title,
   294→            severity: issue.severity,
   295→            description: issue.description,
   296→            timestamps: issue.timestamps || [],
   297→            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],
   298→          })));
   299→        }
   300→
   301→        // Build result from session summary
   302→        const summary = sessionData.summary || {};
   303→        setResult({
   304→          top_issues: issuesData?.map((i: any) => ({
   305→            id: i.id,
   306→            title: i.title,
   307→            severity: i.severity,
   308→            description: i.description,
   309→            affected_metrics: [],
   310→          })) || [],
   311→          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({
   312→            id: d.id,
   313→            name: d.name,
   314→            description: d.description,
   315→            duration_minutes: d.durationMinutes,
   316→            target_metrics: d.targetMetrics,
   317→            instructions: d.steps,
   318→          })) || [],
   319→          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',
   320→          strategy_summary: summary.feedback?.strategy_summary || '',
   321→          training_plan: [],
   322→        });
   323→      }
   324→      setAnalysisState('DONE');
   325→    } catch (err) {
   326→      console.error('Error loading session:', err);
   327→      setError('Failed to load session');
   328→      setAnalysisState('ERROR');
   329→    } finally {
   330→      setAnalyzing(false);
   331→    }
   332→  };
   333→
   334→  // PHASE 1 FIX: Process video with strictly monotonic timestamps
   335→  // Uses base offset approach to handle seeks without recreating PoseLandmarker
   336→  const processVideoWithPose = async (
   337→    videoElement: HTMLVideoElement,
   338→    selectedTracks: number[] = [0]
   339→  ): Promise<FrameAnalysis[]> => {
   340→    if (!poseLandmarkerRef.current) {
   341→      console.warn('Pose landmarker not ready');
   342→      return [];
   343→    }
   344→
   345→    // Prevent concurrent processing
   346→    if (isProcessingRef.current) {
   347→      console.warn('Already processing video, skipping');
   348→      return [];
   349→    }
   350→    isProcessingRef.current = true;
   351→
   352→    const analyses: FrameAnalysis[] = [];
   353→    const videoDuration = videoElement.duration;
   354→    const sampleRate = 10; // Process 10 frames per second
   355→    const totalFrames = Math.floor(videoDuration * sampleRate);
   356→
   357→    // PHASE 1: Reset timestamp tracking for fresh processing
   358→    // Use base offset approach so timestamps always increase even if we restart
   359→    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer
   360→    let localLastTimestamp = timestampBaseOffsetRef.current;
   361→
   362→    let validPoseFrames = 0;
   363→    let lowConfidenceFrames = 0;
   364→    let noPoseFrames = 0;
   365→
   366→    setAnalyzeProgress(10); // Start at 10% after track detection
   367→
   368→    for (let i = 0; i <= totalFrames; i++) {
   369→      const timestamp = i / sampleRate;
   370→      videoElement.currentTime = timestamp;
   371→
   372→      // Wait for video to seek
   373→      await new Promise<void>((resolve) => {
   374→        const onSeeked = () => {
   375→          videoElement.removeEventListener('seeked', onSeeked);
   376→          resolve();
   377→        };
   378→        videoElement.addEventListener('seeked', onSeeked);
   379→      });
   380→
   381→      // Give the video a moment to render the frame
   382→      await new Promise(resolve => setTimeout(resolve, 50));
   383→
   384→      try {
   385→        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp
   386→        // Use base offset + local timestamp to guarantee monotonic increase
   387→        const rawTimestampMs = Math.floor(timestamp * 1000);
   388→        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;
   389→
   390→        // Double-check monotonicity
   391→        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);
   392→        localLastTimestamp = safeTimestampMs;
   393→        lastTimestampMsRef.current = safeTimestampMs;
   394→
   395→        const results = poseLandmarkerRef.current.detectForVideo(
   396→          videoElement,
   397→          safeTimestampMs
   398→        );
   399→
   400→        let landmarks: PoseLandmark[] | null = null;
   401→        let evaluation: EvaluationResult | null = null;
   402→        let metrics: PoseMetrics | null = null;
   403→
   404→        if (results.landmarks && results.landmarks.length > 0) {
   405→          // Only use the selected player's landmarks
   406→          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length
   407→            ? selectedTracks[0]
   408→            : 0;
   409→
   410→          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({
   411→            x: lm.x,
   412→            y: lm.y,
   413→            z: lm.z,
   414→            visibility: lm.visibility ?? 1.0,
   415→          }));
   416→
   417→          if (landmarks && landmarks.length > 0) {
   418→            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;
   419→
   420→            if (avgVisibility < 0.5) {
   421→              lowConfidenceFrames++;
   422→            } else {
   423→              validPoseFrames++;
   424→            }
   425→            metrics = extractMetrics(landmarks);
   426→
   427→            // Use intermediate level for initial processing (auto-level will adjust later)
   428→            const bandedResult = evaluateWithBands(landmarks, 'intermediate');
   429→            evaluation = {
   430→              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',
   431→              score: bandedResult.overall_score,
   432→              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({
   433→                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,
   434→                value: 0,
   435→                feedback: f,
   436→              })) : [],
   437→              passedRules: [],
   438→              highlightJoints: bandedResult.highlight_joints,
   439→              recommendedDrills: [],
   440→            };
   441→          }
   442→        } else {
   443→          noPoseFrames++;
   444→        }
   445→
   446→        analyses.push({
   447→          timestamp,
   448→          landmarks,
   449→          evaluation,
   450→          metrics,
   451→        });
   452→      } catch (err) {
   453→        const errorMsg = err instanceof Error ? err.message : String(err);
   454→        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {
   455→          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);
   456→          // PHASE 1 FIX: On timestamp error, bump the base offset significantly
   457→          timestampBaseOffsetRef.current += 10000; // Add 10 seconds
   458→          localLastTimestamp = timestampBaseOffsetRef.current;
   459→        } else {
   460→          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);
   461→        }
   462→        analyses.push({
   463→          timestamp,
   464→          landmarks: null,
   465→          evaluation: null,
   466→          metrics: null,
   467→        });
   468→      }
   469→
   470→      // Update progress (10-70%)
   471→      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));
   472→    }
   473→
   474→    // PHASE 1: Log pose detection statistics
   475→    const totalProcessed = totalFrames + 1;
   476→    const validRatio = validPoseFrames / totalProcessed;
   477→    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);
   478→
   479→    if (validRatio < 0.3) {
   480→      console.warn('Low pose detection rate - video may have poor lighting or player not visible');
   481→    }
   482→
   483→    isProcessingRef.current = false;
   484→    return analyses;
   485→  };
   486→
   487→  // Detect issues from frame analyses
   488→  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {
   489→    const issueMap: Map<string, {
   490→      rule: any;
   491→      timestamps: number[];
   492→      count: number;
   493→    }> = new Map();
   494→
   495→    for (const frame of analyses) {
   496→      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {
   497→        for (const failed of frame.evaluation.failedRules) {
   498→          const code = failed.rule.code;
   499→          if (!issueMap.has(code)) {
   500→            issueMap.set(code, {
   501→              rule: failed.rule,
   502→              timestamps: [],
   503→              count: 0,
   504→            });
   505→          }
   506→          const issue = issueMap.get(code)!;
   507→          issue.timestamps.push(frame.timestamp);
   508→          issue.count++;
   509→        }
   510→      }
   511→    }
   512→
   513→    // Convert to array and sort by count
   514→    const issues: DetectedIssue[] = Array.from(issueMap.entries())
   515→      .map(([code, data]) => ({
   516→        code,
   517→        title: data.rule.name,
   518→        severity: data.rule.severity,
   519→        description: data.rule.description,
   520→        timestamps: data.timestamps,
   521→        drill: DRILLS[data.rule.drillId],
   522→      }))
   523→      .sort((a, b) => b.timestamps.length - a.timestamps.length)
   524→      .slice(0, 5); // Top 5 issues
   525→
   526→    return issues;
   527→  };
   528→
   529→  // PHASE 3: Auto-detect skill level using Gemini
   530→  const detectSkillLevelWithGemini = async (
   531→    analyses: FrameAnalysis[],
   532→    detectedIssues: DetectedIssue[]
   533→  ): Promise<AutoLevelResult> => {
   534→    setAnalysisState('GEMINI_SCORING');
   535→    setAnalyzeProgress(75);
   536→
   537→    try {
   538→      // Extract features for Gemini analysis
   539→      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);
   540→
   541→      if (validAnalyses.length < 5) {
   542→        // Fallback if not enough data
   543→        return {
   544→          level: 'Intermediate',
   545→          confidence: 0.5,
   546→          rationaleBullets: ['Insufficient pose data for accurate assessment'],
   547→        };
   548→      }
   549→
   550→      // Calculate aggregate metrics
   551→      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;
   552→      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;
   553→      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;
   554→      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;
   555→
   556→      // Calculate consistency (standard deviation proxy)
   557→      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;
   558→      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;
   559→
   560→      // Calculate movement intensity (velocity proxy from position changes)
   561→      let totalMovement = 0;
   562→      for (let i = 1; i < validAnalyses.length; i++) {
   563→        const prev = validAnalyses[i - 1].landmarks;
   564→        const curr = validAnalyses[i].landmarks;
   565→        if (prev && curr) {
   566→          const hipMovement = Math.sqrt(
   567→            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +
   568→            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)
   569→          );
   570→          totalMovement += hipMovement;
   571→        }
   572→      }
   573→      const avgMovement = totalMovement / (validAnalyses.length - 1);
   574→
   575→      // Issue frequency
   576→      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;
   577→
   578→      // Call Gemini API for skill level detection
   579→      const response = await fetch('/api/analysis/auto-level', {
   580→        method: 'POST',
   581→        headers: { 'Content-Type': 'application/json' },
   582→        body: JSON.stringify({
   583→          metrics: {
   584→            avgElbowAngle,
   585→            avgKneeAngle,
   586→            avgStanceWidth,
   587→            avgRotation,
   588→            elbowConsistency: Math.sqrt(elbowVariance),
   589→            kneeConsistency: Math.sqrt(kneeVariance),
   590→            movementIntensity: avgMovement,
   591→            issueFrequency,
   592→            totalFrames: validAnalyses.length,
   593→            issueCount: detectedIssues.length,
   594→          },
   595→          issues: detectedIssues.map(i => ({
   596→            code: i.code,
   597→            title: i.title,
   598→            frequency: i.timestamps.length / validAnalyses.length,
   599→          })),
   600→        }),
   601→      });
   602→
   603→      if (response.ok) {
   604→        const result = await response.json();
   605→        setAnalyzeProgress(90);
   606→        return {
   607→          level: result.level || 'Intermediate',
   608→          confidence: result.confidence || 0.7,
   609→          rationaleBullets: result.rationaleBullets || [],
   610→          guidanceKeyframes: result.guidanceKeyframes,
   611→        };
   612→      }
   613→    } catch (err) {
   614→      console.error('Gemini auto-level detection failed:', err);
   615→    }
   616→
   617→    // Fallback rule-based detection
   618→    setAnalyzeProgress(90);
   619→    return fallbackSkillLevelDetection(analyses, detectedIssues);
   620→  };
   621→
   622→  // Fallback rule-based skill level detection
   623→  const fallbackSkillLevelDetection = (
   624→    analyses: FrameAnalysis[],
   625→    detectedIssues: DetectedIssue[]
   626→  ): AutoLevelResult => {
   627→    const validAnalyses = analyses.filter(a => a.evaluation);
   628→    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;
   629→    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;
   630→    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;
   631→
   632→    if (passRatio >= 0.7 && highSeverityIssues === 0) {
   633→      return {
   634→        level: 'Advanced',
   635→        confidence: 0.75,
   636→        rationaleBullets: [
   637→          'Consistent form across frames',
   638→          'No major technique issues detected',
   639→          'Good body mechanics observed',
   640→        ],
   641→      };
   642→    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {
   643→      return {
   644→        level: 'Intermediate',
   645→        confidence: 0.7,
   646→        rationaleBullets: [
   647→          'Moderate consistency in technique',
   648→          `${highSeverityIssues} area(s) need focused improvement`,
   649→          'Foundations are solid with room to refine',
   650→        ],
   651→      };
   652→    } else {
   653→      return {
   654→        level: 'Beginner',
   655→        confidence: 0.8,
   656→        rationaleBullets: [
   657→          'Multiple technique areas need development',
   658→          'Focus on fundamentals before advancing',
   659→          'Regular practice will show rapid improvement',
   660→        ],
   661→      };
   662→    }
   663→  };
   664→
   665→  // PHASE 4: Generate guidance keyframes from analysis
   666→  const generateGuidanceKeyframes = (
   667→    analyses: FrameAnalysis[],
   668→    detectedIssues: DetectedIssue[]
   669→  ): GuidanceKeyframe[] => {
   670→    const keyframes: GuidanceKeyframe[] = [];
   671→    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);
   672→
   673→    if (validAnalyses.length < 3) return keyframes;
   674→
   675→    // Find key moments: Setup, Contact/Action, Recovery
   676→    // Setup: Early stable frame
   677→    const setupIdx = Math.floor(validAnalyses.length * 0.1);
   678→    const contactIdx = Math.floor(validAnalyses.length * 0.5);
   679→    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);
   680→
   681→    const setupFrame = validAnalyses[setupIdx];
   682→    const contactFrame = validAnalyses[contactIdx];
   683→    const recoveryFrame = validAnalyses[recoveryIdx];
   684→
   685→    // Determine primary issue for corrections
   686→    const primaryIssue = detectedIssues[0];
   687→    let correction = '';
   688→    if (primaryIssue) {
   689→      if (primaryIssue.code.includes('ELBOW')) {
   690→        correction = 'Extend elbow more at contact';
   691→      } else if (primaryIssue.code.includes('KNEE')) {
   692→        correction = 'Maintain athletic knee bend';
   693→      } else if (primaryIssue.code.includes('STANCE')) {
   694→        correction = 'Widen stance for stability';
   695→      } else if (primaryIssue.code.includes('ROTATION')) {
   696→        correction = 'Rotate hips before shoulders';
   697→      }
   698→    }
   699→
   700→    keyframes.push({
   701→      name: 'Setup',
   702→      description: 'Preparation phase',
   703→      landmarks: setupFrame?.landmarks || null,
   704→      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',
   705→    });
   706→
   707→    keyframes.push({
   708→      name: 'Contact',
   709→      description: 'Point of contact',
   710→      landmarks: contactFrame?.landmarks || null,
   711→      correction: correction || undefined,
   712→    });
   713→
   714→    keyframes.push({
   715→      name: 'Recovery',
   716→      description: 'Return to ready',
   717→      landmarks: recoveryFrame?.landmarks || null,
   718→      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',
   719→    });
   720→
   721→    return keyframes;
   722→  };
   723→
   724→  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {
   725→    const file = e.target.files?.[0];
   726→    if (!file) return;
   727→
   728→    if (!file.type.startsWith('video/')) {
   729→      setError('Please select a video file');
   730→      return;
   731→    }
   732→
   733→    if (file.size > 100 * 1024 * 1024) {
   734→      setError('File size must be less than 100MB. Please compress your video before uploading.');
   735→      return;
   736→    }
   737→
   738→    setError(null);
   739→    setVideoFile(file);
   740→    setResult(null);
   741→    setIssues([]);
   742→    setPoseData([]);
   743→    setFrameAnalyses([]);
   744→    setAutoLevelResult(null);
   745→    setGuidanceKeyframes([]);
   746→
   747→    // Create object URL for video preview
   748→    const objectUrl = URL.createObjectURL(file);
   749→    setVideoUrl(objectUrl);
   750→
   751→    // Start analysis
   752→    await analyzeVideo(file, objectUrl);
   753→  };
   754→
   755→  // PHASE 1 FIX: Detect player tracks with monotonic timestamps
   756→  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {
   757→    if (!poseLandmarkerRef.current) return [];
   758→
   759→    const tracks: Map<number, PlayerTrackData> = new Map();
   760→    const sampleFrames = 5;
   761→    const duration = videoElement.duration;
   762→
   763→    // Use separate timestamp tracking for track detection
   764→    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;
   765→
   766→    for (let i = 0; i < sampleFrames; i++) {
   767→      const timestamp = (i / sampleFrames) * duration;
   768→      videoElement.currentTime = timestamp;
   769→
   770→      await new Promise<void>((resolve) => {
   771→        const onSeeked = () => {
   772→          videoElement.removeEventListener('seeked', onSeeked);
   773→          resolve();
   774→        };
   775→        videoElement.addEventListener('seeked', onSeeked);
   776→      });
   777→
   778→      await new Promise(resolve => setTimeout(resolve, 50));
   779→
   780→      try {
   781→        // PHASE 1 FIX: Ensure monotonic timestamp
   782→        trackDetectionTimestamp += 100; // 100ms between samples
   783→        const safeTimestamp = trackDetectionTimestamp;
   784→        lastTimestampMsRef.current = safeTimestamp;
   785→
   786→        const results = poseLandmarkerRef.current.detectForVideo(
   787→          videoElement,
   788→          safeTimestamp
   789→        );
   790→
   791→        if (results.landmarks && results.landmarks.length > 0) {
   792→          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {
   793→            const landmarks = results.landmarks[poseIdx];
   794→            const bbox = calculateBoundingBox(landmarks);
   795→
   796→            if (!tracks.has(poseIdx)) {
   797→              tracks.set(poseIdx, {
   798→                track_id: poseIdx,
   799→                bbox_samples: [],
   800→                is_selected: false,
   801→                confidence_avg: 0,
   802→                frame_count: 0,
   803→                side: bbox.y < 0.5 ? 'far' : 'near',
   804→              });
   805→            }
   806→
   807→            const track = tracks.get(poseIdx)!;
   808→            track.bbox_samples.push({
   809→              frame: i,
   810→              x: bbox.x,
   811→              y: bbox.y,
   812→              w: bbox.w,
   813→              h: bbox.h,
   814→              confidence: landmarks[0].visibility || 0.5,
   815→            });
   816→            track.frame_count++;
   817→            track.confidence_avg =
   818→              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /
   819→              track.frame_count;
   820→          }
   821→        }
   822→      } catch (err) {
   823→        console.warn('Error detecting poses in frame:', err);
   824→      }
   825→    }
   826→
   827→    // Generate thumbnails
   828→    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);
   829→
   830→    if (tracksArray.length > 0) {
   831→      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;
   832→      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;
   833→      videoElement.currentTime = Math.max(0.5, bestTimestamp);
   834→
   835→      await new Promise<void>((resolve) => {
   836→        const onSeeked = () => {
   837→          videoElement.removeEventListener('seeked', onSeeked);
   838→          resolve();
   839→        };
   840→        videoElement.addEventListener('seeked', onSeeked);
   841→      });
   842→      await new Promise(resolve => setTimeout(resolve, 100));
   843→
   844→      for (const track of tracksArray) {
   845→        if (track.bbox_samples.length > 0) {
   846→          const bestBbox = track.bbox_samples.reduce((best, current) =>
   847→            (current.confidence || 0) > (best.confidence || 0) ? current : best
   848→          );
   849→
   850→          const thumbnail = generateThumbnail(videoElement, {
   851→            x: bestBbox.x,
   852→            y: bestBbox.y,
   853→            w: bestBbox.w,
   854→            h: bestBbox.h,
   855→          });
   856→
   857→          if (thumbnail) {
   858→            track.thumbnail_url = thumbnail;
   859→          }
   860→        }
   861→      }
   862→    }
   863→
   864→    return tracksArray;
   865→  };
   866→
   867→  // Calculate bounding box from landmarks
   868→  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {
   869→    let minX = 1, minY = 1, maxX = 0, maxY = 0;
   870→    for (const lm of landmarks) {
   871→      if (lm.visibility > 0.5) {
   872→        minX = Math.min(minX, lm.x);
   873→        minY = Math.min(minY, lm.y);
   874→        maxX = Math.max(maxX, lm.x);
   875→        maxY = Math.max(maxY, lm.y);
   876→      }
   877→    }
   878→    return {
   879→      x: minX,
   880→      y: minY,
   881→      w: maxX - minX,
   882→      h: maxY - minY,
   883→    };
   884→  };
   885→
   886→  // Generate thumbnail from video at specific bounding box
   887→  const generateThumbnail = (
   888→    video: HTMLVideoElement,
   889→    bbox: { x: number; y: number; w: number; h: number },
   890→    padding: number = 0.1
   891→  ): string | null => {
   892→    try {
   893→      const canvas = document.createElement('canvas');
   894→      const ctx = canvas.getContext('2d');
   895→      if (!ctx) return null;
   896→
   897→      const vw = video.videoWidth;
   898→      const vh = video.videoHeight;
   899→
   900→      const padX = bbox.w * padding;
   901→      const padY = bbox.h * padding;
   902→
   903→      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));
   904→      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));
   905→      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));
   906→      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));
   907→
   908→      if (cropW <= 0 || cropH <= 0) return null;
   909→
   910→      const maxSize = 150;
   911→      const scale = Math.min(maxSize / cropW, maxSize / cropH);
   912→      canvas.width = Math.floor(cropW * scale);
   913→      canvas.height = Math.floor(cropH * scale);
   914→
   915→      ctx.drawImage(
   916→        video,
   917→        cropX, cropY, cropW, cropH,
   918→        0, 0, canvas.width, canvas.height
   919→      );
   920→
   921→      return canvas.toDataURL('image/jpeg', 0.8);
   922→    } catch (err) {
   923→      console.warn('Error generating thumbnail:', err);
   924→      return null;
   925→    }
   926→  };
   927→
   928→  // Handle player selection confirmation
   929→  const handlePlayerSelectionConfirm = (
   930→    selectedTracks: number[],
   931→    format: 'singles' | 'doubles',
   932→    event: string
   933→  ) => {
   934→    setSelectedTrackIds(selectedTracks);
   935→    setMatchFormat(format);
   936→    setEventType(event);
   937→    setShowPlayerSelection(false);
   938→
   939→    if (processVideoRef.current && videoFile) {
   940→      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);
   941→    }
   942→  };
   943→
   944→  // Continue analysis after player selection
   945→  const continueAnalysisWithSelection = async (
   946→    processVideo: HTMLVideoElement,
   947→    selectedTracks: number[]
   948→  ) => {
   949→    setAnalysisState('EXTRACTING_POSE');
   950→    const analyses = await processVideoWithPose(processVideo, selectedTracks);
   951→    setFrameAnalyses(analyses);
   952→
   953→    const poseArray = analyses.map(a => a.landmarks);
   954→    setPoseData(poseArray);
   955→
   956→    const detectedIssues = detectIssuesFromAnalyses(analyses);
   957→    setIssues(detectedIssues);
   958→
   959→    // PHASE 3: Auto-detect skill level
   960→    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);
   961→    setAutoLevelResult(levelResult);
   962→
   963→    // PHASE 4: Generate guidance keyframes
   964→    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);
   965→    setGuidanceKeyframes(guidance);
   966→
   967→    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;
   968→    const totalFrames = analyses.filter(a => a.evaluation).length;
   969→    const avgScore = totalFrames > 0
   970→      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames
   971→      : 0;
   972→
   973→    setResult({
   974→      top_issues: detectedIssues.map(issue => ({
   975→        id: issue.code,
   976→        title: issue.title,
   977→        severity: issue.severity,
   978→        description: issue.description || '',
   979→        affected_metrics: [],
   980→      })),
   981→      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({
   982→        id: d.id,
   983→        name: d.name,
   984→        description: d.description,
   985→        duration_minutes: d.durationMinutes,
   986→        target_metrics: d.targetMetrics,
   987→        instructions: d.steps,
   988→      })),
   989→      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,
   990→      strategy_summary: passedFrames > totalFrames * 0.7
   991→        ? 'Your form is generally good. Focus on the specific issues identified.'
   992→        : 'Work on maintaining consistent form throughout your movements.',
   993→      training_plan: [],
   994→    });
   995→
   996→    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);
   997→    if (!saveResult.success) {
   998→      setError(saveResult.error || 'Failed to save analysis');
   999→    }
  1000→    setAnalyzing(false);
  1001→    setAnalysisState('DONE');
  1002→    setAnalyzeProgress(100);
  1003→  };
  1004→
  1005→  const analyzeVideo = async (file: File, videoObjectUrl: string) => {
  1006→    setAnalyzing(true);
  1007→    setAnalyzeProgress(0);
  1008→    setAnalysisState('DETECTING_PLAYERS');
  1009→
  1010→    try {
  1011→      const processVideo = document.createElement('video');
  1012→      processVideo.src = videoObjectUrl;
  1013→      processVideo.muted = true;
  1014→      processVideo.playsInline = true;
  1015→      processVideoRef.current = processVideo;
  1016→
  1017→      await new Promise<void>((resolve, reject) => {
  1018→        processVideo.onloadedmetadata = () => {
  1019→          setDuration(processVideo.duration);
  1020→          setFps(30);
  1021→          resolve();
  1022→        };
  1023→        processVideo.onerror = () => reject(new Error('Failed to load video'));
  1024→      });
  1025→
  1026→      await new Promise<void>((resolve) => {
  1027→        if (processVideo.readyState >= 2) {
  1028→          resolve();
  1029→        } else {
  1030→          processVideo.oncanplay = () => resolve();
  1031→        }
  1032→      });
  1033→
  1034→      // Detect player tracks first
  1035→      setAnalyzeProgress(5);
  1036→      const tracks = await detectPlayerTracks(processVideo);
  1037→      setDetectedTracks(tracks);
  1038→
  1039→      const uniquePlayers = tracks.length;
  1040→      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';
  1041→      setDetectedMatchFormat(detectedFormat);
  1042→
  1043→      if (tracks.length > 1) {
  1044→        setShowPlayerSelection(true);
  1045→        return;
  1046→      }
  1047→
  1048→      if (tracks.length === 1) {
  1049→        setSelectedTrackIds([tracks[0].track_id]);
  1050→      }
  1051→
  1052→      // Process video with pose detection
  1053→      let analyses: FrameAnalysis[] = [];
  1054→
  1055→      if (poseLandmarkerReady && poseLandmarkerRef.current) {
  1056→        setAnalysisState('EXTRACTING_POSE');
  1057→        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);
  1058→        setFrameAnalyses(analyses);
  1059→
  1060→        const poseArray = analyses.map(a => a.landmarks);
  1061→        setPoseData(poseArray);
  1062→
  1063→        const detectedIssues = detectIssuesFromAnalyses(analyses);
  1064→        setIssues(detectedIssues);
  1065→
  1066→        // PHASE 3: Auto-detect skill level
  1067→        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);
  1068→        setAutoLevelResult(levelResult);
  1069→
  1070→        // PHASE 4: Generate guidance keyframes
  1071→        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);
  1072→        setGuidanceKeyframes(guidance);
  1073→
  1074→        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;
  1075→        const totalFrames = analyses.filter(a => a.evaluation).length;
  1076→        const avgScore = totalFrames > 0
  1077→          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames
  1078→          : 0;
  1079→
  1080→        setResult({
  1081→          top_issues: detectedIssues.map(issue => ({
  1082→            id: issue.code,
  1083→            title: issue.title,
  1084→            severity: issue.severity,
  1085→            description: issue.description || '',
  1086→            affected_metrics: [],
  1087→          })),
  1088→          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({
  1089→            id: d.id,
  1090→            name: d.name,
  1091→            description: d.description,
  1092→            duration_minutes: d.durationMinutes,
  1093→            target_metrics: d.targetMetrics,
  1094→            instructions: d.steps,
  1095→          })),
  1096→          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,
  1097→          strategy_summary: passedFrames > totalFrames * 0.7
  1098→            ? 'Your form is generally good. Focus on the specific issues identified.'
  1099→            : 'Work on maintaining consistent form throughout your movements.',
  1100→          training_plan: [],
  1101→        });
  1102→
  1103→        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);
  1104→        if (!saveResult.success) {
  1105→          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');
  1106→        }
  1107→        setAnalysisState('DONE');
  1108→      } else {
  1109→        setError('Pose detection not available. Using demo mode.');
  1110→        setAnalysisState('ERROR');
  1111→
  1112→        const demoIssues: DetectedIssue[] = [
  1113→          {
  1114→            code: 'ELBOW_ANGLE_OVERHEAD',
  1115→            title: 'Elbow Extension (Overhead)',
  1116→            severity: 'high',
  1117→            description: 'Elbow should be nearly straight at contact point',
  1118→            timestamps: [1.2, 3.5, 7.8],
  1119→            drill: DRILLS['elbow-extension'],
  1120→          },
  1121→          {
  1122→            code: 'KNEE_BEND',
  1123→            title: 'Knee Bend',
  1124→            severity: 'medium',
  1125→            description: 'Bend knees more for power',
  1126→            timestamps: [2.1, 5.3],
  1127→            drill: DRILLS['lunge-practice'],
  1128→          },
  1129→        ];
  1130→        setIssues(demoIssues);
  1131→        setAutoLevelResult({
  1132→          level: 'Intermediate',
  1133→          confidence: 0.5,
  1134→          rationaleBullets: ['Demo mode - upload video for real analysis'],
  1135→        });
  1136→        setResult({
  1137→          top_issues: demoIssues.map(i => ({
  1138→            id: i.code,
  1139→            title: i.title,
  1140→            severity: i.severity,
  1141→            description: i.description || '',
  1142→            affected_metrics: [],
  1143→          })),
  1144→          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({
  1145→            id: d!.id,
  1146→            name: d!.name,
  1147→            description: d!.description,
  1148→            duration_minutes: d!.durationMinutes,
  1149→            target_metrics: d!.targetMetrics,
  1150→            instructions: d!.steps,
  1151→          })),
  1152→          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',
  1153→          strategy_summary: '',
  1154→          training_plan: [],
  1155→        });
  1156→      }
  1157→
  1158→    } catch (err) {
  1159→      console.error('Analysis error:', err);
  1160→      setError('Failed to analyze video. Please try again.');
  1161→      setAnalysisState('ERROR');
  1162→    } finally {
  1163→      setAnalyzing(false);
  1164→      setAnalyzeProgress(100);
  1165→    }
  1166→  };
  1167→
  1168→  const saveAnalysisToDatabase = async (
  1169→    file: File,
  1170→    analyses: FrameAnalysis[],
  1171→    detectedIssues: DetectedIssue[],
  1172→    avgScore: number,
  1173→    levelResult?: AutoLevelResult
  1174→  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {
  1175→    try {
  1176→      const { data: { user } } = await supabase.auth.getUser();
  1177→      if (!user) {
  1178→        return { success: false, error: 'Not authenticated' };
  1179→      }
  1180→
  1181→      let videoPath: string | null = null;
  1182→      let publicVideoUrl = '';
  1183→
  1184→      try {
  1185→        videoPath = await uploadVideo(file, user.id, (progress) => {
  1186→          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));
  1187→        });
  1188→
  1189→        if (!videoPath) {
  1190→          throw new Error('Upload returned empty path');
  1191→        }
  1192→
  1193→        publicVideoUrl = getVideoUrl(videoPath);
  1194→        console.log('Video uploaded successfully:', videoPath);
  1195→
  1196→      } catch (uploadError) {
  1197→        console.error('Video upload failed:', uploadError);
  1198→        const errorMessage = uploadError instanceof Error
  1199→          ? uploadError.message
  1200→          : 'Failed to upload video. Please try again.';
  1201→        setError(errorMessage);
  1202→        return { success: false, error: errorMessage };
  1203→      }
  1204→
  1205→      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;
  1206→      const totalFrames = analyses.filter(a => a.evaluation).length;
  1207→
  1208→      const { data: session, error: sessionError } = await supabase
  1209→        .from('sessions')
  1210→        .insert({
  1211→          user_id: user.id,
  1212→          type: 'analytics',
  1213→          video_path: videoPath,
  1214→          video_url: publicVideoUrl,
  1215→          filename: file.name,
  1216→          frame_count: analyses.length,
  1217→          overall_score: Math.round(avgScore),
  1218→          pose_data: analyses.map(a => a.landmarks),
  1219→          status: 'ready',
  1220→          match_format: matchFormat,
  1221→          event_type: eventType || null,
  1222→          selected_tracks: selectedTrackIds,
  1223→          skill_level: levelResult?.level.toLowerCase() || 'intermediate',
  1224→          rules_version: 'v1',
  1225→          summary: {
  1226→            total_frames: totalFrames,
  1227→            green_frames: passedFrames,
  1228→            red_frames: totalFrames - passedFrames,
  1229→            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,
  1230→            average_score: avgScore,
  1231→            duration_seconds: duration,
  1232→            auto_level: levelResult,
  1233→          },
  1234→        })
  1235→        .select()
  1236→        .single();
  1237→
  1238→      if (sessionError) {
  1239→        console.error('Session save error:', sessionError);
  1240→        return { success: false, error: 'Failed to save session data' };
  1241→      }
  1242→
  1243→      if (session && detectedIssues.length > 0) {
  1244→        const issueInserts = detectedIssues.map(issue => ({
  1245→          session_id: session.id,
  1246→          code: issue.code,
  1247→          title: issue.title,
  1248→          severity: issue.severity,
  1249→          description: issue.description,
  1250→          timestamps: issue.timestamps,
  1251→          drill: issue.drill,
  1252→        }));
  1253→
  1254→        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);
  1255→        if (issuesError) {
  1256→          console.warn('Issues save warning:', issuesError);
  1257→        }
  1258→      }
  1259→
  1260→      setAnalyzeProgress(100);
  1261→      return { success: true, sessionId: session.id };
  1262→
  1263→    } catch (err) {
  1264→      console.error('Error saving to database:', err);
  1265→      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';
  1266→      return { success: false, error: errorMessage };
  1267→    }
  1268→  };
  1269→
  1270→  // PHASE 2 FIX: Video frame rendering with proper canvas alignment
  1271→  const renderFrame = useCallback(() => {
  1272→    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;
  1273→
  1274→    const video = videoRef.current;
  1275→    const canvas = canvasRef.current;
  1276→    const ctx = canvas.getContext('2d');
  1277→    if (!ctx) return;
  1278→
  1279→    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)
  1280→    const container = videoContainerRef.current;
  1281→    const containerRect = container.getBoundingClientRect();
  1282→
  1283→    if (video.videoWidth === 0 || video.videoHeight === 0) return;
  1284→
  1285→    const videoAspect = video.videoWidth / video.videoHeight;
  1286→    const containerAspect = containerRect.width / containerRect.height;
  1287→
  1288→    let renderWidth, renderHeight, offsetX, offsetY;
  1289→
  1290→    if (videoAspect > containerAspect) {
  1291→      // Video is wider - letterbox top/bottom
  1292→      renderWidth = containerRect.width;
  1293→      renderHeight = containerRect.width / videoAspect;
  1294→      offsetX = 0;
  1295→      offsetY = (containerRect.height - renderHeight) / 2;
  1296→    } else {
  1297→      // Video is taller - letterbox left/right
  1298→      renderHeight = containerRect.height;
  1299→      renderWidth = containerRect.height * videoAspect;
  1300→      offsetX = (containerRect.width - renderWidth) / 2;
  1301→      offsetY = 0;
  1302→    }
  1303→
  1304→    // Set canvas to match container size
  1305→    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {
  1306→      canvas.width = containerRect.width;
  1307→      canvas.height = containerRect.height;
  1308→    }
  1309→
  1310→    // Clear canvas
  1311→    ctx.clearRect(0, 0, canvas.width, canvas.height);
  1312→
  1313→    if (!showSkeleton) return;
  1314→
  1315→    // Find the closest frame analysis
  1316→    let closestFrame: FrameAnalysis | null = null;
  1317→    let minDiff = Infinity;
  1318→
  1319→    for (const frame of frameAnalyses) {
  1320→      const diff = Math.abs(frame.timestamp - video.currentTime);
  1321→      if (diff < minDiff) {
  1322→        minDiff = diff;
  1323→        closestFrame = frame;
  1324→      }
  1325→    }
  1326→
  1327→    // Also check raw poseData array (for loaded sessions)
  1328→    if (!closestFrame && poseData.length > 0) {
  1329→      const frameIndex = Math.floor(video.currentTime * 10);
  1330→      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];
  1331→      if (landmarks) {
  1332→        closestFrame = {
  1333→          timestamp: video.currentTime,
  1334→          landmarks,
  1335→          evaluation: evaluateForm(landmarks, 'general'),
  1336→          metrics: extractMetrics(landmarks),
  1337→        };
  1338→      }
  1339→    }
  1340→
  1341→    if (closestFrame?.landmarks) {
  1342→      // Get skill level from auto-detection or default to intermediate
  1343→      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';
  1344→      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);
  1345→      setCurrentBandedScore(bandedResult);
  1346→
  1347→      const isGreen = bandedResult.overall_band === 'green';
  1348→      const isYellow = bandedResult.overall_band === 'yellow';
  1349→      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';
  1350→
  1351→      ctx.strokeStyle = color;
  1352→      ctx.lineWidth = 3;
  1353→      ctx.fillStyle = color;
  1354→
  1355→      // PHASE 2 FIX: Draw skeleton with proper offset and scaling
  1356→      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {
  1357→        const start = closestFrame.landmarks[startIdx];
  1358→        const end = closestFrame.landmarks[endIdx];
  1359→        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {
  1360→          ctx.beginPath();
  1361→          // Apply offset and scale to match actual video render position
  1362→          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);
  1363→          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);
  1364→          ctx.stroke();
  1365→        }
  1366→      }
  1367→
  1368→      // Draw joints
  1369→      for (const landmark of closestFrame.landmarks) {
  1370→        if (landmark.visibility > 0.5) {
  1371→          ctx.beginPath();
  1372→          ctx.arc(
  1373→            offsetX + landmark.x * renderWidth,
  1374→            offsetY + landmark.y * renderHeight,
  1375→            5,
  1376→            0,
  1377→            2 * Math.PI
  1378→          );
  1379→          ctx.fill();
  1380→        }
  1381→      }
  1382→    }
  1383→
  1384→    if (!video.paused) {
  1385→      animationRef.current = requestAnimationFrame(renderFrame);
  1386→    }
  1387→  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);
  1388→
  1389→  // Trigger skeleton render when poseData is loaded
  1390→  useEffect(() => {
  1391→    if (poseData.length > 0 && videoRef.current) {
  1392→      const tryRender = () => {
  1393→        if (videoRef.current && videoRef.current.readyState >= 2) {
  1394→          renderFrame();
  1395→        } else {
  1396→          setTimeout(tryRender, 100);
  1397→        }
  1398→      };
  1399→      tryRender();
  1400→    }
  1401→  }, [poseData, renderFrame]);
  1402→
  1403→  // Handle video time updates
  1404→  const handleTimeUpdate = useCallback(() => {
  1405→    if (videoRef.current) {
  1406→      setCurrentTime(videoRef.current.currentTime);
  1407→      renderFrame();
  1408→    }
  1409→  }, [renderFrame]);
  1410→
  1411→  // Handle video play/pause
  1412→  const togglePlayPause = useCallback(() => {
  1413→    if (videoRef.current) {
  1414→      if (videoRef.current.paused) {
  1415→        videoRef.current.play();
  1416→        setIsPlaying(true);
  1417→        animationRef.current = requestAnimationFrame(renderFrame);
  1418→      } else {
  1419→        videoRef.current.pause();
  1420→        setIsPlaying(false);
  1421→        if (animationRef.current) {
  1422→          cancelAnimationFrame(animationRef.current);
  1423→        }
  1424→      }
  1425→    }
  1426→  }, [renderFrame]);
  1427→
  1428→  // Jump to timestamp
  1429→  const jumpToTimestamp = useCallback((timestamp: number) => {
  1430→    if (videoRef.current) {
  1431→      videoRef.current.currentTime = timestamp;
  1432→      videoRef.current.pause();
  1433→      setIsPlaying(false);
  1434→      setCurrentTime(timestamp);
  1435→      setTimeout(renderFrame, 50);
  1436→    }
  1437→  }, [renderFrame]);
  1438→
  1439→  // Find next mistake
  1440→  const goToNextMistake = useCallback(() => {
  1441→    const allTimestamps = issues
  1442→      .flatMap((i) => i.timestamps || [])
  1443→      .sort((a, b) => a - b);
  1444→
  1445→    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);
  1446→    if (nextTimestamp !== undefined) {
  1447→      jumpToTimestamp(nextTimestamp);
  1448→    } else if (allTimestamps.length > 0) {
  1449→      jumpToTimestamp(allTimestamps[0]);
  1450→    }
  1451→  }, [issues, currentTime, jumpToTimestamp]);
  1452→
  1453→  // Handle video metadata loaded
  1454→  const handleLoadedMetadata = useCallback(() => {
  1455→    if (videoRef.current) {
  1456→      setDuration(videoRef.current.duration);
  1457→      setTimeout(renderFrame, 100);
  1458→    }
  1459→  }, [renderFrame]);
  1460→
  1461→  const getSeverityColor = (severity: string) => {
  1462→    switch (severity) {
  1463→      case 'high':
  1464→        return 'bg-red-50 border-red-200 text-red-800';
  1465→      case 'medium':
  1466→        return 'bg-yellow-50 border-yellow-200 text-yellow-800';
  1467→      case 'low':
  1468→        return 'bg-green-50 border-green-200 text-green-800';
  1469→      default:
  1470→        return 'bg-gray-50 border-gray-200 text-gray-800';
  1471→    }
  1472→  };
  1473→
  1474→  const formatTime = (seconds: number) => {
  1475→    const mins = Math.floor(seconds / 60);
  1476→    const secs = Math.floor(seconds % 60);
  1477→    return `${mins}:${secs.toString().padStart(2, '0')}`;
  1478→  };
  1479→
  1480→  // Get current frame info for display
  1481→  const getCurrentFrameInfo = () => {
  1482→    if (frameAnalyses.length === 0) return null;
  1483→
  1484→    let closestFrame: FrameAnalysis | null = null;
  1485→    let minDiff = Infinity;
  1486→
  1487→    for (const frame of frameAnalyses) {
  1488→      const diff = Math.abs(frame.timestamp - currentTime);
  1489→      if (diff < minDiff) {
  1490→        minDiff = diff;
  1491→        closestFrame = frame;
  1492→      }
  1493→    }
  1494→
  1495→    return closestFrame;
  1496→  };
  1497→
  1498→  const currentFrameInfo = getCurrentFrameInfo();
  1499→
  1500→  // PHASE 5: Get analysis state message
  1501→  const getAnalysisStateMessage = () => {
  1502→    switch (analysisState) {
  1503→      case 'DETECTING_PLAYERS':
  1504→        return 'Detecting players in video...';
  1505→      case 'EXTRACTING_POSE':
  1506→        return 'Extracting pose data from frames...';
  1507→      case 'GEMINI_SCORING':
  1508→        return 'AI analyzing skill level...';
  1509→      case 'DONE':
  1510→        return 'Analysis complete!';
  1511→      case 'ERROR':
  1512→        return 'Analysis failed';
  1513→      default:
  1514→        return 'Ready to analyze';
  1515→    }
  1516→  };
  1517→
  1518→  return (
  1519→    <div className="min-h-screen bg-gray-50">
  1520→      <DashboardNav />
  1521→
  1522→      <main className="ml-64 p-8">
  1523→        <div className="max-w-7xl mx-auto">
  1524→          {/* Header */}
  1525→          <div className="mb-8">
  1526→            <h1 className="text-3xl font-bold text-gray-900">Video Analytics</h1>
  1527→            <p className="text-gray-600 mt-1">
  1528→              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}
  1529→            </p>
  1530→          </div>
  1531→
  1532→          {/* Upload Section */}
  1533→          {!result && !videoUrl && (
  1534→            <div className="bg-white rounded-xl p-8 shadow-sm mb-8">
  1535→              <div
  1536→                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${
  1537→                  uploading || analyzing
  1538→                    ? 'border-primary-300 bg-primary-50'
  1539→                    : 'border-gray-300 hover:border-primary-400'
  1540→                }`}
  1541→              >
  1542→                {uploading ? (
  1543→                  <div className="space-y-4">
  1544→                    <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto"></div>
  1545→                    <p className="text-gray-600">Uploading video...</p>
  1546→                  </div>
  1547→                ) : analyzing ? (
  1548→                  // PHASE 5: Enhanced loading state with state machine
  1549→                  <div className="space-y-4">
  1550→                    <div className="w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative">
  1551→                      <svg className="w-8 h-8 text-primary-500 animate-pulse" fill="none" stroke="currentColor" viewBox="0 0 24 24">
  1552→                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z" />
  1553→                      </svg>
  1554→                      {/* Spinning ring */}
  1555→                      <div className="absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin"></div>
  1556→                    </div>
  1557→                    <p className="text-gray-900 font-medium">{getAnalysisStateMessage()}</p>
  1558→
  1559→                    {/* Progress steps */}
  1560→                    <div className="flex justify-center gap-2 mt-4">
  1561→                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (
  1562→                        <div
  1563→                          key={state}
  1564→                          className={`w-3 h-3 rounded-full transition-colors ${
  1565→                            analysisState === state
  1566→                              ? 'bg-primary-500 animate-pulse'
  1567→                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx
  1568→                              ? 'bg-green-500'
  1569→                              : 'bg-gray-300'
  1570→                          }`}
  1571→                        />
  1572→                      ))}
  1573→                    </div>
  1574→                    <p className="text-gray-500 text-sm">
  1575→                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}
  1576→                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}
  1577→                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}
  1578→                    </p>
  1579→
  1580→                    <div className="w-64 mx-auto bg-gray-200 rounded-full h-2">
  1581→                      <div
  1582→                        className="bg-primary-500 h-2 rounded-full transition-all duration-300"
  1583→                        style={{ width: `${analyzeProgress}%` }}
  1584→                      ></div>
  1585→                    </div>
  1586→                    <p className="text-sm text-gray-500">{analyzeProgress}% complete</p>
  1587→                  </div>
  1588→                ) : (
  1589→                  <>
  1590→                    <div className="w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4">
  1591→                      <svg className="w-8 h-8 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
  1592→                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12" />
  1593→                      </svg>
  1594→                    </div>
  1595→                    <h3 className="text-lg font-medium text-gray-900 mb-2">Upload your badminton video</h3>
  1596→                    <p className="text-gray-500 mb-4">MP4, MOV, or WebM up to 100MB</p>
  1597→                    {poseLandmarkerReady && (
  1598→                      <p className="text-sm text-green-600 mb-4">Pose detection ready</p>
  1599→                    )}
  1600→                    <input ref={fileInputRef} type="file" accept="video/*" onChange={handleFileSelect} className="hidden" />
  1601→                    <button onClick={() => fileInputRef.current?.click()} className="px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition">
  1602→                      Select Video
  1603→                    </button>
  1604→                  </>
  1605→                )}
  1606→              </div>
  1607→
  1608→              {error && (
  1609→                <div className="mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700">{error}</div>
  1610→              )}
  1611→            </div>
  1612→          )}
  1613→
  1614→          {/* Video Player with Overlay */}
  1615→          {videoUrl && (
  1616→            <div className="grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8">
  1617→              <div className="lg:col-span-2">
  1618→                <div className="bg-gray-900 rounded-xl overflow-hidden">
  1619→                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}
  1620→                  <div ref={videoContainerRef} className="relative aspect-video">
  1621→                    <video
  1622→                      ref={videoRef}
  1623→                      src={videoUrl}
  1624→                      className="absolute inset-0 w-full h-full object-contain"
  1625→                      onTimeUpdate={handleTimeUpdate}
  1626→                      onLoadedMetadata={handleLoadedMetadata}
  1627→                      onEnded={() => setIsPlaying(false)}
  1628→                      playsInline
  1629→                    />
  1630→                    <canvas
  1631→                      ref={canvasRef}
  1632→                      className={`absolute inset-0 w-full h-full pointer-events-none ${
  1633→                        showSkeleton ? '' : 'hidden'
  1634→                      }`}
  1635→                    />
  1636→
  1637→                    {/* Status indicator with auto-detected level */}
  1638→                    {currentBandedScore && (
  1639→                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${
  1640→                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :
  1641→                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :
  1642→                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :
  1643→                        'bg-gray-500 text-white'
  1644→                      }`}>
  1645→                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}
  1646→                        <span className="ml-2 opacity-75">
  1647→                          {Math.round(currentBandedScore.overall_score)}%
  1648→                        </span>
  1649→                      </div>
  1650→                    )}
  1651→
  1652→                    {/* Time display */}
  1653→                    <div className="absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm">
  1654→                      {formatTime(currentTime)} / {formatTime(duration)}
  1655→                    </div>
  1656→
  1657→                    {/* Current metrics display */}
  1658→                    {currentFrameInfo?.metrics && (
  1659→                      <div className="absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs">
  1660→                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>
  1661→                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>
  1662→                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>
  1663→                      </div>
  1664→                    )}
  1665→                  </div>
  1666→
  1667→                  {/* Controls - PHASE 3: Removed skill level dropdown */}
  1668→                  <div className="p-4 flex items-center justify-between">
  1669→                    <div className="flex items-center gap-2">
  1670→                      <button
  1671→                        onClick={togglePlayPause}
  1672→                        className="p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition"
  1673→                      >
  1674→                        {isPlaying ? (
  1675→                          <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
  1676→                            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z" />
  1677→                          </svg>
  1678→                        ) : (
  1679→                          <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
  1680→                            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z" />
  1681→                            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
  1682→                          </svg>
  1683→                        )}
  1684→                      </button>
  1685→
  1686→                      <button
  1687→                        onClick={goToNextMistake}
  1688→                        disabled={issues.length === 0 || analyzing}
  1689→                        className="px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50"
  1690→                      >
  1691→                        Next Mistake
  1692→                      </button>
  1693→                    </div>
  1694→
  1695→                    <div className="flex items-center gap-4">
  1696→                      {/* PHASE 3: Show auto-detected level instead of dropdown */}
  1697→                      {autoLevelResult && (
  1698→                        <div className="flex items-center gap-2 text-white text-sm">
  1699→                          <span className="px-2 py-1 bg-primary-600 rounded text-xs font-medium">
  1700→                            {autoLevelResult.level}
  1701→                          </span>
  1702→                          <span className="text-gray-400 text-xs">
  1703→                            {Math.round(autoLevelResult.confidence * 100)}% confidence
  1704→                          </span>
  1705→                        </div>
  1706→                      )}
  1707→
  1708→                      <label className="flex items-center gap-2 text-white text-sm">
  1709→                        <input
  1710→                          type="checkbox"
  1711→                          checked={showSkeleton}
  1712→                          onChange={(e) => {
  1713→                            setShowSkeleton(e.target.checked);
  1714→                            if (e.target.checked) {
  1715→                              setTimeout(renderFrame, 50);
  1716→                            }
  1717→                          }}
  1718→                          className="rounded"
  1719→                        />
  1720→                        Show Skeleton
  1721→                      </label>
  1722→                    </div>
  1723→                  </div>
  1724→
  1725→                  {/* Timeline scrubber */}
  1726→                  <div className="px-4 pb-4">
  1727→                    <input
  1728→                      type="range"
  1729→                      min={0}
  1730→                      max={duration || 100}
  1731→                      step={0.1}
  1732→                      value={currentTime}
  1733→                      onChange={(e) => {
  1734→                        const time = parseFloat(e.target.value);
  1735→                        if (videoRef.current) {
  1736→                          videoRef.current.currentTime = time;
  1737→                          setCurrentTime(time);
  1738→                          setTimeout(renderFrame, 50);
  1739→                        }
  1740→                      }}
  1741→                      className="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer"
  1742→                    />
  1743→                  </div>
  1744→                </div>
  1745→
  1746→                {/* PHASE 3: Auto-level detection result panel */}
  1747→                {autoLevelResult && (
  1748→                  <div className="mt-6 bg-white rounded-xl p-6 shadow-sm">
  1749→                    <div className="flex items-center justify-between mb-4">
  1750→                      <h3 className="font-semibold text-gray-900">AI Skill Assessment</h3>
  1751→                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${
  1752→                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :
  1753→                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :
  1754→                        'bg-blue-100 text-blue-800'
  1755→                      }`}>
  1756→                        {autoLevelResult.level}
  1757→                      </span>
  1758→                    </div>
  1759→                    <div className="space-y-2">
  1760→                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (
  1761→                        <div key={idx} className="flex items-start gap-2 text-sm text-gray-600">
  1762→                          <svg className="w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0" fill="currentColor" viewBox="0 0 20 20">
  1763→                            <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clipRule="evenodd" />
  1764→                          </svg>
  1765→                          <span>{bullet}</span>
  1766→                        </div>
  1767→                      ))}
  1768→                    </div>
  1769→                  </div>
  1770→                )}
  1771→
  1772→                {/* PHASE 4: Guidance Animation */}
  1773→                {guidanceKeyframes.length > 0 && (
  1774→                  <div className="mt-6">
  1775→                    <div className="flex items-center justify-between mb-4">
  1776→                      <h3 className="font-semibold text-gray-900">Movement Guidance</h3>
  1777→                      <button
  1778→                        onClick={() => setShowGuidance(!showGuidance)}
  1779→                        className="text-sm text-primary-600 hover:text-primary-700"
  1780→                      >
  1781→                        {showGuidance ? 'Hide' : 'Show'} Animation
  1782→                      </button>
  1783→                    </div>
  1784→                    {showGuidance && (
  1785→                      <GuidanceAnimation
  1786→                        keyframes={guidanceKeyframes}
  1787→                        primaryIssue={issues[0]}
  1788→                      />
  1789→                    )}
  1790→                  </div>
  1791→                )}
  1792→
  1793→                {/* Analysis Summary */}
  1794→                {result && (
  1795→                  <div className="mt-6 bg-white rounded-xl p-6 shadow-sm">
  1796→                    <h3 className="font-semibold text-gray-900 mb-3">Analysis Summary</h3>
  1797→                    <p className="text-gray-600">{result.technique_summary}</p>
  1798→                    {result.strategy_summary && (
  1799→                      <p className="text-gray-500 mt-2 text-sm">{result.strategy_summary}</p>
  1800→                    )}
  1801→                  </div>
  1802→                )}
  1803→              </div>
  1804→
  1805→              {/* Issues Panel */}
  1806→              <div className="space-y-4">
  1807→                <h3 className="font-semibold text-gray-900">Detected Issues</h3>
  1808→                {analyzing ? (
  1809→                  <div className="bg-white rounded-xl p-6 shadow-sm">
  1810→                    {/* Shimmer loading animation */}
  1811→                    <div className="animate-pulse space-y-4">
  1812→                      <div className="h-4 bg-gray-200 rounded w-3/4"></div>
  1813→                      <div className="h-4 bg-gray-200 rounded w-1/2"></div>
  1814→                      <div className="h-20 bg-gray-200 rounded"></div>
  1815→                      <div className="h-4 bg-gray-200 rounded w-2/3"></div>
  1816→                    </div>
  1817→                  </div>
  1818→                ) : issues.length > 0 ? (
  1819→                  <div className="space-y-4 max-h-[600px] overflow-y-auto">
  1820→                    {issues.map((issue, index) => (
  1821→                      <DrillCard
  1822→                        key={index}
  1823→                        issue={issue}
  1824→                        onTimestampClick={jumpToTimestamp}
  1825→                        currentTime={currentTime}
  1826→                      />
  1827→                    ))}
  1828→                  </div>
  1829→                ) : (
  1830→                  <div className="bg-green-50 border border-green-200 rounded-xl p-4 text-green-800">
  1831→                    <p className="font-medium">Great form!</p>
  1832→                    <p className="text-sm">No major issues detected in this video.</p>
  1833→                  </div>
  1834→                )}
  1835→
  1836→                {/* Reset button */}
  1837→                {videoUrl && !analyzing && (
  1838→                  <button
  1839→                    onClick={() => {
  1840→                      setResult(null);
  1841→                      setVideoUrl(null);
  1842→                      setVideoFile(null);
  1843→                      setIssues([]);
  1844→                      setPoseData([]);
  1845→                      setFrameAnalyses([]);
  1846→                      setCurrentTime(0);
  1847→                      setDuration(0);
  1848→                      setAutoLevelResult(null);
  1849→                      setGuidanceKeyframes([]);
  1850→                      setAnalysisState('IDLE');
  1851→                    }}
  1852→                    className="w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition"
  1853→                  >
  1854→                    Analyze Another Video
  1855→                  </button>
  1856→                )}
  1857→              </div>
  1858→            </div>
  1859→          )}
  1860→
  1861→          {/* Results Section (legacy format without video) */}
  1862→          {result && !videoUrl && (
  1863→            <div className="grid grid-cols-1 lg:grid-cols-2 gap-8">
  1864→              {/* Left Column - Issues */}
  1865→              <div className="space-y-6">
  1866→                <div className="bg-white rounded-xl p-6 shadow-sm">
  1867→                  <h2 className="text-lg font-semibold text-gray-900 mb-4">Areas to Improve</h2>
  1868→                  <div className="space-y-3">
  1869→                    {result.top_issues.map((issue) => (
  1870→                      <button
  1871→                        key={issue.id}
  1872→                        onClick={() => setSelectedIssue(issue)}
  1873→                        className={`w-full text-left p-4 rounded-lg border transition ${
  1874→                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''
  1875→                        } ${getSeverityColor(issue.severity)}`}
  1876→                      >
  1877→                        <div className="flex items-center justify-between mb-1">
  1878→                          <span className="font-medium">{issue.title}</span>
  1879→                          <span className="text-xs uppercase font-semibold">{issue.severity}</span>
  1880→                        </div>
  1881→                        <p className="text-sm opacity-80">{issue.description}</p>
  1882→                      </button>
  1883→                    ))}
  1884→                  </div>
  1885→                </div>
  1886→
  1887→                <div className="bg-white rounded-xl p-6 shadow-sm">
  1888→                  <h2 className="text-lg font-semibold text-gray-900 mb-3">Technique Summary</h2>
  1889→                  <p className="text-gray-600">{result.technique_summary}</p>
  1890→                </div>
  1891→              </div>
  1892→
  1893→              {/* Right Column - Drills */}
  1894→              <div className="space-y-6">
  1895→                <div className="bg-white rounded-xl p-6 shadow-sm">
  1896→                  <h2 className="text-lg font-semibold text-gray-900 mb-4">Recommended Drills</h2>
  1897→                  <div className="space-y-3">
  1898→                    {result.drills.map((drill) => (
  1899→                      <button
  1900→                        key={drill.id}
  1901→                        onClick={() => setSelectedDrill(drill)}
  1902→                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${
  1903→                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''
  1904→                        }`}
  1905→                      >
  1906→                        <div className="flex items-center justify-between mb-1">
  1907→                          <span className="font-medium text-gray-900">{drill.name}</span>
  1908→                          <span className="text-sm text-gray-500">{drill.duration_minutes} min</span>
  1909→                        </div>
  1910→                        <p className="text-sm text-gray-600">{drill.description}</p>
  1911→                      </button>
  1912→                    ))}
  1913→                  </div>
  1914→                </div>
  1915→
  1916→                {selectedDrill && (
  1917→                  <div className="bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6">
  1918→                    <div className="flex items-center justify-between mb-4">
  1919→                      <h3 className="text-lg font-semibold text-gray-900">{selectedDrill.name}</h3>
  1920→                      <Link
  1921→                        href={`/practice?drill=${selectedDrill.id}`}
  1922→                        className="px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition"
  1923→                      >
  1924→                        Let&apos;s Practice
  1925→                      </Link>
  1926→                    </div>
  1927→                    <div className="space-y-3">
  1928→                      <p className="text-gray-700">{selectedDrill.description}</p>
  1929→                      <div>
  1930→                        <p className="font-medium text-gray-900 mb-2">Instructions:</p>
  1931→                        <ol className="list-decimal list-inside space-y-1 text-gray-700">
  1932→                          {selectedDrill.instructions.map((instruction, i) => (
  1933→                            <li key={i}>{instruction}</li>
  1934→                          ))}
  1935→                        </ol>
  1936→                      </div>
  1937→                    </div>
  1938→                  </div>
  1939→                )}
  1940→
  1941→                <button
  1942→                  onClick={() => {
  1943→                    setResult(null);
  1944→                    setSelectedIssue(null);
  1945→                    setSelectedDrill(null);
  1946→                    setVideoUrl(null);
  1947→                    setPoseData([]);
  1948→                    setIssues([]);
  1949→                    setAutoLevelResult(null);
  1950→                    setGuidanceKeyframes([]);
  1951→                    setAnalysisState('IDLE');
  1952→                  }}
  1953→                  className="w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition"
  1954→                >
  1955→                  Analyze Another Video
  1956→                </button>
  1957→              </div>
  1958→            </div>
  1959→          )}
  1960→        </div>
  1961→      </main>
  1962→
  1963→      {/* Player Selection Modal */}
  1964→      <PlayerSelectionModal
  1965→        isOpen={showPlayerSelection}
  1966→        onClose={() => {
  1967→          setShowPlayerSelection(false);
  1968→          setAnalyzing(false);
  1969→          setVideoUrl(null);
  1970→          setVideoFile(null);
  1971→          setAnalysisState('IDLE');
  1972→        }}
  1973→        onConfirm={handlePlayerSelectionConfirm}
  1974→        tracks={detectedTracks}
  1975→        detectedFormat={detectedMatchFormat}
  1976→      />
  1977→    </div>
  1978→  );
  1979→}
  1980→
  1981→function AnalyticsLoading() {
  1982→  return (
  1983→    <div className="min-h-screen bg-gray-50">
  1984→      <DashboardNav />
  1985→      <main className="ml-64 p-8">
  1986→        <div className="max-w-7xl mx-auto">
  1987→          <div className="animate-pulse">
  1988→            <div className="h-8 bg-gray-200 rounded w-48 mb-4"></div>
  1989→            <div className="h-4 bg-gray-200 rounded w-96 mb-8"></div>
  1990→            <div className="bg-gray-200 rounded-xl h-96"></div>
  1991→          </div>
  1992→        </div>
  1993→      </main>
  1994→    </div>
  1995→  );
  1996→}
  1997→
  1998→export default function AnalyticsPage() {
  1999→  return (
  2000→    <Suspense fallback={<AnalyticsLoading />}>
  2001→      <AnalyticsContent />
  2002→    </Suspense>
  2003→  );
  2004→}
  2005→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
