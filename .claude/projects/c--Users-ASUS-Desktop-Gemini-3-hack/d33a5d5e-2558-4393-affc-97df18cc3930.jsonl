{"type":"file-history-snapshot","messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","snapshot":{"messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","trackedFileBackups":{},"timestamp":"2026-01-28T05:05:21.590Z"},"isSnapshotUpdate":false}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","type":"user","message":{"role":"user","content":"You are Claude running inside VS Code. You will VIBE CODE as a multi-agent team:\n- PLANNER (architecture + file map)\n- BUILDER (implement end-to-end)\n- REFINER (polish UX + performance)\n- SUPERVISOR (verify “real not mock”, run checks, produce test checklist)\n\nYou MUST use ALL available MCP tools (filesystem read/search, terminal, git, supabase, etc.) to inspect and modify the real codebase. No stubs, no placeholders, no random outputs. If anything is missing, implement it properly.\n\nPROJECT CONTEXT (READ THIS CAREFULLY)\nThis repo is RallyCoach with this structure:\n- backend/ (FastAPI, MediaPipe, OpenCV, Gemini, Supabase)\n  - main.py, analysis.py, pose_estimation.py, gemini_client.py, video_annotator.py, video_processing.py\n- rallycoach/ (Next.js 14 App Router frontend)\n  - src/app/analytics, practice, strategy, etc.\n  - src/lib/pose-utils.ts, rules-engine.ts, scoring-rules.ts, strategy_engine, courtSpec.ts\nThere are existing APIs:\n- backend: /api/analyze etc.\n- frontend routes: /api/analysis/start, /api/analysis/auto-level, etc.\n(Confirm by reading README + code.)\n\nMISSION\nImplement these 3 features FOR REAL in the Video Analytics experience (and reuse in Practice mode where feasible):\n\n1) Ghost Rival Overlay (visual wow)\n2) Mistake Timeline -> click-to-jump + Animation Cards (product polish)\n3) Auto Skill Estimation + Confidence Meters (ML credibility)\n\nNON-NEGOTIABLE REQUIREMENTS\n- START by reading the repo. Do not code until you map the current data flow:\n  (Upload -> backend analyze -> DB save -> frontend fetch -> video render + overlay)\n- Must work with real uploaded videos and real pose output.\n- Must not rely on user selecting Beginner/Intermediate/Advanced. Remove that UI if it exists.\n- Must show loading animation while analysis is running.\n- Must store results in Supabase (sessions/issues or new fields) so history works.\n\nKEY TECH CONSTRAINTS\n- “Confidence” must come from actual pose detection signals:\n  - In MediaPipe Pose outputs, landmarks include `visibility` in [0,1] (likelihood landmark is visible/not occluded). Use that as a main confidence signal.\n  - In Tasks-Vision PoseLandmarker config, there are minPoseDetectionConfidence / minPosePresenceConfidence / minTrackingConfidence; use them and any available scores to derive confidence.\n  Do NOT invent confidence numbers. Derive from visibility, detection success rate, and dropout frequency.\n\n- Timeline seeking must be implemented by setting HTMLMediaElement.currentTime and syncing UI via timeupdate events.\n  (Implement proper seek on click; keep overlay synced.)\n\nPHASE 1 — PLANNER (repo read + plan)\n1) Use MCP filesystem search to locate:\n   - Frontend video player component(s) on analytics page\n   - Overlay rendering (canvas / Three.js overlay / annotated video display)\n   - Where pose frames + issues are shown\n   - Current “level selection” UI and why it always says “perfect”\n   - Backend analysis pipeline outputs and how they’re stored (Supabase schema usage)\n2) Output a short map:\n   - file paths + what they do\n   - current JSON shapes for analysis output\n3) Propose an implementation plan with minimal changes but clean architecture:\n   - EXACT files to edit\n   - EXACT new files/modules to add (if needed)\n   - DB schema changes ONLY if necessary (provide SQL migration if you add columns)\n4) Define acceptance criteria for each feature (below). Then implement.\n\nPHASE 2 — BUILDER (implement end-to-end)\n\n========================\nFEATURE 1: GHOST RIVAL OVERLAY\n========================\nGoal: Show a translucent “ghost” skeleton over the user’s video, time-synced, with a toggle.\nThis MUST be real.\n\nGhost Source (must support at least one real source):\nA) “My Best Rep” (required): ghost is taken from the SAME uploaded video by selecting the highest-quality segment based on your scoring rules.\n   - Find top-N shot events (you already do shot detection).\n   - For each shot window (e.g., t-0.8s to t+0.6s), compute a “form quality score” using existing rules-engine/scoring-rules.\n   - Choose best segment => store as ghostPoseSequence (pose frames + normalized time 0..1 or absolute timestamps).\n   - This is always available and fully real.\n\nB) “Pro Template” (optional but nice): if the repo already contains a reference clip or reference landmark JSON, support it.\n   - If not present, do NOT fake it. Just implement “My Best Rep” first.\n\nSync strategy:\n- Default alignment: absolute time if ghost is from same clip.\n- If ghost uses normalized time (0..1), map userTime within chosen shot window to ghostTime via linear normalization.\n- Overlay must stay synced during play/pause/seek.\n\nRendering:\n- Frontend overlay should render 2 skeletons:\n  - user skeleton (existing colors)\n  - ghost skeleton (distinct color + low opacity)\n- Provide a toggle “Ghost Rival” and a selector “Ghost: My Best Rep / Pro Template (if available)”\n- Ensure overlay continues to render even when the user switches modes/levels (remove reliance on user-selected level).\n\nBackend changes (likely):\n- In backend/analysis.py or associated pipeline: compute best-rep window + store ghost frames (compressed) OR store the window boundaries and rely on frontend to extract frames from stored pose frames.\n- If pose frames are huge, store ghost as a downsampled sequence (e.g., 15 FPS) for rendering.\n\n========================\nFEATURE 2: MISTAKE TIMELINE + CLICK-TO-JUMP + ANIMATION CARDS\n========================\n2.1 Mistake Timeline\nGoal: a horizontal timeline under the video:\n- entire duration\n- colored mistake segments by severity (red/orange)\n- playhead that tracks currentTime\n- clicking a segment seeks video to that time\n\nImplementation:\n- Use HTMLVideoElement.currentTime to seek on click.\n- Subscribe to timeupdate to update playhead + selected mistake.\n- When user clicks anywhere on timeline, seek to the corresponding time (not only segment start).\n- Mistake segments must come from real computed events in analysis output:\n  Each mistake event:\n  {\n    id, type, startTimeSec, endTimeSec,\n    severity (0..1),\n    confidence (0..1) derived from pose visibility/detection stability,\n    joints: [..] (which landmarks matter),\n    summaryTitle (short)\n  }\n\nMistake detection rules (use what you can reliably compute now from landmarks):\nImplement at least 3 mistake types that are feasible with pose landmarks:\n- Overhead contact too low: wrist/hand y relative to shoulder/head at “contact moment”\n- No split-step (or late split-step proxy): detect lack of small hop/stance widening before large movement onset\n- Poor lunge recovery: time from deepest knee flexion back to neutral stance; trunk lean too large\n(Choose based on what your current rules engine already supports. Do not make up events.)\n\n2.2 Animation Cards (must be animated, not text-only)\nGoal: When a mistake is selected, show a “Fix-it” card with a 2–5 sec loop animation:\n- Stick-figure animation rendered in Canvas or SVG (your choice)\n- 3 key phases (setup / contact / recover), with interpolation\n- Minimal text: title + at most 1 sentence\n\nData source for animation:\n- If ghost (best rep) exists for that mistake’s shot window, use ghost keyframes as “correct motion”.\n- Otherwise create a corrected keyframe set using your rules-engine target pose (e.g., adjust elbow lead, raise contact point, correct stance width).\nBut must be derived from actual pose frames + computed corrections, not stock animations.\n\nWhere to implement:\n- Frontend: new component e.g. rallycoach/src/components/Analytics/MistakeTimeline.tsx + FixItCard.tsx\n- Shared math: rallycoach/src/lib/pose-utils.ts additions or new lib modules.\n\n========================\nFEATURE 3: AUTO SKILL ESTIMATION + CONFIDENCE METERS\n========================\nGoal:\n- Remove manual level selection UI on analytics page (and anywhere else).\n- Replace with auto computed:\n  - skillScore (0–100)\n  - levelLabel (Beginner/Intermediate/Advanced)\n  - confidencePercent (0–100) + reasons if low\n\nImplementation constraints:\n- SkillScore must be computed from real metrics (not Gemini alone):\n  Use features you can compute from pose frames and your scoring rules:\n  - consistency of key joint angles over shots\n  - recovery speed after lunges\n  - stance stability + split-step presence\n  - overhead sequence quality (shoulder/hip separation proxy)\n- LevelLabel is derived from thresholds (tune using observed distribution):\n  Example: <40 Beginner, 40–70 Intermediate, >70 Advanced (adjust).\n- Confidence must be derived from pose visibility / tracking stability:\n  - mean landmark visibility across key joints\n  - % frames above a visibility threshold\n  - dropout rate (frames with missing/low visibility)\nOptionally incorporate Tasks-Vision confidence settings where available.\n\nGemini integration:\n- Keep Gemini for “coaching narrative” and natural-language feedback.\n- But the numeric score/label must come from your computed metrics.\n- Update backend/gemini_client.py prompts so Gemini references the computed score + key metrics instead of inventing levels.\n\nStore results:\n- Save skillScore, levelLabel, confidence, and mistake events in Supabase with the session.\n- Ensure history page can load them.\n\nPHASE 3 — REFINER (polish + performance)\n- Add loading animation overlay in analytics during analysis (skeleton shimmer or spinner).\n- Optimize rendering:\n  - Overlay uses requestAnimationFrame, not heavy React re-renders.\n  - Downsample ghost sequence for drawing.\n- Clean UI:\n  - Ghost toggle + source selector\n  - Skill badge + confidence meter\n  - Timeline + fix-it card below video\n- Ensure skeleton overlay still shows in analytics (this fixes your previous “skeleton overlay not showing” class of bug if related).\n\nPHASE 4 — SUPERVISOR (verify)\n- Run backend + frontend locally\n- Provide a “How to test” checklist:\n  1) Upload a video\n  2) See loading\n  3) See skill score + confidence\n  4) See mistake timeline segments\n  5) Click timeline -> video seeks correctly, overlay stays synced\n  6) Turn on Ghost Rival -> ghost appears and follows correctly\n  7) Select mistake -> animated fix-it card plays\n- Confirm no mocked numbers: show where confidence is computed from visibility/tracking outputs.\n\nDELIVERABLES\n- Actual code changes committed (if git is available) with meaningful commit messages.\n- If DB schema change is needed, write a migration SQL file and update README.\n- Update README “Features” section to include:\n  - Ghost Rival Overlay\n  - Mistake Timeline + click-to-jump\n  - Auto skill score + confidence meters\n\nNOW START:\n1) PLANNER: read files and produce a file-level plan\n2) BUILDER: implement\n3) REFINER: polish\n4) SUPERVISOR: verify + checklist\n READ ALL FILES FIRST TO UNDERSTAND ENTIRE PROJECT AND DECIDE HOW TO WORK. "},"uuid":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","timestamp":"2026-01-28T05:05:21.575Z","thinkingMetadata":{"maxThinkingTokens":31999},"todos":[],"permissionMode":"default"}
{"parentUuid":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","message":{"model":"claude-opus-4-5-20251101","id":"msg_01TETP3nVczNHcqz4W7gKBzH","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user wants me to implement three major features for the RallyCoach application:\n1. Ghost Rival Overlay\n2. Mistake Timeline with click-to-jump and Animation Cards\n3. Auto Skill Estimation + Confidence Meters\n\nLet me start by reading the repository structure and understanding the current codebase. I'll begin with the README and then explore the backend and frontend code.\n\nLet me start with PHASE 1 - PLANNER by reading and understanding the codebase.","signature":"Eu4ECkYICxgCKkC9cc0keu1427yuAl1VbWFs/CidfZzW5Jt59A70hFV5zi46Tp0ArppDiCU7DQ1O3wJFcspuqR69yz5eeniklVMVEgxcoI7BXwsL5Jciy9caDOfJtUtUjOPPEFdh3yIwV43lLU+Wph604oKZFUFIj2W+ZJqR5L6lNSpD1M6KkK59FeNOAqkNuTZ4VpfW7yQ6KtUDHclDUIZu70iLj/nJCSEC0p3i4mNV4o/MnoYXcIvA4+3Z6Hi+RCb6Wsg0icvWl+oaVCwOT0sSjddzDIyR5N0KOopF8/iJY3BeS4NxJYwb8fVdZ5Ke8ZbAo49OAcXmjPvPO+r8Yq3DmrcZp3kVFiThiUa5+2b8660TWV2wHO6O8lKh9nzY0gh/j/0OgyDMKM5Gj1CYgvIEbnHi/UAfm5BOwbt6Md68LT6OY+Bl37wBn6ktYvarHjMdmO3smz/4Fv0VVQTne/eu6nyx04/5p1Q0+G1qEpdrltd40w19M1mzcJPbYqpko7WqLVljCGmVutsCJ5OgiyHbnLvR3aY3s4FR1an9/vlgHnD4/7kJRfHRrQJnilVKWCr1XdPZq9wrNA15TxDGzs3Ivr8+jUgBhG/Ta309DG7y1B6mKJPS27NPcMdBR9qe5cKJXJUcXNbzI8+EhyOFKoNsw9M6SPF5GXaOsnpAh/Yp2QLTAp0pT5LeJWPJEUUgdxDL/+jcBxcwewdGYKv32Ceu2D6pw8JaqCTOv+2GYVC0intTijmfdrJTzjxU3Nc+Lw43zNpzFc8VSINK/Np4z61fZP5Jzky5vNFi2BYO5vl4i2x4CIcHZJy/Tbh+/+4jvxgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":9,"cache_creation_input_tokens":29768,"cache_read_input_tokens":10331,"cache_creation":{"ephemeral_5m_input_tokens":29768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCBUnPFjEbWbZiubwKP","type":"assistant","uuid":"4c57c2d2-7fca-46fb-b4c4-6239794e1c79","timestamp":"2026-01-28T05:05:25.733Z"}
{"parentUuid":"4c57c2d2-7fca-46fb-b4c4-6239794e1c79","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","message":{"model":"claude-opus-4-5-20251101","id":"msg_01TETP3nVczNHcqz4W7gKBzH","type":"message","role":"assistant","content":[{"type":"text","text":"I'll start with **PHASE 1 - PLANNER** by thoroughly reading the codebase to understand the current architecture before implementing anything.\n\nLet me begin by exploring the repository structure and reading key files."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":9,"cache_creation_input_tokens":29768,"cache_read_input_tokens":10331,"cache_creation":{"ephemeral_5m_input_tokens":29768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCBUnPFjEbWbZiubwKP","type":"assistant","uuid":"b7d099d7-481d-4007-9c89-8325cf56b2e6","timestamp":"2026-01-28T05:05:26.782Z"}
{"parentUuid":"b7d099d7-481d-4007-9c89-8325cf56b2e6","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","message":{"model":"claude-opus-4-5-20251101","id":"msg_01TETP3nVczNHcqz4W7gKBzH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WGwx6VrMxv8fCPx3iMqbJY","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\README.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":9,"cache_creation_input_tokens":29768,"cache_read_input_tokens":10331,"cache_creation":{"ephemeral_5m_input_tokens":29768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCBUnPFjEbWbZiubwKP","type":"assistant","uuid":"164d72aa-6314-46bb-8e0f-9561e5ea4835","timestamp":"2026-01-28T05:05:27.374Z"}
{"parentUuid":"164d72aa-6314-46bb-8e0f-9561e5ea4835","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","message":{"model":"claude-opus-4-5-20251101","id":"msg_01TETP3nVczNHcqz4W7gKBzH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PK2z3JLY1rxD8EciF17nbS","name":"Glob","input":{"pattern":"**/*","path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":9,"cache_creation_input_tokens":29768,"cache_read_input_tokens":10331,"cache_creation":{"ephemeral_5m_input_tokens":29768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCBUnPFjEbWbZiubwKP","type":"assistant","uuid":"e01d86b8-62a0-451b-962d-e2c19b3ec03c","timestamp":"2026-01-28T05:05:27.904Z"}
{"parentUuid":"164d72aa-6314-46bb-8e0f-9561e5ea4835","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WGwx6VrMxv8fCPx3iMqbJY","type":"tool_result","content":"     1→# RallyCoach - AI-Powered Badminton Coach\n     2→\n     3→An intelligent badminton coaching application that uses computer vision and AI to analyze technique, provide real-time feedback, generate tactical insights, and recommend equipment.\n     4→\n     5→## Features\n     6→\n     7→### Video Analytics\n     8→Upload badminton videos for comprehensive AI analysis:\n     9→- **Pose Detection**: MediaPipe extracts body landmarks from every frame\n    10→- **Shot Detection**: Automatically identifies shots based on wrist velocity patterns\n    11→- **Form Analysis**: Compares player form against ideal technique and identifies errors\n    12→- **AI Skill Assessment**: Gemini AI auto-detects skill level (Beginner/Intermediate/Advanced)\n    13→- **Multi-Player Support**: Detects multiple players in doubles matches with player selection\n    14→- **Skeleton Overlay**: Visual feedback with color-coded form quality (green/yellow/red)\n    15→- **Drill Recommendations**: Targeted drills for each detected issue\n    16→\n    17→### Practice Mode\n    18→Real-time form coaching using your webcam:\n    19→- **Live Pose Tracking**: MediaPipe runs in-browser for instant feedback\n    20→- **Green/Red Skeleton**: Visual indicator of form quality\n    21→- **Coaching Cues**: Text feedback guiding your movements\n    22→- **Session Recording**: Optionally record practice sessions for later review\n    23→- **Metrics Display**: Real-time elbow angle, knee angle, stance width\n    24→- **Progress Tracking**: Green/red frame ratio tracks consistency\n    25→\n    26→### Strategy Analysis\n    27→Analyze rally patterns and get tactical insights:\n    28→- **Trajectory Tracking**: Visualize shot placement patterns\n    29→- **2D/3D Court View**: Interactive court visualization with Three.js\n    30→- **Rally State Machine**: Tracks attack/defense/neutral phases\n    31→- **Shot Recommendations**: AI suggests optimal shot selections with rationale\n    32→- **Coaching Points**: Personalized tactical advice\n    33→\n    34→### Racket Finder\n    35→Personalized equipment recommendations:\n    36→- **Profile-Based Matching**: Based on skill level, play style, and weaknesses\n    37→- **Detailed Specs**: Weight, balance, flexibility, price range\n    38→- **Match Scoring**: Percentage match for each recommendation\n    39→- **eBay Integration**: Direct links to purchase options\n    40→- **Favorites**: Save rackets for later reference\n    41→\n    42→## Tech Stack\n    43→\n    44→### Frontend (rallycoach/)\n    45→- **Next.js 14** with App Router\n    46→- **React 18** with TypeScript\n    47→- **TailwindCSS** for styling\n    48→- **@mediapipe/tasks-vision** for in-browser pose detection\n    49→- **@react-three/fiber** + **Three.js** for 3D court visualization\n    50→- **Recharts** for analytics charts\n    51→- **@supabase/supabase-js** for auth and data\n    52→\n    53→### Backend (backend/)\n    54→- **Python 3.11** with FastAPI\n    55→- **MediaPipe** for server-side pose estimation\n    56→- **OpenCV** for video processing and annotation\n    57→- **Google Gemini API** (gemini-2.0-flash-exp) for AI coaching feedback\n    58→- **Supabase** for authentication, database, and video storage\n    59→\n    60→## Project Structure\n    61→\n    62→```\n    63→RallyCoach/\n    64→├── backend/\n    65→│   ├── main.py              # FastAPI server with all endpoints\n    66→│   ├── analysis.py          # Video analysis pipeline\n    67→│   ├── pose_estimation.py   # MediaPipe pose detection\n    68→│   ├── gemini_client.py     # Gemini API integration\n    69→│   ├── video_annotator.py   # Skeleton overlay rendering\n    70→│   ├── video_processing.py  # Video frame utilities\n    71→│   ├── requirements.txt     # Python dependencies\n    72→│   └── .env                 # Backend environment variables\n    73→├── rallycoach/              # Next.js frontend\n    74→│   ├── src/\n    75→│   │   ├── app/             # Next.js App Router pages\n    76→│   │   │   ├── page.tsx           # Landing page\n    77→│   │   │   ├── dashboard/         # User dashboard\n    78→│   │   │   ├── analytics/         # Video analysis page\n    79→│   │   │   ├── practice/          # Real-time practice mode\n    80→│   │   │   ├── strategy/          # Strategy analysis\n    81→│   │   │   ├── racket/            # Racket recommendations\n    82→│   │   │   ├── history/           # Session history\n    83→│   │   │   └── api/               # API routes\n    84→│   │   ├── components/      # React components\n    85→│   │   ├── lib/             # Utilities and engines\n    86→│   │   │   ├── supabase.ts        # Supabase client\n    87→│   │   │   ├── pose-utils.ts      # Pose processing utilities\n    88→│   │   │   ├── rules-engine.ts    # Form evaluation rules\n    89→│   │   │   ├── scoring-rules.ts   # Banded scoring system\n    90→│   │   │   ├── strategy_engine/   # Rally analysis engine\n    91→│   │   │   └── courtSpec.ts       # BWF court specifications\n    92→│   │   └── data/            # Static data (rackets.json)\n    93→│   ├── package.json\n    94→│   └── .env.local           # Frontend environment variables\n    95→├── supabase-setup.sql       # Initial database schema\n    96→├── supabase-migration-v2.sql # Extended schema with sessions/issues\n    97→└── README.md\n    98→```\n    99→\n   100→## Setup Instructions\n   101→\n   102→### Prerequisites\n   103→- Python 3.11+\n   104→- Node.js 18+\n   105→- Supabase account\n   106→- Google AI Studio account (for Gemini API)\n   107→\n   108→### 1. Supabase Setup\n   109→\n   110→1. Create a project at [supabase.com](https://supabase.com)\n   111→\n   112→2. Get your credentials from Settings > API:\n   113→   - Project URL\n   114→   - Anon Key (public)\n   115→   - Service Role Key (secret, for backend)\n   116→\n   117→3. Run the database migrations in SQL Editor:\n   118→   - First run `supabase-setup.sql` for base tables\n   119→   - Then run `supabase-migration-v2.sql` for extended schema\n   120→\n   121→4. Create a Storage bucket named `videos`:\n   122→   - Set to Private\n   123→   - Add policies for authenticated users\n   124→\n   125→### 2. Get Gemini API Key\n   126→\n   127→1. Go to [Google AI Studio](https://aistudio.google.com/app/apikey)\n   128→2. Create a new API key\n   129→3. Copy for later use\n   130→\n   131→### 3. Backend Setup\n   132→\n   133→```bash\n   134→cd backend\n   135→\n   136→# Create virtual environment\n   137→python -m venv venv\n   138→\n   139→# Activate virtual environment\n   140→# Windows:\n   141→venv\\Scripts\\activate\n   142→# Mac/Linux:\n   143→source venv/bin/activate\n   144→\n   145→# Install dependencies\n   146→pip install -r requirements.txt\n   147→\n   148→# Configure environment variables in backend/.env:\n   149→# GEMINI_API_KEY=your-gemini-key\n   150→# SUPABASE_URL=https://your-project.supabase.co\n   151→# SUPABASE_ANON_KEY=your-anon-key\n   152→# SUPABASE_SERVICE_KEY=your-service-role-key\n   153→```\n   154→\n   155→### 4. Frontend Setup\n   156→\n   157→```bash\n   158→cd rallycoach\n   159→\n   160→# Install dependencies\n   161→npm install\n   162→\n   163→# Configure environment variables in .env.local:\n   164→# NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co\n   165→# NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key\n   166→# GEMINI_API_KEY=your-gemini-key (for API routes)\n   167→```\n   168→\n   169→### 5. Run the Application\n   170→\n   171→**Start Backend:**\n   172→```bash\n   173→cd backend\n   174→# Ensure venv is activated\n   175→python main.py\n   176→```\n   177→Backend runs on `http://localhost:8000`\n   178→\n   179→**Start Frontend:**\n   180→```bash\n   181→cd rallycoach\n   182→npm run dev\n   183→```\n   184→Frontend runs on `http://localhost:3000`\n   185→\n   186→## Usage\n   187→\n   188→1. **Sign Up / Sign In** - Create an account at the landing page\n   189→\n   190→2. **Video Analytics** - Upload a badminton video to get:\n   191→   - Pose skeleton overlay\n   192→   - Shot-by-shot analysis\n   193→   - Form error detection\n   194→   - AI skill level assessment\n   195→   - Recommended drills\n   196→\n   197→3. **Practice Mode** - Use your webcam for real-time coaching:\n   198→   - Stand 6-8 feet from camera\n   199→   - Ensure good lighting\n   200→   - Follow the skeleton overlay colors\n   201→\n   202→4. **Strategy Analysis** - Upload match footage to:\n   203→   - Visualize rally patterns\n   204→   - Get tactical recommendations\n   205→   - Review coaching points\n   206→\n   207→5. **Racket Finder** - Get equipment recommendations:\n   208→   - Select skill level and play style\n   209→   - Choose areas to improve\n   210→   - Browse matched rackets\n   211→\n   212→## API Endpoints\n   213→\n   214→### Backend API (FastAPI)\n   215→\n   216→| Endpoint | Method | Description |\n   217→|----------|--------|-------------|\n   218→| `/` | GET | Health check |\n   219→| `/health` | GET | Service status |\n   220→| `/api/analyze` | POST | Analyze uploaded video |\n   221→| `/api/sessions` | GET | List user sessions |\n   222→| `/api/sessions/{id}` | GET | Get session details |\n   223→| `/api/practice` | POST | Save practice session |\n   224→| `/api/stats/dashboard` | GET | Dashboard statistics |\n   225→| `/temp/{filename}` | GET | Serve annotated videos |\n   226→\n   227→### Frontend API Routes (Next.js)\n   228→\n   229→| Route | Description |\n   230→|-------|-------------|\n   231→| `/api/analysis/start` | Start video analysis |\n   232→| `/api/analysis/auto-level` | Gemini skill level detection |\n   233→| `/api/practice/tick` | Practice mode tick feedback |\n   234→| `/api/strategy/recommend` | Strategy recommendations |\n   235→| `/api/racket/recommend` | Racket recommendations |\n   236→\n   237→## How It Works\n   238→\n   239→### Video Analysis Pipeline\n   240→\n   241→1. **Upload** - Video uploaded via TUS resumable protocol to Supabase Storage\n   242→2. **Pose Extraction** - MediaPipe extracts 33 body landmarks per frame\n   243→3. **Shot Detection** - Wrist velocity spikes identify shot events\n   244→4. **Shot Classification** - Heuristics classify shots (Smash, Clear, Net Shot, etc.)\n   245→5. **Form Evaluation** - Rules engine compares poses to ideal form\n   246→6. **Skill Assessment** - Gemini AI analyzes metrics to determine skill level\n   247→7. **Feedback Generation** - Gemini provides coaching feedback and training plans\n   248→8. **Annotation** - Skeleton overlay rendered on video with color-coded quality\n   249→9. **Storage** - Results saved to Supabase (sessions, issues tables)\n   250→\n   251→### Real-Time Practice\n   252→\n   253→1. **Webcam Capture** - Browser MediaDevices API\n   254→2. **In-Browser Pose** - MediaPipe Tasks Vision runs client-side\n   255→3. **Rule Evaluation** - Form rules evaluated every frame\n   256→4. **Visual Feedback** - Canvas overlay shows skeleton in green/red\n   257→5. **Coaching Cues** - Text feedback guides corrections\n   258→6. **Session Tracking** - Metrics aggregated and saved\n   259→\n   260→## Troubleshooting\n   261→\n   262→### Video Upload Issues\n   263→- Check file size (max 100MB)\n   264→- Verify Supabase storage bucket exists and has correct policies\n   265→- Check browser console for CORS errors\n   266→\n   267→### Pose Detection Issues\n   268→- Ensure good lighting and camera angle\n   269→- Keep full body visible in frame\n   270→- Try the demo mode if camera fails\n   271→\n   272→### Gemini API Errors\n   273→- Verify API key is valid\n   274→- Check quota limits in Google AI Studio\n   275→- Ensure network connectivity\n   276→\n   277→### Database Errors\n   278→- Run both SQL migration files in order\n   279→- Check RLS policies are configured\n   280→- Verify service role key for backend writes\n   281→\n   282→## License\n   283→\n   284→MIT License - Feel free to use and modify for your projects.\n   285→\n   286→## Acknowledgments\n   287→\n   288→- [MediaPipe](https://mediapipe.dev/) for pose estimation\n   289→- [Google Gemini](https://ai.google.dev/) for AI coaching\n   290→- [Supabase](https://supabase.com/) for backend services\n   291→- [Next.js](https://nextjs.org/) and [React](https://react.dev/) for the frontend\n   292→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"1a885ab8-b50c-4aaf-b902-422df4b732f4","timestamp":"2026-01-28T05:05:29.938Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\README.md","content":"# RallyCoach - AI-Powered Badminton Coach\n\nAn intelligent badminton coaching application that uses computer vision and AI to analyze technique, provide real-time feedback, generate tactical insights, and recommend equipment.\n\n## Features\n\n### Video Analytics\nUpload badminton videos for comprehensive AI analysis:\n- **Pose Detection**: MediaPipe extracts body landmarks from every frame\n- **Shot Detection**: Automatically identifies shots based on wrist velocity patterns\n- **Form Analysis**: Compares player form against ideal technique and identifies errors\n- **AI Skill Assessment**: Gemini AI auto-detects skill level (Beginner/Intermediate/Advanced)\n- **Multi-Player Support**: Detects multiple players in doubles matches with player selection\n- **Skeleton Overlay**: Visual feedback with color-coded form quality (green/yellow/red)\n- **Drill Recommendations**: Targeted drills for each detected issue\n\n### Practice Mode\nReal-time form coaching using your webcam:\n- **Live Pose Tracking**: MediaPipe runs in-browser for instant feedback\n- **Green/Red Skeleton**: Visual indicator of form quality\n- **Coaching Cues**: Text feedback guiding your movements\n- **Session Recording**: Optionally record practice sessions for later review\n- **Metrics Display**: Real-time elbow angle, knee angle, stance width\n- **Progress Tracking**: Green/red frame ratio tracks consistency\n\n### Strategy Analysis\nAnalyze rally patterns and get tactical insights:\n- **Trajectory Tracking**: Visualize shot placement patterns\n- **2D/3D Court View**: Interactive court visualization with Three.js\n- **Rally State Machine**: Tracks attack/defense/neutral phases\n- **Shot Recommendations**: AI suggests optimal shot selections with rationale\n- **Coaching Points**: Personalized tactical advice\n\n### Racket Finder\nPersonalized equipment recommendations:\n- **Profile-Based Matching**: Based on skill level, play style, and weaknesses\n- **Detailed Specs**: Weight, balance, flexibility, price range\n- **Match Scoring**: Percentage match for each recommendation\n- **eBay Integration**: Direct links to purchase options\n- **Favorites**: Save rackets for later reference\n\n## Tech Stack\n\n### Frontend (rallycoach/)\n- **Next.js 14** with App Router\n- **React 18** with TypeScript\n- **TailwindCSS** for styling\n- **@mediapipe/tasks-vision** for in-browser pose detection\n- **@react-three/fiber** + **Three.js** for 3D court visualization\n- **Recharts** for analytics charts\n- **@supabase/supabase-js** for auth and data\n\n### Backend (backend/)\n- **Python 3.11** with FastAPI\n- **MediaPipe** for server-side pose estimation\n- **OpenCV** for video processing and annotation\n- **Google Gemini API** (gemini-2.0-flash-exp) for AI coaching feedback\n- **Supabase** for authentication, database, and video storage\n\n## Project Structure\n\n```\nRallyCoach/\n├── backend/\n│   ├── main.py              # FastAPI server with all endpoints\n│   ├── analysis.py          # Video analysis pipeline\n│   ├── pose_estimation.py   # MediaPipe pose detection\n│   ├── gemini_client.py     # Gemini API integration\n│   ├── video_annotator.py   # Skeleton overlay rendering\n│   ├── video_processing.py  # Video frame utilities\n│   ├── requirements.txt     # Python dependencies\n│   └── .env                 # Backend environment variables\n├── rallycoach/              # Next.js frontend\n│   ├── src/\n│   │   ├── app/             # Next.js App Router pages\n│   │   │   ├── page.tsx           # Landing page\n│   │   │   ├── dashboard/         # User dashboard\n│   │   │   ├── analytics/         # Video analysis page\n│   │   │   ├── practice/          # Real-time practice mode\n│   │   │   ├── strategy/          # Strategy analysis\n│   │   │   ├── racket/            # Racket recommendations\n│   │   │   ├── history/           # Session history\n│   │   │   └── api/               # API routes\n│   │   ├── components/      # React components\n│   │   ├── lib/             # Utilities and engines\n│   │   │   ├── supabase.ts        # Supabase client\n│   │   │   ├── pose-utils.ts      # Pose processing utilities\n│   │   │   ├── rules-engine.ts    # Form evaluation rules\n│   │   │   ├── scoring-rules.ts   # Banded scoring system\n│   │   │   ├── strategy_engine/   # Rally analysis engine\n│   │   │   └── courtSpec.ts       # BWF court specifications\n│   │   └── data/            # Static data (rackets.json)\n│   ├── package.json\n│   └── .env.local           # Frontend environment variables\n├── supabase-setup.sql       # Initial database schema\n├── supabase-migration-v2.sql # Extended schema with sessions/issues\n└── README.md\n```\n\n## Setup Instructions\n\n### Prerequisites\n- Python 3.11+\n- Node.js 18+\n- Supabase account\n- Google AI Studio account (for Gemini API)\n\n### 1. Supabase Setup\n\n1. Create a project at [supabase.com](https://supabase.com)\n\n2. Get your credentials from Settings > API:\n   - Project URL\n   - Anon Key (public)\n   - Service Role Key (secret, for backend)\n\n3. Run the database migrations in SQL Editor:\n   - First run `supabase-setup.sql` for base tables\n   - Then run `supabase-migration-v2.sql` for extended schema\n\n4. Create a Storage bucket named `videos`:\n   - Set to Private\n   - Add policies for authenticated users\n\n### 2. Get Gemini API Key\n\n1. Go to [Google AI Studio](https://aistudio.google.com/app/apikey)\n2. Create a new API key\n3. Copy for later use\n\n### 3. Backend Setup\n\n```bash\ncd backend\n\n# Create virtual environment\npython -m venv venv\n\n# Activate virtual environment\n# Windows:\nvenv\\Scripts\\activate\n# Mac/Linux:\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt\n\n# Configure environment variables in backend/.env:\n# GEMINI_API_KEY=your-gemini-key\n# SUPABASE_URL=https://your-project.supabase.co\n# SUPABASE_ANON_KEY=your-anon-key\n# SUPABASE_SERVICE_KEY=your-service-role-key\n```\n\n### 4. Frontend Setup\n\n```bash\ncd rallycoach\n\n# Install dependencies\nnpm install\n\n# Configure environment variables in .env.local:\n# NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co\n# NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key\n# GEMINI_API_KEY=your-gemini-key (for API routes)\n```\n\n### 5. Run the Application\n\n**Start Backend:**\n```bash\ncd backend\n# Ensure venv is activated\npython main.py\n```\nBackend runs on `http://localhost:8000`\n\n**Start Frontend:**\n```bash\ncd rallycoach\nnpm run dev\n```\nFrontend runs on `http://localhost:3000`\n\n## Usage\n\n1. **Sign Up / Sign In** - Create an account at the landing page\n\n2. **Video Analytics** - Upload a badminton video to get:\n   - Pose skeleton overlay\n   - Shot-by-shot analysis\n   - Form error detection\n   - AI skill level assessment\n   - Recommended drills\n\n3. **Practice Mode** - Use your webcam for real-time coaching:\n   - Stand 6-8 feet from camera\n   - Ensure good lighting\n   - Follow the skeleton overlay colors\n\n4. **Strategy Analysis** - Upload match footage to:\n   - Visualize rally patterns\n   - Get tactical recommendations\n   - Review coaching points\n\n5. **Racket Finder** - Get equipment recommendations:\n   - Select skill level and play style\n   - Choose areas to improve\n   - Browse matched rackets\n\n## API Endpoints\n\n### Backend API (FastAPI)\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/` | GET | Health check |\n| `/health` | GET | Service status |\n| `/api/analyze` | POST | Analyze uploaded video |\n| `/api/sessions` | GET | List user sessions |\n| `/api/sessions/{id}` | GET | Get session details |\n| `/api/practice` | POST | Save practice session |\n| `/api/stats/dashboard` | GET | Dashboard statistics |\n| `/temp/{filename}` | GET | Serve annotated videos |\n\n### Frontend API Routes (Next.js)\n\n| Route | Description |\n|-------|-------------|\n| `/api/analysis/start` | Start video analysis |\n| `/api/analysis/auto-level` | Gemini skill level detection |\n| `/api/practice/tick` | Practice mode tick feedback |\n| `/api/strategy/recommend` | Strategy recommendations |\n| `/api/racket/recommend` | Racket recommendations |\n\n## How It Works\n\n### Video Analysis Pipeline\n\n1. **Upload** - Video uploaded via TUS resumable protocol to Supabase Storage\n2. **Pose Extraction** - MediaPipe extracts 33 body landmarks per frame\n3. **Shot Detection** - Wrist velocity spikes identify shot events\n4. **Shot Classification** - Heuristics classify shots (Smash, Clear, Net Shot, etc.)\n5. **Form Evaluation** - Rules engine compares poses to ideal form\n6. **Skill Assessment** - Gemini AI analyzes metrics to determine skill level\n7. **Feedback Generation** - Gemini provides coaching feedback and training plans\n8. **Annotation** - Skeleton overlay rendered on video with color-coded quality\n9. **Storage** - Results saved to Supabase (sessions, issues tables)\n\n### Real-Time Practice\n\n1. **Webcam Capture** - Browser MediaDevices API\n2. **In-Browser Pose** - MediaPipe Tasks Vision runs client-side\n3. **Rule Evaluation** - Form rules evaluated every frame\n4. **Visual Feedback** - Canvas overlay shows skeleton in green/red\n5. **Coaching Cues** - Text feedback guides corrections\n6. **Session Tracking** - Metrics aggregated and saved\n\n## Troubleshooting\n\n### Video Upload Issues\n- Check file size (max 100MB)\n- Verify Supabase storage bucket exists and has correct policies\n- Check browser console for CORS errors\n\n### Pose Detection Issues\n- Ensure good lighting and camera angle\n- Keep full body visible in frame\n- Try the demo mode if camera fails\n\n### Gemini API Errors\n- Verify API key is valid\n- Check quota limits in Google AI Studio\n- Ensure network connectivity\n\n### Database Errors\n- Run both SQL migration files in order\n- Check RLS policies are configured\n- Verify service role key for backend writes\n\n## License\n\nMIT License - Feel free to use and modify for your projects.\n\n## Acknowledgments\n\n- [MediaPipe](https://mediapipe.dev/) for pose estimation\n- [Google Gemini](https://ai.google.dev/) for AI coaching\n- [Supabase](https://supabase.com/) for backend services\n- [Next.js](https://nextjs.org/) and [React](https://react.dev/) for the frontend\n","numLines":292,"startLine":1,"totalLines":292}},"sourceToolAssistantUUID":"164d72aa-6314-46bb-8e0f-9561e5ea4835"}
{"parentUuid":"1a885ab8-b50c-4aaf-b902-422df4b732f4","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01WGwx6VrMxv8fCPx3iMqbJY","toolUseID":"toolu_01WGwx6VrMxv8fCPx3iMqbJY","timestamp":"2026-01-28T05:05:29.953Z","uuid":"db4f62a4-e26b-4fc7-9481-ca939e4c575a"}
{"parentUuid":"e01d86b8-62a0-451b-962d-e2c19b3ec03c","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PK2z3JLY1rxD8EciF17nbS","type":"tool_result","content":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\distutils-precedence.pth\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\_distutils_hack\\override.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\appdirs.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\zipp.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\_adapters.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\_common.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\_compat.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\_itertools.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\abc.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\_legacy.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\readers.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\simple.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\jaraco\\context.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\jaraco\\functools.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\jaraco\\text\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\jaraco\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\more_itertools\\more.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\more_itertools\\recipes.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\more_itertools\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\markers.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\requirements.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\specifiers.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\_manylinux.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\_musllinux.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\_structures.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\__about__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\extern\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\tags.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\utils.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\version.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\actions.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\common.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\core.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\diagram\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\exceptions.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\helpers.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\results.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\testing.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\unicode.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\util.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\archive_util.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\build_meta.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\cli-32.exe\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\cli-64.exe\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\cli-arm64.exe\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\cli.exe\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\depends.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\dep_util.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\discovery.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_deprecation_warning.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_entry_points.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_imp.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_importlib.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_itertools.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_path.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_reqs.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\dist.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\errors.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\extension.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\glob.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\gui-32.exe\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\gui-64.exe\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\gui-arm64.exe\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\gui.exe\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\installer.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\launch.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\logging.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\monkey.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\msvc.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\namespaces.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\package_index.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\py34compat.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\sandbox.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\script (dev).tmpl\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\script.tmpl\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\unicode_utils.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\version.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\wheel.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\windows_support.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\_collections.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\_functools.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\_macos_compat.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\archive_util.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\bcppcompiler.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\ccompiler.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\config.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\core.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\cygwinccompiler.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\debug.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\dep_util.py\n(Results are truncated. Consider using a more specific path or pattern.)"}]},"uuid":"b7a148ac-378c-47c3-8215-6c6076d3a948","timestamp":"2026-01-28T05:05:32.081Z","toolUseResult":{"filenames":["C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\distutils-precedence.pth","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\_distutils_hack\\override.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\appdirs.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\zipp.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\_adapters.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\_common.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\_compat.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\_itertools.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\abc.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\_legacy.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\readers.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\importlib_resources\\simple.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\jaraco\\context.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\jaraco\\functools.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\jaraco\\text\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\jaraco\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\more_itertools\\more.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\more_itertools\\recipes.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\more_itertools\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\markers.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\requirements.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\specifiers.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\_manylinux.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\_musllinux.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\_structures.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\__about__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\extern\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\tags.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\utils.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\packaging\\version.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\actions.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\common.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\core.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\diagram\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\exceptions.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\helpers.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\results.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\testing.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\unicode.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\util.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\pkg_resources\\_vendor\\pyparsing\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\archive_util.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\build_meta.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\cli-32.exe","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\cli-64.exe","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\cli-arm64.exe","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\cli.exe","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\depends.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\dep_util.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\discovery.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_deprecation_warning.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_entry_points.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_imp.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_importlib.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_itertools.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_path.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_reqs.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\dist.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\errors.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\extension.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\glob.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\gui-32.exe","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\gui-64.exe","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\gui-arm64.exe","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\gui.exe","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\installer.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\launch.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\logging.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\monkey.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\msvc.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\namespaces.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\package_index.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\py34compat.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\sandbox.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\script (dev).tmpl","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\script.tmpl","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\unicode_utils.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\version.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\wheel.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\windows_support.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\_collections.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\_functools.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\_macos_compat.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\archive_util.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\bcppcompiler.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\ccompiler.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\config.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\core.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\cygwinccompiler.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\debug.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\venv\\Lib\\site-packages\\setuptools\\_distutils\\dep_util.py"],"durationMs":2268,"numFiles":100,"truncated":true},"sourceToolAssistantUUID":"e01d86b8-62a0-451b-962d-e2c19b3ec03c"}
{"parentUuid":"b7a148ac-378c-47c3-8215-6c6076d3a948","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Glob","command":"callback"},"parentToolUseID":"toolu_01PK2z3JLY1rxD8EciF17nbS","toolUseID":"toolu_01PK2z3JLY1rxD8EciF17nbS","timestamp":"2026-01-28T05:05:32.086Z","uuid":"72ba5d23-de49-4e62-afcd-54aa23b86d54"}
{"parentUuid":"72ba5d23-de49-4e62-afcd-54aa23b86d54","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01GbvxXzaQQBu6r5ayTpJox7","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The glob returned too many files from venv. Let me search for the actual project files, excluding venv.","signature":"Eo8CCkYICxgCKkDszQ8e7p7rkRXEli0a+C3Lr3pCm/VcrQKVbkwGiw5wnq2tsfKqesRUhxMiuBoFTqkqQU08NjTSPITmsxoguBrGEgwgZ5aIH8leJeyOsO8aDCDdfoPKbD9cA5qEWiIwp59C6IVSFSKY3nDuD5uFi4ExpdEZP7UG3gNy+hb1W02Cs+GJTaAj/woycgu3vhfcKnckCvDiIyDTJM39McaMVeZSZrpzFrCylisaDXGtXGACHyg2lguO1vmVaHUpFy3asDV7r2HgNYUaH+lf8sMOeIwOkWrapANZZ+qCF20MBlPNGahaz6BxmEIdTX09TyssBhonFPpc2vspStoUK5ymkn9XNZUHFEpqHBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":8104,"cache_read_input_tokens":40099,"cache_creation":{"ephemeral_5m_input_tokens":8104,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCCEywjWEBEDypgE4z3","type":"assistant","uuid":"ecb37ad8-846f-4361-8d88-6aa05d887264","timestamp":"2026-01-28T05:05:34.652Z"}
{"parentUuid":"ecb37ad8-846f-4361-8d88-6aa05d887264","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01GbvxXzaQQBu6r5ayTpJox7","type":"message","role":"assistant","content":[{"type":"text","text":"Let me get a more focused view of the project structure, excluding the venv folder."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":8104,"cache_read_input_tokens":40099,"cache_creation":{"ephemeral_5m_input_tokens":8104,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCCEywjWEBEDypgE4z3","type":"assistant","uuid":"11482be9-b37b-43ff-b6b3-f334f2b05cde","timestamp":"2026-01-28T05:05:35.335Z"}
{"parentUuid":"11482be9-b37b-43ff-b6b3-f334f2b05cde","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01GbvxXzaQQBu6r5ayTpJox7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01E7hvZV5FD9PuHNDAdg5GL2","name":"Glob","input":{"pattern":"backend/**/*.py","path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":8104,"cache_read_input_tokens":40099,"cache_creation":{"ephemeral_5m_input_tokens":8104,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCCEywjWEBEDypgE4z3","type":"assistant","uuid":"882df693-7926-4474-9a65-0a82d8ac2b8e","timestamp":"2026-01-28T05:05:36.132Z"}
{"parentUuid":"882df693-7926-4474-9a65-0a82d8ac2b8e","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01GbvxXzaQQBu6r5ayTpJox7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01G1McDGmsTGGJeEXfkp6B5r","name":"Glob","input":{"pattern":"rallycoach/**/*.{ts,tsx}","path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":8104,"cache_read_input_tokens":40099,"cache_creation":{"ephemeral_5m_input_tokens":8104,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCCEywjWEBEDypgE4z3","type":"assistant","uuid":"89311deb-afe9-4c19-82ab-3896ed7e76bc","timestamp":"2026-01-28T05:05:36.873Z"}
{"parentUuid":"89311deb-afe9-4c19-82ab-3896ed7e76bc","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01GbvxXzaQQBu6r5ayTpJox7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017kP578Pm8ZCWnbbie5o4U4","name":"Glob","input":{"pattern":"*.sql","path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":8104,"cache_read_input_tokens":40099,"cache_creation":{"ephemeral_5m_input_tokens":8104,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCCEywjWEBEDypgE4z3","type":"assistant","uuid":"97c15583-712e-4eec-a4d1-155203381919","timestamp":"2026-01-28T05:05:37.398Z"}
{"parentUuid":"97c15583-712e-4eec-a4d1-155203381919","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017kP578Pm8ZCWnbbie5o4U4","type":"tool_result","content":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\supabase-setup.sql\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\supabase-migration-v2.sql\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\schema.sql\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\migration.sql\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\migration-v3.sql\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\migration-v4-fix-type-constraint.sql\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\migration-v5-practice-recordings.sql\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\migration-v4-strategy-engine.sql"}]},"uuid":"8286d815-9c65-4249-a3f0-7a626871452f","timestamp":"2026-01-28T05:05:40.052Z","toolUseResult":{"filenames":["C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\supabase-setup.sql","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\supabase-migration-v2.sql","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\schema.sql","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\migration.sql","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\migration-v3.sql","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\migration-v4-fix-type-constraint.sql","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\migration-v5-practice-recordings.sql","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\supabase\\migration-v4-strategy-engine.sql"],"durationMs":394,"numFiles":8,"truncated":false},"sourceToolAssistantUUID":"97c15583-712e-4eec-a4d1-155203381919"}
{"parentUuid":"8286d815-9c65-4249-a3f0-7a626871452f","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Glob","command":"callback"},"parentToolUseID":"toolu_017kP578Pm8ZCWnbbie5o4U4","toolUseID":"toolu_017kP578Pm8ZCWnbbie5o4U4","timestamp":"2026-01-28T05:05:40.057Z","uuid":"cefb1f8a-7898-4a99-8694-2fcfe6283228"}
{"parentUuid":"89311deb-afe9-4c19-82ab-3896ed7e76bc","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01G1McDGmsTGGJeEXfkp6B5r","type":"tool_result","content":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\tailwind.config.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\pose-utils.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\page.tsx\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\login\\page.tsx\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\signup\\page.tsx\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\api\\analysis\\start\\route.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\api\\analysis\\[id]\\route.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\api\\practice\\tick\\route.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\api\\racket\\recommend\\route.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\next-env.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\gemini.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\json5\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\is-binary-path\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\has-flag\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\is-fullwidth-code-point\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\shebang-regex\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\callsites\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\slash\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\array-union\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\path-type\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\path-exists\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi-cjs\\node_modules\\emoji-regex\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\string-width-cjs\\node_modules\\emoji-regex\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@nolyfill\\is-core-module\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\phoenix\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\prop-types\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react\\canary.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react-dom\\canary.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-path\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-timer\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-color\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\keyv\\src\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-ease\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\undici-types\\agent.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react-dom\\client.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-interpolate\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-time\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react\\experimental.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\ts-interface-checker\\dist\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\ws\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-array\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\type-fest\\source\\async-return-type.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\postcss-nested\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\anymatch\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\ansi-regex\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\arg\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\queue-microtask\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\word-wrap\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\yocto-queue\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\p-limit\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\p-locate\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\strip-ansi-cjs\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\string-width\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\string-width-cjs\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\locate-path\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\import-fresh\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\is-path-inside\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\path-key\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\strip-ansi\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\strip-json-comments\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@isaacs\\cliui\\node_modules\\ansi-regex\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@isaacs\\cliui\\node_modules\\strip-ansi\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react-dom\\experimental.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\escape-string-regexp\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\find-up\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\pirates\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\readdirp\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\string-width\\node_modules\\ansi-regex\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\string-width\\node_modules\\strip-ansi\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\undici-types\\api.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi\\node_modules\\ansi-regex\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi\\node_modules\\strip-ansi\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi-cjs\\node_modules\\string-width\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@alloc\\quick-lru\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\ansi-styles\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react\\global.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi\\node_modules\\ansi-styles\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\ecdsa-sig-formatter\\src\\ecdsa-sig-formatter.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\safe-buffer\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\lines-and-columns\\build\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\lilconfig\\src\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\unrs-resolver\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-scale\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\binary-extensions\\binary-extensions.json.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@rtsao\\scc\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react-dom\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\picocolors\\picocolors.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\undici-types\\balanced-pool.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\acorn-jsx\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\type-fest\\source\\asyncify.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-shape\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\stable-hash\\dist\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\tsconfig-paths\\lib\\config-loader.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@protobufjs\\path\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@protobufjs\\base64\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@protobufjs\\codegen\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\globals\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\ignore\\index.d.ts\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@protobufjs\\aspromise\\index.d.ts\n(Results are truncated. Consider using a more specific path or pattern.)"}]},"uuid":"79ece214-7a23-4f62-a0c3-f6a254838b92","timestamp":"2026-01-28T05:05:40.150Z","toolUseResult":{"filenames":["C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\tailwind.config.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\pose-utils.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\page.tsx","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\login\\page.tsx","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\signup\\page.tsx","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\api\\analysis\\start\\route.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\api\\analysis\\[id]\\route.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\api\\practice\\tick\\route.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\api\\racket\\recommend\\route.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\next-env.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\gemini.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\json5\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\is-binary-path\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\has-flag\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\is-fullwidth-code-point\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\shebang-regex\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\callsites\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\slash\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\array-union\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\path-type\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\path-exists\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi-cjs\\node_modules\\emoji-regex\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\string-width-cjs\\node_modules\\emoji-regex\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@nolyfill\\is-core-module\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\phoenix\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\prop-types\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react\\canary.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react-dom\\canary.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-path\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-timer\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-color\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\keyv\\src\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-ease\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\undici-types\\agent.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react-dom\\client.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-interpolate\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-time\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react\\experimental.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\ts-interface-checker\\dist\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\ws\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-array\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\type-fest\\source\\async-return-type.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\postcss-nested\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\anymatch\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\ansi-regex\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\arg\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\queue-microtask\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\word-wrap\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\yocto-queue\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\p-limit\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\p-locate\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\strip-ansi-cjs\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\string-width\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\string-width-cjs\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\locate-path\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\import-fresh\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\is-path-inside\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\path-key\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\strip-ansi\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\strip-json-comments\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@isaacs\\cliui\\node_modules\\ansi-regex\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@isaacs\\cliui\\node_modules\\strip-ansi\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react-dom\\experimental.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\escape-string-regexp\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\find-up\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\pirates\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\readdirp\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\string-width\\node_modules\\ansi-regex\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\string-width\\node_modules\\strip-ansi\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\undici-types\\api.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi\\node_modules\\ansi-regex\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi\\node_modules\\strip-ansi\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi-cjs\\node_modules\\string-width\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@alloc\\quick-lru\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\ansi-styles\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react\\global.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\wrap-ansi\\node_modules\\ansi-styles\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\ecdsa-sig-formatter\\src\\ecdsa-sig-formatter.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\safe-buffer\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\lines-and-columns\\build\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\lilconfig\\src\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\unrs-resolver\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-scale\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\binary-extensions\\binary-extensions.json.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@rtsao\\scc\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\react-dom\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\picocolors\\picocolors.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\undici-types\\balanced-pool.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\acorn-jsx\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\type-fest\\source\\asyncify.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@types\\d3-shape\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\stable-hash\\dist\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\tsconfig-paths\\lib\\config-loader.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@protobufjs\\path\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@protobufjs\\base64\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@protobufjs\\codegen\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\globals\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\ignore\\index.d.ts","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\node_modules\\@protobufjs\\aspromise\\index.d.ts"],"durationMs":492,"numFiles":100,"truncated":true},"sourceToolAssistantUUID":"89311deb-afe9-4c19-82ab-3896ed7e76bc"}
{"parentUuid":"79ece214-7a23-4f62-a0c3-f6a254838b92","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Glob","command":"callback"},"parentToolUseID":"toolu_01G1McDGmsTGGJeEXfkp6B5r","toolUseID":"toolu_01G1McDGmsTGGJeEXfkp6B5r","timestamp":"2026-01-28T05:05:40.156Z","uuid":"2f8aeb66-581c-4c4e-96f5-23455280a6d8"}
{"parentUuid":"882df693-7926-4474-9a65-0a82d8ac2b8e","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01E7hvZV5FD9PuHNDAdg5GL2","type":"tool_result","content":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\test_setup.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\build_env.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cache.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\configuration.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\exceptions.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\main.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\pyproject.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\self_outdated_check.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\wheel_builder.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\__main__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\__pip-runner__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\autocompletion.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\cmdoptions.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\command_context.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\index_command.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\main.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\main_parser.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\parser.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\spinners.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\status_codes.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\cache.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\check.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\completion.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\configuration.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\debug.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\download.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\freeze.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\hash.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\help.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\index.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\inspect.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\list.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\lock.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\search.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\show.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\uninstall.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\wheel.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\distributions\\base.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\distributions\\installed.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\distributions\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\distributions\\wheel.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\index\\collector.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\index\\package_finder.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\index\\sources.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\index\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\locations\\base.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\locations\\_distutils.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\locations\\_sysconfig.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\locations\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\base.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\_json.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_compat.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_dists.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_envs.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\candidate.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\direct_url.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\format_control.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\index.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\installation_report.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\link.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\pylock.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\scheme.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\search_scope.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\selection_prefs.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\target_python.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\wheel.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\auth.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\cache.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\download.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\lazy_wheel.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\session.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\utils.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\xmlrpc.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\check.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\freeze.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\build_tracker.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata_editable.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata_legacy.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel_editable.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel_legacy.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\__init__.py\nC:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\install\\editable_legacy.py\n(Results are truncated. Consider using a more specific path or pattern.)"}]},"uuid":"a0251b73-f845-4b84-b08e-6251fccbecfc","timestamp":"2026-01-28T05:05:40.180Z","toolUseResult":{"filenames":["C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\test_setup.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\build_env.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cache.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\configuration.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\exceptions.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\main.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\pyproject.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\self_outdated_check.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\wheel_builder.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\__main__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\__pip-runner__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\autocompletion.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\cmdoptions.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\command_context.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\index_command.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\main.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\main_parser.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\parser.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\spinners.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\cli\\status_codes.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\cache.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\check.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\completion.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\configuration.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\debug.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\download.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\freeze.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\hash.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\help.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\index.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\inspect.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\install.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\list.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\lock.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\search.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\show.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\uninstall.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\commands\\wheel.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\distributions\\base.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\distributions\\installed.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\distributions\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\distributions\\wheel.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\index\\collector.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\index\\package_finder.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\index\\sources.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\index\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\locations\\base.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\locations\\_distutils.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\locations\\_sysconfig.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\locations\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\base.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\_json.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_compat.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_dists.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_envs.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\candidate.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\direct_url.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\format_control.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\index.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\installation_report.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\link.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\pylock.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\scheme.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\search_scope.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\selection_prefs.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\target_python.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\wheel.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\models\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\auth.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\cache.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\download.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\lazy_wheel.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\session.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\utils.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\network\\xmlrpc.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\check.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\freeze.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\build_tracker.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata_editable.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata_legacy.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel_editable.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel_legacy.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\__init__.py","C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\venv\\Lib\\site-packages\\pip\\_internal\\operations\\install\\editable_legacy.py"],"durationMs":521,"numFiles":100,"truncated":true},"sourceToolAssistantUUID":"882df693-7926-4474-9a65-0a82d8ac2b8e"}
{"parentUuid":"a0251b73-f845-4b84-b08e-6251fccbecfc","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Glob","command":"callback"},"parentToolUseID":"toolu_01E7hvZV5FD9PuHNDAdg5GL2","toolUseID":"toolu_01E7hvZV5FD9PuHNDAdg5GL2","timestamp":"2026-01-28T05:05:40.188Z","uuid":"0336998a-6bbe-42fd-97f1-9d6c6f33011e"}
{"parentUuid":"0336998a-6bbe-42fd-97f1-9d6c6f33011e","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01TKzY1LbHiHJ3y9C6h4b1QF","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The glob search is including node_modules and venv which is not helpful. Let me search for the actual source files in backend and rallycoach/src directly.","signature":"EsMCCkYICxgCKkBdcTNTvFGDZULCVJZ0FKbdmYhrUXZsyc3xHvX1kL1Bcbu3JwSsX0NOCDte1Sy1KgBwYjerTAP7kwE3bjgigk3lEgw9kiCPqcDSe5LG3NQaDOGlnC5/r0svcUrmjiIwCwznXcHbQCVmi0yfTtrPcXSNzbk9QYl5p15OyMJH20PTdsaTmeRFaZbo9cPO9t56KqoBggmrowPAhs3gZeN1qtrviuv5j9Bz7TVh1DK9ovgSL3WEGwdReDg/WoMvplc+xLmBUh+jnJ1o1bG+6Bp+G3ojXUJGZ24Vx8NASu3R7zZ9+aBcz0578zS5M/n9Y50zsASLbHpV9siX40/ltA3gLa3CEG4rW3X2VOrA241RUBbH/vrh+POhCq6AyWu7zrLW9RP53i9ZREWCFejLNKrQ/9uhEnaQOR4I5AExiEoYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4288,"cache_creation_input_tokens":4416,"cache_read_input_tokens":48203,"cache_creation":{"ephemeral_5m_input_tokens":4416,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCCq7HTGSetcSvxxd9K","type":"assistant","uuid":"0384baf1-90c7-4288-b62f-49f447646dd8","timestamp":"2026-01-28T05:05:42.989Z"}
{"parentUuid":"0384baf1-90c7-4288-b62f-49f447646dd8","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01TKzY1LbHiHJ3y9C6h4b1QF","type":"message","role":"assistant","content":[{"type":"text","text":"Let me get a cleaner view by reading the actual source files directly."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4288,"cache_creation_input_tokens":4416,"cache_read_input_tokens":48203,"cache_creation":{"ephemeral_5m_input_tokens":4416,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCCq7HTGSetcSvxxd9K","type":"assistant","uuid":"16c9554e-5cf3-4f87-a908-f6db349692ab","timestamp":"2026-01-28T05:05:43.675Z"}
{"parentUuid":"16c9554e-5cf3-4f87-a908-f6db349692ab","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01TKzY1LbHiHJ3y9C6h4b1QF","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01H5FQrNPLEHPmJDaRhPishm","name":"Bash","input":{"command":"cd \"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\" && dir /s /b backend\\*.py 2>nul | findstr /v /i \"venv\"","description":"List Python files in backend excluding venv"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4288,"cache_creation_input_tokens":4416,"cache_read_input_tokens":48203,"cache_creation":{"ephemeral_5m_input_tokens":4416,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCCq7HTGSetcSvxxd9K","type":"assistant","uuid":"fc8a1a20-814f-45a1-8f1b-dcf893b29730","timestamp":"2026-01-28T05:05:45.027Z"}
{"parentUuid":"fc8a1a20-814f-45a1-8f1b-dcf893b29730","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01TKzY1LbHiHJ3y9C6h4b1QF","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Hb9uzUxE1hUkYSBb8ynBPd","name":"Bash","input":{"command":"cd \"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\" && dir /s /b *.ts *.tsx 2>nul | findstr /v /i \"node_modules\"","description":"List TypeScript files in rallycoach/src"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4288,"cache_creation_input_tokens":4416,"cache_read_input_tokens":48203,"cache_creation":{"ephemeral_5m_input_tokens":4416,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCCq7HTGSetcSvxxd9K","type":"assistant","uuid":"c89b4b3a-83ce-4653-97a7-e39dda89a229","timestamp":"2026-01-28T05:05:46.052Z"}
{"parentUuid":"fc8a1a20-814f-45a1-8f1b-dcf893b29730","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Exit code 1\ndir: cannot access '/s': No such file or directory\ndir: cannot access '/b': No such file or directory\ndir: cannot access 'backend*.py': No such file or directory\ndir: cannot access '2': No such file or directory\nFINDSTR: �޷��� I:/","is_error":true,"tool_use_id":"toolu_01H5FQrNPLEHPmJDaRhPishm"}]},"uuid":"0cd85840-793a-43d2-bfb1-bac4edefb2a2","timestamp":"2026-01-28T05:05:52.543Z","toolUseResult":"Error: Exit code 1\ndir: cannot access '/s': No such file or directory\ndir: cannot access '/b': No such file or directory\ndir: cannot access 'backend*.py': No such file or directory\ndir: cannot access '2': No such file or directory\nFINDSTR: �޷��� I:/","sourceToolAssistantUUID":"fc8a1a20-814f-45a1-8f1b-dcf893b29730"}
{"parentUuid":"c89b4b3a-83ce-4653-97a7-e39dda89a229","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Exit code 1\ndir: cannot access '/s': No such file or directory\ndir: cannot access '/b': No such file or directory\ndir: cannot access '*.ts': No such file or directory\ndir: cannot access '*.tsx': No such file or directory\ndir: cannot access '2': No such file or directory\nFINDSTR: �޷��� I:/\r\nFINDSTR: �޷��� node_modules","is_error":true,"tool_use_id":"toolu_01Hb9uzUxE1hUkYSBb8ynBPd"}]},"uuid":"677cabeb-0f14-4a40-b5d4-8cabb9818d34","timestamp":"2026-01-28T05:06:01.526Z","toolUseResult":"Error: Exit code 1\ndir: cannot access '/s': No such file or directory\ndir: cannot access '/b': No such file or directory\ndir: cannot access '*.ts': No such file or directory\ndir: cannot access '*.tsx': No such file or directory\ndir: cannot access '2': No such file or directory\nFINDSTR: �޷��� I:/\r\nFINDSTR: �޷��� node_modules","sourceToolAssistantUUID":"c89b4b3a-83ce-4653-97a7-e39dda89a229"}
{"parentUuid":"677cabeb-0f14-4a40-b5d4-8cabb9818d34","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0132MfGknCoCHp3q38xuAf6s","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"It seems like the bash is running in a Git Bash or similar environment on Windows. Let me use proper Unix commands.","signature":"EpwCCkYICxgCKkDHXi1j69g/fV7miyizerRfBFrASUMLcdfaR6Cex8+9V+QoHeAPV15r4+scE1RuuIazOGR4Cv7L+mrW5XUzUkmOEgxVcCpG4ng5JYoYP0UaDN7MChFP+okNvVEPjSIwxFn81tLD6OAw+E5whETtKv6G727QefvcuDXmWW3ZL7C0bqYGhtFmiWZWvodYIsG/KoMBsIC4kx6iG3AEkcfEHoybNy2S68FDwnGraBLoB4mdo1SKUqsyL7vinN1tWlNqI0Gs4nv99t4goYHr5KmJjXl72MfTfcGwEzYgHOSSFjATUXQuzW4pZE3oIsNuhRWhMYHRP0sV+awp5aoPX0ZuTtW7GpATE7hczur7ZtbG2PQEyiYbkaIYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":4923,"cache_read_input_tokens":52619,"cache_creation":{"ephemeral_5m_input_tokens":4923,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCEQWV9yBW46rUYdyVW","type":"assistant","uuid":"58a66869-2aca-4c81-b6d0-109b7cb408f7","timestamp":"2026-01-28T05:06:04.331Z"}
{"parentUuid":"58a66869-2aca-4c81-b6d0-109b7cb408f7","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0132MfGknCoCHp3q38xuAf6s","type":"message","role":"assistant","content":[{"type":"text","text":"Let me use proper bash commands."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":4923,"cache_read_input_tokens":52619,"cache_creation":{"ephemeral_5m_input_tokens":4923,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCEQWV9yBW46rUYdyVW","type":"assistant","uuid":"d9b833c7-1959-48fb-b4da-146e4437c7c1","timestamp":"2026-01-28T05:06:04.635Z"}
{"parentUuid":"d9b833c7-1959-48fb-b4da-146e4437c7c1","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0132MfGknCoCHp3q38xuAf6s","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012Euhfxtd5UMyguERSd2Lbv","name":"Bash","input":{"command":"find \"/c/Users/ASUS/Desktop/Gemini 3 hack/backend\" -name \"*.py\" -not -path \"*/venv/*\" 2>/dev/null | head -50","description":"List Python files in backend excluding venv"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":4923,"cache_read_input_tokens":52619,"cache_creation":{"ephemeral_5m_input_tokens":4923,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCEQWV9yBW46rUYdyVW","type":"assistant","uuid":"35469645-5d1d-4110-b27f-5b416001dc96","timestamp":"2026-01-28T05:06:05.589Z"}
{"parentUuid":"35469645-5d1d-4110-b27f-5b416001dc96","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0132MfGknCoCHp3q38xuAf6s","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XU8LuqRxtuaaQGF47xECq2","name":"Bash","input":{"command":"find \"/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src\" -name \"*.ts\" -o -name \"*.tsx\" 2>/dev/null | head -100","description":"List TypeScript files in rallycoach/src"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":4923,"cache_read_input_tokens":52619,"cache_creation":{"ephemeral_5m_input_tokens":4923,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCEQWV9yBW46rUYdyVW","type":"assistant","uuid":"4b400974-25e0-4aa8-b5ae-9dc6a310140c","timestamp":"2026-01-28T05:06:06.360Z"}
{"parentUuid":"4b400974-25e0-4aa8-b5ae-9dc6a310140c","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XU8LuqRxtuaaQGF47xECq2","type":"tool_result","content":"/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/analytics/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/analysis/auto-level/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/analysis/start/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/analysis/[id]/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/practice/tick/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/racket/recommend/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/strategy/recommend/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/dashboard/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/history/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/history/[sessionId]/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/layout.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/login/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/practice/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/racket/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/signup/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/strategy/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/CourtTrajectory3D.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/DashboardNav.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/DrillCard.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/GuidanceAnimation.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/PlayerSelectionModal.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/Skeleton3D.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/courtSpec.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/gemini.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/playback-engine.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/pose-utils.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/rules-engine.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/scoring-rules.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/constants.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/feature-extraction.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/index.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/rally-state-machine.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/recommendation-generator.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/scoring-engine.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/shot-segmentation.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/types.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/__tests__/rally-state-machine.test.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/__tests__/recommendation-generator.test.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/__tests__/shot-segmentation.test.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/supabase.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/types.ts","is_error":false}]},"uuid":"27bc3b27-fd98-4d2e-a25e-eec0fdfccd1a","timestamp":"2026-01-28T05:06:08.526Z","toolUseResult":{"stdout":"/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/analytics/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/analysis/auto-level/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/analysis/start/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/analysis/[id]/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/practice/tick/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/racket/recommend/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/api/strategy/recommend/route.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/dashboard/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/history/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/history/[sessionId]/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/layout.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/login/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/practice/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/racket/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/signup/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/app/strategy/page.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/CourtTrajectory3D.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/DashboardNav.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/DrillCard.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/GuidanceAnimation.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/PlayerSelectionModal.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/components/Skeleton3D.tsx\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/courtSpec.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/gemini.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/playback-engine.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/pose-utils.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/rules-engine.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/scoring-rules.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/constants.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/feature-extraction.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/index.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/rally-state-machine.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/recommendation-generator.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/scoring-engine.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/shot-segmentation.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/types.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/__tests__/rally-state-machine.test.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/__tests__/recommendation-generator.test.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/strategy_engine/__tests__/shot-segmentation.test.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/supabase.ts\n/c/Users/ASUS/Desktop/Gemini 3 hack/rallycoach/src/lib/types.ts\r","stderr":"","interrupted":false,"isImage":false},"sourceToolAssistantUUID":"4b400974-25e0-4aa8-b5ae-9dc6a310140c"}
{"parentUuid":"35469645-5d1d-4110-b27f-5b416001dc96","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012Euhfxtd5UMyguERSd2Lbv","type":"tool_result","content":"/c/Users/ASUS/Desktop/Gemini 3 hack/backend/analysis.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/gemini_client.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/main.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/pose_estimation.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/shuttlecock_tracking.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/test_setup.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/video_annotator.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/video_processing.py","is_error":false}]},"uuid":"6c6d7bac-7618-4265-977f-3fb98574dfec","timestamp":"2026-01-28T05:06:08.688Z","toolUseResult":{"stdout":"/c/Users/ASUS/Desktop/Gemini 3 hack/backend/analysis.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/gemini_client.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/main.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/pose_estimation.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/shuttlecock_tracking.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/test_setup.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/video_annotator.py\n/c/Users/ASUS/Desktop/Gemini 3 hack/backend/video_processing.py\r","stderr":"","interrupted":false,"isImage":false},"sourceToolAssistantUUID":"35469645-5d1d-4110-b27f-5b416001dc96"}
{"parentUuid":"6c6d7bac-7618-4265-977f-3fb98574dfec","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BdTo181vtuuhRafR6vEnyq","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a clear view of the project structure. Let me read the key files to understand the current architecture:\n\n1. Backend files:\n   - main.py - FastAPI server\n   - analysis.py - Video analysis pipeline\n   - pose_estimation.py - MediaPipe pose detection\n   - gemini_client.py - Gemini API integration\n   - video_annotator.py - Skeleton overlay rendering\n   - video_processing.py - Video frame utilities\n\n2. Frontend files:\n   - analytics/page.tsx - Video analysis page\n   - lib/pose-utils.ts - Pose processing utilities\n   - lib/rules-engine.ts - Form evaluation rules\n   - lib/scoring-rules.ts - Scoring system\n   - lib/types.ts - Type definitions\n\nLet me read these key files to understand the data flow.","signature":"EuMGCkYICxgCKkD0f2snerZDxCvz3tE5x2kEhKRsCKjj7oixZFiGgQ7uOtcTZb0QLtcTdh1mumghES9bGVcU+V1QAAj90Jgt3OozEgw8zsLQtKfbYz01JrYaDOfkCtN8XntWcaWdqyIwf9u/ern9+mHBPk2PbtJIOI5Y1N3e0hQGm4TBX8bpBuCvIngx4+EU5DSY0FPF113TKsoFY9ouJGd1xfBSuzswybUp76TW8uSKaWXm409jrLvzcnKKUBc0jhQTCAf6IgMxm8lQX6lmeSWoKYkfSVKX095POdfF2tJbBPO1DxXWkpsnPkcC4N3SfrZ7H4HuEWWm4OmPH3JIeNCt/Lx8PZGtZaX08catqzrStXZZc3SWCn/aAVfkN5sN+4C+PDNCR+qzx3pVVqjMFECDbZ3NK+Gq6OYtGNqihCExFV1bUN17IzxgnfYujWHeUK1vxyL/fekJhfC+NGMS4vFSWxxPi4NoouMkhqdwfTORBAch9HliZD8sW7ywcHsgXNmMXN/bLuCNoV63gqtESt6ocG4vRmrNlDlKiqm/LoTACLnNA7ONZfkaQ+oLiWo1bbEMStdMZ/tEjME9h8Qdd04z7EWz5LQw/xfcpn+XrH2Ai60916EVYdBGa8eR5/zbigdEuiXrj6IAYyCt1x5pEa/yZ4yIjPhpgHcIVo77pD9wiiaaqpTe3fhs/PpjiqFefFWXa5Sx2Pcm9/rj1iwFFCnikpVwHGeXKKv0SQdipHk/N9Sz7JfyjGLicSqxq7bR4tGppkP9tVS6ug6LZ2jOZIN7VcYe4KGBBLOFWgudvrfkLoYnM2a+egpV0OH/l8eGW6e2ScgBvH9G4ZFD4ewz3HmqpXb/A6dFjL00kX+OoWESDS5Wad8bHRqbPhadMCmi+31PfRB0asH1bEpb5jGz0PxU33I/ailw9NWxdyfM40da+5jsK4O0lgc5TjMYQydc1iksOMeZZNWE8ew8MAMeg6Cm4FasQrZmxYE1iaP5ZzgGaQnndfTkwZycVTAbOWBi9Vpop/wv0oYKWKtYDmt1YvXDQ0MVb7OZA72x/ldUBSwT9psPK/6RB+jFR/f0nr9ojSFKcaU3pgUHOyY3/83OeGXgHr8tLUhxL7X/ekLFXX2FHsC3jKr2qyyVVoPGvQGSfZ7Gtz4KGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1556,"cache_creation_input_tokens":528,"cache_read_input_tokens":57542,"cache_creation":{"ephemeral_5m_input_tokens":528,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCEwAyCwVcUV7iC3k54","type":"assistant","uuid":"40f36a02-521b-426d-909b-545a0ca30caf","timestamp":"2026-01-28T05:06:13.639Z"}
{"parentUuid":"40f36a02-521b-426d-909b-545a0ca30caf","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BdTo181vtuuhRafR6vEnyq","type":"message","role":"assistant","content":[{"type":"text","text":"Now I have the file structure. Let me read the key files to understand the current data flow. I'll start with the backend analysis pipeline and frontend analytics page."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1556,"cache_creation_input_tokens":528,"cache_read_input_tokens":57542,"cache_creation":{"ephemeral_5m_input_tokens":528,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCEwAyCwVcUV7iC3k54","type":"assistant","uuid":"0186b5f9-a0f8-4deb-899a-44183e1114d3","timestamp":"2026-01-28T05:06:14.428Z"}
{"parentUuid":"0186b5f9-a0f8-4deb-899a-44183e1114d3","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BdTo181vtuuhRafR6vEnyq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01C3Gj7smCDBoVNbgLaTMaE4","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\analysis.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1556,"cache_creation_input_tokens":528,"cache_read_input_tokens":57542,"cache_creation":{"ephemeral_5m_input_tokens":528,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCEwAyCwVcUV7iC3k54","type":"assistant","uuid":"3020e885-e10c-4700-ae70-b84fd6c0e1ba","timestamp":"2026-01-28T05:06:14.855Z"}
{"parentUuid":"3020e885-e10c-4700-ae70-b84fd6c0e1ba","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BdTo181vtuuhRafR6vEnyq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013cBTiYfRMpEzDXgVfw59jj","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\main.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1556,"cache_creation_input_tokens":528,"cache_read_input_tokens":57542,"cache_creation":{"ephemeral_5m_input_tokens":528,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCEwAyCwVcUV7iC3k54","type":"assistant","uuid":"f51b9078-ff44-465b-bcc8-f37cbceddbce","timestamp":"2026-01-28T05:06:15.329Z"}
{"parentUuid":"f51b9078-ff44-465b-bcc8-f37cbceddbce","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BdTo181vtuuhRafR6vEnyq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016SmTVPNZ4r1MTn8vt1FPsg","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\pose_estimation.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1556,"cache_creation_input_tokens":528,"cache_read_input_tokens":57542,"cache_creation":{"ephemeral_5m_input_tokens":528,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCEwAyCwVcUV7iC3k54","type":"assistant","uuid":"f2ab1f1d-1d76-4029-8b07-f2e93a6454fd","timestamp":"2026-01-28T05:06:15.755Z"}
{"parentUuid":"3020e885-e10c-4700-ae70-b84fd6c0e1ba","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01C3Gj7smCDBoVNbgLaTMaE4","type":"tool_result","content":"     1→import math\n     2→from pose_estimation import extract_pose_from_video, calc_angle\n     3→from gemini_client import generate_coaching_feedback\n     4→\n     5→\n     6→def analyze_video(video_path, language=\"en\"):\n     7→    \"\"\"\n     8→    Main video analysis pipeline.\n     9→\n    10→    Steps:\n    11→    1. Extract pose data from video\n    12→    2. Detect shot events\n    13→    3. Analyze pose for each shot\n    14→    4. Generate Gemini feedback\n    15→    5. Return structured JSON\n    16→    \"\"\"\n    17→\n    18→    # Step 1: Extract pose data\n    19→    pose_data, frames = extract_pose_from_video(video_path)\n    20→\n    21→    # Step 2: Detect shots based on wrist movement\n    22→    shot_events = detect_shots(pose_data, frames)\n    23→\n    24→    # Step 3: Analyze each shot for form errors\n    25→    for shot in shot_events:\n    26→        frame_idx = shot[\"frame\"]\n    27→        if pose_data[frame_idx]:\n    28→            shot[\"pose_errors\"] = analyze_shot_pose(\n    29→                pose_data[frame_idx],\n    30→                shot[\"shot_type\"]\n    31→            )\n    32→\n    33→    # Step 4: Prepare summary for Gemini\n    34→    analysis_summary = prepare_summary(shot_events)\n    35→\n    36→    # Step 5: Get Gemini feedback (with language support)\n    37→    feedback = generate_coaching_feedback(analysis_summary, language)\n    38→\n    39→    # Step 6: Build result JSON\n    40→    result = {\n    41→        \"shots\": shot_events,\n    42→        \"gemini_feedback\": feedback\n    43→    }\n    44→\n    45→    return result\n    46→\n    47→\n    48→def detect_shots(pose_data, frames):\n    49→    \"\"\"\n    50→    Detect shot events based on wrist velocity spikes.\n    51→    Returns list of shots with frame index and type.\n    52→    \"\"\"\n    53→    shot_events = []\n    54→    last_shot_frame = -100\n    55→\n    56→    for i in range(1, len(frames) - 1):\n    57→        if pose_data[i] is None or pose_data[i-1] is None:\n    58→            continue\n    59→\n    60→        shot_detected = False\n    61→\n    62→        # Check right wrist velocity\n    63→        if 'right_wrist' in pose_data[i] and 'right_wrist' in pose_data[i-1]:\n    64→            rw_prev = pose_data[i-1]['right_wrist']\n    65→            rw_curr = pose_data[i]['right_wrist']\n    66→            speed = math.hypot(rw_curr[0] - rw_prev[0], rw_curr[1] - rw_prev[1])\n    67→\n    68→            # Threshold for fast swing (tunable)\n    69→            if speed > 20:\n    70→                shot_detected = True\n    71→\n    72→        # Avoid double-counting shots too close together\n    73→        if shot_detected and i - last_shot_frame > 5:\n    74→            last_shot_frame = i\n    75→\n    76→            # Determine shot type by pose heuristics\n    77→            shot_type = classify_shot_type(pose_data[i])\n    78→\n    79→            shot_events.append({\n    80→                \"frame\": i,\n    81→                \"shot_type\": shot_type,\n    82→                \"pose_errors\": []\n    83→            })\n    84→\n    85→    return shot_events\n    86→\n    87→\n    88→def classify_shot_type(pose):\n    89→    \"\"\"\n    90→    Classify shot type based on pose heuristics.\n    91→    Very basic logic for MVP.\n    92→    \"\"\"\n    93→    if not pose:\n    94→        return \"Other\"\n    95→\n    96→    # Calculate elbow angle\n    97→    right_elbow_angle = calc_angle(\n    98→        pose['right_shoulder'],\n    99→        pose['right_elbow'],\n   100→        pose['right_wrist']\n   101→    )\n   102→\n   103→    # Simple classification rules\n   104→    # If wrist is above shoulder and arm nearly straight\n   105→    if pose['right_wrist'][1] < pose['right_shoulder'][1]:\n   106→        if right_elbow_angle < 160:\n   107→            return \"Smash/Clear\"\n   108→        else:\n   109→            return \"Overhead\"\n   110→    # If wrist is below shoulder\n   111→    elif pose['right_wrist'][1] > pose['right_shoulder'][1]:\n   112→        # Check if near hip level (net shot)\n   113→        if 'right_hip' in pose and pose['right_wrist'][1] < pose['right_hip'][1]:\n   114→            return \"Net Shot\"\n   115→        else:\n   116→            return \"Underhand\"\n   117→    else:\n   118→        return \"Other\"\n   119→\n   120→\n   121→def analyze_shot_pose(pose, shot_type):\n   122→    \"\"\"\n   123→    Compare pose with ideal form and detect errors.\n   124→    Returns list of error messages.\n   125→    \"\"\"\n   126→    pose_errors = []\n   127→\n   128→    if shot_type == \"Smash/Clear\":\n   129→        # Check elbow extension\n   130→        angle = calc_angle(\n   131→            pose['right_shoulder'],\n   132→            pose['right_elbow'],\n   133→            pose['right_wrist']\n   134→        )\n   135→        if angle < 170:\n   136→            pose_errors.append(f\"Elbow not fully extended (angle ~{int(angle)}°, ideal 170°+)\")\n   137→\n   138→        # Check if arm is raised high enough\n   139→        if pose['right_wrist'][1] > pose['right_shoulder'][1]:\n   140→            pose_errors.append(\"Arm not raised high enough for overhead shot\")\n   141→\n   142→    elif shot_type == \"Net Shot\":\n   143→        # Check knee bend (simple heuristic)\n   144→        if 'right_knee' in pose and 'right_hip' in pose and 'right_ankle' in pose:\n   145→            knee_angle = calc_angle(\n   146→                pose['right_hip'],\n   147→                pose['right_knee'],\n   148→                pose['right_ankle']\n   149→            )\n   150→            if knee_angle > 150:  # Too straight\n   151→                pose_errors.append(\"Knees not bent enough for lunge (increase knee bend)\")\n   152→\n   153→    # General posture checks could be added here\n   154→\n   155→    return pose_errors\n   156→\n   157→\n   158→def prepare_summary(shot_events):\n   159→    \"\"\"\n   160→    Prepare a text summary of analysis for Gemini prompt.\n   161→    \"\"\"\n   162→    summary_lines = []\n   163→\n   164→    if not shot_events:\n   165→        summary_lines.append(\"No clear shots detected in the video.\")\n   166→    else:\n   167→        summary_lines.append(f\"Detected {len(shot_events)} shot(s):\\n\")\n   168→\n   169→        for i, shot in enumerate(shot_events, 1):\n   170→            shot_type = shot[\"shot_type\"]\n   171→            errors = shot[\"pose_errors\"]\n   172→\n   173→            if errors:\n   174→                error_text = \"; \".join(errors)\n   175→                summary_lines.append(f\"{i}. {shot_type} at frame {shot['frame']}: Issues found - {error_text}\")\n   176→            else:\n   177→                summary_lines.append(f\"{i}. {shot_type} at frame {shot['frame']}: Good form\")\n   178→\n   179→    return \"\\n\".join(summary_lines)\n   180→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"5f9cb61c-84ff-4a44-9d3f-1f65d1fa96f0","timestamp":"2026-01-28T05:06:18.178Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\analysis.py","content":"import math\nfrom pose_estimation import extract_pose_from_video, calc_angle\nfrom gemini_client import generate_coaching_feedback\n\n\ndef analyze_video(video_path, language=\"en\"):\n    \"\"\"\n    Main video analysis pipeline.\n\n    Steps:\n    1. Extract pose data from video\n    2. Detect shot events\n    3. Analyze pose for each shot\n    4. Generate Gemini feedback\n    5. Return structured JSON\n    \"\"\"\n\n    # Step 1: Extract pose data\n    pose_data, frames = extract_pose_from_video(video_path)\n\n    # Step 2: Detect shots based on wrist movement\n    shot_events = detect_shots(pose_data, frames)\n\n    # Step 3: Analyze each shot for form errors\n    for shot in shot_events:\n        frame_idx = shot[\"frame\"]\n        if pose_data[frame_idx]:\n            shot[\"pose_errors\"] = analyze_shot_pose(\n                pose_data[frame_idx],\n                shot[\"shot_type\"]\n            )\n\n    # Step 4: Prepare summary for Gemini\n    analysis_summary = prepare_summary(shot_events)\n\n    # Step 5: Get Gemini feedback (with language support)\n    feedback = generate_coaching_feedback(analysis_summary, language)\n\n    # Step 6: Build result JSON\n    result = {\n        \"shots\": shot_events,\n        \"gemini_feedback\": feedback\n    }\n\n    return result\n\n\ndef detect_shots(pose_data, frames):\n    \"\"\"\n    Detect shot events based on wrist velocity spikes.\n    Returns list of shots with frame index and type.\n    \"\"\"\n    shot_events = []\n    last_shot_frame = -100\n\n    for i in range(1, len(frames) - 1):\n        if pose_data[i] is None or pose_data[i-1] is None:\n            continue\n\n        shot_detected = False\n\n        # Check right wrist velocity\n        if 'right_wrist' in pose_data[i] and 'right_wrist' in pose_data[i-1]:\n            rw_prev = pose_data[i-1]['right_wrist']\n            rw_curr = pose_data[i]['right_wrist']\n            speed = math.hypot(rw_curr[0] - rw_prev[0], rw_curr[1] - rw_prev[1])\n\n            # Threshold for fast swing (tunable)\n            if speed > 20:\n                shot_detected = True\n\n        # Avoid double-counting shots too close together\n        if shot_detected and i - last_shot_frame > 5:\n            last_shot_frame = i\n\n            # Determine shot type by pose heuristics\n            shot_type = classify_shot_type(pose_data[i])\n\n            shot_events.append({\n                \"frame\": i,\n                \"shot_type\": shot_type,\n                \"pose_errors\": []\n            })\n\n    return shot_events\n\n\ndef classify_shot_type(pose):\n    \"\"\"\n    Classify shot type based on pose heuristics.\n    Very basic logic for MVP.\n    \"\"\"\n    if not pose:\n        return \"Other\"\n\n    # Calculate elbow angle\n    right_elbow_angle = calc_angle(\n        pose['right_shoulder'],\n        pose['right_elbow'],\n        pose['right_wrist']\n    )\n\n    # Simple classification rules\n    # If wrist is above shoulder and arm nearly straight\n    if pose['right_wrist'][1] < pose['right_shoulder'][1]:\n        if right_elbow_angle < 160:\n            return \"Smash/Clear\"\n        else:\n            return \"Overhead\"\n    # If wrist is below shoulder\n    elif pose['right_wrist'][1] > pose['right_shoulder'][1]:\n        # Check if near hip level (net shot)\n        if 'right_hip' in pose and pose['right_wrist'][1] < pose['right_hip'][1]:\n            return \"Net Shot\"\n        else:\n            return \"Underhand\"\n    else:\n        return \"Other\"\n\n\ndef analyze_shot_pose(pose, shot_type):\n    \"\"\"\n    Compare pose with ideal form and detect errors.\n    Returns list of error messages.\n    \"\"\"\n    pose_errors = []\n\n    if shot_type == \"Smash/Clear\":\n        # Check elbow extension\n        angle = calc_angle(\n            pose['right_shoulder'],\n            pose['right_elbow'],\n            pose['right_wrist']\n        )\n        if angle < 170:\n            pose_errors.append(f\"Elbow not fully extended (angle ~{int(angle)}°, ideal 170°+)\")\n\n        # Check if arm is raised high enough\n        if pose['right_wrist'][1] > pose['right_shoulder'][1]:\n            pose_errors.append(\"Arm not raised high enough for overhead shot\")\n\n    elif shot_type == \"Net Shot\":\n        # Check knee bend (simple heuristic)\n        if 'right_knee' in pose and 'right_hip' in pose and 'right_ankle' in pose:\n            knee_angle = calc_angle(\n                pose['right_hip'],\n                pose['right_knee'],\n                pose['right_ankle']\n            )\n            if knee_angle > 150:  # Too straight\n                pose_errors.append(\"Knees not bent enough for lunge (increase knee bend)\")\n\n    # General posture checks could be added here\n\n    return pose_errors\n\n\ndef prepare_summary(shot_events):\n    \"\"\"\n    Prepare a text summary of analysis for Gemini prompt.\n    \"\"\"\n    summary_lines = []\n\n    if not shot_events:\n        summary_lines.append(\"No clear shots detected in the video.\")\n    else:\n        summary_lines.append(f\"Detected {len(shot_events)} shot(s):\\n\")\n\n        for i, shot in enumerate(shot_events, 1):\n            shot_type = shot[\"shot_type\"]\n            errors = shot[\"pose_errors\"]\n\n            if errors:\n                error_text = \"; \".join(errors)\n                summary_lines.append(f\"{i}. {shot_type} at frame {shot['frame']}: Issues found - {error_text}\")\n            else:\n                summary_lines.append(f\"{i}. {shot_type} at frame {shot['frame']}: Good form\")\n\n    return \"\\n\".join(summary_lines)\n","numLines":180,"startLine":1,"totalLines":180}},"sourceToolAssistantUUID":"3020e885-e10c-4700-ae70-b84fd6c0e1ba"}
{"parentUuid":"f2ab1f1d-1d76-4029-8b07-f2e93a6454fd","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016SmTVPNZ4r1MTn8vt1FPsg","type":"tool_result","content":"     1→import cv2\n     2→import math\n     3→import mediapipe as mp\n     4→\n     5→# Initialize MediaPipe Pose (simpler, no model file needed)\n     6→mp_pose = mp.solutions.pose\n     7→pose_estimator = mp_pose.Pose(\n     8→    static_image_mode=False,\n     9→    model_complexity=1,\n    10→    enable_segmentation=False\n    11→)\n    12→\n    13→\n    14→def calc_angle(p1, p2, p3):\n    15→    \"\"\"Calculate angle at p2 formed by points p1->p2->p3.\"\"\"\n    16→    ax, ay = p1\n    17→    bx, by = p2\n    18→    cx, cy = p3\n    19→\n    20→    BA = (ax - bx, ay - by)\n    21→    BC = (cx - bx, cy - by)\n    22→\n    23→    dot = BA[0] * BC[0] + BA[1] * BC[1]\n    24→    magBA = math.hypot(*BA)\n    25→    magBC = math.hypot(*BC)\n    26→\n    27→    if magBA * magBC == 0:\n    28→        return 0.0\n    29→\n    30→    cos_angle = max(-1.0, min(1.0, dot / (magBA * magBC)))\n    31→    angle = math.degrees(math.acos(cos_angle))\n    32→    return angle\n    33→\n    34→\n    35→def extract_pose_from_video(video_path):\n    36→    \"\"\"\n    37→    Extract pose data from video using MediaPipe Pose.\n    38→    Returns list of pose dictionaries and frames.\n    39→    \"\"\"\n    40→    cap = cv2.VideoCapture(video_path)\n    41→    pose_data = []\n    42→    frames = []\n    43→\n    44→    while True:\n    45→        ret, frame = cap.read()\n    46→        if not ret:\n    47→            break\n    48→\n    49→        frames.append(frame)\n    50→\n    51→        # Convert BGR to RGB for MediaPipe\n    52→        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    53→        results = pose_estimator.process(rgb)\n    54→\n    55→        if results.pose_landmarks:\n    56→            h, w, _ = frame.shape\n    57→            landmarks = results.pose_landmarks.landmark\n    58→\n    59→            pose = {\n    60→                'right_shoulder': (landmarks[12].x * w, landmarks[12].y * h),\n    61→                'right_elbow': (landmarks[14].x * w, landmarks[14].y * h),\n    62→                'right_wrist': (landmarks[16].x * w, landmarks[16].y * h),\n    63→                'left_shoulder': (landmarks[11].x * w, landmarks[11].y * h),\n    64→                'left_elbow': (landmarks[13].x * w, landmarks[13].y * h),\n    65→                'left_wrist': (landmarks[15].x * w, landmarks[15].y * h),\n    66→                'right_hip': (landmarks[24].x * w, landmarks[24].y * h),\n    67→                'left_hip': (landmarks[23].x * w, landmarks[23].y * h),\n    68→                'right_knee': (landmarks[26].x * w, landmarks[26].y * h),\n    69→                'left_knee': (landmarks[25].x * w, landmarks[25].y * h),\n    70→                'right_ankle': (landmarks[28].x * w, landmarks[28].y * h),\n    71→                'left_ankle': (landmarks[27].x * w, landmarks[27].y * h),\n    72→            }\n    73→        else:\n    74→            pose = None\n    75→\n    76→        pose_data.append(pose)\n    77→\n    78→    cap.release()\n    79→    return pose_data, frames\n    80→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"c4707033-8dcd-458b-a9a6-e15e31cef837","timestamp":"2026-01-28T05:06:18.178Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\pose_estimation.py","content":"import cv2\nimport math\nimport mediapipe as mp\n\n# Initialize MediaPipe Pose (simpler, no model file needed)\nmp_pose = mp.solutions.pose\npose_estimator = mp_pose.Pose(\n    static_image_mode=False,\n    model_complexity=1,\n    enable_segmentation=False\n)\n\n\ndef calc_angle(p1, p2, p3):\n    \"\"\"Calculate angle at p2 formed by points p1->p2->p3.\"\"\"\n    ax, ay = p1\n    bx, by = p2\n    cx, cy = p3\n\n    BA = (ax - bx, ay - by)\n    BC = (cx - bx, cy - by)\n\n    dot = BA[0] * BC[0] + BA[1] * BC[1]\n    magBA = math.hypot(*BA)\n    magBC = math.hypot(*BC)\n\n    if magBA * magBC == 0:\n        return 0.0\n\n    cos_angle = max(-1.0, min(1.0, dot / (magBA * magBC)))\n    angle = math.degrees(math.acos(cos_angle))\n    return angle\n\n\ndef extract_pose_from_video(video_path):\n    \"\"\"\n    Extract pose data from video using MediaPipe Pose.\n    Returns list of pose dictionaries and frames.\n    \"\"\"\n    cap = cv2.VideoCapture(video_path)\n    pose_data = []\n    frames = []\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        frames.append(frame)\n\n        # Convert BGR to RGB for MediaPipe\n        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        results = pose_estimator.process(rgb)\n\n        if results.pose_landmarks:\n            h, w, _ = frame.shape\n            landmarks = results.pose_landmarks.landmark\n\n            pose = {\n                'right_shoulder': (landmarks[12].x * w, landmarks[12].y * h),\n                'right_elbow': (landmarks[14].x * w, landmarks[14].y * h),\n                'right_wrist': (landmarks[16].x * w, landmarks[16].y * h),\n                'left_shoulder': (landmarks[11].x * w, landmarks[11].y * h),\n                'left_elbow': (landmarks[13].x * w, landmarks[13].y * h),\n                'left_wrist': (landmarks[15].x * w, landmarks[15].y * h),\n                'right_hip': (landmarks[24].x * w, landmarks[24].y * h),\n                'left_hip': (landmarks[23].x * w, landmarks[23].y * h),\n                'right_knee': (landmarks[26].x * w, landmarks[26].y * h),\n                'left_knee': (landmarks[25].x * w, landmarks[25].y * h),\n                'right_ankle': (landmarks[28].x * w, landmarks[28].y * h),\n                'left_ankle': (landmarks[27].x * w, landmarks[27].y * h),\n            }\n        else:\n            pose = None\n\n        pose_data.append(pose)\n\n    cap.release()\n    return pose_data, frames\n","numLines":80,"startLine":1,"totalLines":80}},"sourceToolAssistantUUID":"f2ab1f1d-1d76-4029-8b07-f2e93a6454fd"}
{"parentUuid":"c4707033-8dcd-458b-a9a6-e15e31cef837","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01C3Gj7smCDBoVNbgLaTMaE4","toolUseID":"toolu_01C3Gj7smCDBoVNbgLaTMaE4","timestamp":"2026-01-28T05:06:18.194Z","uuid":"0de0bdb9-8fea-4209-92fd-33ad899488e4"}
{"parentUuid":"0de0bdb9-8fea-4209-92fd-33ad899488e4","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_016SmTVPNZ4r1MTn8vt1FPsg","toolUseID":"toolu_016SmTVPNZ4r1MTn8vt1FPsg","timestamp":"2026-01-28T05:06:18.194Z","uuid":"df53034d-4d00-47ca-b165-a70b66534727"}
{"parentUuid":"f51b9078-ff44-465b-bcc8-f37cbceddbce","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013cBTiYfRMpEzDXgVfw59jj","type":"tool_result","content":"     1→import os\n     2→import shutil\n     3→from typing import Optional, List\n     4→from fastapi import FastAPI, File, UploadFile, HTTPException, Form, Query\n     5→from fastapi.middleware.cors import CORSMiddleware\n     6→from fastapi.responses import JSONResponse, FileResponse\n     7→from pydantic import BaseModel\n     8→from dotenv import load_dotenv\n     9→from supabase import create_client\n    10→\n    11→# Import analysis modules\n    12→from analysis import analyze_video\n    13→from pose_estimation import extract_pose_from_video\n    14→from video_annotator import create_annotated_video_with_analysis\n    15→\n    16→load_dotenv()\n    17→\n    18→app = FastAPI(title=\"Badminton Analyzer & Coach API\")\n    19→\n    20→# ============================================\n    21→# Pydantic Models for Request/Response\n    22→# ============================================\n    23→\n    24→class PracticeSessionData(BaseModel):\n    25→    user_id: str\n    26→    drill_type: str\n    27→    total_frames: int\n    28→    green_frames: int\n    29→    red_frames: int\n    30→    duration_seconds: float\n    31→    avg_elbow_angle: Optional[float] = None\n    32→    avg_stance_width: Optional[float] = None\n    33→    peak_form_score: Optional[float] = 0\n    34→    issues: Optional[List[dict]] = []\n    35→\n    36→class IssueData(BaseModel):\n    37→    code: str\n    38→    title: str\n    39→    severity: str = \"medium\"\n    40→    description: Optional[str] = None\n    41→    drill: Optional[dict] = {}\n    42→    timestamps: Optional[List[float]] = []\n    43→    occurrence_count: Optional[int] = 1\n    44→\n    45→# CORS - Allow frontend to connect\n    46→app.add_middleware(\n    47→    CORSMiddleware,\n    48→    allow_origins=[\"*\"],  # Allow all origins for development\n    49→    allow_credentials=True,\n    50→    allow_methods=[\"*\"],\n    51→    allow_headers=[\"*\"],\n    52→)\n    53→\n    54→# Supabase Setup\n    55→SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n    56→SUPABASE_ANON_KEY = os.getenv(\"SUPABASE_ANON_KEY\")\n    57→SUPABASE_SERVICE_KEY = os.getenv(\"SUPABASE_SERVICE_KEY\")\n    58→\n    59→# Create Supabase client with SERVICE_ROLE key for backend operations\n    60→# This bypasses RLS and allows database writes without authentication\n    61→supabase = None\n    62→if SUPABASE_URL and SUPABASE_URL != \"https://your-project.supabase.co\":\n    63→    if SUPABASE_SERVICE_KEY and SUPABASE_SERVICE_KEY != \"your-service-role-key\":\n    64→        try:\n    65→            supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)\n    66→            print(\"[OK] Supabase initialized with SERVICE_ROLE key (RLS bypass enabled)\")\n    67→        except Exception as e:\n    68→            print(f\"[ERROR] Supabase initialization failed: {e}\")\n    69→    else:\n    70→        print(\"[ERROR] SUPABASE_SERVICE_KEY not configured - database writes will fail\")\n    71→\n    72→@app.get(\"/\")\n    73→def root():\n    74→    return {\"status\": \"Badminton Coach API Active\", \"version\": \"1.0\"}\n    75→\n    76→@app.get(\"/health\")\n    77→def health():\n    78→    return {\n    79→        \"status\": \"healthy\",\n    80→        \"supabase_connected\": supabase is not None,\n    81→        \"gemini_api_key\": os.getenv(\"GEMINI_API_KEY\") != \"your-gemini-api-key-here\"\n    82→    }\n    83→\n    84→@app.get(\"/temp/{filename}\")\n    85→async def serve_temp_video(filename: str):\n    86→    \"\"\"Serve annotated videos from temp directory for local playback\"\"\"\n    87→    file_path = f\"temp/{filename}\"\n    88→    if os.path.exists(file_path):\n    89→        return FileResponse(\n    90→            file_path,\n    91→            media_type=\"video/mp4\",\n    92→            headers={\n    93→                \"Accept-Ranges\": \"bytes\",\n    94→                \"Cache-Control\": \"no-cache\"\n    95→            }\n    96→        )\n    97→    raise HTTPException(status_code=404, detail=\"Video not found\")\n    98→\n    99→@app.post(\"/api/analyze\")\n   100→async def analyze_badminton_video(\n   101→    file: UploadFile = File(...),\n   102→    user_id: str = Form(\"guest\"),\n   103→    language: str = Form(\"en\")\n   104→):\n   105→    \"\"\"\n   106→    Analyze uploaded badminton video.\n   107→    Returns: pose data, shot detection, Gemini feedback, and annotated video URL.\n   108→    Saves to both legacy analysis_results and new sessions/issues tables.\n   109→    \"\"\"\n   110→\n   111→    # Setup temp directory\n   112→    os.makedirs(\"temp\", exist_ok=True)\n   113→    temp_input_path = f\"temp/input_{file.filename}\"\n   114→    temp_annotated_path = f\"temp/annotated_{file.filename}\"\n   115→    session_id = None\n   116→\n   117→    try:\n   118→        # 1. Save uploaded video\n   119→        with open(temp_input_path, \"wb\") as buffer:\n   120→            shutil.copyfileobj(file.file, buffer)\n   121→\n   122→        print(f\"Video saved: {temp_input_path}\")\n   123→\n   124→        # 2. Run analysis (pose detection + shot analysis + Gemini feedback)\n   125→        analysis_result = analyze_video(temp_input_path, language)\n   126→\n   127→        print(f\"Analysis complete: {len(analysis_result.get('shots', []))} shots detected\")\n   128→\n   129→        # 3. Extract pose data for annotation\n   130→        pose_data, frames = extract_pose_from_video(temp_input_path)\n   131→\n   132→        # 4. Create annotated video with skeleton overlay\n   133→        create_annotated_video_with_analysis(\n   134→            temp_input_path,\n   135→            temp_annotated_path,\n   136→            pose_data,\n   137→            analysis_result.get('shots', [])\n   138→        )\n   139→\n   140→        print(f\"Annotated video created: {temp_annotated_path}\")\n   141→\n   142→        # 5. Upload annotated video to Supabase Storage (if configured)\n   143→        annotated_video_url = \"\"\n   144→        if supabase:\n   145→            try:\n   146→                storage_path = f\"{user_id}/annotated/{os.path.basename(temp_annotated_path)}\"\n   147→\n   148→                with open(temp_annotated_path, 'rb') as video_file:\n   149→                    video_bytes = video_file.read()\n   150→\n   151→                # Upload to Supabase Storage\n   152→                result = supabase.storage.from_(\"videos\").upload(\n   153→                    storage_path,\n   154→                    video_bytes,\n   155→                    file_options={\"content-type\": \"video/mp4\", \"upsert\": \"true\"}\n   156→                )\n   157→\n   158→                # Get public URL\n   159→                annotated_video_url = supabase.storage.from_(\"videos\").get_public_url(storage_path)\n   160→\n   161→                print(f\"Video uploaded to Supabase: {annotated_video_url}\")\n   162→\n   163→                # 6. Calculate overall score based on pose errors\n   164→                shots = analysis_result.get('shots', [])\n   165→                total_errors = sum(len(shot.get('pose_errors', [])) for shot in shots)\n   166→                overall_score = max(0, 100 - (total_errors * 10))  # Deduct 10 points per error\n   167→\n   168→                # 7. Convert pose_data to frontend-compatible format (landmarks array)\n   169→                pose_landmarks_array = convert_pose_to_landmarks(pose_data)\n   170→\n   171→                # 8. Extract issues from shots for the issues table\n   172→                detected_issues = extract_issues_from_shots(shots)\n   173→\n   174→                # 9. Save to NEW sessions table\n   175→                try:\n   176→                    session_payload = {\n   177→                        \"user_id\": user_id if user_id != \"guest\" else None,\n   178→                        \"type\": \"analytics\",\n   179→                        \"video_path\": storage_path,\n   180→                        \"video_url\": annotated_video_url,\n   181→                        \"filename\": file.filename,\n   182→                        \"overall_score\": overall_score,\n   183→                        \"frame_count\": len(pose_data),\n   184→                        \"pose_data\": pose_landmarks_array,  # Full pose data for overlay\n   185→                        \"summary\": {\n   186→                            \"shot_count\": len(shots),\n   187→                            \"error_count\": total_errors,\n   188→                            \"feedback\": analysis_result.get('gemini_feedback', {}),\n   189→                            \"language\": language\n   190→                        }\n   191→                    }\n   192→\n   193→                    session_response = supabase.table(\"sessions\").insert(session_payload).execute()\n   194→                    if session_response.data:\n   195→                        session_id = session_response.data[0]['id']\n   196→                        print(f\"[OK] Session saved: {session_id}\")\n   197→\n   198→                        # 10. Save issues to issues table\n   199→                        for issue in detected_issues:\n   200→                            issue_payload = {\n   201→                                \"session_id\": session_id,\n   202→                                \"code\": issue['code'],\n   203→                                \"title\": issue['title'],\n   204→                                \"severity\": issue.get('severity', 'medium'),\n   205→                                \"description\": issue.get('description', ''),\n   206→                                \"timestamps\": issue.get('timestamps', []),\n   207→                                \"occurrence_count\": issue.get('occurrence_count', 1),\n   208→                                \"drill\": issue.get('drill', {})\n   209→                            }\n   210→                            supabase.table(\"issues\").insert(issue_payload).execute()\n   211→\n   212→                        print(f\"[OK] {len(detected_issues)} issues saved\")\n   213→\n   214→                except Exception as session_error:\n   215→                    print(f\"[WARN] Session table insert failed (table may not exist): {session_error}\")\n   216→                    # Continue with legacy table\n   217→\n   218→                # 11. Save to LEGACY analysis_results table (backward compatibility)\n   219→                try:\n   220→                    db_payload = {\n   221→                        \"result_json\": {\n   222→                            \"user_id\": user_id,\n   223→                            \"video_url\": annotated_video_url,\n   224→                            \"shot_count\": len(shots),\n   225→                            \"shots\": shots,\n   226→                            \"feedback\": analysis_result.get('gemini_feedback', {}),\n   227→                            \"language\": language,\n   228→                            \"session_id\": session_id  # Link to new session\n   229→                        }\n   230→                    }\n   231→\n   232→                    db_response = supabase.table(\"analysis_results\").insert(db_payload).execute()\n   233→                    print(f\"[OK] Legacy database insert: Record ID = {db_response.data[0]['id'] if db_response.data else 'N/A'}\")\n   234→\n   235→                except Exception as db_error:\n   236→                    print(f\"[ERROR] Legacy database insert failed: {db_error}\")\n   237→\n   238→            except Exception as e:\n   239→                print(f\"Supabase upload error: {e}\")\n   240→                annotated_video_url = f\"http://localhost:8000/temp/{os.path.basename(temp_annotated_path)}\"\n   241→        else:\n   242→            print(\"Supabase not configured - video saved locally only\")\n   243→            annotated_video_url = f\"http://localhost:8000/temp/{os.path.basename(temp_annotated_path)}\"\n   244→\n   245→        # 12. Prepare response with full pose data for frontend overlay\n   246→        response = {\n   247→            \"session_id\": session_id,\n   248→            \"shots\": analysis_result.get('shots', []),\n   249→            \"gemini_feedback\": analysis_result.get('gemini_feedback', ''),\n   250→            \"annotated_video_url\": annotated_video_url,\n   251→            \"pose_data\": convert_pose_to_landmarks(pose_data),  # Full landmarks for overlay\n   252→            \"total_shots\": len(analysis_result.get('shots', [])),\n   253→            \"overall_score\": overall_score if supabase else 0,\n   254→            \"issues\": detected_issues if supabase else []\n   255→        }\n   256→\n   257→        print(f\"[OK] Sending response with video URL: {annotated_video_url}\")\n   258→        print(f\"[OK] Session ID: {session_id}\")\n   259→        print(f\"[OK] Pose frames: {len(pose_data)}\")\n   260→\n   261→        return JSONResponse(content=response)\n   262→\n   263→    except Exception as e:\n   264→        print(f\"Error during analysis: {e}\")\n   265→        import traceback\n   266→        traceback.print_exc()\n   267→        raise HTTPException(status_code=500, detail=f\"Analysis failed: {str(e)}\")\n   268→\n   269→    finally:\n   270→        # Cleanup temp input file (keep annotated for serving)\n   271→        try:\n   272→            if os.path.exists(temp_input_path):\n   273→                os.remove(temp_input_path)\n   274→        except Exception as e:\n   275→            print(f\"Cleanup error: {e}\")\n   276→\n   277→\n   278→# ============================================\n   279→# Helper Functions\n   280→# ============================================\n   281→\n   282→def convert_pose_to_landmarks(pose_data):\n   283→    \"\"\"\n   284→    Convert backend pose_data format to frontend-compatible landmarks array.\n   285→    Each frame becomes an array of {x, y, z, visibility} for each landmark.\n   286→    \"\"\"\n   287→    landmarks_array = []\n   288→\n   289→    # MediaPipe landmark mapping\n   290→    landmark_names = [\n   291→        'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer',\n   292→        'right_eye_inner', 'right_eye', 'right_eye_outer',\n   293→        'left_ear', 'right_ear', 'mouth_left', 'mouth_right',\n   294→        'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n   295→        'left_wrist', 'right_wrist', 'left_pinky', 'right_pinky',\n   296→        'left_index', 'right_index', 'left_thumb', 'right_thumb',\n   297→        'left_hip', 'right_hip', 'left_knee', 'right_knee',\n   298→        'left_ankle', 'right_ankle', 'left_heel', 'right_heel',\n   299→        'left_foot_index', 'right_foot_index'\n   300→    ]\n   301→\n   302→    for frame_pose in pose_data:\n   303→        if frame_pose is None:\n   304→            landmarks_array.append(None)\n   305→            continue\n   306→\n   307→        frame_landmarks = []\n   308→        for name in landmark_names:\n   309→            if name in frame_pose:\n   310→                coords = frame_pose[name]\n   311→                # Normalize coordinates (assuming video width/height ~640x480)\n   312→                frame_landmarks.append({\n   313→                    'x': coords[0] / 640 if coords[0] else 0,\n   314→                    'y': coords[1] / 480 if coords[1] else 0,\n   315→                    'z': 0,\n   316→                    'visibility': 1.0\n   317→                })\n   318→            else:\n   319→                frame_landmarks.append({'x': 0, 'y': 0, 'z': 0, 'visibility': 0})\n   320→\n   321→        landmarks_array.append(frame_landmarks)\n   322→\n   323→    return landmarks_array\n   324→\n   325→\n   326→def extract_issues_from_shots(shots):\n   327→    \"\"\"\n   328→    Extract and aggregate issues from shot analysis results.\n   329→    Groups similar errors and records timestamps.\n   330→    \"\"\"\n   331→    issues_map = {}\n   332→\n   333→    # Issue code mapping\n   334→    error_to_code = {\n   335→        'elbow not fully extended': 'ELBOW_ANGLE_OVERHEAD',\n   336→        'arm not raised': 'ARM_NOT_RAISED',\n   337→        'knees not bent': 'KNEE_BEND',\n   338→    }\n   339→\n   340→    for shot in shots:\n   341→        frame = shot.get('frame', 0)\n   342→        # Estimate timestamp (assuming 30fps)\n   343→        timestamp = frame / 30.0\n   344→\n   345→        for error in shot.get('pose_errors', []):\n   346→            error_lower = error.lower()\n   347→\n   348→            # Find matching code\n   349→            code = 'FORM_ERROR'\n   350→            for key, val in error_to_code.items():\n   351→                if key in error_lower:\n   352→                    code = val\n   353→                    break\n   354→\n   355→            if code not in issues_map:\n   356→                issues_map[code] = {\n   357→                    'code': code,\n   358→                    'title': get_issue_title(code),\n   359→                    'severity': get_issue_severity(code),\n   360→                    'description': error,\n   361→                    'timestamps': [],\n   362→                    'occurrence_count': 0,\n   363→                    'drill': get_drill_for_issue(code)\n   364→                }\n   365→\n   366→            issues_map[code]['timestamps'].append(round(timestamp, 2))\n   367→            issues_map[code]['occurrence_count'] += 1\n   368→\n   369→    return list(issues_map.values())\n   370→\n   371→\n   372→def get_issue_title(code):\n   373→    \"\"\"Get human-readable title for issue code.\"\"\"\n   374→    titles = {\n   375→        'ELBOW_ANGLE_OVERHEAD': 'Elbow Extension (Overhead)',\n   376→        'ARM_NOT_RAISED': 'Arm Not Raised High Enough',\n   377→        'KNEE_BEND': 'Knee Bend (Lunge)',\n   378→        'STANCE_WIDTH': 'Stance Width',\n   379→        'FORM_ERROR': 'Form Issue'\n   380→    }\n   381→    return titles.get(code, code.replace('_', ' ').title())\n   382→\n   383→\n   384→def get_issue_severity(code):\n   385→    \"\"\"Get severity level for issue code.\"\"\"\n   386→    high_severity = ['ELBOW_ANGLE_OVERHEAD', 'KNEE_BEND']\n   387→    medium_severity = ['ARM_NOT_RAISED', 'STANCE_WIDTH']\n   388→\n   389→    if code in high_severity:\n   390→        return 'high'\n   391→    elif code in medium_severity:\n   392→        return 'medium'\n   393→    return 'low'\n   394→\n   395→\n   396→def get_drill_for_issue(code):\n   397→    \"\"\"Get recommended drill for issue code.\"\"\"\n   398→    drills = {\n   399→        'ELBOW_ANGLE_OVERHEAD': {\n   400→            'id': 'elbow-extension',\n   401→            'name': 'Elbow Extension Drill',\n   402→            'steps': [\n   403→                'Stand with racket arm extended overhead',\n   404→                'Practice full extension motion slowly',\n   405→                'Focus on locking elbow at contact point'\n   406→            ],\n   407→            'tips': ['Keep wrist relaxed', 'Use mirror for feedback'],\n   408→            'duration_minutes': 5\n   409→        },\n   410→        'KNEE_BEND': {\n   411→            'id': 'lunge-practice',\n   412→            'name': 'Lunge Practice Drill',\n   413→            'steps': [\n   414→                'Start in ready stance',\n   415→                'Step forward with lead leg',\n   416→                'Bend knee to 90 degrees, push back'\n   417→            ],\n   418→            'tips': ['Keep back straight', 'Push through heel'],\n   419→            'duration_minutes': 10\n   420→        },\n   421→        'ARM_NOT_RAISED': {\n   422→            'id': 'overhead-preparation',\n   423→            'name': 'Overhead Preparation Drill',\n   424→            'steps': [\n   425→                'Practice racket preparation motion',\n   426→                'Raise arm with elbow high',\n   427→                'Focus on early preparation'\n   428→            ],\n   429→            'tips': ['Watch the shuttle early', 'Turn sideways'],\n   430→            'duration_minutes': 5\n   431→        }\n   432→    }\n   433→    return drills.get(code, {'id': 'general', 'name': 'General Form Drill', 'steps': [], 'tips': []})\n   434→\n   435→\n   436→# ============================================\n   437→# Session Management Endpoints\n   438→# ============================================\n   439→\n   440→@app.get(\"/api/sessions\")\n   441→async def list_sessions(\n   442→    user_id: str = Query(..., description=\"User ID to fetch sessions for\"),\n   443→    session_type: Optional[str] = Query(None, description=\"Filter by type: analytics or practice\"),\n   444→    limit: int = Query(50, ge=1, le=100, description=\"Max number of results\")\n   445→):\n   446→    \"\"\"\n   447→    List sessions for a user with optional type filter.\n   448→    Returns sessions from the new sessions table.\n   449→    \"\"\"\n   450→    if not supabase:\n   451→        raise HTTPException(status_code=503, detail=\"Database not configured\")\n   452→\n   453→    try:\n   454→        query = supabase.table(\"sessions\").select(\"*\").eq(\"user_id\", user_id)\n   455→\n   456→        if session_type:\n   457→            query = query.eq(\"type\", session_type)\n   458→\n   459→        query = query.order(\"created_at\", desc=True).limit(limit)\n   460→\n   461→        response = query.execute()\n   462→\n   463→        return JSONResponse(content={\n   464→            \"sessions\": response.data if response.data else [],\n   465→            \"count\": len(response.data) if response.data else 0\n   466→        })\n   467→\n   468→    except Exception as e:\n   469→        print(f\"Error listing sessions: {e}\")\n   470→        raise HTTPException(status_code=500, detail=f\"Failed to list sessions: {str(e)}\")\n   471→\n   472→\n   473→@app.get(\"/api/sessions/{session_id}\")\n   474→async def get_session(session_id: str):\n   475→    \"\"\"\n   476→    Get a single session by ID with all associated issues.\n   477→    Returns full session data including pose_data for overlay rendering.\n   478→    \"\"\"\n   479→    if not supabase:\n   480→        raise HTTPException(status_code=503, detail=\"Database not configured\")\n   481→\n   482→    try:\n   483→        # Fetch session\n   484→        session_response = supabase.table(\"sessions\").select(\"*\").eq(\"id\", session_id).single().execute()\n   485→\n   486→        if not session_response.data:\n   487→            raise HTTPException(status_code=404, detail=\"Session not found\")\n   488→\n   489→        session = session_response.data\n   490→\n   491→        # Fetch associated issues\n   492→        issues_response = supabase.table(\"issues\").select(\"*\").eq(\"session_id\", session_id).execute()\n   493→\n   494→        session['issues'] = issues_response.data if issues_response.data else []\n   495→\n   496→        return JSONResponse(content=session)\n   497→\n   498→    except HTTPException:\n   499→        raise\n   500→    except Exception as e:\n   501→        print(f\"Error fetching session: {e}\")\n   502→        raise HTTPException(status_code=500, detail=f\"Failed to fetch session: {str(e)}\")\n   503→\n   504→\n   505→@app.post(\"/api/practice\")\n   506→async def save_practice_session(data: PracticeSessionData):\n   507→    \"\"\"\n   508→    Save a practice session from the frontend.\n   509→    Creates entries in sessions, practice_stats, and optionally issues tables.\n   510→    \"\"\"\n   511→    if not supabase:\n   512→        raise HTTPException(status_code=503, detail=\"Database not configured\")\n   513→\n   514→    try:\n   515→        # Calculate green ratio\n   516→        green_ratio = data.green_frames / data.total_frames if data.total_frames > 0 else 0\n   517→        overall_score = int(green_ratio * 100)\n   518→\n   519→        # 1. Create session record\n   520→        session_payload = {\n   521→            \"user_id\": data.user_id if data.user_id != \"guest\" else None,\n   522→            \"type\": \"practice\",\n   523→            \"duration_seconds\": data.duration_seconds,\n   524→            \"overall_score\": overall_score,\n   525→            \"summary\": {\n   526→                \"drill_type\": data.drill_type,\n   527→                \"green_ratio\": round(green_ratio, 3),\n   528→                \"total_frames\": data.total_frames,\n   529→                \"green_frames\": data.green_frames,\n   530→                \"red_frames\": data.red_frames\n   531→            }\n   532→        }\n   533→\n   534→        session_response = supabase.table(\"sessions\").insert(session_payload).execute()\n   535→\n   536→        if not session_response.data:\n   537→            raise HTTPException(status_code=500, detail=\"Failed to create session\")\n   538→\n   539→        session_id = session_response.data[0]['id']\n   540→\n   541→        # 2. Create practice_stats record\n   542→        stats_payload = {\n   543→            \"user_id\": data.user_id if data.user_id != \"guest\" else None,\n   544→            \"session_id\": session_id,\n   545→            \"drill_type\": data.drill_type,\n   546→            \"total_frames\": data.total_frames,\n   547→            \"green_frames\": data.green_frames,\n   548→            \"red_frames\": data.red_frames,\n   549→            \"avg_elbow_angle\": data.avg_elbow_angle,\n   550→            \"avg_stance_width\": data.avg_stance_width,\n   551→            \"peak_form_score\": data.peak_form_score,\n   552→            \"duration_seconds\": data.duration_seconds\n   553→        }\n   554→\n   555→        supabase.table(\"practice_stats\").insert(stats_payload).execute()\n   556→\n   557→        # 3. Save any detected issues\n   558→        for issue in data.issues:\n   559→            issue_payload = {\n   560→                \"session_id\": session_id,\n   561→                \"code\": issue.get('code', 'FORM_ERROR'),\n   562→                \"title\": issue.get('title', 'Form Issue'),\n   563→                \"severity\": issue.get('severity', 'medium'),\n   564→                \"description\": issue.get('description', ''),\n   565→                \"timestamps\": issue.get('timestamps', []),\n   566→                \"occurrence_count\": issue.get('occurrence_count', 1),\n   567→                \"drill\": issue.get('drill', {})\n   568→            }\n   569→            supabase.table(\"issues\").insert(issue_payload).execute()\n   570→\n   571→        print(f\"[OK] Practice session saved: {session_id}\")\n   572→\n   573→        return JSONResponse(content={\n   574→            \"success\": True,\n   575→            \"session_id\": session_id,\n   576→            \"overall_score\": overall_score,\n   577→            \"green_ratio\": round(green_ratio, 3)\n   578→        })\n   579→\n   580→    except HTTPException:\n   581→        raise\n   582→    except Exception as e:\n   583→        print(f\"Error saving practice session: {e}\")\n   584→        raise HTTPException(status_code=500, detail=f\"Failed to save practice session: {str(e)}\")\n   585→\n   586→\n   587→@app.get(\"/api/stats/dashboard\")\n   588→async def get_dashboard_stats(user_id: str = Query(..., description=\"User ID\")):\n   589→    \"\"\"\n   590→    Get aggregated stats for the dashboard.\n   591→    Returns 7-day history, top issues, and summary metrics.\n   592→    \"\"\"\n   593→    if not supabase:\n   594→        raise HTTPException(status_code=503, detail=\"Database not configured\")\n   595→\n   596→    try:\n   597→        # Fetch recent sessions\n   598→        sessions_response = supabase.table(\"sessions\")\\\n   599→            .select(\"id, created_at, type, overall_score, summary\")\\\n   600→            .eq(\"user_id\", user_id)\\\n   601→            .order(\"created_at\", desc=True)\\\n   602→            .limit(100)\\\n   603→            .execute()\n   604→\n   605→        sessions = sessions_response.data if sessions_response.data else []\n   606→\n   607→        # Fetch practice stats\n   608→        practice_response = supabase.table(\"practice_stats\")\\\n   609→            .select(\"*\")\\\n   610→            .eq(\"user_id\", user_id)\\\n   611→            .order(\"created_at\", desc=True)\\\n   612→            .limit(50)\\\n   613→            .execute()\n   614→\n   615→        practice_stats = practice_response.data if practice_response.data else []\n   616→\n   617→        # Fetch daily aggregates (if available)\n   618→        daily_response = supabase.table(\"daily_aggregates\")\\\n   619→            .select(\"*\")\\\n   620→            .eq(\"user_id\", user_id)\\\n   621→            .order(\"date\", desc=True)\\\n   622→            .limit(7)\\\n   623→            .execute()\n   624→\n   625→        daily_aggregates = daily_response.data if daily_response.data else []\n   626→\n   627→        # Calculate summary metrics\n   628→        total_sessions = len(sessions)\n   629→        analytics_sessions = len([s for s in sessions if s.get('type') == 'analytics'])\n   630→        practice_sessions = len([s for s in sessions if s.get('type') == 'practice'])\n   631→\n   632→        avg_score = 0\n   633→        if sessions:\n   634→            scores = [s.get('overall_score', 0) for s in sessions if s.get('overall_score')]\n   635→            avg_score = sum(scores) / len(scores) if scores else 0\n   636→\n   637→        total_practice_time = sum(ps.get('duration_seconds', 0) for ps in practice_stats)\n   638→        avg_green_ratio = 0\n   639→        if practice_stats:\n   640→            ratios = [ps.get('green_ratio', 0) for ps in practice_stats if ps.get('green_ratio')]\n   641→            avg_green_ratio = sum(ratios) / len(ratios) if ratios else 0\n   642→\n   643→        # Get top issues from recent sessions\n   644→        all_issues = []\n   645→        for session in sessions[:20]:\n   646→            issues_resp = supabase.table(\"issues\").select(\"code, title, occurrence_count\")\\\n   647→                .eq(\"session_id\", session['id']).execute()\n   648→            if issues_resp.data:\n   649→                all_issues.extend(issues_resp.data)\n   650→\n   651→        # Aggregate issues by code\n   652→        issue_counts = {}\n   653→        for issue in all_issues:\n   654→            code = issue.get('code', 'unknown')\n   655→            if code not in issue_counts:\n   656→                issue_counts[code] = {'code': code, 'title': issue.get('title', code), 'count': 0}\n   657→            issue_counts[code]['count'] += issue.get('occurrence_count', 1)\n   658→\n   659→        top_issues = sorted(issue_counts.values(), key=lambda x: x['count'], reverse=True)[:5]\n   660→\n   661→        return JSONResponse(content={\n   662→            \"summary\": {\n   663→                \"total_sessions\": total_sessions,\n   664→                \"analytics_sessions\": analytics_sessions,\n   665→                \"practice_sessions\": practice_sessions,\n   666→                \"avg_score\": round(avg_score, 1),\n   667→                \"total_practice_minutes\": round(total_practice_time / 60, 1),\n   668→                \"avg_green_ratio\": round(avg_green_ratio, 3)\n   669→            },\n   670→            \"daily_aggregates\": daily_aggregates,\n   671→            \"top_issues\": top_issues,\n   672→            \"recent_sessions\": sessions[:10]\n   673→        })\n   674→\n   675→    except Exception as e:\n   676→        print(f\"Error fetching dashboard stats: {e}\")\n   677→        raise HTTPException(status_code=500, detail=f\"Failed to fetch dashboard stats: {str(e)}\")\n   678→\n   679→\n   680→if __name__ == \"__main__\":\n   681→    import uvicorn\n   682→    print(\"Starting Badminton Coach API...\")\n   683→    print(f\"Supabase configured: {supabase is not None}\")\n   684→    print(f\"Gemini API configured: {os.getenv('GEMINI_API_KEY', 'NOT SET') != 'your-gemini-api-key-here'}\")\n   685→    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n   686→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"bdc5ceef-7762-4058-8c20-a66a549e0c18","timestamp":"2026-01-28T05:06:18.358Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\main.py","content":"import os\nimport shutil\nfrom typing import Optional, List\nfrom fastapi import FastAPI, File, UploadFile, HTTPException, Form, Query\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import JSONResponse, FileResponse\nfrom pydantic import BaseModel\nfrom dotenv import load_dotenv\nfrom supabase import create_client\n\n# Import analysis modules\nfrom analysis import analyze_video\nfrom pose_estimation import extract_pose_from_video\nfrom video_annotator import create_annotated_video_with_analysis\n\nload_dotenv()\n\napp = FastAPI(title=\"Badminton Analyzer & Coach API\")\n\n# ============================================\n# Pydantic Models for Request/Response\n# ============================================\n\nclass PracticeSessionData(BaseModel):\n    user_id: str\n    drill_type: str\n    total_frames: int\n    green_frames: int\n    red_frames: int\n    duration_seconds: float\n    avg_elbow_angle: Optional[float] = None\n    avg_stance_width: Optional[float] = None\n    peak_form_score: Optional[float] = 0\n    issues: Optional[List[dict]] = []\n\nclass IssueData(BaseModel):\n    code: str\n    title: str\n    severity: str = \"medium\"\n    description: Optional[str] = None\n    drill: Optional[dict] = {}\n    timestamps: Optional[List[float]] = []\n    occurrence_count: Optional[int] = 1\n\n# CORS - Allow frontend to connect\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],  # Allow all origins for development\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Supabase Setup\nSUPABASE_URL = os.getenv(\"SUPABASE_URL\")\nSUPABASE_ANON_KEY = os.getenv(\"SUPABASE_ANON_KEY\")\nSUPABASE_SERVICE_KEY = os.getenv(\"SUPABASE_SERVICE_KEY\")\n\n# Create Supabase client with SERVICE_ROLE key for backend operations\n# This bypasses RLS and allows database writes without authentication\nsupabase = None\nif SUPABASE_URL and SUPABASE_URL != \"https://your-project.supabase.co\":\n    if SUPABASE_SERVICE_KEY and SUPABASE_SERVICE_KEY != \"your-service-role-key\":\n        try:\n            supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)\n            print(\"[OK] Supabase initialized with SERVICE_ROLE key (RLS bypass enabled)\")\n        except Exception as e:\n            print(f\"[ERROR] Supabase initialization failed: {e}\")\n    else:\n        print(\"[ERROR] SUPABASE_SERVICE_KEY not configured - database writes will fail\")\n\n@app.get(\"/\")\ndef root():\n    return {\"status\": \"Badminton Coach API Active\", \"version\": \"1.0\"}\n\n@app.get(\"/health\")\ndef health():\n    return {\n        \"status\": \"healthy\",\n        \"supabase_connected\": supabase is not None,\n        \"gemini_api_key\": os.getenv(\"GEMINI_API_KEY\") != \"your-gemini-api-key-here\"\n    }\n\n@app.get(\"/temp/{filename}\")\nasync def serve_temp_video(filename: str):\n    \"\"\"Serve annotated videos from temp directory for local playback\"\"\"\n    file_path = f\"temp/{filename}\"\n    if os.path.exists(file_path):\n        return FileResponse(\n            file_path,\n            media_type=\"video/mp4\",\n            headers={\n                \"Accept-Ranges\": \"bytes\",\n                \"Cache-Control\": \"no-cache\"\n            }\n        )\n    raise HTTPException(status_code=404, detail=\"Video not found\")\n\n@app.post(\"/api/analyze\")\nasync def analyze_badminton_video(\n    file: UploadFile = File(...),\n    user_id: str = Form(\"guest\"),\n    language: str = Form(\"en\")\n):\n    \"\"\"\n    Analyze uploaded badminton video.\n    Returns: pose data, shot detection, Gemini feedback, and annotated video URL.\n    Saves to both legacy analysis_results and new sessions/issues tables.\n    \"\"\"\n\n    # Setup temp directory\n    os.makedirs(\"temp\", exist_ok=True)\n    temp_input_path = f\"temp/input_{file.filename}\"\n    temp_annotated_path = f\"temp/annotated_{file.filename}\"\n    session_id = None\n\n    try:\n        # 1. Save uploaded video\n        with open(temp_input_path, \"wb\") as buffer:\n            shutil.copyfileobj(file.file, buffer)\n\n        print(f\"Video saved: {temp_input_path}\")\n\n        # 2. Run analysis (pose detection + shot analysis + Gemini feedback)\n        analysis_result = analyze_video(temp_input_path, language)\n\n        print(f\"Analysis complete: {len(analysis_result.get('shots', []))} shots detected\")\n\n        # 3. Extract pose data for annotation\n        pose_data, frames = extract_pose_from_video(temp_input_path)\n\n        # 4. Create annotated video with skeleton overlay\n        create_annotated_video_with_analysis(\n            temp_input_path,\n            temp_annotated_path,\n            pose_data,\n            analysis_result.get('shots', [])\n        )\n\n        print(f\"Annotated video created: {temp_annotated_path}\")\n\n        # 5. Upload annotated video to Supabase Storage (if configured)\n        annotated_video_url = \"\"\n        if supabase:\n            try:\n                storage_path = f\"{user_id}/annotated/{os.path.basename(temp_annotated_path)}\"\n\n                with open(temp_annotated_path, 'rb') as video_file:\n                    video_bytes = video_file.read()\n\n                # Upload to Supabase Storage\n                result = supabase.storage.from_(\"videos\").upload(\n                    storage_path,\n                    video_bytes,\n                    file_options={\"content-type\": \"video/mp4\", \"upsert\": \"true\"}\n                )\n\n                # Get public URL\n                annotated_video_url = supabase.storage.from_(\"videos\").get_public_url(storage_path)\n\n                print(f\"Video uploaded to Supabase: {annotated_video_url}\")\n\n                # 6. Calculate overall score based on pose errors\n                shots = analysis_result.get('shots', [])\n                total_errors = sum(len(shot.get('pose_errors', [])) for shot in shots)\n                overall_score = max(0, 100 - (total_errors * 10))  # Deduct 10 points per error\n\n                # 7. Convert pose_data to frontend-compatible format (landmarks array)\n                pose_landmarks_array = convert_pose_to_landmarks(pose_data)\n\n                # 8. Extract issues from shots for the issues table\n                detected_issues = extract_issues_from_shots(shots)\n\n                # 9. Save to NEW sessions table\n                try:\n                    session_payload = {\n                        \"user_id\": user_id if user_id != \"guest\" else None,\n                        \"type\": \"analytics\",\n                        \"video_path\": storage_path,\n                        \"video_url\": annotated_video_url,\n                        \"filename\": file.filename,\n                        \"overall_score\": overall_score,\n                        \"frame_count\": len(pose_data),\n                        \"pose_data\": pose_landmarks_array,  # Full pose data for overlay\n                        \"summary\": {\n                            \"shot_count\": len(shots),\n                            \"error_count\": total_errors,\n                            \"feedback\": analysis_result.get('gemini_feedback', {}),\n                            \"language\": language\n                        }\n                    }\n\n                    session_response = supabase.table(\"sessions\").insert(session_payload).execute()\n                    if session_response.data:\n                        session_id = session_response.data[0]['id']\n                        print(f\"[OK] Session saved: {session_id}\")\n\n                        # 10. Save issues to issues table\n                        for issue in detected_issues:\n                            issue_payload = {\n                                \"session_id\": session_id,\n                                \"code\": issue['code'],\n                                \"title\": issue['title'],\n                                \"severity\": issue.get('severity', 'medium'),\n                                \"description\": issue.get('description', ''),\n                                \"timestamps\": issue.get('timestamps', []),\n                                \"occurrence_count\": issue.get('occurrence_count', 1),\n                                \"drill\": issue.get('drill', {})\n                            }\n                            supabase.table(\"issues\").insert(issue_payload).execute()\n\n                        print(f\"[OK] {len(detected_issues)} issues saved\")\n\n                except Exception as session_error:\n                    print(f\"[WARN] Session table insert failed (table may not exist): {session_error}\")\n                    # Continue with legacy table\n\n                # 11. Save to LEGACY analysis_results table (backward compatibility)\n                try:\n                    db_payload = {\n                        \"result_json\": {\n                            \"user_id\": user_id,\n                            \"video_url\": annotated_video_url,\n                            \"shot_count\": len(shots),\n                            \"shots\": shots,\n                            \"feedback\": analysis_result.get('gemini_feedback', {}),\n                            \"language\": language,\n                            \"session_id\": session_id  # Link to new session\n                        }\n                    }\n\n                    db_response = supabase.table(\"analysis_results\").insert(db_payload).execute()\n                    print(f\"[OK] Legacy database insert: Record ID = {db_response.data[0]['id'] if db_response.data else 'N/A'}\")\n\n                except Exception as db_error:\n                    print(f\"[ERROR] Legacy database insert failed: {db_error}\")\n\n            except Exception as e:\n                print(f\"Supabase upload error: {e}\")\n                annotated_video_url = f\"http://localhost:8000/temp/{os.path.basename(temp_annotated_path)}\"\n        else:\n            print(\"Supabase not configured - video saved locally only\")\n            annotated_video_url = f\"http://localhost:8000/temp/{os.path.basename(temp_annotated_path)}\"\n\n        # 12. Prepare response with full pose data for frontend overlay\n        response = {\n            \"session_id\": session_id,\n            \"shots\": analysis_result.get('shots', []),\n            \"gemini_feedback\": analysis_result.get('gemini_feedback', ''),\n            \"annotated_video_url\": annotated_video_url,\n            \"pose_data\": convert_pose_to_landmarks(pose_data),  # Full landmarks for overlay\n            \"total_shots\": len(analysis_result.get('shots', [])),\n            \"overall_score\": overall_score if supabase else 0,\n            \"issues\": detected_issues if supabase else []\n        }\n\n        print(f\"[OK] Sending response with video URL: {annotated_video_url}\")\n        print(f\"[OK] Session ID: {session_id}\")\n        print(f\"[OK] Pose frames: {len(pose_data)}\")\n\n        return JSONResponse(content=response)\n\n    except Exception as e:\n        print(f\"Error during analysis: {e}\")\n        import traceback\n        traceback.print_exc()\n        raise HTTPException(status_code=500, detail=f\"Analysis failed: {str(e)}\")\n\n    finally:\n        # Cleanup temp input file (keep annotated for serving)\n        try:\n            if os.path.exists(temp_input_path):\n                os.remove(temp_input_path)\n        except Exception as e:\n            print(f\"Cleanup error: {e}\")\n\n\n# ============================================\n# Helper Functions\n# ============================================\n\ndef convert_pose_to_landmarks(pose_data):\n    \"\"\"\n    Convert backend pose_data format to frontend-compatible landmarks array.\n    Each frame becomes an array of {x, y, z, visibility} for each landmark.\n    \"\"\"\n    landmarks_array = []\n\n    # MediaPipe landmark mapping\n    landmark_names = [\n        'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer',\n        'right_eye_inner', 'right_eye', 'right_eye_outer',\n        'left_ear', 'right_ear', 'mouth_left', 'mouth_right',\n        'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n        'left_wrist', 'right_wrist', 'left_pinky', 'right_pinky',\n        'left_index', 'right_index', 'left_thumb', 'right_thumb',\n        'left_hip', 'right_hip', 'left_knee', 'right_knee',\n        'left_ankle', 'right_ankle', 'left_heel', 'right_heel',\n        'left_foot_index', 'right_foot_index'\n    ]\n\n    for frame_pose in pose_data:\n        if frame_pose is None:\n            landmarks_array.append(None)\n            continue\n\n        frame_landmarks = []\n        for name in landmark_names:\n            if name in frame_pose:\n                coords = frame_pose[name]\n                # Normalize coordinates (assuming video width/height ~640x480)\n                frame_landmarks.append({\n                    'x': coords[0] / 640 if coords[0] else 0,\n                    'y': coords[1] / 480 if coords[1] else 0,\n                    'z': 0,\n                    'visibility': 1.0\n                })\n            else:\n                frame_landmarks.append({'x': 0, 'y': 0, 'z': 0, 'visibility': 0})\n\n        landmarks_array.append(frame_landmarks)\n\n    return landmarks_array\n\n\ndef extract_issues_from_shots(shots):\n    \"\"\"\n    Extract and aggregate issues from shot analysis results.\n    Groups similar errors and records timestamps.\n    \"\"\"\n    issues_map = {}\n\n    # Issue code mapping\n    error_to_code = {\n        'elbow not fully extended': 'ELBOW_ANGLE_OVERHEAD',\n        'arm not raised': 'ARM_NOT_RAISED',\n        'knees not bent': 'KNEE_BEND',\n    }\n\n    for shot in shots:\n        frame = shot.get('frame', 0)\n        # Estimate timestamp (assuming 30fps)\n        timestamp = frame / 30.0\n\n        for error in shot.get('pose_errors', []):\n            error_lower = error.lower()\n\n            # Find matching code\n            code = 'FORM_ERROR'\n            for key, val in error_to_code.items():\n                if key in error_lower:\n                    code = val\n                    break\n\n            if code not in issues_map:\n                issues_map[code] = {\n                    'code': code,\n                    'title': get_issue_title(code),\n                    'severity': get_issue_severity(code),\n                    'description': error,\n                    'timestamps': [],\n                    'occurrence_count': 0,\n                    'drill': get_drill_for_issue(code)\n                }\n\n            issues_map[code]['timestamps'].append(round(timestamp, 2))\n            issues_map[code]['occurrence_count'] += 1\n\n    return list(issues_map.values())\n\n\ndef get_issue_title(code):\n    \"\"\"Get human-readable title for issue code.\"\"\"\n    titles = {\n        'ELBOW_ANGLE_OVERHEAD': 'Elbow Extension (Overhead)',\n        'ARM_NOT_RAISED': 'Arm Not Raised High Enough',\n        'KNEE_BEND': 'Knee Bend (Lunge)',\n        'STANCE_WIDTH': 'Stance Width',\n        'FORM_ERROR': 'Form Issue'\n    }\n    return titles.get(code, code.replace('_', ' ').title())\n\n\ndef get_issue_severity(code):\n    \"\"\"Get severity level for issue code.\"\"\"\n    high_severity = ['ELBOW_ANGLE_OVERHEAD', 'KNEE_BEND']\n    medium_severity = ['ARM_NOT_RAISED', 'STANCE_WIDTH']\n\n    if code in high_severity:\n        return 'high'\n    elif code in medium_severity:\n        return 'medium'\n    return 'low'\n\n\ndef get_drill_for_issue(code):\n    \"\"\"Get recommended drill for issue code.\"\"\"\n    drills = {\n        'ELBOW_ANGLE_OVERHEAD': {\n            'id': 'elbow-extension',\n            'name': 'Elbow Extension Drill',\n            'steps': [\n                'Stand with racket arm extended overhead',\n                'Practice full extension motion slowly',\n                'Focus on locking elbow at contact point'\n            ],\n            'tips': ['Keep wrist relaxed', 'Use mirror for feedback'],\n            'duration_minutes': 5\n        },\n        'KNEE_BEND': {\n            'id': 'lunge-practice',\n            'name': 'Lunge Practice Drill',\n            'steps': [\n                'Start in ready stance',\n                'Step forward with lead leg',\n                'Bend knee to 90 degrees, push back'\n            ],\n            'tips': ['Keep back straight', 'Push through heel'],\n            'duration_minutes': 10\n        },\n        'ARM_NOT_RAISED': {\n            'id': 'overhead-preparation',\n            'name': 'Overhead Preparation Drill',\n            'steps': [\n                'Practice racket preparation motion',\n                'Raise arm with elbow high',\n                'Focus on early preparation'\n            ],\n            'tips': ['Watch the shuttle early', 'Turn sideways'],\n            'duration_minutes': 5\n        }\n    }\n    return drills.get(code, {'id': 'general', 'name': 'General Form Drill', 'steps': [], 'tips': []})\n\n\n# ============================================\n# Session Management Endpoints\n# ============================================\n\n@app.get(\"/api/sessions\")\nasync def list_sessions(\n    user_id: str = Query(..., description=\"User ID to fetch sessions for\"),\n    session_type: Optional[str] = Query(None, description=\"Filter by type: analytics or practice\"),\n    limit: int = Query(50, ge=1, le=100, description=\"Max number of results\")\n):\n    \"\"\"\n    List sessions for a user with optional type filter.\n    Returns sessions from the new sessions table.\n    \"\"\"\n    if not supabase:\n        raise HTTPException(status_code=503, detail=\"Database not configured\")\n\n    try:\n        query = supabase.table(\"sessions\").select(\"*\").eq(\"user_id\", user_id)\n\n        if session_type:\n            query = query.eq(\"type\", session_type)\n\n        query = query.order(\"created_at\", desc=True).limit(limit)\n\n        response = query.execute()\n\n        return JSONResponse(content={\n            \"sessions\": response.data if response.data else [],\n            \"count\": len(response.data) if response.data else 0\n        })\n\n    except Exception as e:\n        print(f\"Error listing sessions: {e}\")\n        raise HTTPException(status_code=500, detail=f\"Failed to list sessions: {str(e)}\")\n\n\n@app.get(\"/api/sessions/{session_id}\")\nasync def get_session(session_id: str):\n    \"\"\"\n    Get a single session by ID with all associated issues.\n    Returns full session data including pose_data for overlay rendering.\n    \"\"\"\n    if not supabase:\n        raise HTTPException(status_code=503, detail=\"Database not configured\")\n\n    try:\n        # Fetch session\n        session_response = supabase.table(\"sessions\").select(\"*\").eq(\"id\", session_id).single().execute()\n\n        if not session_response.data:\n            raise HTTPException(status_code=404, detail=\"Session not found\")\n\n        session = session_response.data\n\n        # Fetch associated issues\n        issues_response = supabase.table(\"issues\").select(\"*\").eq(\"session_id\", session_id).execute()\n\n        session['issues'] = issues_response.data if issues_response.data else []\n\n        return JSONResponse(content=session)\n\n    except HTTPException:\n        raise\n    except Exception as e:\n        print(f\"Error fetching session: {e}\")\n        raise HTTPException(status_code=500, detail=f\"Failed to fetch session: {str(e)}\")\n\n\n@app.post(\"/api/practice\")\nasync def save_practice_session(data: PracticeSessionData):\n    \"\"\"\n    Save a practice session from the frontend.\n    Creates entries in sessions, practice_stats, and optionally issues tables.\n    \"\"\"\n    if not supabase:\n        raise HTTPException(status_code=503, detail=\"Database not configured\")\n\n    try:\n        # Calculate green ratio\n        green_ratio = data.green_frames / data.total_frames if data.total_frames > 0 else 0\n        overall_score = int(green_ratio * 100)\n\n        # 1. Create session record\n        session_payload = {\n            \"user_id\": data.user_id if data.user_id != \"guest\" else None,\n            \"type\": \"practice\",\n            \"duration_seconds\": data.duration_seconds,\n            \"overall_score\": overall_score,\n            \"summary\": {\n                \"drill_type\": data.drill_type,\n                \"green_ratio\": round(green_ratio, 3),\n                \"total_frames\": data.total_frames,\n                \"green_frames\": data.green_frames,\n                \"red_frames\": data.red_frames\n            }\n        }\n\n        session_response = supabase.table(\"sessions\").insert(session_payload).execute()\n\n        if not session_response.data:\n            raise HTTPException(status_code=500, detail=\"Failed to create session\")\n\n        session_id = session_response.data[0]['id']\n\n        # 2. Create practice_stats record\n        stats_payload = {\n            \"user_id\": data.user_id if data.user_id != \"guest\" else None,\n            \"session_id\": session_id,\n            \"drill_type\": data.drill_type,\n            \"total_frames\": data.total_frames,\n            \"green_frames\": data.green_frames,\n            \"red_frames\": data.red_frames,\n            \"avg_elbow_angle\": data.avg_elbow_angle,\n            \"avg_stance_width\": data.avg_stance_width,\n            \"peak_form_score\": data.peak_form_score,\n            \"duration_seconds\": data.duration_seconds\n        }\n\n        supabase.table(\"practice_stats\").insert(stats_payload).execute()\n\n        # 3. Save any detected issues\n        for issue in data.issues:\n            issue_payload = {\n                \"session_id\": session_id,\n                \"code\": issue.get('code', 'FORM_ERROR'),\n                \"title\": issue.get('title', 'Form Issue'),\n                \"severity\": issue.get('severity', 'medium'),\n                \"description\": issue.get('description', ''),\n                \"timestamps\": issue.get('timestamps', []),\n                \"occurrence_count\": issue.get('occurrence_count', 1),\n                \"drill\": issue.get('drill', {})\n            }\n            supabase.table(\"issues\").insert(issue_payload).execute()\n\n        print(f\"[OK] Practice session saved: {session_id}\")\n\n        return JSONResponse(content={\n            \"success\": True,\n            \"session_id\": session_id,\n            \"overall_score\": overall_score,\n            \"green_ratio\": round(green_ratio, 3)\n        })\n\n    except HTTPException:\n        raise\n    except Exception as e:\n        print(f\"Error saving practice session: {e}\")\n        raise HTTPException(status_code=500, detail=f\"Failed to save practice session: {str(e)}\")\n\n\n@app.get(\"/api/stats/dashboard\")\nasync def get_dashboard_stats(user_id: str = Query(..., description=\"User ID\")):\n    \"\"\"\n    Get aggregated stats for the dashboard.\n    Returns 7-day history, top issues, and summary metrics.\n    \"\"\"\n    if not supabase:\n        raise HTTPException(status_code=503, detail=\"Database not configured\")\n\n    try:\n        # Fetch recent sessions\n        sessions_response = supabase.table(\"sessions\")\\\n            .select(\"id, created_at, type, overall_score, summary\")\\\n            .eq(\"user_id\", user_id)\\\n            .order(\"created_at\", desc=True)\\\n            .limit(100)\\\n            .execute()\n\n        sessions = sessions_response.data if sessions_response.data else []\n\n        # Fetch practice stats\n        practice_response = supabase.table(\"practice_stats\")\\\n            .select(\"*\")\\\n            .eq(\"user_id\", user_id)\\\n            .order(\"created_at\", desc=True)\\\n            .limit(50)\\\n            .execute()\n\n        practice_stats = practice_response.data if practice_response.data else []\n\n        # Fetch daily aggregates (if available)\n        daily_response = supabase.table(\"daily_aggregates\")\\\n            .select(\"*\")\\\n            .eq(\"user_id\", user_id)\\\n            .order(\"date\", desc=True)\\\n            .limit(7)\\\n            .execute()\n\n        daily_aggregates = daily_response.data if daily_response.data else []\n\n        # Calculate summary metrics\n        total_sessions = len(sessions)\n        analytics_sessions = len([s for s in sessions if s.get('type') == 'analytics'])\n        practice_sessions = len([s for s in sessions if s.get('type') == 'practice'])\n\n        avg_score = 0\n        if sessions:\n            scores = [s.get('overall_score', 0) for s in sessions if s.get('overall_score')]\n            avg_score = sum(scores) / len(scores) if scores else 0\n\n        total_practice_time = sum(ps.get('duration_seconds', 0) for ps in practice_stats)\n        avg_green_ratio = 0\n        if practice_stats:\n            ratios = [ps.get('green_ratio', 0) for ps in practice_stats if ps.get('green_ratio')]\n            avg_green_ratio = sum(ratios) / len(ratios) if ratios else 0\n\n        # Get top issues from recent sessions\n        all_issues = []\n        for session in sessions[:20]:\n            issues_resp = supabase.table(\"issues\").select(\"code, title, occurrence_count\")\\\n                .eq(\"session_id\", session['id']).execute()\n            if issues_resp.data:\n                all_issues.extend(issues_resp.data)\n\n        # Aggregate issues by code\n        issue_counts = {}\n        for issue in all_issues:\n            code = issue.get('code', 'unknown')\n            if code not in issue_counts:\n                issue_counts[code] = {'code': code, 'title': issue.get('title', code), 'count': 0}\n            issue_counts[code]['count'] += issue.get('occurrence_count', 1)\n\n        top_issues = sorted(issue_counts.values(), key=lambda x: x['count'], reverse=True)[:5]\n\n        return JSONResponse(content={\n            \"summary\": {\n                \"total_sessions\": total_sessions,\n                \"analytics_sessions\": analytics_sessions,\n                \"practice_sessions\": practice_sessions,\n                \"avg_score\": round(avg_score, 1),\n                \"total_practice_minutes\": round(total_practice_time / 60, 1),\n                \"avg_green_ratio\": round(avg_green_ratio, 3)\n            },\n            \"daily_aggregates\": daily_aggregates,\n            \"top_issues\": top_issues,\n            \"recent_sessions\": sessions[:10]\n        })\n\n    except Exception as e:\n        print(f\"Error fetching dashboard stats: {e}\")\n        raise HTTPException(status_code=500, detail=f\"Failed to fetch dashboard stats: {str(e)}\")\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n    print(\"Starting Badminton Coach API...\")\n    print(f\"Supabase configured: {supabase is not None}\")\n    print(f\"Gemini API configured: {os.getenv('GEMINI_API_KEY', 'NOT SET') != 'your-gemini-api-key-here'}\")\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n","numLines":686,"startLine":1,"totalLines":686}},"sourceToolAssistantUUID":"f51b9078-ff44-465b-bcc8-f37cbceddbce"}
{"parentUuid":"bdc5ceef-7762-4058-8c20-a66a549e0c18","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_013cBTiYfRMpEzDXgVfw59jj","toolUseID":"toolu_013cBTiYfRMpEzDXgVfw59jj","timestamp":"2026-01-28T05:06:18.363Z","uuid":"e75b4ac5-f2c3-4244-9876-759b5f8ec24e"}
{"parentUuid":"e75b4ac5-f2c3-4244-9876-759b5f8ec24e","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Xy7hrreHwt1q3AQdhwJjee","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me read the frontend analytics page and other related files to understand the current frontend architecture.","signature":"Ep0CCkYICxgCKkA6KPgt8UhMPCdfTyGrgxNGDs4aZ8GOZ7XRKV9rum7g2kV1d/sBDLvAWMYfdO34DZjOkbmH0fmyUMe5+vtTmO5QEgwDZNhMV6rsCr25OXwaDCBth6FJEj/hOCmqiyIwFX/Pt0r/ebiLj+aHzPYLO9e0gn8q+w4P+RJRGoIBSL5i8UfvWbrWW3OdthBCUeHMKoQBeo5C4JwaiPheoVODT4N0xixhGOVk59ETe7iRxj5+dSCILx36us8p4lTUtN07Nx4PR5s3FMNMAy5EqfjGh7MJ0tzd/3RB48YxfCYZ2QsYECAy++a1L3ZlqhW++BF0vyiOX8nuwfRToTGDLNbugqLt9SiUF7/LHwnVTdeis2vcFFOl71ljGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1171,"cache_creation_input_tokens":13617,"cache_read_input_tokens":58070,"cache_creation":{"ephemeral_5m_input_tokens":13617,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXZCFfMjVNepRQ8FZ51r9","type":"assistant","uuid":"a20c21a0-6c9d-4eaf-b6be-d587aff66c06","timestamp":"2026-01-28T05:06:20.921Z"}
{"parentUuid":"a20c21a0-6c9d-4eaf-b6be-d587aff66c06","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Xy7hrreHwt1q3AQdhwJjee","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me read the frontend files - analytics page, pose-utils, rules-engine, scoring-rules, and other components."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1171,"cache_creation_input_tokens":13617,"cache_read_input_tokens":58070,"cache_creation":{"ephemeral_5m_input_tokens":13617,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXZCFfMjVNepRQ8FZ51r9","type":"assistant","uuid":"95ba4f7b-3ac6-4c28-9079-1c57e353389d","timestamp":"2026-01-28T05:06:21.958Z"}
{"parentUuid":"95ba4f7b-3ac6-4c28-9079-1c57e353389d","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Xy7hrreHwt1q3AQdhwJjee","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DdTmdNqnCu6vc1ysXD4bN9","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1171,"cache_creation_input_tokens":13617,"cache_read_input_tokens":58070,"cache_creation":{"ephemeral_5m_input_tokens":13617,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXZCFfMjVNepRQ8FZ51r9","type":"assistant","uuid":"a9cb365c-aeef-4006-82a9-7428b042823e","timestamp":"2026-01-28T05:06:23.020Z"}
{"parentUuid":"a9cb365c-aeef-4006-82a9-7428b042823e","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Xy7hrreHwt1q3AQdhwJjee","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0188tdydf1ttSkUk3ikSpHSZ","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\pose-utils.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1171,"cache_creation_input_tokens":13617,"cache_read_input_tokens":58070,"cache_creation":{"ephemeral_5m_input_tokens":13617,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXZCFfMjVNepRQ8FZ51r9","type":"assistant","uuid":"1affb76e-31ba-4c9c-9d3a-feee81b36757","timestamp":"2026-01-28T05:06:23.505Z"}
{"parentUuid":"1affb76e-31ba-4c9c-9d3a-feee81b36757","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Xy7hrreHwt1q3AQdhwJjee","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BV83FTGJrZG2xS33REU6tg","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\rules-engine.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1171,"cache_creation_input_tokens":13617,"cache_read_input_tokens":58070,"cache_creation":{"ephemeral_5m_input_tokens":13617,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXZCFfMjVNepRQ8FZ51r9","type":"assistant","uuid":"4e539777-1799-4d90-aed2-22ab8973eba0","timestamp":"2026-01-28T05:06:23.993Z"}
{"parentUuid":"1affb76e-31ba-4c9c-9d3a-feee81b36757","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0188tdydf1ttSkUk3ikSpHSZ","type":"tool_result","content":"     1→import type { PoseMetrics, PoseLandmark } from './types';\n     2→\n     3→// MediaPipe Pose landmark indices\n     4→export const POSE_LANDMARKS = {\n     5→  NOSE: 0,\n     6→  LEFT_EYE_INNER: 1,\n     7→  LEFT_EYE: 2,\n     8→  LEFT_EYE_OUTER: 3,\n     9→  RIGHT_EYE_INNER: 4,\n    10→  RIGHT_EYE: 5,\n    11→  RIGHT_EYE_OUTER: 6,\n    12→  LEFT_EAR: 7,\n    13→  RIGHT_EAR: 8,\n    14→  MOUTH_LEFT: 9,\n    15→  MOUTH_RIGHT: 10,\n    16→  LEFT_SHOULDER: 11,\n    17→  RIGHT_SHOULDER: 12,\n    18→  LEFT_ELBOW: 13,\n    19→  RIGHT_ELBOW: 14,\n    20→  LEFT_WRIST: 15,\n    21→  RIGHT_WRIST: 16,\n    22→  LEFT_PINKY: 17,\n    23→  RIGHT_PINKY: 18,\n    24→  LEFT_INDEX: 19,\n    25→  RIGHT_INDEX: 20,\n    26→  LEFT_THUMB: 21,\n    27→  RIGHT_THUMB: 22,\n    28→  LEFT_HIP: 23,\n    29→  RIGHT_HIP: 24,\n    30→  LEFT_KNEE: 25,\n    31→  RIGHT_KNEE: 26,\n    32→  LEFT_ANKLE: 27,\n    33→  RIGHT_ANKLE: 28,\n    34→  LEFT_HEEL: 29,\n    35→  RIGHT_HEEL: 30,\n    36→  LEFT_FOOT_INDEX: 31,\n    37→  RIGHT_FOOT_INDEX: 32,\n    38→};\n    39→\n    40→// Calculate angle between three points (in degrees)\n    41→export function calculateAngle(\n    42→  p1: PoseLandmark,\n    43→  p2: PoseLandmark, // vertex\n    44→  p3: PoseLandmark\n    45→): number {\n    46→  const v1 = { x: p1.x - p2.x, y: p1.y - p2.y };\n    47→  const v2 = { x: p3.x - p2.x, y: p3.y - p2.y };\n    48→\n    49→  const dot = v1.x * v2.x + v1.y * v2.y;\n    50→  const mag1 = Math.sqrt(v1.x * v1.x + v1.y * v1.y);\n    51→  const mag2 = Math.sqrt(v2.x * v2.x + v2.y * v2.y);\n    52→\n    53→  if (mag1 === 0 || mag2 === 0) return 0;\n    54→\n    55→  const cosAngle = Math.max(-1, Math.min(1, dot / (mag1 * mag2)));\n    56→  return Math.acos(cosAngle) * (180 / Math.PI);\n    57→}\n    58→\n    59→// Calculate distance between two points\n    60→export function calculateDistance(p1: PoseLandmark, p2: PoseLandmark): number {\n    61→  const dx = p2.x - p1.x;\n    62→  const dy = p2.y - p1.y;\n    63→  return Math.sqrt(dx * dx + dy * dy);\n    64→}\n    65→\n    66→// Extract metrics from pose landmarks\n    67→export function extractMetrics(landmarks: PoseLandmark[]): PoseMetrics {\n    68→  // Get relevant landmarks\n    69→  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n    70→  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n    71→  const leftElbow = landmarks[POSE_LANDMARKS.LEFT_ELBOW];\n    72→  const rightElbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n    73→  const leftWrist = landmarks[POSE_LANDMARKS.LEFT_WRIST];\n    74→  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n    75→  const leftHip = landmarks[POSE_LANDMARKS.LEFT_HIP];\n    76→  const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n    77→  const leftKnee = landmarks[POSE_LANDMARKS.LEFT_KNEE];\n    78→  const rightKnee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n    79→  const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n    80→  const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n    81→\n    82→  // Calculate elbow angle (use the more visible arm)\n    83→  const leftElbowAngle = calculateAngle(leftShoulder, leftElbow, leftWrist);\n    84→  const rightElbowAngle = calculateAngle(rightShoulder, rightElbow, rightWrist);\n    85→  const elbowAngle =\n    86→    leftElbow.visibility > rightElbow.visibility ? leftElbowAngle : rightElbowAngle;\n    87→\n    88→  // Calculate knee angle (average of both knees)\n    89→  const leftKneeAngle = calculateAngle(leftHip, leftKnee, leftAnkle);\n    90→  const rightKneeAngle = calculateAngle(rightHip, rightKnee, rightAnkle);\n    91→  const kneeAngle = (leftKneeAngle + rightKneeAngle) / 2;\n    92→\n    93→  // Calculate stance width normalized by shoulder width\n    94→  const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n    95→  const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n    96→  const stanceWidthNorm = shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n    97→\n    98→  // Calculate shoulder-hip rotation proxy\n    99→  // This measures the rotation difference between shoulder line and hip line\n   100→  const shoulderAngle = Math.atan2(\n   101→    rightShoulder.y - leftShoulder.y,\n   102→    rightShoulder.x - leftShoulder.x\n   103→  );\n   104→  const hipAngle = Math.atan2(rightHip.y - leftHip.y, rightHip.x - leftHip.x);\n   105→  const rotationProxy = Math.abs(shoulderAngle - hipAngle);\n   106→\n   107→  return {\n   108→    elbow_angle: elbowAngle,\n   109→    knee_angle: kneeAngle,\n   110→    stance_width_norm: stanceWidthNorm,\n   111→    shoulder_hip_rotation_proxy: rotationProxy,\n   112→    timestamp: Date.now(),\n   113→  };\n   114→}\n   115→\n   116→// Check if metrics are within acceptable thresholds\n   117→export function evaluateMetrics(metrics: PoseMetrics): {\n   118→  isGreen: boolean;\n   119→  feedback: string[];\n   120→} {\n   121→  const feedback: string[] = [];\n   122→  let greenCount = 0;\n   123→  const totalChecks = 4;\n   124→\n   125→  // Elbow angle check (90-120 degrees is ideal)\n   126→  if (metrics.elbow_angle >= 90 && metrics.elbow_angle <= 120) {\n   127→    greenCount++;\n   128→  } else if (metrics.elbow_angle < 90) {\n   129→    feedback.push('Extend your elbow more');\n   130→  } else {\n   131→    feedback.push('Bend your elbow slightly');\n   132→  }\n   133→\n   134→  // Knee angle check (120-150 degrees is ideal)\n   135→  if (metrics.knee_angle >= 120 && metrics.knee_angle <= 150) {\n   136→    greenCount++;\n   137→  } else if (metrics.knee_angle < 120) {\n   138→    feedback.push('Straighten your knees a bit');\n   139→  } else {\n   140→    feedback.push('Bend your knees more');\n   141→  }\n   142→\n   143→  // Stance width check (0.3-0.5 normalized is ideal)\n   144→  if (metrics.stance_width_norm >= 0.3 && metrics.stance_width_norm <= 0.5) {\n   145→    greenCount++;\n   146→  } else if (metrics.stance_width_norm < 0.3) {\n   147→    feedback.push('Widen your stance');\n   148→  } else {\n   149→    feedback.push('Narrow your stance slightly');\n   150→  }\n   151→\n   152→  // Rotation check (0.1-0.3 is ideal for most shots)\n   153→  if (\n   154→    metrics.shoulder_hip_rotation_proxy >= 0.1 &&\n   155→    metrics.shoulder_hip_rotation_proxy <= 0.3\n   156→  ) {\n   157→    greenCount++;\n   158→  } else if (metrics.shoulder_hip_rotation_proxy < 0.1) {\n   159→    feedback.push('Rotate your body more');\n   160→  } else {\n   161→    feedback.push('Control your rotation');\n   162→  }\n   163→\n   164→  return {\n   165→    isGreen: greenCount >= 3, // Green if at least 3 out of 4 metrics are good\n   166→    feedback: feedback.length > 0 ? feedback : ['Great form! Keep it up!'],\n   167→  };\n   168→}\n   169→\n   170→// Generate mock metrics for demo/fallback\n   171→export function generateMockMetrics(): PoseMetrics {\n   172→  return {\n   173→    elbow_angle: 95 + Math.random() * 30,\n   174→    knee_angle: 125 + Math.random() * 30,\n   175→    stance_width_norm: 0.35 + Math.random() * 0.2,\n   176→    shoulder_hip_rotation_proxy: 0.15 + Math.random() * 0.2,\n   177→    timestamp: Date.now(),\n   178→  };\n   179→}\n   180→\n   181→// Drawing utilities for canvas\n   182→export const POSE_CONNECTIONS = [\n   183→  // Face\n   184→  [POSE_LANDMARKS.LEFT_EAR, POSE_LANDMARKS.LEFT_EYE],\n   185→  [POSE_LANDMARKS.LEFT_EYE, POSE_LANDMARKS.NOSE],\n   186→  [POSE_LANDMARKS.NOSE, POSE_LANDMARKS.RIGHT_EYE],\n   187→  [POSE_LANDMARKS.RIGHT_EYE, POSE_LANDMARKS.RIGHT_EAR],\n   188→  // Torso\n   189→  [POSE_LANDMARKS.LEFT_SHOULDER, POSE_LANDMARKS.RIGHT_SHOULDER],\n   190→  [POSE_LANDMARKS.LEFT_SHOULDER, POSE_LANDMARKS.LEFT_HIP],\n   191→  [POSE_LANDMARKS.RIGHT_SHOULDER, POSE_LANDMARKS.RIGHT_HIP],\n   192→  [POSE_LANDMARKS.LEFT_HIP, POSE_LANDMARKS.RIGHT_HIP],\n   193→  // Left arm\n   194→  [POSE_LANDMARKS.LEFT_SHOULDER, POSE_LANDMARKS.LEFT_ELBOW],\n   195→  [POSE_LANDMARKS.LEFT_ELBOW, POSE_LANDMARKS.LEFT_WRIST],\n   196→  // Right arm\n   197→  [POSE_LANDMARKS.RIGHT_SHOULDER, POSE_LANDMARKS.RIGHT_ELBOW],\n   198→  [POSE_LANDMARKS.RIGHT_ELBOW, POSE_LANDMARKS.RIGHT_WRIST],\n   199→  // Left leg\n   200→  [POSE_LANDMARKS.LEFT_HIP, POSE_LANDMARKS.LEFT_KNEE],\n   201→  [POSE_LANDMARKS.LEFT_KNEE, POSE_LANDMARKS.LEFT_ANKLE],\n   202→  // Right leg\n   203→  [POSE_LANDMARKS.RIGHT_HIP, POSE_LANDMARKS.RIGHT_KNEE],\n   204→  [POSE_LANDMARKS.RIGHT_KNEE, POSE_LANDMARKS.RIGHT_ANKLE],\n   205→];\n   206→\n   207→export function drawSkeleton(\n   208→  ctx: CanvasRenderingContext2D,\n   209→  landmarks: PoseLandmark[],\n   210→  isGreen: boolean,\n   211→  width: number,\n   212→  height: number\n   213→) {\n   214→  const color = isGreen ? '#22c55e' : '#ef4444';\n   215→\n   216→  // Draw connections\n   217→  ctx.strokeStyle = color;\n   218→  ctx.lineWidth = 3;\n   219→\n   220→  for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n   221→    const start = landmarks[startIdx];\n   222→    const end = landmarks[endIdx];\n   223→\n   224→    if (start.visibility > 0.5 && end.visibility > 0.5) {\n   225→      ctx.beginPath();\n   226→      ctx.moveTo(start.x * width, start.y * height);\n   227→      ctx.lineTo(end.x * width, end.y * height);\n   228→      ctx.stroke();\n   229→    }\n   230→  }\n   231→\n   232→  // Draw landmarks\n   233→  ctx.fillStyle = color;\n   234→  for (const landmark of landmarks) {\n   235→    if (landmark.visibility > 0.5) {\n   236→      ctx.beginPath();\n   237→      ctx.arc(landmark.x * width, landmark.y * height, 5, 0, 2 * Math.PI);\n   238→      ctx.fill();\n   239→    }\n   240→  }\n   241→}\n   242→\n   243→// Default thresholds for metrics\n   244→export const DEFAULT_THRESHOLDS = {\n   245→  elbow_angle: { min: 90, max: 120 },\n   246→  knee_angle: { min: 120, max: 150 },\n   247→  stance_width_norm: { min: 0.3, max: 0.5 },\n   248→  shoulder_hip_rotation_proxy: { min: 0.1, max: 0.3 },\n   249→};\n   250→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"0d131fe2-1a23-4aef-9a0b-a5582b44ae9a","timestamp":"2026-01-28T05:06:26.387Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\pose-utils.ts","content":"import type { PoseMetrics, PoseLandmark } from './types';\n\n// MediaPipe Pose landmark indices\nexport const POSE_LANDMARKS = {\n  NOSE: 0,\n  LEFT_EYE_INNER: 1,\n  LEFT_EYE: 2,\n  LEFT_EYE_OUTER: 3,\n  RIGHT_EYE_INNER: 4,\n  RIGHT_EYE: 5,\n  RIGHT_EYE_OUTER: 6,\n  LEFT_EAR: 7,\n  RIGHT_EAR: 8,\n  MOUTH_LEFT: 9,\n  MOUTH_RIGHT: 10,\n  LEFT_SHOULDER: 11,\n  RIGHT_SHOULDER: 12,\n  LEFT_ELBOW: 13,\n  RIGHT_ELBOW: 14,\n  LEFT_WRIST: 15,\n  RIGHT_WRIST: 16,\n  LEFT_PINKY: 17,\n  RIGHT_PINKY: 18,\n  LEFT_INDEX: 19,\n  RIGHT_INDEX: 20,\n  LEFT_THUMB: 21,\n  RIGHT_THUMB: 22,\n  LEFT_HIP: 23,\n  RIGHT_HIP: 24,\n  LEFT_KNEE: 25,\n  RIGHT_KNEE: 26,\n  LEFT_ANKLE: 27,\n  RIGHT_ANKLE: 28,\n  LEFT_HEEL: 29,\n  RIGHT_HEEL: 30,\n  LEFT_FOOT_INDEX: 31,\n  RIGHT_FOOT_INDEX: 32,\n};\n\n// Calculate angle between three points (in degrees)\nexport function calculateAngle(\n  p1: PoseLandmark,\n  p2: PoseLandmark, // vertex\n  p3: PoseLandmark\n): number {\n  const v1 = { x: p1.x - p2.x, y: p1.y - p2.y };\n  const v2 = { x: p3.x - p2.x, y: p3.y - p2.y };\n\n  const dot = v1.x * v2.x + v1.y * v2.y;\n  const mag1 = Math.sqrt(v1.x * v1.x + v1.y * v1.y);\n  const mag2 = Math.sqrt(v2.x * v2.x + v2.y * v2.y);\n\n  if (mag1 === 0 || mag2 === 0) return 0;\n\n  const cosAngle = Math.max(-1, Math.min(1, dot / (mag1 * mag2)));\n  return Math.acos(cosAngle) * (180 / Math.PI);\n}\n\n// Calculate distance between two points\nexport function calculateDistance(p1: PoseLandmark, p2: PoseLandmark): number {\n  const dx = p2.x - p1.x;\n  const dy = p2.y - p1.y;\n  return Math.sqrt(dx * dx + dy * dy);\n}\n\n// Extract metrics from pose landmarks\nexport function extractMetrics(landmarks: PoseLandmark[]): PoseMetrics {\n  // Get relevant landmarks\n  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const leftElbow = landmarks[POSE_LANDMARKS.LEFT_ELBOW];\n  const rightElbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n  const leftWrist = landmarks[POSE_LANDMARKS.LEFT_WRIST];\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n  const leftHip = landmarks[POSE_LANDMARKS.LEFT_HIP];\n  const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const leftKnee = landmarks[POSE_LANDMARKS.LEFT_KNEE];\n  const rightKnee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n  const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n  const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n\n  // Calculate elbow angle (use the more visible arm)\n  const leftElbowAngle = calculateAngle(leftShoulder, leftElbow, leftWrist);\n  const rightElbowAngle = calculateAngle(rightShoulder, rightElbow, rightWrist);\n  const elbowAngle =\n    leftElbow.visibility > rightElbow.visibility ? leftElbowAngle : rightElbowAngle;\n\n  // Calculate knee angle (average of both knees)\n  const leftKneeAngle = calculateAngle(leftHip, leftKnee, leftAnkle);\n  const rightKneeAngle = calculateAngle(rightHip, rightKnee, rightAnkle);\n  const kneeAngle = (leftKneeAngle + rightKneeAngle) / 2;\n\n  // Calculate stance width normalized by shoulder width\n  const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n  const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n  const stanceWidthNorm = shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n\n  // Calculate shoulder-hip rotation proxy\n  // This measures the rotation difference between shoulder line and hip line\n  const shoulderAngle = Math.atan2(\n    rightShoulder.y - leftShoulder.y,\n    rightShoulder.x - leftShoulder.x\n  );\n  const hipAngle = Math.atan2(rightHip.y - leftHip.y, rightHip.x - leftHip.x);\n  const rotationProxy = Math.abs(shoulderAngle - hipAngle);\n\n  return {\n    elbow_angle: elbowAngle,\n    knee_angle: kneeAngle,\n    stance_width_norm: stanceWidthNorm,\n    shoulder_hip_rotation_proxy: rotationProxy,\n    timestamp: Date.now(),\n  };\n}\n\n// Check if metrics are within acceptable thresholds\nexport function evaluateMetrics(metrics: PoseMetrics): {\n  isGreen: boolean;\n  feedback: string[];\n} {\n  const feedback: string[] = [];\n  let greenCount = 0;\n  const totalChecks = 4;\n\n  // Elbow angle check (90-120 degrees is ideal)\n  if (metrics.elbow_angle >= 90 && metrics.elbow_angle <= 120) {\n    greenCount++;\n  } else if (metrics.elbow_angle < 90) {\n    feedback.push('Extend your elbow more');\n  } else {\n    feedback.push('Bend your elbow slightly');\n  }\n\n  // Knee angle check (120-150 degrees is ideal)\n  if (metrics.knee_angle >= 120 && metrics.knee_angle <= 150) {\n    greenCount++;\n  } else if (metrics.knee_angle < 120) {\n    feedback.push('Straighten your knees a bit');\n  } else {\n    feedback.push('Bend your knees more');\n  }\n\n  // Stance width check (0.3-0.5 normalized is ideal)\n  if (metrics.stance_width_norm >= 0.3 && metrics.stance_width_norm <= 0.5) {\n    greenCount++;\n  } else if (metrics.stance_width_norm < 0.3) {\n    feedback.push('Widen your stance');\n  } else {\n    feedback.push('Narrow your stance slightly');\n  }\n\n  // Rotation check (0.1-0.3 is ideal for most shots)\n  if (\n    metrics.shoulder_hip_rotation_proxy >= 0.1 &&\n    metrics.shoulder_hip_rotation_proxy <= 0.3\n  ) {\n    greenCount++;\n  } else if (metrics.shoulder_hip_rotation_proxy < 0.1) {\n    feedback.push('Rotate your body more');\n  } else {\n    feedback.push('Control your rotation');\n  }\n\n  return {\n    isGreen: greenCount >= 3, // Green if at least 3 out of 4 metrics are good\n    feedback: feedback.length > 0 ? feedback : ['Great form! Keep it up!'],\n  };\n}\n\n// Generate mock metrics for demo/fallback\nexport function generateMockMetrics(): PoseMetrics {\n  return {\n    elbow_angle: 95 + Math.random() * 30,\n    knee_angle: 125 + Math.random() * 30,\n    stance_width_norm: 0.35 + Math.random() * 0.2,\n    shoulder_hip_rotation_proxy: 0.15 + Math.random() * 0.2,\n    timestamp: Date.now(),\n  };\n}\n\n// Drawing utilities for canvas\nexport const POSE_CONNECTIONS = [\n  // Face\n  [POSE_LANDMARKS.LEFT_EAR, POSE_LANDMARKS.LEFT_EYE],\n  [POSE_LANDMARKS.LEFT_EYE, POSE_LANDMARKS.NOSE],\n  [POSE_LANDMARKS.NOSE, POSE_LANDMARKS.RIGHT_EYE],\n  [POSE_LANDMARKS.RIGHT_EYE, POSE_LANDMARKS.RIGHT_EAR],\n  // Torso\n  [POSE_LANDMARKS.LEFT_SHOULDER, POSE_LANDMARKS.RIGHT_SHOULDER],\n  [POSE_LANDMARKS.LEFT_SHOULDER, POSE_LANDMARKS.LEFT_HIP],\n  [POSE_LANDMARKS.RIGHT_SHOULDER, POSE_LANDMARKS.RIGHT_HIP],\n  [POSE_LANDMARKS.LEFT_HIP, POSE_LANDMARKS.RIGHT_HIP],\n  // Left arm\n  [POSE_LANDMARKS.LEFT_SHOULDER, POSE_LANDMARKS.LEFT_ELBOW],\n  [POSE_LANDMARKS.LEFT_ELBOW, POSE_LANDMARKS.LEFT_WRIST],\n  // Right arm\n  [POSE_LANDMARKS.RIGHT_SHOULDER, POSE_LANDMARKS.RIGHT_ELBOW],\n  [POSE_LANDMARKS.RIGHT_ELBOW, POSE_LANDMARKS.RIGHT_WRIST],\n  // Left leg\n  [POSE_LANDMARKS.LEFT_HIP, POSE_LANDMARKS.LEFT_KNEE],\n  [POSE_LANDMARKS.LEFT_KNEE, POSE_LANDMARKS.LEFT_ANKLE],\n  // Right leg\n  [POSE_LANDMARKS.RIGHT_HIP, POSE_LANDMARKS.RIGHT_KNEE],\n  [POSE_LANDMARKS.RIGHT_KNEE, POSE_LANDMARKS.RIGHT_ANKLE],\n];\n\nexport function drawSkeleton(\n  ctx: CanvasRenderingContext2D,\n  landmarks: PoseLandmark[],\n  isGreen: boolean,\n  width: number,\n  height: number\n) {\n  const color = isGreen ? '#22c55e' : '#ef4444';\n\n  // Draw connections\n  ctx.strokeStyle = color;\n  ctx.lineWidth = 3;\n\n  for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n    const start = landmarks[startIdx];\n    const end = landmarks[endIdx];\n\n    if (start.visibility > 0.5 && end.visibility > 0.5) {\n      ctx.beginPath();\n      ctx.moveTo(start.x * width, start.y * height);\n      ctx.lineTo(end.x * width, end.y * height);\n      ctx.stroke();\n    }\n  }\n\n  // Draw landmarks\n  ctx.fillStyle = color;\n  for (const landmark of landmarks) {\n    if (landmark.visibility > 0.5) {\n      ctx.beginPath();\n      ctx.arc(landmark.x * width, landmark.y * height, 5, 0, 2 * Math.PI);\n      ctx.fill();\n    }\n  }\n}\n\n// Default thresholds for metrics\nexport const DEFAULT_THRESHOLDS = {\n  elbow_angle: { min: 90, max: 120 },\n  knee_angle: { min: 120, max: 150 },\n  stance_width_norm: { min: 0.3, max: 0.5 },\n  shoulder_hip_rotation_proxy: { min: 0.1, max: 0.3 },\n};\n","numLines":250,"startLine":1,"totalLines":250}},"sourceToolAssistantUUID":"1affb76e-31ba-4c9c-9d3a-feee81b36757"}
{"parentUuid":"4e539777-1799-4d90-aed2-22ab8973eba0","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BV83FTGJrZG2xS33REU6tg","type":"tool_result","content":"     1→/**\n     2→ * Rules Engine for Badminton Form Evaluation\n     3→ * Provides form rules, drill recommendations, and keyframe generation\n     4→ */\n     5→\n     6→import type { PoseLandmark, PoseMetrics } from './types';\n     7→import { calculateAngle, calculateDistance, POSE_LANDMARKS } from './pose-utils';\n     8→\n     9→// ============================================\n    10→// Form Rules Configuration\n    11→// ============================================\n    12→\n    13→export interface FormRule {\n    14→  code: string;\n    15→  name: string;\n    16→  description: string;\n    17→  compute: (landmarks: PoseLandmark[], width?: number) => number;\n    18→  threshold: { min: number; max: number };\n    19→  severity: 'low' | 'medium' | 'high';\n    20→  drillId: string;\n    21→  drillTypes: string[];\n    22→  feedback: {\n    23→    tooLow: string;\n    24→    tooHigh: string;\n    25→    good: string;\n    26→  };\n    27→}\n    28→\n    29→export const FORM_RULES: Record<string, FormRule> = {\n    30→  ELBOW_ANGLE_OVERHEAD: {\n    31→    code: 'ELBOW_ANGLE_OVERHEAD',\n    32→    name: 'Elbow Extension (Overhead)',\n    33→    description: 'Elbow should be nearly straight at contact point for overhead shots',\n    34→    compute: (landmarks) => {\n    35→      const shoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n    36→      const elbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n    37→      const wrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n    38→      return calculateAngle(shoulder, elbow, wrist);\n    39→    },\n    40→    threshold: { min: 150, max: 180 },\n    41→    severity: 'high',\n    42→    drillId: 'elbow-extension',\n    43→    drillTypes: ['smash', 'clear'],\n    44→    feedback: {\n    45→      tooLow: 'Extend your elbow more at contact',\n    46→      tooHigh: 'Good extension!',\n    47→      good: 'Perfect elbow extension!',\n    48→    },\n    49→  },\n    50→  ELBOW_ANGLE_DRIVE: {\n    51→    code: 'ELBOW_ANGLE_DRIVE',\n    52→    name: 'Elbow Angle (Drive)',\n    53→    description: 'Elbow should be at 90-120 degrees for drive shots',\n    54→    compute: (landmarks) => {\n    55→      const shoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n    56→      const elbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n    57→      const wrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n    58→      return calculateAngle(shoulder, elbow, wrist);\n    59→    },\n    60→    threshold: { min: 90, max: 120 },\n    61→    severity: 'medium',\n    62→    drillId: 'drive-technique',\n    63→    drillTypes: ['drive', 'netshot'],\n    64→    feedback: {\n    65→      tooLow: 'Extend your elbow slightly more',\n    66→      tooHigh: 'Bend your elbow more for control',\n    67→      good: 'Good elbow position!',\n    68→    },\n    69→  },\n    70→  STANCE_WIDTH: {\n    71→    code: 'STANCE_WIDTH',\n    72→    name: 'Stance Width',\n    73→    description: 'Feet should be shoulder-width apart for stability',\n    74→    compute: (landmarks, width = 640) => {\n    75→      const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n    76→      const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n    77→      const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n    78→      const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n    79→      const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n    80→      const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n    81→      return shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n    82→    },\n    83→    threshold: { min: 0.8, max: 1.5 },\n    84→    severity: 'medium',\n    85→    drillId: 'footwork-basics',\n    86→    drillTypes: ['footwork', 'general'],\n    87→    feedback: {\n    88→      tooLow: 'Widen your stance for better balance',\n    89→      tooHigh: 'Narrow your stance slightly',\n    90→      good: 'Good stance width!',\n    91→    },\n    92→  },\n    93→  KNEE_BEND: {\n    94→    code: 'KNEE_BEND',\n    95→    name: 'Knee Bend',\n    96→    description: 'Knees should be bent for ready position and lunges',\n    97→    compute: (landmarks) => {\n    98→      const hip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n    99→      const knee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n   100→      const ankle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n   101→      return calculateAngle(hip, knee, ankle);\n   102→    },\n   103→    threshold: { min: 100, max: 160 },\n   104→    severity: 'high',\n   105→    drillId: 'lunge-practice',\n   106→    drillTypes: ['netshot', 'footwork', 'general'],\n   107→    feedback: {\n   108→      tooLow: 'Straighten your legs a bit more',\n   109→      tooHigh: 'Bend your knees more for power',\n   110→      good: 'Good knee bend!',\n   111→    },\n   112→  },\n   113→  BODY_ROTATION: {\n   114→    code: 'BODY_ROTATION',\n   115→    name: 'Body Rotation',\n   116→    description: 'Proper hip-shoulder separation for power generation',\n   117→    compute: (landmarks) => {\n   118→      const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n   119→      const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n   120→      const leftHip = landmarks[POSE_LANDMARKS.LEFT_HIP];\n   121→      const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n   122→      const shoulderAngle = Math.atan2(\n   123→        rightShoulder.y - leftShoulder.y,\n   124→        rightShoulder.x - leftShoulder.x\n   125→      );\n   126→      const hipAngle = Math.atan2(rightHip.y - leftHip.y, rightHip.x - leftHip.x);\n   127→      return Math.abs(shoulderAngle - hipAngle) * (180 / Math.PI);\n   128→    },\n   129→    threshold: { min: 10, max: 45 },\n   130→    severity: 'medium',\n   131→    drillId: 'rotation-drill',\n   132→    drillTypes: ['smash', 'clear'],\n   133→    feedback: {\n   134→      tooLow: 'Rotate your body more for power',\n   135→      tooHigh: 'Control your rotation',\n   136→      good: 'Good body rotation!',\n   137→    },\n   138→  },\n   139→};\n   140→\n   141→// ============================================\n   142→// Drill Definitions\n   143→// ============================================\n   144→\n   145→export interface DrillDefinition {\n   146→  id: string;\n   147→  name: string;\n   148→  description: string;\n   149→  steps: string[];\n   150→  tips: string[];\n   151→  durationMinutes: number;\n   152→  targetMetrics: string[];\n   153→  keyframeType: 'smash' | 'clear' | 'netshot' | 'footwork' | 'drive';\n   154→}\n   155→\n   156→export const DRILLS: Record<string, DrillDefinition> = {\n   157→  'elbow-extension': {\n   158→    id: 'elbow-extension',\n   159→    name: 'Elbow Extension Drill',\n   160→    description: 'Practice full arm extension for powerful overhead shots',\n   161→    steps: [\n   162→      'Stand with racket arm extended overhead',\n   163→      'Practice full extension motion slowly',\n   164→      'Focus on locking elbow at contact point',\n   165→      'Repeat 20 times with shadow swing',\n   166→    ],\n   167→    tips: ['Keep wrist relaxed', 'Use mirror for feedback', 'Focus on smooth motion'],\n   168→    durationMinutes: 5,\n   169→    targetMetrics: ['elbow_angle'],\n   170→    keyframeType: 'smash',\n   171→  },\n   172→  'lunge-practice': {\n   173→    id: 'lunge-practice',\n   174→    name: 'Lunge Practice Drill',\n   175→    description: 'Develop proper lunge technique for net play',\n   176→    steps: [\n   177→      'Start in ready stance',\n   178→      'Step forward with lead leg',\n   179→      'Bend knee to 90 degrees',\n   180→      'Push back to starting position',\n   181→    ],\n   182→    tips: ['Keep back straight', 'Push through heel', 'Stay low'],\n   183→    durationMinutes: 10,\n   184→    targetMetrics: ['knee_angle', 'stance_width'],\n   185→    keyframeType: 'netshot',\n   186→  },\n   187→  'footwork-basics': {\n   188→    id: 'footwork-basics',\n   189→    name: 'Footwork Basics',\n   190→    description: 'Master the fundamental footwork patterns',\n   191→    steps: [\n   192→      'Start in center position',\n   193→      'Move to each corner using proper footwork',\n   194→      'Return to center after each move',\n   195→      'Focus on split step timing',\n   196→    ],\n   197→    tips: ['Stay on balls of feet', 'Keep center of gravity low', 'Use small, quick steps'],\n   198→    durationMinutes: 15,\n   199→    targetMetrics: ['stance_width', 'knee_angle'],\n   200→    keyframeType: 'footwork',\n   201→  },\n   202→  'rotation-drill': {\n   203→    id: 'rotation-drill',\n   204→    name: 'Body Rotation Drill',\n   205→    description: 'Develop hip-shoulder separation for power',\n   206→    steps: [\n   207→      'Stand sideways to the net',\n   208→      'Rotate hips first, then shoulders',\n   209→      'Practice the throwing motion',\n   210→      'Add racket swing gradually',\n   211→    ],\n   212→    tips: ['Lead with hips', 'Keep eye on shuttle', 'Follow through completely'],\n   213→    durationMinutes: 10,\n   214→    targetMetrics: ['body_rotation'],\n   215→    keyframeType: 'smash',\n   216→  },\n   217→  'drive-technique': {\n   218→    id: 'drive-technique',\n   219→    name: 'Drive Shot Technique',\n   220→    description: 'Practice flat, fast drive shots',\n   221→    steps: [\n   222→      'Position racket at shoulder height',\n   223→      'Use short, punchy swing',\n   224→      'Contact shuttle in front of body',\n   225→      'Follow through towards target',\n   226→    ],\n   227→    tips: ['Keep grip relaxed', 'Use forearm rotation', 'Stay compact'],\n   228→    durationMinutes: 10,\n   229→    targetMetrics: ['elbow_angle'],\n   230→    keyframeType: 'drive',\n   231→  },\n   232→};\n   233→\n   234→// ============================================\n   235→// Evaluation Functions\n   236→// ============================================\n   237→\n   238→export interface EvaluationResult {\n   239→  passed: boolean;\n   240→  score: number;\n   241→  failedRules: Array<{\n   242→    rule: FormRule;\n   243→    value: number;\n   244→    feedback: string;\n   245→  }>;\n   246→  passedRules: Array<{\n   247→    rule: FormRule;\n   248→    value: number;\n   249→  }>;\n   250→  highlightJoints: number[];\n   251→  recommendedDrills: DrillDefinition[];\n   252→}\n   253→\n   254→export function evaluateForm(\n   255→  landmarks: PoseLandmark[],\n   256→  drillType: string = 'general',\n   257→  canvasWidth: number = 640\n   258→): EvaluationResult {\n   259→  const failedRules: EvaluationResult['failedRules'] = [];\n   260→  const passedRules: EvaluationResult['passedRules'] = [];\n   261→  const highlightJoints: number[] = [];\n   262→  const drillIds = new Set<string>();\n   263→\n   264→  // Get rules applicable to this drill type\n   265→  const applicableRules = Object.values(FORM_RULES).filter(\n   266→    (rule) => rule.drillTypes.includes(drillType) || rule.drillTypes.includes('general')\n   267→  );\n   268→\n   269→  for (const rule of applicableRules) {\n   270→    const value = rule.compute(landmarks, canvasWidth);\n   271→    const { min, max } = rule.threshold;\n   272→\n   273→    if (value >= min && value <= max) {\n   274→      passedRules.push({ rule, value });\n   275→    } else {\n   276→      const feedback = value < min ? rule.feedback.tooLow : rule.feedback.tooHigh;\n   277→      failedRules.push({ rule, value, feedback });\n   278→      drillIds.add(rule.drillId);\n   279→\n   280→      // Add joints to highlight based on rule\n   281→      if (rule.code.includes('ELBOW')) {\n   282→        highlightJoints.push(POSE_LANDMARKS.RIGHT_ELBOW, POSE_LANDMARKS.RIGHT_WRIST);\n   283→      }\n   284→      if (rule.code.includes('KNEE')) {\n   285→        highlightJoints.push(POSE_LANDMARKS.RIGHT_KNEE, POSE_LANDMARKS.LEFT_KNEE);\n   286→      }\n   287→      if (rule.code.includes('STANCE')) {\n   288→        highlightJoints.push(POSE_LANDMARKS.LEFT_ANKLE, POSE_LANDMARKS.RIGHT_ANKLE);\n   289→      }\n   290→    }\n   291→  }\n   292→\n   293→  const totalRules = applicableRules.length;\n   294→  const score = totalRules > 0 ? (passedRules.length / totalRules) * 100 : 100;\n   295→  const passed = score >= 75; // Pass if 75% or more rules pass\n   296→\n   297→  // Get recommended drills\n   298→  const recommendedDrills = Array.from(drillIds)\n   299→    .map((id) => DRILLS[id])\n   300→    .filter(Boolean);\n   301→\n   302→  return {\n   303→    passed,\n   304→    score,\n   305→    failedRules,\n   306→    passedRules,\n   307→    highlightJoints,\n   308→    recommendedDrills,\n   309→  };\n   310→}\n   311→\n   312→// ============================================\n   313→// SVG Keyframe Generation\n   314→// ============================================\n   315→\n   316→const IDEAL_POSES: Record<string, Array<{ x: number; y: number }>> = {\n   317→  smash: [\n   318→    // Frame 1: Preparation\n   319→    { x: 0.5, y: 0.15 }, // nose\n   320→    { x: 0.45, y: 0.25 }, // left shoulder\n   321→    { x: 0.55, y: 0.25 }, // right shoulder\n   322→    { x: 0.35, y: 0.35 }, // left elbow\n   323→    { x: 0.75, y: 0.15 }, // right elbow (raised)\n   324→    { x: 0.25, y: 0.45 }, // left wrist\n   325→    { x: 0.85, y: 0.1 }, // right wrist (racket back)\n   326→    { x: 0.45, y: 0.5 }, // left hip\n   327→    { x: 0.55, y: 0.5 }, // right hip\n   328→    { x: 0.4, y: 0.75 }, // left knee\n   329→    { x: 0.6, y: 0.7 }, // right knee\n   330→    { x: 0.35, y: 0.95 }, // left ankle\n   331→    { x: 0.65, y: 0.95 }, // right ankle\n   332→  ],\n   333→  clear: [\n   334→    { x: 0.5, y: 0.15 },\n   335→    { x: 0.45, y: 0.25 },\n   336→    { x: 0.55, y: 0.25 },\n   337→    { x: 0.35, y: 0.35 },\n   338→    { x: 0.7, y: 0.2 },\n   339→    { x: 0.25, y: 0.45 },\n   340→    { x: 0.8, y: 0.1 },\n   341→    { x: 0.45, y: 0.5 },\n   342→    { x: 0.55, y: 0.5 },\n   343→    { x: 0.4, y: 0.75 },\n   344→    { x: 0.6, y: 0.7 },\n   345→    { x: 0.35, y: 0.95 },\n   346→    { x: 0.65, y: 0.95 },\n   347→  ],\n   348→  netshot: [\n   349→    { x: 0.5, y: 0.2 },\n   350→    { x: 0.45, y: 0.3 },\n   351→    { x: 0.55, y: 0.3 },\n   352→    { x: 0.4, y: 0.4 },\n   353→    { x: 0.65, y: 0.35 },\n   354→    { x: 0.35, y: 0.5 },\n   355→    { x: 0.75, y: 0.4 },\n   356→    { x: 0.45, y: 0.55 },\n   357→    { x: 0.55, y: 0.55 },\n   358→    { x: 0.35, y: 0.75 },\n   359→    { x: 0.7, y: 0.65 },\n   360→    { x: 0.3, y: 0.95 },\n   361→    { x: 0.8, y: 0.85 },\n   362→  ],\n   363→  footwork: [\n   364→    { x: 0.5, y: 0.15 },\n   365→    { x: 0.4, y: 0.25 },\n   366→    { x: 0.6, y: 0.25 },\n   367→    { x: 0.35, y: 0.4 },\n   368→    { x: 0.65, y: 0.4 },\n   369→    { x: 0.3, y: 0.5 },\n   370→    { x: 0.7, y: 0.5 },\n   371→    { x: 0.42, y: 0.5 },\n   372→    { x: 0.58, y: 0.5 },\n   373→    { x: 0.35, y: 0.75 },\n   374→    { x: 0.65, y: 0.75 },\n   375→    { x: 0.3, y: 0.95 },\n   376→    { x: 0.7, y: 0.95 },\n   377→  ],\n   378→  drive: [\n   379→    { x: 0.5, y: 0.15 },\n   380→    { x: 0.45, y: 0.25 },\n   381→    { x: 0.55, y: 0.25 },\n   382→    { x: 0.4, y: 0.35 },\n   383→    { x: 0.65, y: 0.3 },\n   384→    { x: 0.35, y: 0.45 },\n   385→    { x: 0.8, y: 0.3 },\n   386→    { x: 0.45, y: 0.5 },\n   387→    { x: 0.55, y: 0.5 },\n   388→    { x: 0.4, y: 0.75 },\n   389→    { x: 0.6, y: 0.75 },\n   390→    { x: 0.35, y: 0.95 },\n   391→    { x: 0.65, y: 0.95 },\n   392→  ],\n   393→};\n   394→\n   395→const SKELETON_CONNECTIONS = [\n   396→  [0, 1], [0, 2], // Head to shoulders\n   397→  [1, 2], // Shoulder to shoulder\n   398→  [1, 3], [3, 5], // Left arm\n   399→  [2, 4], [4, 6], // Right arm\n   400→  [1, 7], [2, 8], // Shoulders to hips\n   401→  [7, 8], // Hip to hip\n   402→  [7, 9], [9, 11], // Left leg\n   403→  [8, 10], [10, 12], // Right leg\n   404→];\n   405→\n   406→export function generateKeyframeSVG(\n   407→  drillType: 'smash' | 'clear' | 'netshot' | 'footwork' | 'drive',\n   408→  frame: number = 0,\n   409→  options: { width?: number; height?: number; color?: string } = {}\n   410→): string {\n   411→  const { width = 120, height = 180, color = '#0ea5e9' } = options;\n   412→  const pose = IDEAL_POSES[drillType] || IDEAL_POSES.footwork;\n   413→\n   414→  // Simple frame variation (slightly different poses)\n   415→  const offset = frame * 0.02;\n   416→\n   417→  let pathD = '';\n   418→  for (const [i, j] of SKELETON_CONNECTIONS) {\n   419→    const p1 = pose[i];\n   420→    const p2 = pose[j];\n   421→    if (p1 && p2) {\n   422→      const x1 = (p1.x + offset) * width;\n   423→      const y1 = p1.y * height;\n   424→      const x2 = (p2.x + offset) * width;\n   425→      const y2 = p2.y * height;\n   426→      pathD += `M${x1},${y1}L${x2},${y2}`;\n   427→    }\n   428→  }\n   429→\n   430→  let circles = '';\n   431→  for (const point of pose) {\n   432→    const x = (point.x + offset) * width;\n   433→    const y = point.y * height;\n   434→    circles += `<circle cx=\"${x}\" cy=\"${y}\" r=\"4\" fill=\"${color}\"/>`;\n   435→  }\n   436→\n   437→  return `<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 ${width} ${height}\" width=\"${width}\" height=\"${height}\">\n   438→    <rect width=\"${width}\" height=\"${height}\" fill=\"#f8fafc\" rx=\"8\"/>\n   439→    <path d=\"${pathD}\" stroke=\"${color}\" stroke-width=\"3\" fill=\"none\" stroke-linecap=\"round\"/>\n   440→    ${circles}\n   441→  </svg>`;\n   442→}\n   443→\n   444→export function getKeyframeSVGs(\n   445→  drillType: 'smash' | 'clear' | 'netshot' | 'footwork' | 'drive',\n   446→  options: { width?: number; height?: number } = {}\n   447→): Array<{ svg: string; label: string }> {\n   448→  const labels = {\n   449→    smash: ['Setup', 'Load', 'Strike'],\n   450→    clear: ['Prepare', 'Reach', 'Follow'],\n   451→    netshot: ['Approach', 'Extend', 'Tap'],\n   452→    footwork: ['Ready', 'Step', 'Return'],\n   453→    drive: ['Position', 'Contact', 'Follow'],\n   454→  };\n   455→\n   456→  return [0, 1, 2].map((frame) => ({\n   457→    svg: generateKeyframeSVG(drillType, frame, options),\n   458→    label: labels[drillType]?.[frame] || `Step ${frame + 1}`,\n   459→  }));\n   460→}\n   461→\n   462→// ============================================\n   463→// Session Stats Aggregation\n   464→// ============================================\n   465→\n   466→export interface SessionStats {\n   467→  totalFrames: number;\n   468→  greenFrames: number;\n   469→  redFrames: number;\n   470→  greenRatio: number;\n   471→  avgScore: number;\n   472→  topIssues: Array<{ code: string; count: number }>;\n   473→  recommendedDrills: DrillDefinition[];\n   474→}\n   475→\n   476→export function aggregateSessionStats(\n   477→  frameResults: EvaluationResult[]\n   478→): SessionStats {\n   479→  const totalFrames = frameResults.length;\n   480→  const greenFrames = frameResults.filter((r) => r.passed).length;\n   481→  const redFrames = totalFrames - greenFrames;\n   482→  const greenRatio = totalFrames > 0 ? greenFrames / totalFrames : 0;\n   483→  const avgScore = totalFrames > 0\n   484→    ? frameResults.reduce((sum, r) => sum + r.score, 0) / totalFrames\n   485→    : 0;\n   486→\n   487→  // Count issues\n   488→  const issueCounts: Record<string, number> = {};\n   489→  for (const result of frameResults) {\n   490→    for (const failed of result.failedRules) {\n   491→      const code = failed.rule.code;\n   492→      issueCounts[code] = (issueCounts[code] || 0) + 1;\n   493→    }\n   494→  }\n   495→\n   496→  const topIssues = Object.entries(issueCounts)\n   497→    .map(([code, count]) => ({ code, count }))\n   498→    .sort((a, b) => b.count - a.count)\n   499→    .slice(0, 5);\n   500→\n   501→  // Get unique recommended drills\n   502→  const drillIds = new Set<string>();\n   503→  for (const result of frameResults) {\n   504→    for (const drill of result.recommendedDrills) {\n   505→      drillIds.add(drill.id);\n   506→    }\n   507→  }\n   508→  const recommendedDrills = Array.from(drillIds)\n   509→    .map((id) => DRILLS[id])\n   510→    .filter(Boolean)\n   511→    .slice(0, 3);\n   512→\n   513→  return {\n   514→    totalFrames,\n   515→    greenFrames,\n   516→    redFrames,\n   517→    greenRatio,\n   518→    avgScore,\n   519→    topIssues,\n   520→    recommendedDrills,\n   521→  };\n   522→}\n   523→\n   524→// ============================================\n   525→// Timestamp Violation Detection\n   526→// ============================================\n   527→\n   528→export function findViolationTimestamps(\n   529→  frameResults: Array<{ timestamp: number; result: EvaluationResult }>,\n   530→  ruleCode?: string\n   531→): number[] {\n   532→  return frameResults\n   533→    .filter((frame) => {\n   534→      if (ruleCode) {\n   535→        return frame.result.failedRules.some((f) => f.rule.code === ruleCode);\n   536→      }\n   537→      return !frame.result.passed;\n   538→    })\n   539→    .map((frame) => frame.timestamp);\n   540→}\n   541→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"580ce839-197f-4e2d-bd32-3028a5998978","timestamp":"2026-01-28T05:06:26.387Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\rules-engine.ts","content":"/**\n * Rules Engine for Badminton Form Evaluation\n * Provides form rules, drill recommendations, and keyframe generation\n */\n\nimport type { PoseLandmark, PoseMetrics } from './types';\nimport { calculateAngle, calculateDistance, POSE_LANDMARKS } from './pose-utils';\n\n// ============================================\n// Form Rules Configuration\n// ============================================\n\nexport interface FormRule {\n  code: string;\n  name: string;\n  description: string;\n  compute: (landmarks: PoseLandmark[], width?: number) => number;\n  threshold: { min: number; max: number };\n  severity: 'low' | 'medium' | 'high';\n  drillId: string;\n  drillTypes: string[];\n  feedback: {\n    tooLow: string;\n    tooHigh: string;\n    good: string;\n  };\n}\n\nexport const FORM_RULES: Record<string, FormRule> = {\n  ELBOW_ANGLE_OVERHEAD: {\n    code: 'ELBOW_ANGLE_OVERHEAD',\n    name: 'Elbow Extension (Overhead)',\n    description: 'Elbow should be nearly straight at contact point for overhead shots',\n    compute: (landmarks) => {\n      const shoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n      const elbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n      const wrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n      return calculateAngle(shoulder, elbow, wrist);\n    },\n    threshold: { min: 150, max: 180 },\n    severity: 'high',\n    drillId: 'elbow-extension',\n    drillTypes: ['smash', 'clear'],\n    feedback: {\n      tooLow: 'Extend your elbow more at contact',\n      tooHigh: 'Good extension!',\n      good: 'Perfect elbow extension!',\n    },\n  },\n  ELBOW_ANGLE_DRIVE: {\n    code: 'ELBOW_ANGLE_DRIVE',\n    name: 'Elbow Angle (Drive)',\n    description: 'Elbow should be at 90-120 degrees for drive shots',\n    compute: (landmarks) => {\n      const shoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n      const elbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n      const wrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n      return calculateAngle(shoulder, elbow, wrist);\n    },\n    threshold: { min: 90, max: 120 },\n    severity: 'medium',\n    drillId: 'drive-technique',\n    drillTypes: ['drive', 'netshot'],\n    feedback: {\n      tooLow: 'Extend your elbow slightly more',\n      tooHigh: 'Bend your elbow more for control',\n      good: 'Good elbow position!',\n    },\n  },\n  STANCE_WIDTH: {\n    code: 'STANCE_WIDTH',\n    name: 'Stance Width',\n    description: 'Feet should be shoulder-width apart for stability',\n    compute: (landmarks, width = 640) => {\n      const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n      const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n      const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n      const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n      const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n      const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n      return shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n    },\n    threshold: { min: 0.8, max: 1.5 },\n    severity: 'medium',\n    drillId: 'footwork-basics',\n    drillTypes: ['footwork', 'general'],\n    feedback: {\n      tooLow: 'Widen your stance for better balance',\n      tooHigh: 'Narrow your stance slightly',\n      good: 'Good stance width!',\n    },\n  },\n  KNEE_BEND: {\n    code: 'KNEE_BEND',\n    name: 'Knee Bend',\n    description: 'Knees should be bent for ready position and lunges',\n    compute: (landmarks) => {\n      const hip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n      const knee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n      const ankle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n      return calculateAngle(hip, knee, ankle);\n    },\n    threshold: { min: 100, max: 160 },\n    severity: 'high',\n    drillId: 'lunge-practice',\n    drillTypes: ['netshot', 'footwork', 'general'],\n    feedback: {\n      tooLow: 'Straighten your legs a bit more',\n      tooHigh: 'Bend your knees more for power',\n      good: 'Good knee bend!',\n    },\n  },\n  BODY_ROTATION: {\n    code: 'BODY_ROTATION',\n    name: 'Body Rotation',\n    description: 'Proper hip-shoulder separation for power generation',\n    compute: (landmarks) => {\n      const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n      const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n      const leftHip = landmarks[POSE_LANDMARKS.LEFT_HIP];\n      const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n      const shoulderAngle = Math.atan2(\n        rightShoulder.y - leftShoulder.y,\n        rightShoulder.x - leftShoulder.x\n      );\n      const hipAngle = Math.atan2(rightHip.y - leftHip.y, rightHip.x - leftHip.x);\n      return Math.abs(shoulderAngle - hipAngle) * (180 / Math.PI);\n    },\n    threshold: { min: 10, max: 45 },\n    severity: 'medium',\n    drillId: 'rotation-drill',\n    drillTypes: ['smash', 'clear'],\n    feedback: {\n      tooLow: 'Rotate your body more for power',\n      tooHigh: 'Control your rotation',\n      good: 'Good body rotation!',\n    },\n  },\n};\n\n// ============================================\n// Drill Definitions\n// ============================================\n\nexport interface DrillDefinition {\n  id: string;\n  name: string;\n  description: string;\n  steps: string[];\n  tips: string[];\n  durationMinutes: number;\n  targetMetrics: string[];\n  keyframeType: 'smash' | 'clear' | 'netshot' | 'footwork' | 'drive';\n}\n\nexport const DRILLS: Record<string, DrillDefinition> = {\n  'elbow-extension': {\n    id: 'elbow-extension',\n    name: 'Elbow Extension Drill',\n    description: 'Practice full arm extension for powerful overhead shots',\n    steps: [\n      'Stand with racket arm extended overhead',\n      'Practice full extension motion slowly',\n      'Focus on locking elbow at contact point',\n      'Repeat 20 times with shadow swing',\n    ],\n    tips: ['Keep wrist relaxed', 'Use mirror for feedback', 'Focus on smooth motion'],\n    durationMinutes: 5,\n    targetMetrics: ['elbow_angle'],\n    keyframeType: 'smash',\n  },\n  'lunge-practice': {\n    id: 'lunge-practice',\n    name: 'Lunge Practice Drill',\n    description: 'Develop proper lunge technique for net play',\n    steps: [\n      'Start in ready stance',\n      'Step forward with lead leg',\n      'Bend knee to 90 degrees',\n      'Push back to starting position',\n    ],\n    tips: ['Keep back straight', 'Push through heel', 'Stay low'],\n    durationMinutes: 10,\n    targetMetrics: ['knee_angle', 'stance_width'],\n    keyframeType: 'netshot',\n  },\n  'footwork-basics': {\n    id: 'footwork-basics',\n    name: 'Footwork Basics',\n    description: 'Master the fundamental footwork patterns',\n    steps: [\n      'Start in center position',\n      'Move to each corner using proper footwork',\n      'Return to center after each move',\n      'Focus on split step timing',\n    ],\n    tips: ['Stay on balls of feet', 'Keep center of gravity low', 'Use small, quick steps'],\n    durationMinutes: 15,\n    targetMetrics: ['stance_width', 'knee_angle'],\n    keyframeType: 'footwork',\n  },\n  'rotation-drill': {\n    id: 'rotation-drill',\n    name: 'Body Rotation Drill',\n    description: 'Develop hip-shoulder separation for power',\n    steps: [\n      'Stand sideways to the net',\n      'Rotate hips first, then shoulders',\n      'Practice the throwing motion',\n      'Add racket swing gradually',\n    ],\n    tips: ['Lead with hips', 'Keep eye on shuttle', 'Follow through completely'],\n    durationMinutes: 10,\n    targetMetrics: ['body_rotation'],\n    keyframeType: 'smash',\n  },\n  'drive-technique': {\n    id: 'drive-technique',\n    name: 'Drive Shot Technique',\n    description: 'Practice flat, fast drive shots',\n    steps: [\n      'Position racket at shoulder height',\n      'Use short, punchy swing',\n      'Contact shuttle in front of body',\n      'Follow through towards target',\n    ],\n    tips: ['Keep grip relaxed', 'Use forearm rotation', 'Stay compact'],\n    durationMinutes: 10,\n    targetMetrics: ['elbow_angle'],\n    keyframeType: 'drive',\n  },\n};\n\n// ============================================\n// Evaluation Functions\n// ============================================\n\nexport interface EvaluationResult {\n  passed: boolean;\n  score: number;\n  failedRules: Array<{\n    rule: FormRule;\n    value: number;\n    feedback: string;\n  }>;\n  passedRules: Array<{\n    rule: FormRule;\n    value: number;\n  }>;\n  highlightJoints: number[];\n  recommendedDrills: DrillDefinition[];\n}\n\nexport function evaluateForm(\n  landmarks: PoseLandmark[],\n  drillType: string = 'general',\n  canvasWidth: number = 640\n): EvaluationResult {\n  const failedRules: EvaluationResult['failedRules'] = [];\n  const passedRules: EvaluationResult['passedRules'] = [];\n  const highlightJoints: number[] = [];\n  const drillIds = new Set<string>();\n\n  // Get rules applicable to this drill type\n  const applicableRules = Object.values(FORM_RULES).filter(\n    (rule) => rule.drillTypes.includes(drillType) || rule.drillTypes.includes('general')\n  );\n\n  for (const rule of applicableRules) {\n    const value = rule.compute(landmarks, canvasWidth);\n    const { min, max } = rule.threshold;\n\n    if (value >= min && value <= max) {\n      passedRules.push({ rule, value });\n    } else {\n      const feedback = value < min ? rule.feedback.tooLow : rule.feedback.tooHigh;\n      failedRules.push({ rule, value, feedback });\n      drillIds.add(rule.drillId);\n\n      // Add joints to highlight based on rule\n      if (rule.code.includes('ELBOW')) {\n        highlightJoints.push(POSE_LANDMARKS.RIGHT_ELBOW, POSE_LANDMARKS.RIGHT_WRIST);\n      }\n      if (rule.code.includes('KNEE')) {\n        highlightJoints.push(POSE_LANDMARKS.RIGHT_KNEE, POSE_LANDMARKS.LEFT_KNEE);\n      }\n      if (rule.code.includes('STANCE')) {\n        highlightJoints.push(POSE_LANDMARKS.LEFT_ANKLE, POSE_LANDMARKS.RIGHT_ANKLE);\n      }\n    }\n  }\n\n  const totalRules = applicableRules.length;\n  const score = totalRules > 0 ? (passedRules.length / totalRules) * 100 : 100;\n  const passed = score >= 75; // Pass if 75% or more rules pass\n\n  // Get recommended drills\n  const recommendedDrills = Array.from(drillIds)\n    .map((id) => DRILLS[id])\n    .filter(Boolean);\n\n  return {\n    passed,\n    score,\n    failedRules,\n    passedRules,\n    highlightJoints,\n    recommendedDrills,\n  };\n}\n\n// ============================================\n// SVG Keyframe Generation\n// ============================================\n\nconst IDEAL_POSES: Record<string, Array<{ x: number; y: number }>> = {\n  smash: [\n    // Frame 1: Preparation\n    { x: 0.5, y: 0.15 }, // nose\n    { x: 0.45, y: 0.25 }, // left shoulder\n    { x: 0.55, y: 0.25 }, // right shoulder\n    { x: 0.35, y: 0.35 }, // left elbow\n    { x: 0.75, y: 0.15 }, // right elbow (raised)\n    { x: 0.25, y: 0.45 }, // left wrist\n    { x: 0.85, y: 0.1 }, // right wrist (racket back)\n    { x: 0.45, y: 0.5 }, // left hip\n    { x: 0.55, y: 0.5 }, // right hip\n    { x: 0.4, y: 0.75 }, // left knee\n    { x: 0.6, y: 0.7 }, // right knee\n    { x: 0.35, y: 0.95 }, // left ankle\n    { x: 0.65, y: 0.95 }, // right ankle\n  ],\n  clear: [\n    { x: 0.5, y: 0.15 },\n    { x: 0.45, y: 0.25 },\n    { x: 0.55, y: 0.25 },\n    { x: 0.35, y: 0.35 },\n    { x: 0.7, y: 0.2 },\n    { x: 0.25, y: 0.45 },\n    { x: 0.8, y: 0.1 },\n    { x: 0.45, y: 0.5 },\n    { x: 0.55, y: 0.5 },\n    { x: 0.4, y: 0.75 },\n    { x: 0.6, y: 0.7 },\n    { x: 0.35, y: 0.95 },\n    { x: 0.65, y: 0.95 },\n  ],\n  netshot: [\n    { x: 0.5, y: 0.2 },\n    { x: 0.45, y: 0.3 },\n    { x: 0.55, y: 0.3 },\n    { x: 0.4, y: 0.4 },\n    { x: 0.65, y: 0.35 },\n    { x: 0.35, y: 0.5 },\n    { x: 0.75, y: 0.4 },\n    { x: 0.45, y: 0.55 },\n    { x: 0.55, y: 0.55 },\n    { x: 0.35, y: 0.75 },\n    { x: 0.7, y: 0.65 },\n    { x: 0.3, y: 0.95 },\n    { x: 0.8, y: 0.85 },\n  ],\n  footwork: [\n    { x: 0.5, y: 0.15 },\n    { x: 0.4, y: 0.25 },\n    { x: 0.6, y: 0.25 },\n    { x: 0.35, y: 0.4 },\n    { x: 0.65, y: 0.4 },\n    { x: 0.3, y: 0.5 },\n    { x: 0.7, y: 0.5 },\n    { x: 0.42, y: 0.5 },\n    { x: 0.58, y: 0.5 },\n    { x: 0.35, y: 0.75 },\n    { x: 0.65, y: 0.75 },\n    { x: 0.3, y: 0.95 },\n    { x: 0.7, y: 0.95 },\n  ],\n  drive: [\n    { x: 0.5, y: 0.15 },\n    { x: 0.45, y: 0.25 },\n    { x: 0.55, y: 0.25 },\n    { x: 0.4, y: 0.35 },\n    { x: 0.65, y: 0.3 },\n    { x: 0.35, y: 0.45 },\n    { x: 0.8, y: 0.3 },\n    { x: 0.45, y: 0.5 },\n    { x: 0.55, y: 0.5 },\n    { x: 0.4, y: 0.75 },\n    { x: 0.6, y: 0.75 },\n    { x: 0.35, y: 0.95 },\n    { x: 0.65, y: 0.95 },\n  ],\n};\n\nconst SKELETON_CONNECTIONS = [\n  [0, 1], [0, 2], // Head to shoulders\n  [1, 2], // Shoulder to shoulder\n  [1, 3], [3, 5], // Left arm\n  [2, 4], [4, 6], // Right arm\n  [1, 7], [2, 8], // Shoulders to hips\n  [7, 8], // Hip to hip\n  [7, 9], [9, 11], // Left leg\n  [8, 10], [10, 12], // Right leg\n];\n\nexport function generateKeyframeSVG(\n  drillType: 'smash' | 'clear' | 'netshot' | 'footwork' | 'drive',\n  frame: number = 0,\n  options: { width?: number; height?: number; color?: string } = {}\n): string {\n  const { width = 120, height = 180, color = '#0ea5e9' } = options;\n  const pose = IDEAL_POSES[drillType] || IDEAL_POSES.footwork;\n\n  // Simple frame variation (slightly different poses)\n  const offset = frame * 0.02;\n\n  let pathD = '';\n  for (const [i, j] of SKELETON_CONNECTIONS) {\n    const p1 = pose[i];\n    const p2 = pose[j];\n    if (p1 && p2) {\n      const x1 = (p1.x + offset) * width;\n      const y1 = p1.y * height;\n      const x2 = (p2.x + offset) * width;\n      const y2 = p2.y * height;\n      pathD += `M${x1},${y1}L${x2},${y2}`;\n    }\n  }\n\n  let circles = '';\n  for (const point of pose) {\n    const x = (point.x + offset) * width;\n    const y = point.y * height;\n    circles += `<circle cx=\"${x}\" cy=\"${y}\" r=\"4\" fill=\"${color}\"/>`;\n  }\n\n  return `<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 ${width} ${height}\" width=\"${width}\" height=\"${height}\">\n    <rect width=\"${width}\" height=\"${height}\" fill=\"#f8fafc\" rx=\"8\"/>\n    <path d=\"${pathD}\" stroke=\"${color}\" stroke-width=\"3\" fill=\"none\" stroke-linecap=\"round\"/>\n    ${circles}\n  </svg>`;\n}\n\nexport function getKeyframeSVGs(\n  drillType: 'smash' | 'clear' | 'netshot' | 'footwork' | 'drive',\n  options: { width?: number; height?: number } = {}\n): Array<{ svg: string; label: string }> {\n  const labels = {\n    smash: ['Setup', 'Load', 'Strike'],\n    clear: ['Prepare', 'Reach', 'Follow'],\n    netshot: ['Approach', 'Extend', 'Tap'],\n    footwork: ['Ready', 'Step', 'Return'],\n    drive: ['Position', 'Contact', 'Follow'],\n  };\n\n  return [0, 1, 2].map((frame) => ({\n    svg: generateKeyframeSVG(drillType, frame, options),\n    label: labels[drillType]?.[frame] || `Step ${frame + 1}`,\n  }));\n}\n\n// ============================================\n// Session Stats Aggregation\n// ============================================\n\nexport interface SessionStats {\n  totalFrames: number;\n  greenFrames: number;\n  redFrames: number;\n  greenRatio: number;\n  avgScore: number;\n  topIssues: Array<{ code: string; count: number }>;\n  recommendedDrills: DrillDefinition[];\n}\n\nexport function aggregateSessionStats(\n  frameResults: EvaluationResult[]\n): SessionStats {\n  const totalFrames = frameResults.length;\n  const greenFrames = frameResults.filter((r) => r.passed).length;\n  const redFrames = totalFrames - greenFrames;\n  const greenRatio = totalFrames > 0 ? greenFrames / totalFrames : 0;\n  const avgScore = totalFrames > 0\n    ? frameResults.reduce((sum, r) => sum + r.score, 0) / totalFrames\n    : 0;\n\n  // Count issues\n  const issueCounts: Record<string, number> = {};\n  for (const result of frameResults) {\n    for (const failed of result.failedRules) {\n      const code = failed.rule.code;\n      issueCounts[code] = (issueCounts[code] || 0) + 1;\n    }\n  }\n\n  const topIssues = Object.entries(issueCounts)\n    .map(([code, count]) => ({ code, count }))\n    .sort((a, b) => b.count - a.count)\n    .slice(0, 5);\n\n  // Get unique recommended drills\n  const drillIds = new Set<string>();\n  for (const result of frameResults) {\n    for (const drill of result.recommendedDrills) {\n      drillIds.add(drill.id);\n    }\n  }\n  const recommendedDrills = Array.from(drillIds)\n    .map((id) => DRILLS[id])\n    .filter(Boolean)\n    .slice(0, 3);\n\n  return {\n    totalFrames,\n    greenFrames,\n    redFrames,\n    greenRatio,\n    avgScore,\n    topIssues,\n    recommendedDrills,\n  };\n}\n\n// ============================================\n// Timestamp Violation Detection\n// ============================================\n\nexport function findViolationTimestamps(\n  frameResults: Array<{ timestamp: number; result: EvaluationResult }>,\n  ruleCode?: string\n): number[] {\n  return frameResults\n    .filter((frame) => {\n      if (ruleCode) {\n        return frame.result.failedRules.some((f) => f.rule.code === ruleCode);\n      }\n      return !frame.result.passed;\n    })\n    .map((frame) => frame.timestamp);\n}\n","numLines":541,"startLine":1,"totalLines":541}},"sourceToolAssistantUUID":"4e539777-1799-4d90-aed2-22ab8973eba0"}
{"parentUuid":"580ce839-197f-4e2d-bd32-3028a5998978","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_0188tdydf1ttSkUk3ikSpHSZ","toolUseID":"toolu_0188tdydf1ttSkUk3ikSpHSZ","timestamp":"2026-01-28T05:06:26.401Z","uuid":"cdf91256-155d-40d4-9ab7-d69f81fa485d"}
{"parentUuid":"cdf91256-155d-40d4-9ab7-d69f81fa485d","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01BV83FTGJrZG2xS33REU6tg","toolUseID":"toolu_01BV83FTGJrZG2xS33REU6tg","timestamp":"2026-01-28T05:06:26.401Z","uuid":"3b40fa0c-475c-4334-9c6d-f994bf5c2890"}
{"parentUuid":"a9cb365c-aeef-4006-82a9-7428b042823e","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DdTmdNqnCu6vc1ysXD4bN9","type":"tool_result","content":"     1→'use client';\n     2→\n     3→import { useState, useEffect, useRef, useCallback, Suspense } from 'react';\n     4→import { useSearchParams } from 'next/navigation';\n     5→import Link from 'next/link';\n     6→import DashboardNav from '@/components/DashboardNav';\n     7→import DrillCard from '@/components/DrillCard';\n     8→import { TabbedDrillAnimation } from '@/components/Skeleton3D';\n     9→import PlayerSelectionModal from '@/components/PlayerSelectionModal';\n    10→import GuidanceAnimation from '@/components/GuidanceAnimation';\n    11→import { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\n    12→import {\n    13→  drawSkeleton,\n    14→  extractMetrics,\n    15→  POSE_CONNECTIONS,\n    16→  POSE_LANDMARKS\n    17→} from '@/lib/pose-utils';\n    18→import {\n    19→  DRILLS,\n    20→  FORM_RULES,\n    21→  evaluateForm,\n    22→  findViolationTimestamps,\n    23→  type EvaluationResult\n    24→} from '@/lib/rules-engine';\n    25→import {\n    26→  evaluateWithBands,\n    27→  SCORING_LEGEND,\n    28→  SKILL_LEVEL_DESCRIPTIONS,\n    29→  validateSessionPoseData,\n    30→} from '@/lib/scoring-rules';\n    31→import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData } from '@/lib/types';\n    32→\n    33→// MediaPipe Types\n    34→type PoseLandmarker = any;\n    35→\n    36→interface FrameAnalysis {\n    37→  timestamp: number;\n    38→  landmarks: PoseLandmark[] | null;\n    39→  evaluation: EvaluationResult | null;\n    40→  metrics: PoseMetrics | null;\n    41→}\n    42→\n    43→interface DetectedIssue {\n    44→  code: string;\n    45→  title: string;\n    46→  severity: 'low' | 'medium' | 'high';\n    47→  description?: string;\n    48→  timestamps: number[];\n    49→  drill?: any;\n    50→}\n    51→\n    52→// PHASE 5: Analysis state machine\n    53→type AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n    54→\n    55→// PHASE 3: Auto-level detection result from Gemini\n    56→interface AutoLevelResult {\n    57→  level: 'Beginner' | 'Intermediate' | 'Advanced';\n    58→  confidence: number;\n    59→  rationaleBullets: string[];\n    60→  guidanceKeyframes?: GuidanceKeyframe[];\n    61→}\n    62→\n    63→// PHASE 4: Guidance keyframe for animation\n    64→interface GuidanceKeyframe {\n    65→  name: string;\n    66→  description: string;\n    67→  landmarks: PoseLandmark[] | null;\n    68→  targetLandmarks?: PoseLandmark[] | null;\n    69→  correction?: string;\n    70→}\n    71→\n    72→function AnalyticsContent() {\n    73→  const searchParams = useSearchParams();\n    74→  const sessionId = searchParams.get('session');\n    75→\n    76→  // State\n    77→  const [uploading, setUploading] = useState(false);\n    78→  const [analyzing, setAnalyzing] = useState(false);\n    79→  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n    80→  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n    81→  const [analysisId, setAnalysisId] = useState<string | null>(null);\n    82→  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n    83→  const [error, setError] = useState<string | null>(null);\n    84→  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n    85→  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n    86→\n    87→  // Multi-pose and player selection state\n    88→  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n    89→  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n    90→  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n    91→  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n    92→  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n    93→  const [eventType, setEventType] = useState<string>('');\n    94→\n    95→  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n    96→  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n    97→  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n    98→\n    99→  // PHASE 4: Guidance animation state\n   100→  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n   101→  const [showGuidance, setShowGuidance] = useState(false);\n   102→\n   103→  // Video playback state\n   104→  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n   105→  const [videoFile, setVideoFile] = useState<File | null>(null);\n   106→  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n   107→  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n   108→  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n   109→  const [currentTime, setCurrentTime] = useState(0);\n   110→  const [duration, setDuration] = useState(0);\n   111→  const [isPlaying, setIsPlaying] = useState(false);\n   112→  const [showSkeleton, setShowSkeleton] = useState(true);\n   113→  const [fps, setFps] = useState(30);\n   114→\n   115→  // PHASE 2: Canvas overlay alignment state\n   116→  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n   117→\n   118→  // Pose detection\n   119→  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n   120→  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n   121→\n   122→  // PHASE 1: Timestamp tracking for monotonic enforcement\n   123→  const lastTimestampMsRef = useRef<number>(-1);\n   124→  const timestampBaseOffsetRef = useRef<number>(0);\n   125→  const isProcessingRef = useRef<boolean>(false);\n   126→\n   127→  // Refs\n   128→  const fileInputRef = useRef<HTMLInputElement>(null);\n   129→  const videoRef = useRef<HTMLVideoElement>(null);\n   130→  const canvasRef = useRef<HTMLCanvasElement>(null);\n   131→  const videoContainerRef = useRef<HTMLDivElement>(null);\n   132→  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n   133→  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n   134→  const animationRef = useRef<number | null>(null);\n   135→\n   136→  // Initialize MediaPipe Pose Landmarker\n   137→  useEffect(() => {\n   138→    initializePoseLandmarker();\n   139→    return () => {\n   140→      cleanup();\n   141→    };\n   142→  }, []);\n   143→\n   144→  // Load session if ID provided\n   145→  useEffect(() => {\n   146→    if (sessionId) {\n   147→      loadSession(sessionId);\n   148→    }\n   149→  }, [sessionId]);\n   150→\n   151→  // PHASE 2: Update canvas size on video resize\n   152→  useEffect(() => {\n   153→    const updateVideoRect = () => {\n   154→      if (videoRef.current && videoContainerRef.current) {\n   155→        const video = videoRef.current;\n   156→        const container = videoContainerRef.current;\n   157→\n   158→        // Calculate the actual rendered video rectangle (accounting for object-contain)\n   159→        const containerRect = container.getBoundingClientRect();\n   160→        const videoAspect = video.videoWidth / video.videoHeight;\n   161→        const containerAspect = containerRect.width / containerRect.height;\n   162→\n   163→        let renderWidth, renderHeight, offsetX, offsetY;\n   164→\n   165→        if (videoAspect > containerAspect) {\n   166→          // Video is wider - letterbox top/bottom\n   167→          renderWidth = containerRect.width;\n   168→          renderHeight = containerRect.width / videoAspect;\n   169→          offsetX = 0;\n   170→          offsetY = (containerRect.height - renderHeight) / 2;\n   171→        } else {\n   172→          // Video is taller - letterbox left/right\n   173→          renderHeight = containerRect.height;\n   174→          renderWidth = containerRect.height * videoAspect;\n   175→          offsetX = (containerRect.width - renderWidth) / 2;\n   176→          offsetY = 0;\n   177→        }\n   178→\n   179→        setVideoRect({\n   180→          x: offsetX,\n   181→          y: offsetY,\n   182→          width: renderWidth,\n   183→          height: renderHeight,\n   184→          top: offsetY,\n   185→          left: offsetX,\n   186→          right: offsetX + renderWidth,\n   187→          bottom: offsetY + renderHeight,\n   188→          toJSON: () => ({})\n   189→        } as DOMRect);\n   190→      }\n   191→    };\n   192→\n   193→    updateVideoRect();\n   194→    window.addEventListener('resize', updateVideoRect);\n   195→\n   196→    return () => window.removeEventListener('resize', updateVideoRect);\n   197→  }, [videoUrl]);\n   198→\n   199→  const initializePoseLandmarker = async () => {\n   200→    try {\n   201→      const vision = await import('@mediapipe/tasks-vision');\n   202→      const { PoseLandmarker, FilesetResolver } = vision;\n   203→\n   204→      const filesetResolver = await FilesetResolver.forVisionTasks(\n   205→        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n   206→      );\n   207→\n   208→      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n   209→        baseOptions: {\n   210→          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n   211→          delegate: 'GPU',\n   212→        },\n   213→        runningMode: 'VIDEO',\n   214→        numPoses: 4, // Support up to 4 players for doubles\n   215→        minPoseDetectionConfidence: 0.5,\n   216→        minPosePresenceConfidence: 0.5,\n   217→        minTrackingConfidence: 0.5,\n   218→      });\n   219→\n   220→      setPoseLandmarkerReady(true);\n   221→    } catch (error) {\n   222→      console.error('Failed to load MediaPipe Pose:', error);\n   223→      // Continue without pose detection - will use fallback\n   224→    }\n   225→  };\n   226→\n   227→  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n   228→  const recreatePoseLandmarker = async () => {\n   229→    if (poseLandmarkerRef.current) {\n   230→      poseLandmarkerRef.current.close();\n   231→    }\n   232→    lastTimestampMsRef.current = -1;\n   233→    timestampBaseOffsetRef.current = 0;\n   234→    await initializePoseLandmarker();\n   235→  };\n   236→\n   237→  const cleanup = () => {\n   238→    if (pollIntervalRef.current) {\n   239→      clearInterval(pollIntervalRef.current);\n   240→    }\n   241→    if (animationRef.current) {\n   242→      cancelAnimationFrame(animationRef.current);\n   243→    }\n   244→    if (poseLandmarkerRef.current) {\n   245→      poseLandmarkerRef.current.close();\n   246→    }\n   247→  };\n   248→\n   249→  const loadSession = async (id: string) => {\n   250→    try {\n   251→      setAnalyzing(true);\n   252→      setAnalysisState('EXTRACTING_POSE');\n   253→\n   254→      // Try new sessions table first\n   255→      const { data: sessionData, error: sessionError } = await supabase\n   256→        .from('sessions')\n   257→        .select('*')\n   258→        .eq('id', id)\n   259→        .single();\n   260→\n   261→      if (sessionError) {\n   262→        // Try legacy table\n   263→        const { data: legacyData, error: legacyError } = await supabase\n   264→          .from('analysis_results')\n   265→          .select('*')\n   266→          .eq('id', id)\n   267→          .single();\n   268→\n   269→        if (legacyError) throw legacyError;\n   270→        if (legacyData?.result_json) {\n   271→          setResult(legacyData.result_json);\n   272→          if (legacyData.result_json.video_url) {\n   273→            setVideoUrl(legacyData.result_json.video_url);\n   274→          }\n   275→        }\n   276→      } else if (sessionData) {\n   277→        // New session format\n   278→        setVideoUrl(sessionData.video_url);\n   279→\n   280→        if (sessionData.pose_data) {\n   281→          setPoseData(sessionData.pose_data);\n   282→        }\n   283→\n   284→        // Fetch issues\n   285→        const { data: issuesData } = await supabase\n   286→          .from('issues')\n   287→          .select('*')\n   288→          .eq('session_id', id);\n   289→\n   290→        if (issuesData && issuesData.length > 0) {\n   291→          setIssues(issuesData.map((issue: any) => ({\n   292→            code: issue.code,\n   293→            title: issue.title,\n   294→            severity: issue.severity,\n   295→            description: issue.description,\n   296→            timestamps: issue.timestamps || [],\n   297→            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n   298→          })));\n   299→        }\n   300→\n   301→        // Build result from session summary\n   302→        const summary = sessionData.summary || {};\n   303→        setResult({\n   304→          top_issues: issuesData?.map((i: any) => ({\n   305→            id: i.id,\n   306→            title: i.title,\n   307→            severity: i.severity,\n   308→            description: i.description,\n   309→            affected_metrics: [],\n   310→          })) || [],\n   311→          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n   312→            id: d.id,\n   313→            name: d.name,\n   314→            description: d.description,\n   315→            duration_minutes: d.durationMinutes,\n   316→            target_metrics: d.targetMetrics,\n   317→            instructions: d.steps,\n   318→          })) || [],\n   319→          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n   320→          strategy_summary: summary.feedback?.strategy_summary || '',\n   321→          training_plan: [],\n   322→        });\n   323→      }\n   324→      setAnalysisState('DONE');\n   325→    } catch (err) {\n   326→      console.error('Error loading session:', err);\n   327→      setError('Failed to load session');\n   328→      setAnalysisState('ERROR');\n   329→    } finally {\n   330→      setAnalyzing(false);\n   331→    }\n   332→  };\n   333→\n   334→  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n   335→  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n   336→  const processVideoWithPose = async (\n   337→    videoElement: HTMLVideoElement,\n   338→    selectedTracks: number[] = [0]\n   339→  ): Promise<FrameAnalysis[]> => {\n   340→    if (!poseLandmarkerRef.current) {\n   341→      console.warn('Pose landmarker not ready');\n   342→      return [];\n   343→    }\n   344→\n   345→    // Prevent concurrent processing\n   346→    if (isProcessingRef.current) {\n   347→      console.warn('Already processing video, skipping');\n   348→      return [];\n   349→    }\n   350→    isProcessingRef.current = true;\n   351→\n   352→    const analyses: FrameAnalysis[] = [];\n   353→    const videoDuration = videoElement.duration;\n   354→    const sampleRate = 10; // Process 10 frames per second\n   355→    const totalFrames = Math.floor(videoDuration * sampleRate);\n   356→\n   357→    // PHASE 1: Reset timestamp tracking for fresh processing\n   358→    // Use base offset approach so timestamps always increase even if we restart\n   359→    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n   360→    let localLastTimestamp = timestampBaseOffsetRef.current;\n   361→\n   362→    let validPoseFrames = 0;\n   363→    let lowConfidenceFrames = 0;\n   364→    let noPoseFrames = 0;\n   365→\n   366→    setAnalyzeProgress(10); // Start at 10% after track detection\n   367→\n   368→    for (let i = 0; i <= totalFrames; i++) {\n   369→      const timestamp = i / sampleRate;\n   370→      videoElement.currentTime = timestamp;\n   371→\n   372→      // Wait for video to seek\n   373→      await new Promise<void>((resolve) => {\n   374→        const onSeeked = () => {\n   375→          videoElement.removeEventListener('seeked', onSeeked);\n   376→          resolve();\n   377→        };\n   378→        videoElement.addEventListener('seeked', onSeeked);\n   379→      });\n   380→\n   381→      // Give the video a moment to render the frame\n   382→      await new Promise(resolve => setTimeout(resolve, 50));\n   383→\n   384→      try {\n   385→        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n   386→        // Use base offset + local timestamp to guarantee monotonic increase\n   387→        const rawTimestampMs = Math.floor(timestamp * 1000);\n   388→        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n   389→\n   390→        // Double-check monotonicity\n   391→        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n   392→        localLastTimestamp = safeTimestampMs;\n   393→        lastTimestampMsRef.current = safeTimestampMs;\n   394→\n   395→        const results = poseLandmarkerRef.current.detectForVideo(\n   396→          videoElement,\n   397→          safeTimestampMs\n   398→        );\n   399→\n   400→        let landmarks: PoseLandmark[] | null = null;\n   401→        let evaluation: EvaluationResult | null = null;\n   402→        let metrics: PoseMetrics | null = null;\n   403→\n   404→        if (results.landmarks && results.landmarks.length > 0) {\n   405→          // Only use the selected player's landmarks\n   406→          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n   407→            ? selectedTracks[0]\n   408→            : 0;\n   409→\n   410→          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n   411→            x: lm.x,\n   412→            y: lm.y,\n   413→            z: lm.z,\n   414→            visibility: lm.visibility ?? 1.0,\n   415→          }));\n   416→\n   417→          if (landmarks && landmarks.length > 0) {\n   418→            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n   419→\n   420→            if (avgVisibility < 0.5) {\n   421→              lowConfidenceFrames++;\n   422→            } else {\n   423→              validPoseFrames++;\n   424→            }\n   425→            metrics = extractMetrics(landmarks);\n   426→\n   427→            // Use intermediate level for initial processing (auto-level will adjust later)\n   428→            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n   429→            evaluation = {\n   430→              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n   431→              score: bandedResult.overall_score,\n   432→              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n   433→                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n   434→                value: 0,\n   435→                feedback: f,\n   436→              })) : [],\n   437→              passedRules: [],\n   438→              highlightJoints: bandedResult.highlight_joints,\n   439→              recommendedDrills: [],\n   440→            };\n   441→          }\n   442→        } else {\n   443→          noPoseFrames++;\n   444→        }\n   445→\n   446→        analyses.push({\n   447→          timestamp,\n   448→          landmarks,\n   449→          evaluation,\n   450→          metrics,\n   451→        });\n   452→      } catch (err) {\n   453→        const errorMsg = err instanceof Error ? err.message : String(err);\n   454→        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n   455→          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n   456→          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n   457→          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n   458→          localLastTimestamp = timestampBaseOffsetRef.current;\n   459→        } else {\n   460→          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n   461→        }\n   462→        analyses.push({\n   463→          timestamp,\n   464→          landmarks: null,\n   465→          evaluation: null,\n   466→          metrics: null,\n   467→        });\n   468→      }\n   469→\n   470→      // Update progress (10-70%)\n   471→      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n   472→    }\n   473→\n   474→    // PHASE 1: Log pose detection statistics\n   475→    const totalProcessed = totalFrames + 1;\n   476→    const validRatio = validPoseFrames / totalProcessed;\n   477→    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n   478→\n   479→    if (validRatio < 0.3) {\n   480→      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n   481→    }\n   482→\n   483→    isProcessingRef.current = false;\n   484→    return analyses;\n   485→  };\n   486→\n   487→  // Detect issues from frame analyses\n   488→  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n   489→    const issueMap: Map<string, {\n   490→      rule: any;\n   491→      timestamps: number[];\n   492→      count: number;\n   493→    }> = new Map();\n   494→\n   495→    for (const frame of analyses) {\n   496→      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n   497→        for (const failed of frame.evaluation.failedRules) {\n   498→          const code = failed.rule.code;\n   499→          if (!issueMap.has(code)) {\n   500→            issueMap.set(code, {\n   501→              rule: failed.rule,\n   502→              timestamps: [],\n   503→              count: 0,\n   504→            });\n   505→          }\n   506→          const issue = issueMap.get(code)!;\n   507→          issue.timestamps.push(frame.timestamp);\n   508→          issue.count++;\n   509→        }\n   510→      }\n   511→    }\n   512→\n   513→    // Convert to array and sort by count\n   514→    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n   515→      .map(([code, data]) => ({\n   516→        code,\n   517→        title: data.rule.name,\n   518→        severity: data.rule.severity,\n   519→        description: data.rule.description,\n   520→        timestamps: data.timestamps,\n   521→        drill: DRILLS[data.rule.drillId],\n   522→      }))\n   523→      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n   524→      .slice(0, 5); // Top 5 issues\n   525→\n   526→    return issues;\n   527→  };\n   528→\n   529→  // PHASE 3: Auto-detect skill level using Gemini\n   530→  const detectSkillLevelWithGemini = async (\n   531→    analyses: FrameAnalysis[],\n   532→    detectedIssues: DetectedIssue[]\n   533→  ): Promise<AutoLevelResult> => {\n   534→    setAnalysisState('GEMINI_SCORING');\n   535→    setAnalyzeProgress(75);\n   536→\n   537→    try {\n   538→      // Extract features for Gemini analysis\n   539→      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n   540→\n   541→      if (validAnalyses.length < 5) {\n   542→        // Fallback if not enough data\n   543→        return {\n   544→          level: 'Intermediate',\n   545→          confidence: 0.5,\n   546→          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n   547→        };\n   548→      }\n   549→\n   550→      // Calculate aggregate metrics\n   551→      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n   552→      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n   553→      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n   554→      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n   555→\n   556→      // Calculate consistency (standard deviation proxy)\n   557→      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n   558→      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n   559→\n   560→      // Calculate movement intensity (velocity proxy from position changes)\n   561→      let totalMovement = 0;\n   562→      for (let i = 1; i < validAnalyses.length; i++) {\n   563→        const prev = validAnalyses[i - 1].landmarks;\n   564→        const curr = validAnalyses[i].landmarks;\n   565→        if (prev && curr) {\n   566→          const hipMovement = Math.sqrt(\n   567→            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n   568→            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n   569→          );\n   570→          totalMovement += hipMovement;\n   571→        }\n   572→      }\n   573→      const avgMovement = totalMovement / (validAnalyses.length - 1);\n   574→\n   575→      // Issue frequency\n   576→      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n   577→\n   578→      // Call Gemini API for skill level detection\n   579→      const response = await fetch('/api/analysis/auto-level', {\n   580→        method: 'POST',\n   581→        headers: { 'Content-Type': 'application/json' },\n   582→        body: JSON.stringify({\n   583→          metrics: {\n   584→            avgElbowAngle,\n   585→            avgKneeAngle,\n   586→            avgStanceWidth,\n   587→            avgRotation,\n   588→            elbowConsistency: Math.sqrt(elbowVariance),\n   589→            kneeConsistency: Math.sqrt(kneeVariance),\n   590→            movementIntensity: avgMovement,\n   591→            issueFrequency,\n   592→            totalFrames: validAnalyses.length,\n   593→            issueCount: detectedIssues.length,\n   594→          },\n   595→          issues: detectedIssues.map(i => ({\n   596→            code: i.code,\n   597→            title: i.title,\n   598→            frequency: i.timestamps.length / validAnalyses.length,\n   599→          })),\n   600→        }),\n   601→      });\n   602→\n   603→      if (response.ok) {\n   604→        const result = await response.json();\n   605→        setAnalyzeProgress(90);\n   606→        return {\n   607→          level: result.level || 'Intermediate',\n   608→          confidence: result.confidence || 0.7,\n   609→          rationaleBullets: result.rationaleBullets || [],\n   610→          guidanceKeyframes: result.guidanceKeyframes,\n   611→        };\n   612→      }\n   613→    } catch (err) {\n   614→      console.error('Gemini auto-level detection failed:', err);\n   615→    }\n   616→\n   617→    // Fallback rule-based detection\n   618→    setAnalyzeProgress(90);\n   619→    return fallbackSkillLevelDetection(analyses, detectedIssues);\n   620→  };\n   621→\n   622→  // Fallback rule-based skill level detection\n   623→  const fallbackSkillLevelDetection = (\n   624→    analyses: FrameAnalysis[],\n   625→    detectedIssues: DetectedIssue[]\n   626→  ): AutoLevelResult => {\n   627→    const validAnalyses = analyses.filter(a => a.evaluation);\n   628→    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n   629→    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n   630→    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n   631→\n   632→    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n   633→      return {\n   634→        level: 'Advanced',\n   635→        confidence: 0.75,\n   636→        rationaleBullets: [\n   637→          'Consistent form across frames',\n   638→          'No major technique issues detected',\n   639→          'Good body mechanics observed',\n   640→        ],\n   641→      };\n   642→    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n   643→      return {\n   644→        level: 'Intermediate',\n   645→        confidence: 0.7,\n   646→        rationaleBullets: [\n   647→          'Moderate consistency in technique',\n   648→          `${highSeverityIssues} area(s) need focused improvement`,\n   649→          'Foundations are solid with room to refine',\n   650→        ],\n   651→      };\n   652→    } else {\n   653→      return {\n   654→        level: 'Beginner',\n   655→        confidence: 0.8,\n   656→        rationaleBullets: [\n   657→          'Multiple technique areas need development',\n   658→          'Focus on fundamentals before advancing',\n   659→          'Regular practice will show rapid improvement',\n   660→        ],\n   661→      };\n   662→    }\n   663→  };\n   664→\n   665→  // PHASE 4: Generate guidance keyframes from analysis\n   666→  const generateGuidanceKeyframes = (\n   667→    analyses: FrameAnalysis[],\n   668→    detectedIssues: DetectedIssue[]\n   669→  ): GuidanceKeyframe[] => {\n   670→    const keyframes: GuidanceKeyframe[] = [];\n   671→    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n   672→\n   673→    if (validAnalyses.length < 3) return keyframes;\n   674→\n   675→    // Find key moments: Setup, Contact/Action, Recovery\n   676→    // Setup: Early stable frame\n   677→    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n   678→    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n   679→    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n   680→\n   681→    const setupFrame = validAnalyses[setupIdx];\n   682→    const contactFrame = validAnalyses[contactIdx];\n   683→    const recoveryFrame = validAnalyses[recoveryIdx];\n   684→\n   685→    // Determine primary issue for corrections\n   686→    const primaryIssue = detectedIssues[0];\n   687→    let correction = '';\n   688→    if (primaryIssue) {\n   689→      if (primaryIssue.code.includes('ELBOW')) {\n   690→        correction = 'Extend elbow more at contact';\n   691→      } else if (primaryIssue.code.includes('KNEE')) {\n   692→        correction = 'Maintain athletic knee bend';\n   693→      } else if (primaryIssue.code.includes('STANCE')) {\n   694→        correction = 'Widen stance for stability';\n   695→      } else if (primaryIssue.code.includes('ROTATION')) {\n   696→        correction = 'Rotate hips before shoulders';\n   697→      }\n   698→    }\n   699→\n   700→    keyframes.push({\n   701→      name: 'Setup',\n   702→      description: 'Preparation phase',\n   703→      landmarks: setupFrame?.landmarks || null,\n   704→      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n   705→    });\n   706→\n   707→    keyframes.push({\n   708→      name: 'Contact',\n   709→      description: 'Point of contact',\n   710→      landmarks: contactFrame?.landmarks || null,\n   711→      correction: correction || undefined,\n   712→    });\n   713→\n   714→    keyframes.push({\n   715→      name: 'Recovery',\n   716→      description: 'Return to ready',\n   717→      landmarks: recoveryFrame?.landmarks || null,\n   718→      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n   719→    });\n   720→\n   721→    return keyframes;\n   722→  };\n   723→\n   724→  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n   725→    const file = e.target.files?.[0];\n   726→    if (!file) return;\n   727→\n   728→    if (!file.type.startsWith('video/')) {\n   729→      setError('Please select a video file');\n   730→      return;\n   731→    }\n   732→\n   733→    if (file.size > 100 * 1024 * 1024) {\n   734→      setError('File size must be less than 100MB. Please compress your video before uploading.');\n   735→      return;\n   736→    }\n   737→\n   738→    setError(null);\n   739→    setVideoFile(file);\n   740→    setResult(null);\n   741→    setIssues([]);\n   742→    setPoseData([]);\n   743→    setFrameAnalyses([]);\n   744→    setAutoLevelResult(null);\n   745→    setGuidanceKeyframes([]);\n   746→\n   747→    // Create object URL for video preview\n   748→    const objectUrl = URL.createObjectURL(file);\n   749→    setVideoUrl(objectUrl);\n   750→\n   751→    // Start analysis\n   752→    await analyzeVideo(file, objectUrl);\n   753→  };\n   754→\n   755→  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n   756→  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n   757→    if (!poseLandmarkerRef.current) return [];\n   758→\n   759→    const tracks: Map<number, PlayerTrackData> = new Map();\n   760→    const sampleFrames = 5;\n   761→    const duration = videoElement.duration;\n   762→\n   763→    // Use separate timestamp tracking for track detection\n   764→    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n   765→\n   766→    for (let i = 0; i < sampleFrames; i++) {\n   767→      const timestamp = (i / sampleFrames) * duration;\n   768→      videoElement.currentTime = timestamp;\n   769→\n   770→      await new Promise<void>((resolve) => {\n   771→        const onSeeked = () => {\n   772→          videoElement.removeEventListener('seeked', onSeeked);\n   773→          resolve();\n   774→        };\n   775→        videoElement.addEventListener('seeked', onSeeked);\n   776→      });\n   777→\n   778→      await new Promise(resolve => setTimeout(resolve, 50));\n   779→\n   780→      try {\n   781→        // PHASE 1 FIX: Ensure monotonic timestamp\n   782→        trackDetectionTimestamp += 100; // 100ms between samples\n   783→        const safeTimestamp = trackDetectionTimestamp;\n   784→        lastTimestampMsRef.current = safeTimestamp;\n   785→\n   786→        const results = poseLandmarkerRef.current.detectForVideo(\n   787→          videoElement,\n   788→          safeTimestamp\n   789→        );\n   790→\n   791→        if (results.landmarks && results.landmarks.length > 0) {\n   792→          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n   793→            const landmarks = results.landmarks[poseIdx];\n   794→            const bbox = calculateBoundingBox(landmarks);\n   795→\n   796→            if (!tracks.has(poseIdx)) {\n   797→              tracks.set(poseIdx, {\n   798→                track_id: poseIdx,\n   799→                bbox_samples: [],\n   800→                is_selected: false,\n   801→                confidence_avg: 0,\n   802→                frame_count: 0,\n   803→                side: bbox.y < 0.5 ? 'far' : 'near',\n   804→              });\n   805→            }\n   806→\n   807→            const track = tracks.get(poseIdx)!;\n   808→            track.bbox_samples.push({\n   809→              frame: i,\n   810→              x: bbox.x,\n   811→              y: bbox.y,\n   812→              w: bbox.w,\n   813→              h: bbox.h,\n   814→              confidence: landmarks[0].visibility || 0.5,\n   815→            });\n   816→            track.frame_count++;\n   817→            track.confidence_avg =\n   818→              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n   819→              track.frame_count;\n   820→          }\n   821→        }\n   822→      } catch (err) {\n   823→        console.warn('Error detecting poses in frame:', err);\n   824→      }\n   825→    }\n   826→\n   827→    // Generate thumbnails\n   828→    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n   829→\n   830→    if (tracksArray.length > 0) {\n   831→      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n   832→      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n   833→      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n   834→\n   835→      await new Promise<void>((resolve) => {\n   836→        const onSeeked = () => {\n   837→          videoElement.removeEventListener('seeked', onSeeked);\n   838→          resolve();\n   839→        };\n   840→        videoElement.addEventListener('seeked', onSeeked);\n   841→      });\n   842→      await new Promise(resolve => setTimeout(resolve, 100));\n   843→\n   844→      for (const track of tracksArray) {\n   845→        if (track.bbox_samples.length > 0) {\n   846→          const bestBbox = track.bbox_samples.reduce((best, current) =>\n   847→            (current.confidence || 0) > (best.confidence || 0) ? current : best\n   848→          );\n   849→\n   850→          const thumbnail = generateThumbnail(videoElement, {\n   851→            x: bestBbox.x,\n   852→            y: bestBbox.y,\n   853→            w: bestBbox.w,\n   854→            h: bestBbox.h,\n   855→          });\n   856→\n   857→          if (thumbnail) {\n   858→            track.thumbnail_url = thumbnail;\n   859→          }\n   860→        }\n   861→      }\n   862→    }\n   863→\n   864→    return tracksArray;\n   865→  };\n   866→\n   867→  // Calculate bounding box from landmarks\n   868→  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n   869→    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n   870→    for (const lm of landmarks) {\n   871→      if (lm.visibility > 0.5) {\n   872→        minX = Math.min(minX, lm.x);\n   873→        minY = Math.min(minY, lm.y);\n   874→        maxX = Math.max(maxX, lm.x);\n   875→        maxY = Math.max(maxY, lm.y);\n   876→      }\n   877→    }\n   878→    return {\n   879→      x: minX,\n   880→      y: minY,\n   881→      w: maxX - minX,\n   882→      h: maxY - minY,\n   883→    };\n   884→  };\n   885→\n   886→  // Generate thumbnail from video at specific bounding box\n   887→  const generateThumbnail = (\n   888→    video: HTMLVideoElement,\n   889→    bbox: { x: number; y: number; w: number; h: number },\n   890→    padding: number = 0.1\n   891→  ): string | null => {\n   892→    try {\n   893→      const canvas = document.createElement('canvas');\n   894→      const ctx = canvas.getContext('2d');\n   895→      if (!ctx) return null;\n   896→\n   897→      const vw = video.videoWidth;\n   898→      const vh = video.videoHeight;\n   899→\n   900→      const padX = bbox.w * padding;\n   901→      const padY = bbox.h * padding;\n   902→\n   903→      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n   904→      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n   905→      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n   906→      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n   907→\n   908→      if (cropW <= 0 || cropH <= 0) return null;\n   909→\n   910→      const maxSize = 150;\n   911→      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n   912→      canvas.width = Math.floor(cropW * scale);\n   913→      canvas.height = Math.floor(cropH * scale);\n   914→\n   915→      ctx.drawImage(\n   916→        video,\n   917→        cropX, cropY, cropW, cropH,\n   918→        0, 0, canvas.width, canvas.height\n   919→      );\n   920→\n   921→      return canvas.toDataURL('image/jpeg', 0.8);\n   922→    } catch (err) {\n   923→      console.warn('Error generating thumbnail:', err);\n   924→      return null;\n   925→    }\n   926→  };\n   927→\n   928→  // Handle player selection confirmation\n   929→  const handlePlayerSelectionConfirm = (\n   930→    selectedTracks: number[],\n   931→    format: 'singles' | 'doubles',\n   932→    event: string\n   933→  ) => {\n   934→    setSelectedTrackIds(selectedTracks);\n   935→    setMatchFormat(format);\n   936→    setEventType(event);\n   937→    setShowPlayerSelection(false);\n   938→\n   939→    if (processVideoRef.current && videoFile) {\n   940→      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n   941→    }\n   942→  };\n   943→\n   944→  // Continue analysis after player selection\n   945→  const continueAnalysisWithSelection = async (\n   946→    processVideo: HTMLVideoElement,\n   947→    selectedTracks: number[]\n   948→  ) => {\n   949→    setAnalysisState('EXTRACTING_POSE');\n   950→    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n   951→    setFrameAnalyses(analyses);\n   952→\n   953→    const poseArray = analyses.map(a => a.landmarks);\n   954→    setPoseData(poseArray);\n   955→\n   956→    const detectedIssues = detectIssuesFromAnalyses(analyses);\n   957→    setIssues(detectedIssues);\n   958→\n   959→    // PHASE 3: Auto-detect skill level\n   960→    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n   961→    setAutoLevelResult(levelResult);\n   962→\n   963→    // PHASE 4: Generate guidance keyframes\n   964→    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n   965→    setGuidanceKeyframes(guidance);\n   966→\n   967→    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n   968→    const totalFrames = analyses.filter(a => a.evaluation).length;\n   969→    const avgScore = totalFrames > 0\n   970→      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n   971→      : 0;\n   972→\n   973→    setResult({\n   974→      top_issues: detectedIssues.map(issue => ({\n   975→        id: issue.code,\n   976→        title: issue.title,\n   977→        severity: issue.severity,\n   978→        description: issue.description || '',\n   979→        affected_metrics: [],\n   980→      })),\n   981→      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n   982→        id: d.id,\n   983→        name: d.name,\n   984→        description: d.description,\n   985→        duration_minutes: d.durationMinutes,\n   986→        target_metrics: d.targetMetrics,\n   987→        instructions: d.steps,\n   988→      })),\n   989→      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n   990→      strategy_summary: passedFrames > totalFrames * 0.7\n   991→        ? 'Your form is generally good. Focus on the specific issues identified.'\n   992→        : 'Work on maintaining consistent form throughout your movements.',\n   993→      training_plan: [],\n   994→    });\n   995→\n   996→    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);\n   997→    if (!saveResult.success) {\n   998→      setError(saveResult.error || 'Failed to save analysis');\n   999→    }\n  1000→    setAnalyzing(false);\n  1001→    setAnalysisState('DONE');\n  1002→    setAnalyzeProgress(100);\n  1003→  };\n  1004→\n  1005→  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n  1006→    setAnalyzing(true);\n  1007→    setAnalyzeProgress(0);\n  1008→    setAnalysisState('DETECTING_PLAYERS');\n  1009→\n  1010→    try {\n  1011→      const processVideo = document.createElement('video');\n  1012→      processVideo.src = videoObjectUrl;\n  1013→      processVideo.muted = true;\n  1014→      processVideo.playsInline = true;\n  1015→      processVideoRef.current = processVideo;\n  1016→\n  1017→      await new Promise<void>((resolve, reject) => {\n  1018→        processVideo.onloadedmetadata = () => {\n  1019→          setDuration(processVideo.duration);\n  1020→          setFps(30);\n  1021→          resolve();\n  1022→        };\n  1023→        processVideo.onerror = () => reject(new Error('Failed to load video'));\n  1024→      });\n  1025→\n  1026→      await new Promise<void>((resolve) => {\n  1027→        if (processVideo.readyState >= 2) {\n  1028→          resolve();\n  1029→        } else {\n  1030→          processVideo.oncanplay = () => resolve();\n  1031→        }\n  1032→      });\n  1033→\n  1034→      // Detect player tracks first\n  1035→      setAnalyzeProgress(5);\n  1036→      const tracks = await detectPlayerTracks(processVideo);\n  1037→      setDetectedTracks(tracks);\n  1038→\n  1039→      const uniquePlayers = tracks.length;\n  1040→      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n  1041→      setDetectedMatchFormat(detectedFormat);\n  1042→\n  1043→      if (tracks.length > 1) {\n  1044→        setShowPlayerSelection(true);\n  1045→        return;\n  1046→      }\n  1047→\n  1048→      if (tracks.length === 1) {\n  1049→        setSelectedTrackIds([tracks[0].track_id]);\n  1050→      }\n  1051→\n  1052→      // Process video with pose detection\n  1053→      let analyses: FrameAnalysis[] = [];\n  1054→\n  1055→      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n  1056→        setAnalysisState('EXTRACTING_POSE');\n  1057→        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n  1058→        setFrameAnalyses(analyses);\n  1059→\n  1060→        const poseArray = analyses.map(a => a.landmarks);\n  1061→        setPoseData(poseArray);\n  1062→\n  1063→        const detectedIssues = detectIssuesFromAnalyses(analyses);\n  1064→        setIssues(detectedIssues);\n  1065→\n  1066→        // PHASE 3: Auto-detect skill level\n  1067→        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n  1068→        setAutoLevelResult(levelResult);\n  1069→\n  1070→        // PHASE 4: Generate guidance keyframes\n  1071→        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n  1072→        setGuidanceKeyframes(guidance);\n  1073→\n  1074→        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n  1075→        const totalFrames = analyses.filter(a => a.evaluation).length;\n  1076→        const avgScore = totalFrames > 0\n  1077→          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n  1078→          : 0;\n  1079→\n  1080→        setResult({\n  1081→          top_issues: detectedIssues.map(issue => ({\n  1082→            id: issue.code,\n  1083→            title: issue.title,\n  1084→            severity: issue.severity,\n  1085→            description: issue.description || '',\n  1086→            affected_metrics: [],\n  1087→          })),\n  1088→          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n  1089→            id: d.id,\n  1090→            name: d.name,\n  1091→            description: d.description,\n  1092→            duration_minutes: d.durationMinutes,\n  1093→            target_metrics: d.targetMetrics,\n  1094→            instructions: d.steps,\n  1095→          })),\n  1096→          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n  1097→          strategy_summary: passedFrames > totalFrames * 0.7\n  1098→            ? 'Your form is generally good. Focus on the specific issues identified.'\n  1099→            : 'Work on maintaining consistent form throughout your movements.',\n  1100→          training_plan: [],\n  1101→        });\n  1102→\n  1103→        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n  1104→        if (!saveResult.success) {\n  1105→          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n  1106→        }\n  1107→        setAnalysisState('DONE');\n  1108→      } else {\n  1109→        setError('Pose detection not available. Using demo mode.');\n  1110→        setAnalysisState('ERROR');\n  1111→\n  1112→        const demoIssues: DetectedIssue[] = [\n  1113→          {\n  1114→            code: 'ELBOW_ANGLE_OVERHEAD',\n  1115→            title: 'Elbow Extension (Overhead)',\n  1116→            severity: 'high',\n  1117→            description: 'Elbow should be nearly straight at contact point',\n  1118→            timestamps: [1.2, 3.5, 7.8],\n  1119→            drill: DRILLS['elbow-extension'],\n  1120→          },\n  1121→          {\n  1122→            code: 'KNEE_BEND',\n  1123→            title: 'Knee Bend',\n  1124→            severity: 'medium',\n  1125→            description: 'Bend knees more for power',\n  1126→            timestamps: [2.1, 5.3],\n  1127→            drill: DRILLS['lunge-practice'],\n  1128→          },\n  1129→        ];\n  1130→        setIssues(demoIssues);\n  1131→        setAutoLevelResult({\n  1132→          level: 'Intermediate',\n  1133→          confidence: 0.5,\n  1134→          rationaleBullets: ['Demo mode - upload video for real analysis'],\n  1135→        });\n  1136→        setResult({\n  1137→          top_issues: demoIssues.map(i => ({\n  1138→            id: i.code,\n  1139→            title: i.title,\n  1140→            severity: i.severity,\n  1141→            description: i.description || '',\n  1142→            affected_metrics: [],\n  1143→          })),\n  1144→          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n  1145→            id: d!.id,\n  1146→            name: d!.name,\n  1147→            description: d!.description,\n  1148→            duration_minutes: d!.durationMinutes,\n  1149→            target_metrics: d!.targetMetrics,\n  1150→            instructions: d!.steps,\n  1151→          })),\n  1152→          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n  1153→          strategy_summary: '',\n  1154→          training_plan: [],\n  1155→        });\n  1156→      }\n  1157→\n  1158→    } catch (err) {\n  1159→      console.error('Analysis error:', err);\n  1160→      setError('Failed to analyze video. Please try again.');\n  1161→      setAnalysisState('ERROR');\n  1162→    } finally {\n  1163→      setAnalyzing(false);\n  1164→      setAnalyzeProgress(100);\n  1165→    }\n  1166→  };\n  1167→\n  1168→  const saveAnalysisToDatabase = async (\n  1169→    file: File,\n  1170→    analyses: FrameAnalysis[],\n  1171→    detectedIssues: DetectedIssue[],\n  1172→    avgScore: number,\n  1173→    levelResult?: AutoLevelResult\n  1174→  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n  1175→    try {\n  1176→      const { data: { user } } = await supabase.auth.getUser();\n  1177→      if (!user) {\n  1178→        return { success: false, error: 'Not authenticated' };\n  1179→      }\n  1180→\n  1181→      let videoPath: string | null = null;\n  1182→      let publicVideoUrl = '';\n  1183→\n  1184→      try {\n  1185→        videoPath = await uploadVideo(file, user.id, (progress) => {\n  1186→          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n  1187→        });\n  1188→\n  1189→        if (!videoPath) {\n  1190→          throw new Error('Upload returned empty path');\n  1191→        }\n  1192→\n  1193→        publicVideoUrl = getVideoUrl(videoPath);\n  1194→        console.log('Video uploaded successfully:', videoPath);\n  1195→\n  1196→      } catch (uploadError) {\n  1197→        console.error('Video upload failed:', uploadError);\n  1198→        const errorMessage = uploadError instanceof Error\n  1199→          ? uploadError.message\n  1200→          : 'Failed to upload video. Please try again.';\n  1201→        setError(errorMessage);\n  1202→        return { success: false, error: errorMessage };\n  1203→      }\n  1204→\n  1205→      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n  1206→      const totalFrames = analyses.filter(a => a.evaluation).length;\n  1207→\n  1208→      const { data: session, error: sessionError } = await supabase\n  1209→        .from('sessions')\n  1210→        .insert({\n  1211→          user_id: user.id,\n  1212→          type: 'analytics',\n  1213→          video_path: videoPath,\n  1214→          video_url: publicVideoUrl,\n  1215→          filename: file.name,\n  1216→          frame_count: analyses.length,\n  1217→          overall_score: Math.round(avgScore),\n  1218→          pose_data: analyses.map(a => a.landmarks),\n  1219→          status: 'ready',\n  1220→          match_format: matchFormat,\n  1221→          event_type: eventType || null,\n  1222→          selected_tracks: selectedTrackIds,\n  1223→          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n  1224→          rules_version: 'v1',\n  1225→          summary: {\n  1226→            total_frames: totalFrames,\n  1227→            green_frames: passedFrames,\n  1228→            red_frames: totalFrames - passedFrames,\n  1229→            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n  1230→            average_score: avgScore,\n  1231→            duration_seconds: duration,\n  1232→            auto_level: levelResult,\n  1233→          },\n  1234→        })\n  1235→        .select()\n  1236→        .single();\n  1237→\n  1238→      if (sessionError) {\n  1239→        console.error('Session save error:', sessionError);\n  1240→        return { success: false, error: 'Failed to save session data' };\n  1241→      }\n  1242→\n  1243→      if (session && detectedIssues.length > 0) {\n  1244→        const issueInserts = detectedIssues.map(issue => ({\n  1245→          session_id: session.id,\n  1246→          code: issue.code,\n  1247→          title: issue.title,\n  1248→          severity: issue.severity,\n  1249→          description: issue.description,\n  1250→          timestamps: issue.timestamps,\n  1251→          drill: issue.drill,\n  1252→        }));\n  1253→\n  1254→        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n  1255→        if (issuesError) {\n  1256→          console.warn('Issues save warning:', issuesError);\n  1257→        }\n  1258→      }\n  1259→\n  1260→      setAnalyzeProgress(100);\n  1261→      return { success: true, sessionId: session.id };\n  1262→\n  1263→    } catch (err) {\n  1264→      console.error('Error saving to database:', err);\n  1265→      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n  1266→      return { success: false, error: errorMessage };\n  1267→    }\n  1268→  };\n  1269→\n  1270→  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  1271→  const renderFrame = useCallback(() => {\n  1272→    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n  1273→\n  1274→    const video = videoRef.current;\n  1275→    const canvas = canvasRef.current;\n  1276→    const ctx = canvas.getContext('2d');\n  1277→    if (!ctx) return;\n  1278→\n  1279→    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n  1280→    const container = videoContainerRef.current;\n  1281→    const containerRect = container.getBoundingClientRect();\n  1282→\n  1283→    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n  1284→\n  1285→    const videoAspect = video.videoWidth / video.videoHeight;\n  1286→    const containerAspect = containerRect.width / containerRect.height;\n  1287→\n  1288→    let renderWidth, renderHeight, offsetX, offsetY;\n  1289→\n  1290→    if (videoAspect > containerAspect) {\n  1291→      // Video is wider - letterbox top/bottom\n  1292→      renderWidth = containerRect.width;\n  1293→      renderHeight = containerRect.width / videoAspect;\n  1294→      offsetX = 0;\n  1295→      offsetY = (containerRect.height - renderHeight) / 2;\n  1296→    } else {\n  1297→      // Video is taller - letterbox left/right\n  1298→      renderHeight = containerRect.height;\n  1299→      renderWidth = containerRect.height * videoAspect;\n  1300→      offsetX = (containerRect.width - renderWidth) / 2;\n  1301→      offsetY = 0;\n  1302→    }\n  1303→\n  1304→    // Set canvas to match container size\n  1305→    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n  1306→      canvas.width = containerRect.width;\n  1307→      canvas.height = containerRect.height;\n  1308→    }\n  1309→\n  1310→    // Clear canvas\n  1311→    ctx.clearRect(0, 0, canvas.width, canvas.height);\n  1312→\n  1313→    if (!showSkeleton) return;\n  1314→\n  1315→    // Find the closest frame analysis\n  1316→    let closestFrame: FrameAnalysis | null = null;\n  1317→    let minDiff = Infinity;\n  1318→\n  1319→    for (const frame of frameAnalyses) {\n  1320→      const diff = Math.abs(frame.timestamp - video.currentTime);\n  1321→      if (diff < minDiff) {\n  1322→        minDiff = diff;\n  1323→        closestFrame = frame;\n  1324→      }\n  1325→    }\n  1326→\n  1327→    // Also check raw poseData array (for loaded sessions)\n  1328→    if (!closestFrame && poseData.length > 0) {\n  1329→      const frameIndex = Math.floor(video.currentTime * 10);\n  1330→      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n  1331→      if (landmarks) {\n  1332→        closestFrame = {\n  1333→          timestamp: video.currentTime,\n  1334→          landmarks,\n  1335→          evaluation: evaluateForm(landmarks, 'general'),\n  1336→          metrics: extractMetrics(landmarks),\n  1337→        };\n  1338→      }\n  1339→    }\n  1340→\n  1341→    if (closestFrame?.landmarks) {\n  1342→      // Get skill level from auto-detection or default to intermediate\n  1343→      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n  1344→      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n  1345→      setCurrentBandedScore(bandedResult);\n  1346→\n  1347→      const isGreen = bandedResult.overall_band === 'green';\n  1348→      const isYellow = bandedResult.overall_band === 'yellow';\n  1349→      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n  1350→\n  1351→      ctx.strokeStyle = color;\n  1352→      ctx.lineWidth = 3;\n  1353→      ctx.fillStyle = color;\n  1354→\n  1355→      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n  1356→      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n  1357→        const start = closestFrame.landmarks[startIdx];\n  1358→        const end = closestFrame.landmarks[endIdx];\n  1359→        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n  1360→          ctx.beginPath();\n  1361→          // Apply offset and scale to match actual video render position\n  1362→          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n  1363→          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n  1364→          ctx.stroke();\n  1365→        }\n  1366→      }\n  1367→\n  1368→      // Draw joints\n  1369→      for (const landmark of closestFrame.landmarks) {\n  1370→        if (landmark.visibility > 0.5) {\n  1371→          ctx.beginPath();\n  1372→          ctx.arc(\n  1373→            offsetX + landmark.x * renderWidth,\n  1374→            offsetY + landmark.y * renderHeight,\n  1375→            5,\n  1376→            0,\n  1377→            2 * Math.PI\n  1378→          );\n  1379→          ctx.fill();\n  1380→        }\n  1381→      }\n  1382→    }\n  1383→\n  1384→    if (!video.paused) {\n  1385→      animationRef.current = requestAnimationFrame(renderFrame);\n  1386→    }\n  1387→  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);\n  1388→\n  1389→  // Trigger skeleton render when poseData is loaded\n  1390→  useEffect(() => {\n  1391→    if (poseData.length > 0 && videoRef.current) {\n  1392→      const tryRender = () => {\n  1393→        if (videoRef.current && videoRef.current.readyState >= 2) {\n  1394→          renderFrame();\n  1395→        } else {\n  1396→          setTimeout(tryRender, 100);\n  1397→        }\n  1398→      };\n  1399→      tryRender();\n  1400→    }\n  1401→  }, [poseData, renderFrame]);\n  1402→\n  1403→  // Handle video time updates\n  1404→  const handleTimeUpdate = useCallback(() => {\n  1405→    if (videoRef.current) {\n  1406→      setCurrentTime(videoRef.current.currentTime);\n  1407→      renderFrame();\n  1408→    }\n  1409→  }, [renderFrame]);\n  1410→\n  1411→  // Handle video play/pause\n  1412→  const togglePlayPause = useCallback(() => {\n  1413→    if (videoRef.current) {\n  1414→      if (videoRef.current.paused) {\n  1415→        videoRef.current.play();\n  1416→        setIsPlaying(true);\n  1417→        animationRef.current = requestAnimationFrame(renderFrame);\n  1418→      } else {\n  1419→        videoRef.current.pause();\n  1420→        setIsPlaying(false);\n  1421→        if (animationRef.current) {\n  1422→          cancelAnimationFrame(animationRef.current);\n  1423→        }\n  1424→      }\n  1425→    }\n  1426→  }, [renderFrame]);\n  1427→\n  1428→  // Jump to timestamp\n  1429→  const jumpToTimestamp = useCallback((timestamp: number) => {\n  1430→    if (videoRef.current) {\n  1431→      videoRef.current.currentTime = timestamp;\n  1432→      videoRef.current.pause();\n  1433→      setIsPlaying(false);\n  1434→      setCurrentTime(timestamp);\n  1435→      setTimeout(renderFrame, 50);\n  1436→    }\n  1437→  }, [renderFrame]);\n  1438→\n  1439→  // Find next mistake\n  1440→  const goToNextMistake = useCallback(() => {\n  1441→    const allTimestamps = issues\n  1442→      .flatMap((i) => i.timestamps || [])\n  1443→      .sort((a, b) => a - b);\n  1444→\n  1445→    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n  1446→    if (nextTimestamp !== undefined) {\n  1447→      jumpToTimestamp(nextTimestamp);\n  1448→    } else if (allTimestamps.length > 0) {\n  1449→      jumpToTimestamp(allTimestamps[0]);\n  1450→    }\n  1451→  }, [issues, currentTime, jumpToTimestamp]);\n  1452→\n  1453→  // Handle video metadata loaded\n  1454→  const handleLoadedMetadata = useCallback(() => {\n  1455→    if (videoRef.current) {\n  1456→      setDuration(videoRef.current.duration);\n  1457→      setTimeout(renderFrame, 100);\n  1458→    }\n  1459→  }, [renderFrame]);\n  1460→\n  1461→  const getSeverityColor = (severity: string) => {\n  1462→    switch (severity) {\n  1463→      case 'high':\n  1464→        return 'bg-red-50 border-red-200 text-red-800';\n  1465→      case 'medium':\n  1466→        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n  1467→      case 'low':\n  1468→        return 'bg-green-50 border-green-200 text-green-800';\n  1469→      default:\n  1470→        return 'bg-gray-50 border-gray-200 text-gray-800';\n  1471→    }\n  1472→  };\n  1473→\n  1474→  const formatTime = (seconds: number) => {\n  1475→    const mins = Math.floor(seconds / 60);\n  1476→    const secs = Math.floor(seconds % 60);\n  1477→    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  1478→  };\n  1479→\n  1480→  // Get current frame info for display\n  1481→  const getCurrentFrameInfo = () => {\n  1482→    if (frameAnalyses.length === 0) return null;\n  1483→\n  1484→    let closestFrame: FrameAnalysis | null = null;\n  1485→    let minDiff = Infinity;\n  1486→\n  1487→    for (const frame of frameAnalyses) {\n  1488→      const diff = Math.abs(frame.timestamp - currentTime);\n  1489→      if (diff < minDiff) {\n  1490→        minDiff = diff;\n  1491→        closestFrame = frame;\n  1492→      }\n  1493→    }\n  1494→\n  1495→    return closestFrame;\n  1496→  };\n  1497→\n  1498→  const currentFrameInfo = getCurrentFrameInfo();\n  1499→\n  1500→  // PHASE 5: Get analysis state message\n  1501→  const getAnalysisStateMessage = () => {\n  1502→    switch (analysisState) {\n  1503→      case 'DETECTING_PLAYERS':\n  1504→        return 'Detecting players in video...';\n  1505→      case 'EXTRACTING_POSE':\n  1506→        return 'Extracting pose data from frames...';\n  1507→      case 'GEMINI_SCORING':\n  1508→        return 'AI analyzing skill level...';\n  1509→      case 'DONE':\n  1510→        return 'Analysis complete!';\n  1511→      case 'ERROR':\n  1512→        return 'Analysis failed';\n  1513→      default:\n  1514→        return 'Ready to analyze';\n  1515→    }\n  1516→  };\n  1517→\n  1518→  return (\n  1519→    <div className=\"min-h-screen bg-gray-50\">\n  1520→      <DashboardNav />\n  1521→\n  1522→      <main className=\"ml-64 p-8\">\n  1523→        <div className=\"max-w-7xl mx-auto\">\n  1524→          {/* Header */}\n  1525→          <div className=\"mb-8\">\n  1526→            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n  1527→            <p className=\"text-gray-600 mt-1\">\n  1528→              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n  1529→            </p>\n  1530→          </div>\n  1531→\n  1532→          {/* Upload Section */}\n  1533→          {!result && !videoUrl && (\n  1534→            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n  1535→              <div\n  1536→                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n  1537→                  uploading || analyzing\n  1538→                    ? 'border-primary-300 bg-primary-50'\n  1539→                    : 'border-gray-300 hover:border-primary-400'\n  1540→                }`}\n  1541→              >\n  1542→                {uploading ? (\n  1543→                  <div className=\"space-y-4\">\n  1544→                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n  1545→                    <p className=\"text-gray-600\">Uploading video...</p>\n  1546→                  </div>\n  1547→                ) : analyzing ? (\n  1548→                  // PHASE 5: Enhanced loading state with state machine\n  1549→                  <div className=\"space-y-4\">\n  1550→                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n  1551→                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1552→                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n  1553→                      </svg>\n  1554→                      {/* Spinning ring */}\n  1555→                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n  1556→                    </div>\n  1557→                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n  1558→\n  1559→                    {/* Progress steps */}\n  1560→                    <div className=\"flex justify-center gap-2 mt-4\">\n  1561→                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n  1562→                        <div\n  1563→                          key={state}\n  1564→                          className={`w-3 h-3 rounded-full transition-colors ${\n  1565→                            analysisState === state\n  1566→                              ? 'bg-primary-500 animate-pulse'\n  1567→                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n  1568→                              ? 'bg-green-500'\n  1569→                              : 'bg-gray-300'\n  1570→                          }`}\n  1571→                        />\n  1572→                      ))}\n  1573→                    </div>\n  1574→                    <p className=\"text-gray-500 text-sm\">\n  1575→                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n  1576→                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n  1577→                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n  1578→                    </p>\n  1579→\n  1580→                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n  1581→                      <div\n  1582→                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n  1583→                        style={{ width: `${analyzeProgress}%` }}\n  1584→                      ></div>\n  1585→                    </div>\n  1586→                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n  1587→                  </div>\n  1588→                ) : (\n  1589→                  <>\n  1590→                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n  1591→                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1592→                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n  1593→                      </svg>\n  1594→                    </div>\n  1595→                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n  1596→                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n  1597→                    {poseLandmarkerReady && (\n  1598→                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n  1599→                    )}\n  1600→                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n  1601→                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n  1602→                      Select Video\n  1603→                    </button>\n  1604→                  </>\n  1605→                )}\n  1606→              </div>\n  1607→\n  1608→              {error && (\n  1609→                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n  1610→              )}\n  1611→            </div>\n  1612→          )}\n  1613→\n  1614→          {/* Video Player with Overlay */}\n  1615→          {videoUrl && (\n  1616→            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n  1617→              <div className=\"lg:col-span-2\">\n  1618→                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n  1619→                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n  1620→                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n  1621→                    <video\n  1622→                      ref={videoRef}\n  1623→                      src={videoUrl}\n  1624→                      className=\"absolute inset-0 w-full h-full object-contain\"\n  1625→                      onTimeUpdate={handleTimeUpdate}\n  1626→                      onLoadedMetadata={handleLoadedMetadata}\n  1627→                      onEnded={() => setIsPlaying(false)}\n  1628→                      playsInline\n  1629→                    />\n  1630→                    <canvas\n  1631→                      ref={canvasRef}\n  1632→                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n  1633→                        showSkeleton ? '' : 'hidden'\n  1634→                      }`}\n  1635→                    />\n  1636→\n  1637→                    {/* Status indicator with auto-detected level */}\n  1638→                    {currentBandedScore && (\n  1639→                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n  1640→                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n  1641→                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n  1642→                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n  1643→                        'bg-gray-500 text-white'\n  1644→                      }`}>\n  1645→                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n  1646→                        <span className=\"ml-2 opacity-75\">\n  1647→                          {Math.round(currentBandedScore.overall_score)}%\n  1648→                        </span>\n  1649→                      </div>\n  1650→                    )}\n  1651→\n  1652→                    {/* Time display */}\n  1653→                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n  1654→                      {formatTime(currentTime)} / {formatTime(duration)}\n  1655→                    </div>\n  1656→\n  1657→                    {/* Current metrics display */}\n  1658→                    {currentFrameInfo?.metrics && (\n  1659→                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n  1660→                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n  1661→                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n  1662→                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n  1663→                      </div>\n  1664→                    )}\n  1665→                  </div>\n  1666→\n  1667→                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n  1668→                  <div className=\"p-4 flex items-center justify-between\">\n  1669→                    <div className=\"flex items-center gap-2\">\n  1670→                      <button\n  1671→                        onClick={togglePlayPause}\n  1672→                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n  1673→                      >\n  1674→                        {isPlaying ? (\n  1675→                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1676→                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n  1677→                          </svg>\n  1678→                        ) : (\n  1679→                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1680→                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n  1681→                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n  1682→                          </svg>\n  1683→                        )}\n  1684→                      </button>\n  1685→\n  1686→                      <button\n  1687→                        onClick={goToNextMistake}\n  1688→                        disabled={issues.length === 0 || analyzing}\n  1689→                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n  1690→                      >\n  1691→                        Next Mistake\n  1692→                      </button>\n  1693→                    </div>\n  1694→\n  1695→                    <div className=\"flex items-center gap-4\">\n  1696→                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n  1697→                      {autoLevelResult && (\n  1698→                        <div className=\"flex items-center gap-2 text-white text-sm\">\n  1699→                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n  1700→                            {autoLevelResult.level}\n  1701→                          </span>\n  1702→                          <span className=\"text-gray-400 text-xs\">\n  1703→                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n  1704→                          </span>\n  1705→                        </div>\n  1706→                      )}\n  1707→\n  1708→                      <label className=\"flex items-center gap-2 text-white text-sm\">\n  1709→                        <input\n  1710→                          type=\"checkbox\"\n  1711→                          checked={showSkeleton}\n  1712→                          onChange={(e) => {\n  1713→                            setShowSkeleton(e.target.checked);\n  1714→                            if (e.target.checked) {\n  1715→                              setTimeout(renderFrame, 50);\n  1716→                            }\n  1717→                          }}\n  1718→                          className=\"rounded\"\n  1719→                        />\n  1720→                        Show Skeleton\n  1721→                      </label>\n  1722→                    </div>\n  1723→                  </div>\n  1724→\n  1725→                  {/* Timeline scrubber */}\n  1726→                  <div className=\"px-4 pb-4\">\n  1727→                    <input\n  1728→                      type=\"range\"\n  1729→                      min={0}\n  1730→                      max={duration || 100}\n  1731→                      step={0.1}\n  1732→                      value={currentTime}\n  1733→                      onChange={(e) => {\n  1734→                        const time = parseFloat(e.target.value);\n  1735→                        if (videoRef.current) {\n  1736→                          videoRef.current.currentTime = time;\n  1737→                          setCurrentTime(time);\n  1738→                          setTimeout(renderFrame, 50);\n  1739→                        }\n  1740→                      }}\n  1741→                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n  1742→                    />\n  1743→                  </div>\n  1744→                </div>\n  1745→\n  1746→                {/* PHASE 3: Auto-level detection result panel */}\n  1747→                {autoLevelResult && (\n  1748→                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n  1749→                    <div className=\"flex items-center justify-between mb-4\">\n  1750→                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n  1751→                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n  1752→                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n  1753→                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n  1754→                        'bg-blue-100 text-blue-800'\n  1755→                      }`}>\n  1756→                        {autoLevelResult.level}\n  1757→                      </span>\n  1758→                    </div>\n  1759→                    <div className=\"space-y-2\">\n  1760→                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n  1761→                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n  1762→                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n  1763→                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n  1764→                          </svg>\n  1765→                          <span>{bullet}</span>\n  1766→                        </div>\n  1767→                      ))}\n  1768→                    </div>\n  1769→                  </div>\n  1770→                )}\n  1771→\n  1772→                {/* PHASE 4: Guidance Animation */}\n  1773→                {guidanceKeyframes.length > 0 && (\n  1774→                  <div className=\"mt-6\">\n  1775→                    <div className=\"flex items-center justify-between mb-4\">\n  1776→                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n  1777→                      <button\n  1778→                        onClick={() => setShowGuidance(!showGuidance)}\n  1779→                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n  1780→                      >\n  1781→                        {showGuidance ? 'Hide' : 'Show'} Animation\n  1782→                      </button>\n  1783→                    </div>\n  1784→                    {showGuidance && (\n  1785→                      <GuidanceAnimation\n  1786→                        keyframes={guidanceKeyframes}\n  1787→                        primaryIssue={issues[0]}\n  1788→                      />\n  1789→                    )}\n  1790→                  </div>\n  1791→                )}\n  1792→\n  1793→                {/* Analysis Summary */}\n  1794→                {result && (\n  1795→                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n  1796→                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n  1797→                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n  1798→                    {result.strategy_summary && (\n  1799→                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n  1800→                    )}\n  1801→                  </div>\n  1802→                )}\n  1803→              </div>\n  1804→\n  1805→              {/* Issues Panel */}\n  1806→              <div className=\"space-y-4\">\n  1807→                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n  1808→                {analyzing ? (\n  1809→                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1810→                    {/* Shimmer loading animation */}\n  1811→                    <div className=\"animate-pulse space-y-4\">\n  1812→                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n  1813→                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n  1814→                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n  1815→                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n  1816→                    </div>\n  1817→                  </div>\n  1818→                ) : issues.length > 0 ? (\n  1819→                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n  1820→                    {issues.map((issue, index) => (\n  1821→                      <DrillCard\n  1822→                        key={index}\n  1823→                        issue={issue}\n  1824→                        onTimestampClick={jumpToTimestamp}\n  1825→                        currentTime={currentTime}\n  1826→                      />\n  1827→                    ))}\n  1828→                  </div>\n  1829→                ) : (\n  1830→                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n  1831→                    <p className=\"font-medium\">Great form!</p>\n  1832→                    <p className=\"text-sm\">No major issues detected in this video.</p>\n  1833→                  </div>\n  1834→                )}\n  1835→\n  1836→                {/* Reset button */}\n  1837→                {videoUrl && !analyzing && (\n  1838→                  <button\n  1839→                    onClick={() => {\n  1840→                      setResult(null);\n  1841→                      setVideoUrl(null);\n  1842→                      setVideoFile(null);\n  1843→                      setIssues([]);\n  1844→                      setPoseData([]);\n  1845→                      setFrameAnalyses([]);\n  1846→                      setCurrentTime(0);\n  1847→                      setDuration(0);\n  1848→                      setAutoLevelResult(null);\n  1849→                      setGuidanceKeyframes([]);\n  1850→                      setAnalysisState('IDLE');\n  1851→                    }}\n  1852→                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n  1853→                  >\n  1854→                    Analyze Another Video\n  1855→                  </button>\n  1856→                )}\n  1857→              </div>\n  1858→            </div>\n  1859→          )}\n  1860→\n  1861→          {/* Results Section (legacy format without video) */}\n  1862→          {result && !videoUrl && (\n  1863→            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n  1864→              {/* Left Column - Issues */}\n  1865→              <div className=\"space-y-6\">\n  1866→                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1867→                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n  1868→                  <div className=\"space-y-3\">\n  1869→                    {result.top_issues.map((issue) => (\n  1870→                      <button\n  1871→                        key={issue.id}\n  1872→                        onClick={() => setSelectedIssue(issue)}\n  1873→                        className={`w-full text-left p-4 rounded-lg border transition ${\n  1874→                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n  1875→                        } ${getSeverityColor(issue.severity)}`}\n  1876→                      >\n  1877→                        <div className=\"flex items-center justify-between mb-1\">\n  1878→                          <span className=\"font-medium\">{issue.title}</span>\n  1879→                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n  1880→                        </div>\n  1881→                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n  1882→                      </button>\n  1883→                    ))}\n  1884→                  </div>\n  1885→                </div>\n  1886→\n  1887→                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1888→                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n  1889→                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n  1890→                </div>\n  1891→              </div>\n  1892→\n  1893→              {/* Right Column - Drills */}\n  1894→              <div className=\"space-y-6\">\n  1895→                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1896→                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n  1897→                  <div className=\"space-y-3\">\n  1898→                    {result.drills.map((drill) => (\n  1899→                      <button\n  1900→                        key={drill.id}\n  1901→                        onClick={() => setSelectedDrill(drill)}\n  1902→                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n  1903→                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n  1904→                        }`}\n  1905→                      >\n  1906→                        <div className=\"flex items-center justify-between mb-1\">\n  1907→                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n  1908→                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n  1909→                        </div>\n  1910→                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n  1911→                      </button>\n  1912→                    ))}\n  1913→                  </div>\n  1914→                </div>\n  1915→\n  1916→                {selectedDrill && (\n  1917→                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n  1918→                    <div className=\"flex items-center justify-between mb-4\">\n  1919→                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n  1920→                      <Link\n  1921→                        href={`/practice?drill=${selectedDrill.id}`}\n  1922→                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n  1923→                      >\n  1924→                        Let&apos;s Practice\n  1925→                      </Link>\n  1926→                    </div>\n  1927→                    <div className=\"space-y-3\">\n  1928→                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n  1929→                      <div>\n  1930→                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n  1931→                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n  1932→                          {selectedDrill.instructions.map((instruction, i) => (\n  1933→                            <li key={i}>{instruction}</li>\n  1934→                          ))}\n  1935→                        </ol>\n  1936→                      </div>\n  1937→                    </div>\n  1938→                  </div>\n  1939→                )}\n  1940→\n  1941→                <button\n  1942→                  onClick={() => {\n  1943→                    setResult(null);\n  1944→                    setSelectedIssue(null);\n  1945→                    setSelectedDrill(null);\n  1946→                    setVideoUrl(null);\n  1947→                    setPoseData([]);\n  1948→                    setIssues([]);\n  1949→                    setAutoLevelResult(null);\n  1950→                    setGuidanceKeyframes([]);\n  1951→                    setAnalysisState('IDLE');\n  1952→                  }}\n  1953→                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n  1954→                >\n  1955→                  Analyze Another Video\n  1956→                </button>\n  1957→              </div>\n  1958→            </div>\n  1959→          )}\n  1960→        </div>\n  1961→      </main>\n  1962→\n  1963→      {/* Player Selection Modal */}\n  1964→      <PlayerSelectionModal\n  1965→        isOpen={showPlayerSelection}\n  1966→        onClose={() => {\n  1967→          setShowPlayerSelection(false);\n  1968→          setAnalyzing(false);\n  1969→          setVideoUrl(null);\n  1970→          setVideoFile(null);\n  1971→          setAnalysisState('IDLE');\n  1972→        }}\n  1973→        onConfirm={handlePlayerSelectionConfirm}\n  1974→        tracks={detectedTracks}\n  1975→        detectedFormat={detectedMatchFormat}\n  1976→      />\n  1977→    </div>\n  1978→  );\n  1979→}\n  1980→\n  1981→function AnalyticsLoading() {\n  1982→  return (\n  1983→    <div className=\"min-h-screen bg-gray-50\">\n  1984→      <DashboardNav />\n  1985→      <main className=\"ml-64 p-8\">\n  1986→        <div className=\"max-w-7xl mx-auto\">\n  1987→          <div className=\"animate-pulse\">\n  1988→            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n  1989→            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n  1990→            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n  1991→          </div>\n  1992→        </div>\n  1993→      </main>\n  1994→    </div>\n  1995→  );\n  1996→}\n  1997→\n  1998→export default function AnalyticsPage() {\n  1999→  return (\n  2000→    <Suspense fallback={<AnalyticsLoading />}>\n  2001→      <AnalyticsContent />\n  2002→    </Suspense>\n  2003→  );\n  2004→}\n  2005→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"ee4bb014-ee2e-40be-82ad-c71fc164bb43","timestamp":"2026-01-28T05:06:26.562Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","content":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // PHASE 3: Auto-detect skill level\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    setAutoLevelResult(levelResult);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n    const avgScore = totalFrames > 0\n      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n      : 0;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","numLines":2005,"startLine":1,"totalLines":2005}},"sourceToolAssistantUUID":"a9cb365c-aeef-4006-82a9-7428b042823e"}
{"parentUuid":"ee4bb014-ee2e-40be-82ad-c71fc164bb43","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01DdTmdNqnCu6vc1ysXD4bN9","toolUseID":"toolu_01DdTmdNqnCu6vc1ysXD4bN9","timestamp":"2026-01-28T05:06:26.568Z","uuid":"c0dd74e8-9d0b-442f-a0c3-131a957dd9e7"}
{"parentUuid":"c0dd74e8-9d0b-442f-a0c3-131a957dd9e7","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01LJ1ymEKfdhmQ3xdfhbmcUT","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me read more files to understand the scoring system, types, and other components:\n1. scoring-rules.ts - for the banded scoring system\n2. types.ts - for type definitions\n3. gemini_client.py - for Gemini integration\n4. video_annotator.py - for skeleton overlay\n5. Supabase schema files - for database structure\n6. DrillCard.tsx, GuidanceAnimation.tsx - existing components","signature":"EqAECkYICxgCKkBz3eTWRUcs8Vhnf+psWDJ1v7GmbENjXjU4ZcE6Flr5MB+Rh3ysHJC1iOtBvS9vgVrAqFRvlr41cacllCUzEgWkEgxB+NBnpxWVOGgavwIaDMIvF2x74ENUf709vCIwKbdGfc5fQCqOzC6ccFnbqVbTCi44jKrAO4x0w3v2DE734/vqVn7oBVT4/1tMPNUZKocDH+j0KuXi0l7nqwXTgLS2wCTyKfC+07WFx6+mWRG7NOCz3c6BMR2OUH7Z7vPAxlGvJpHGw4ZyHf0xOzoZS5mrckreQpXnSbPaBFOZfTfe7BxrNfA230AnZX5WxuVRwuw97J7x49kaW5cJ+pwbYkBwcFAMEVt4uRArPDiQ7W04orqkw+JEM1Aklh5vHBdB/zPe/UyetcHgkBIq5eZDhwuMLMMOrj/77RwvD45MQyEC+fpZ7o4OletEAg2zCwiBK0vfOpidkfdApengUJan/eEwX/jTaf70z/XjM84Je3xQ+xDnXerrIkl/Bkx09f+yQuveDFTI/FUOhvqADaF/cDWJg75FtJsEmyb1pEi6MV070wcyXOhPsXx5iXsFsOZSoaeLQm7Qn4jQgHn6k5sdiNPYi6+VcBdSGfFOogiw7u0zYbRnuIT7DgYjEh8D7pw3CsFZQJ2tETGdAPe6DFwHpUxgFHp/hoScXury44nRckGdjBs7cy1VTSU9jd2uUw9nohPlvTlst/AFvBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":11927,"cache_creation_input_tokens":31069,"cache_read_input_tokens":71687,"cache_creation":{"ephemeral_5m_input_tokens":31069,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCGGWaqKJ8YLXFWX9VJ","type":"assistant","uuid":"d67e6619-d7d9-4484-8081-f8fab5b70ac0","timestamp":"2026-01-28T05:06:31.738Z"}
{"parentUuid":"d67e6619-d7d9-4484-8081-f8fab5b70ac0","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01LJ1ymEKfdhmQ3xdfhbmcUT","type":"message","role":"assistant","content":[{"type":"text","text":"Let me continue reading more key files to complete the picture."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":11927,"cache_creation_input_tokens":31069,"cache_read_input_tokens":71687,"cache_creation":{"ephemeral_5m_input_tokens":31069,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCGGWaqKJ8YLXFWX9VJ","type":"assistant","uuid":"5e9b18f2-78ac-4688-93a8-89d3aefc703a","timestamp":"2026-01-28T05:06:32.221Z"}
{"parentUuid":"5e9b18f2-78ac-4688-93a8-89d3aefc703a","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01LJ1ymEKfdhmQ3xdfhbmcUT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WJkwHb8ijGfqVqYsgC7bvA","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\scoring-rules.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":11927,"cache_creation_input_tokens":31069,"cache_read_input_tokens":71687,"cache_creation":{"ephemeral_5m_input_tokens":31069,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCGGWaqKJ8YLXFWX9VJ","type":"assistant","uuid":"d075fe5b-575d-463b-98b1-92b3f1c14426","timestamp":"2026-01-28T05:06:33.052Z"}
{"parentUuid":"d075fe5b-575d-463b-98b1-92b3f1c14426","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01LJ1ymEKfdhmQ3xdfhbmcUT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MK54ePpzPAK4EKpmBvDDu9","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\types.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":11927,"cache_creation_input_tokens":31069,"cache_read_input_tokens":71687,"cache_creation":{"ephemeral_5m_input_tokens":31069,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCGGWaqKJ8YLXFWX9VJ","type":"assistant","uuid":"0a1cf767-e7fe-47cb-9d33-9cbfcc5f0972","timestamp":"2026-01-28T05:06:33.526Z"}
{"parentUuid":"0a1cf767-e7fe-47cb-9d33-9cbfcc5f0972","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01LJ1ymEKfdhmQ3xdfhbmcUT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012MKSpx34F4UfpDfeCCtvL3","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\gemini_client.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":11927,"cache_creation_input_tokens":31069,"cache_read_input_tokens":71687,"cache_creation":{"ephemeral_5m_input_tokens":31069,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCGGWaqKJ8YLXFWX9VJ","type":"assistant","uuid":"115a176d-9ca9-40cf-8b4d-48b96b5fcd51","timestamp":"2026-01-28T05:06:33.949Z"}
{"parentUuid":"115a176d-9ca9-40cf-8b4d-48b96b5fcd51","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01LJ1ymEKfdhmQ3xdfhbmcUT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01F4ctpnmsTTbsnfmX8iDpHx","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\video_annotator.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":11927,"cache_creation_input_tokens":31069,"cache_read_input_tokens":71687,"cache_creation":{"ephemeral_5m_input_tokens":31069,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCGGWaqKJ8YLXFWX9VJ","type":"assistant","uuid":"7d166515-38d4-4c0a-b656-6784f381506f","timestamp":"2026-01-28T05:06:34.379Z"}
{"parentUuid":"d075fe5b-575d-463b-98b1-92b3f1c14426","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WJkwHb8ijGfqVqYsgC7bvA","type":"tool_result","content":"     1→/**\n     2→ * Banded Scoring Rules Configuration\n     3→ *\n     4→ * This module provides configurable scoring rules with:\n     5→ * - Skill level-based tolerance bands (beginner/intermediate/advanced)\n     6→ * - Three-tier scoring: Green (good), Yellow (minor deviation), Red (major deviation)\n     7→ * - Confidence gating: Low confidence poses are marked as \"unknown\" instead of red\n     8→ * - Phase-aware checks: Different rules for ready vs lunge vs recovery phases\n     9→ *\n    10→ * Version: v1\n    11→ */\n    12→\n    13→import type {\n    14→  ScoringRulesConfig,\n    15→  ScoreBand,\n    16→  BandedScore,\n    17→  PoseLandmark,\n    18→  PoseMetrics\n    19→} from './types';\n    20→import { calculateAngle, calculateDistance, POSE_LANDMARKS } from './pose-utils';\n    21→\n    22→// ============================================\n    23→// Rules Configuration (versioned)\n    24→// ============================================\n    25→\n    26→export const SCORING_RULES_CONFIG: ScoringRulesConfig = {\n    27→  version: 'v1',\n    28→\n    29→  // How much wider the acceptable bands are for each skill level\n    30→  skill_bands: {\n    31→    beginner: {\n    32→      green_tolerance: 0.40, // 40% wider green band\n    33→      yellow_tolerance: 0.60, // 60% wider than ideal for yellow\n    34→    },\n    35→    intermediate: {\n    36→      green_tolerance: 0.25, // 25% wider green band\n    37→      yellow_tolerance: 0.40, // 40% wider for yellow\n    38→    },\n    39→    advanced: {\n    40→      green_tolerance: 0.10, // 10% wider green band (strict)\n    41→      yellow_tolerance: 0.20, // 20% wider for yellow\n    42→    },\n    43→  },\n    44→\n    45→  // Minimum confidence threshold - below this, mark as \"unknown\"\n    46→  confidence_threshold: 0.5,\n    47→\n    48→  // Phase-specific rules\n    49→  phase_rules: {\n    50→    ready: {\n    51→      name: 'Ready Position',\n    52→      applicable_metrics: ['knee_angle', 'stance_width'],\n    53→      thresholds: {\n    54→        knee_angle: { min: 130, max: 160 },\n    55→        stance_width: { min: 0.8, max: 1.3 },\n    56→      },\n    57→    },\n    58→    lunge: {\n    59→      name: 'Lunge/Reach',\n    60→      applicable_metrics: ['knee_angle', 'stance_width', 'elbow_angle'],\n    61→      thresholds: {\n    62→        knee_angle: { min: 90, max: 140 },\n    63→        stance_width: { min: 1.0, max: 2.0 },\n    64→        elbow_angle: { min: 100, max: 160 },\n    65→      },\n    66→    },\n    67→    overhead: {\n    68→      name: 'Overhead Shot',\n    69→      applicable_metrics: ['elbow_angle', 'body_rotation'],\n    70→      thresholds: {\n    71→        elbow_angle: { min: 150, max: 180 },\n    72→        body_rotation: { min: 15, max: 50 },\n    73→      },\n    74→    },\n    75→    recovery: {\n    76→      name: 'Recovery',\n    77→      applicable_metrics: ['knee_angle', 'stance_width'],\n    78→      thresholds: {\n    79→        knee_angle: { min: 120, max: 155 },\n    80→        stance_width: { min: 0.7, max: 1.4 },\n    81→      },\n    82→    },\n    83→  },\n    84→};\n    85→\n    86→// ============================================\n    87→// Metric Definitions with Ideal Ranges\n    88→// ============================================\n    89→\n    90→export interface MetricDefinition {\n    91→  code: string;\n    92→  name: string;\n    93→  unit: string;\n    94→  ideal: { min: number; max: number };\n    95→  description: string;\n    96→  feedback: {\n    97→    green: string;\n    98→    yellow_low: string;\n    99→    yellow_high: string;\n   100→    red_low: string;\n   101→    red_high: string;\n   102→  };\n   103→}\n   104→\n   105→export const METRIC_DEFINITIONS: Record<string, MetricDefinition> = {\n   106→  elbow_angle: {\n   107→    code: 'elbow_angle',\n   108→    name: 'Elbow Angle',\n   109→    unit: 'degrees',\n   110→    ideal: { min: 90, max: 130 }, // General ideal for most shots\n   111→    description: 'Angle at the elbow joint during stroke',\n   112→    feedback: {\n   113→      green: 'Good elbow position!',\n   114→      yellow_low: 'Try extending your elbow a bit more',\n   115→      yellow_high: 'Slight over-extension, maintain control',\n   116→      red_low: 'Elbow too bent - extend more for power',\n   117→      red_high: 'Elbow locked - keep slight flex for control',\n   118→    },\n   119→  },\n   120→  knee_angle: {\n   121→    code: 'knee_angle',\n   122→    name: 'Knee Bend',\n   123→    unit: 'degrees',\n   124→    ideal: { min: 120, max: 155 },\n   125→    description: 'Angle at the knee for athletic stance',\n   126→    feedback: {\n   127→      green: 'Great knee position!',\n   128→      yellow_low: 'Knees slightly too bent',\n   129→      yellow_high: 'Could bend knees more',\n   130→      red_low: 'Too deep - may slow recovery',\n   131→      red_high: 'Legs too straight - bend for explosiveness',\n   132→    },\n   133→  },\n   134→  stance_width: {\n   135→    code: 'stance_width',\n   136→    name: 'Stance Width',\n   137→    unit: 'ratio',\n   138→    ideal: { min: 0.8, max: 1.4 }, // Ratio of ankle width to shoulder width\n   139→    description: 'Foot separation relative to shoulder width',\n   140→    feedback: {\n   141→      green: 'Good stance width!',\n   142→      yellow_low: 'Stance slightly narrow',\n   143→      yellow_high: 'Stance slightly wide',\n   144→      red_low: 'Feet too close - widen for stability',\n   145→      red_high: 'Overly wide stance - may limit mobility',\n   146→    },\n   147→  },\n   148→  body_rotation: {\n   149→    code: 'body_rotation',\n   150→    name: 'Body Rotation',\n   151→    unit: 'degrees',\n   152→    ideal: { min: 10, max: 40 },\n   153→    description: 'Hip-shoulder separation for power generation',\n   154→    feedback: {\n   155→      green: 'Excellent rotation!',\n   156→      yellow_low: 'Could rotate more for power',\n   157→      yellow_high: 'Slight over-rotation',\n   158→      red_low: 'Not enough rotation - use your hips',\n   159→      red_high: 'Too much rotation - control your swing',\n   160→    },\n   161→  },\n   162→};\n   163→\n   164→// ============================================\n   165→// Banded Scoring Functions\n   166→// ============================================\n   167→\n   168→/**\n   169→ * Calculate the score band for a given metric value\n   170→ */\n   171→export function calculateBand(\n   172→  value: number,\n   173→  ideal: { min: number; max: number },\n   174→  skillLevel: 'beginner' | 'intermediate' | 'advanced' = 'intermediate',\n   175→  confidence: number = 1.0\n   176→): BandedScore {\n   177→  const config = SCORING_RULES_CONFIG;\n   178→  const skillConfig = config.skill_bands[skillLevel];\n   179→\n   180→  // Confidence gating - if too low, return unknown\n   181→  if (confidence < config.confidence_threshold) {\n   182→    return {\n   183→      band: 'unknown',\n   184→      value,\n   185→      confidence,\n   186→      feedback: 'Pose confidence too low to evaluate',\n   187→    };\n   188→  }\n   189→\n   190→  const idealRange = ideal.max - ideal.min;\n   191→  const idealMid = (ideal.min + ideal.max) / 2;\n   192→\n   193→  // Calculate tolerance ranges\n   194→  const greenTolerance = idealRange * skillConfig.green_tolerance;\n   195→  const yellowTolerance = idealRange * skillConfig.yellow_tolerance;\n   196→\n   197→  const greenMin = ideal.min - greenTolerance / 2;\n   198→  const greenMax = ideal.max + greenTolerance / 2;\n   199→  const yellowMin = ideal.min - yellowTolerance / 2;\n   200→  const yellowMax = ideal.max + yellowTolerance / 2;\n   201→\n   202→  // Determine band\n   203→  if (value >= greenMin && value <= greenMax) {\n   204→    return {\n   205→      band: 'green',\n   206→      value,\n   207→      confidence,\n   208→    };\n   209→  } else if (value >= yellowMin && value <= yellowMax) {\n   210→    return {\n   211→      band: 'yellow',\n   212→      value,\n   213→      confidence,\n   214→    };\n   215→  } else {\n   216→    return {\n   217→      band: 'red',\n   218→      value,\n   219→      confidence,\n   220→    };\n   221→  }\n   222→}\n   223→\n   224→/**\n   225→ * Get feedback message for a banded score\n   226→ */\n   227→export function getBandedFeedback(\n   228→  metricCode: string,\n   229→  score: BandedScore\n   230→): string {\n   231→  const metric = METRIC_DEFINITIONS[metricCode];\n   232→  if (!metric) return '';\n   233→\n   234→  const { band, value } = score;\n   235→  const { ideal, feedback } = metric;\n   236→  const mid = (ideal.min + ideal.max) / 2;\n   237→\n   238→  switch (band) {\n   239→    case 'green':\n   240→      return feedback.green;\n   241→    case 'yellow':\n   242→      return value < mid ? feedback.yellow_low : feedback.yellow_high;\n   243→    case 'red':\n   244→      return value < ideal.min ? feedback.red_low : feedback.red_high;\n   245→    case 'unknown':\n   246→    default:\n   247→      return 'Unable to evaluate - check camera position';\n   248→  }\n   249→}\n   250→\n   251→// ============================================\n   252→// Phase Detection\n   253→// ============================================\n   254→\n   255→export type MovementPhase = 'ready' | 'lunge' | 'overhead' | 'recovery' | 'general';\n   256→\n   257→/**\n   258→ * Detect the current movement phase from pose landmarks\n   259→ */\n   260→export function detectPhase(landmarks: PoseLandmark[]): MovementPhase {\n   261→  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n   262→  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n   263→  const rightElbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n   264→  const rightKnee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n   265→  const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n   266→\n   267→  // Check if arm is raised (overhead shot)\n   268→  if (rightWrist.y < rightShoulder.y - 0.1) {\n   269→    return 'overhead';\n   270→  }\n   271→\n   272→  // Check knee angle for lunge detection\n   273→  const kneeAngle = calculateAngle(rightHip, rightKnee, landmarks[POSE_LANDMARKS.RIGHT_ANKLE]);\n   274→  if (kneeAngle < 120) {\n   275→    return 'lunge';\n   276→  }\n   277→\n   278→  // Check if in ready position (knees slightly bent, centered)\n   279→  if (kneeAngle >= 130 && kneeAngle <= 160) {\n   280→    return 'ready';\n   281→  }\n   282→\n   283→  // Default to general\n   284→  return 'general';\n   285→}\n   286→\n   287→// ============================================\n   288→// Comprehensive Banded Evaluation\n   289→// ============================================\n   290→\n   291→export interface BandedEvaluationResult {\n   292→  phase: MovementPhase;\n   293→  overall_band: ScoreBand;\n   294→  overall_score: number; // 0-100\n   295→  metrics: Record<string, BandedScore>;\n   296→  feedback: string[];\n   297→  highlight_joints: number[];\n   298→}\n   299→\n   300→/**\n   301→ * Evaluate pose with banded scoring\n   302→ */\n   303→export function evaluateWithBands(\n   304→  landmarks: PoseLandmark[],\n   305→  skillLevel: 'beginner' | 'intermediate' | 'advanced' = 'intermediate',\n   306→  forcePhase?: MovementPhase\n   307→): BandedEvaluationResult {\n   308→  // Calculate average confidence\n   309→  const avgConfidence = landmarks.reduce((sum, l) => sum + (l.visibility || 0), 0) / landmarks.length;\n   310→\n   311→  // Detect phase\n   312→  const phase = forcePhase || detectPhase(landmarks);\n   313→  const phaseRule = SCORING_RULES_CONFIG.phase_rules[phase];\n   314→\n   315→  // Calculate metrics\n   316→  const metrics: Record<string, BandedScore> = {};\n   317→  const feedback: string[] = [];\n   318→  const highlightJoints: number[] = [];\n   319→  let totalScore = 0;\n   320→  let metricCount = 0;\n   321→\n   322→  // Elbow angle\n   323→  const shoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n   324→  const elbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n   325→  const wrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n   326→  const elbowAngle = calculateAngle(shoulder, elbow, wrist);\n   327→  const elbowConfidence = Math.min(shoulder.visibility, elbow.visibility, wrist.visibility);\n   328→\n   329→  const elbowIdeal = phaseRule?.thresholds?.elbow_angle || METRIC_DEFINITIONS.elbow_angle.ideal;\n   330→  metrics.elbow_angle = calculateBand(elbowAngle, elbowIdeal, skillLevel, elbowConfidence);\n   331→  metrics.elbow_angle.feedback = getBandedFeedback('elbow_angle', metrics.elbow_angle);\n   332→\n   333→  if (metrics.elbow_angle.band !== 'green' && metrics.elbow_angle.band !== 'unknown') {\n   334→    feedback.push(metrics.elbow_angle.feedback!);\n   335→    highlightJoints.push(POSE_LANDMARKS.RIGHT_ELBOW, POSE_LANDMARKS.RIGHT_WRIST);\n   336→  }\n   337→\n   338→  // Knee angle\n   339→  const hip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n   340→  const knee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n   341→  const ankle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n   342→  const kneeAngle = calculateAngle(hip, knee, ankle);\n   343→  const kneeConfidence = Math.min(hip.visibility, knee.visibility, ankle.visibility);\n   344→\n   345→  const kneeIdeal = phaseRule?.thresholds?.knee_angle || METRIC_DEFINITIONS.knee_angle.ideal;\n   346→  metrics.knee_angle = calculateBand(kneeAngle, kneeIdeal, skillLevel, kneeConfidence);\n   347→  metrics.knee_angle.feedback = getBandedFeedback('knee_angle', metrics.knee_angle);\n   348→\n   349→  if (metrics.knee_angle.band !== 'green' && metrics.knee_angle.band !== 'unknown') {\n   350→    feedback.push(metrics.knee_angle.feedback!);\n   351→    highlightJoints.push(POSE_LANDMARKS.RIGHT_KNEE, POSE_LANDMARKS.LEFT_KNEE);\n   352→  }\n   353→\n   354→  // Stance width\n   355→  const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n   356→  const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n   357→  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n   358→  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n   359→  const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n   360→  const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n   361→  const stanceWidth = shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n   362→  const stanceConfidence = Math.min(leftAnkle.visibility, rightAnkle.visibility);\n   363→\n   364→  const stanceIdeal = phaseRule?.thresholds?.stance_width || METRIC_DEFINITIONS.stance_width.ideal;\n   365→  metrics.stance_width = calculateBand(stanceWidth, stanceIdeal, skillLevel, stanceConfidence);\n   366→  metrics.stance_width.feedback = getBandedFeedback('stance_width', metrics.stance_width);\n   367→\n   368→  if (metrics.stance_width.band !== 'green' && metrics.stance_width.band !== 'unknown') {\n   369→    feedback.push(metrics.stance_width.feedback!);\n   370→    highlightJoints.push(POSE_LANDMARKS.LEFT_ANKLE, POSE_LANDMARKS.RIGHT_ANKLE);\n   371→  }\n   372→\n   373→  // Body rotation (for overhead phase)\n   374→  if (phase === 'overhead' || !phaseRule) {\n   375→    const leftHip = landmarks[POSE_LANDMARKS.LEFT_HIP];\n   376→    const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n   377→    const shoulderAngle = Math.atan2(\n   378→      rightShoulder.y - leftShoulder.y,\n   379→      rightShoulder.x - leftShoulder.x\n   380→    );\n   381→    const hipAngle = Math.atan2(rightHip.y - leftHip.y, rightHip.x - leftHip.x);\n   382→    const rotation = Math.abs(shoulderAngle - hipAngle) * (180 / Math.PI);\n   383→    const rotationConfidence = Math.min(\n   384→      leftShoulder.visibility, rightShoulder.visibility,\n   385→      leftHip.visibility, rightHip.visibility\n   386→    );\n   387→\n   388→    const rotationIdeal = phaseRule?.thresholds?.body_rotation || METRIC_DEFINITIONS.body_rotation.ideal;\n   389→    metrics.body_rotation = calculateBand(rotation, rotationIdeal, skillLevel, rotationConfidence);\n   390→    metrics.body_rotation.feedback = getBandedFeedback('body_rotation', metrics.body_rotation);\n   391→\n   392→    if (metrics.body_rotation.band !== 'green' && metrics.body_rotation.band !== 'unknown') {\n   393→      feedback.push(metrics.body_rotation.feedback!);\n   394→    }\n   395→  }\n   396→\n   397→  // Calculate overall score\n   398→  const bandScores: Record<ScoreBand, number> = {\n   399→    green: 100,\n   400→    yellow: 70,\n   401→    red: 30,\n   402→    unknown: 50, // Neutral\n   403→  };\n   404→\n   405→  Object.values(metrics).forEach(m => {\n   406→    if (m.band !== 'unknown') {\n   407→      totalScore += bandScores[m.band];\n   408→      metricCount++;\n   409→    }\n   410→  });\n   411→\n   412→  const overallScore = metricCount > 0 ? totalScore / metricCount : 50;\n   413→\n   414→  // Determine overall band\n   415→  let overallBand: ScoreBand;\n   416→  const greenCount = Object.values(metrics).filter(m => m.band === 'green').length;\n   417→  const redCount = Object.values(metrics).filter(m => m.band === 'red').length;\n   418→  const validCount = Object.values(metrics).filter(m => m.band !== 'unknown').length;\n   419→\n   420→  if (validCount === 0) {\n   421→    overallBand = 'unknown';\n   422→  } else if (redCount > 0) {\n   423→    overallBand = redCount > 1 ? 'red' : 'yellow';\n   424→  } else if (greenCount === validCount) {\n   425→    overallBand = 'green';\n   426→  } else {\n   427→    overallBand = 'yellow';\n   428→  }\n   429→\n   430→  // Add encouraging feedback if all green\n   431→  if (overallBand === 'green' && feedback.length === 0) {\n   432→    feedback.push('Excellent form! Keep it up!');\n   433→  }\n   434→\n   435→  return {\n   436→    phase,\n   437→    overall_band: overallBand,\n   438→    overall_score: overallScore,\n   439→    metrics,\n   440→    feedback,\n   441→    highlight_joints: highlightJoints,\n   442→  };\n   443→}\n   444→\n   445→// ============================================\n   446→// Legend/Documentation for UI\n   447→// ============================================\n   448→\n   449→export const SCORING_LEGEND = {\n   450→  green: {\n   451→    label: 'Good',\n   452→    description: 'Within coach-approved range for your skill level',\n   453→    color: '#22c55e',\n   454→    bgColor: '#dcfce7',\n   455→  },\n   456→  yellow: {\n   457→    label: 'Minor Deviation',\n   458→    description: 'Slightly outside ideal range - minor adjustment needed',\n   459→    color: '#eab308',\n   460→    bgColor: '#fef9c3',\n   461→  },\n   462→  red: {\n   463→    label: 'Major Deviation',\n   464→    description: 'Significantly outside ideal range - focus on this area',\n   465→    color: '#ef4444',\n   466→    bgColor: '#fee2e2',\n   467→  },\n   468→  unknown: {\n   469→    label: 'Unknown',\n   470→    description: 'Pose confidence too low to evaluate accurately',\n   471→    color: '#9ca3af',\n   472→    bgColor: '#f3f4f6',\n   473→  },\n   474→};\n   475→\n   476→export const SKILL_LEVEL_DESCRIPTIONS = {\n   477→  beginner: {\n   478→    label: 'Beginner',\n   479→    description: 'Wider tolerance bands - focus on basic form',\n   480→    recommendation: 'Good for learning fundamentals without frustration',\n   481→  },\n   482→  intermediate: {\n   483→    label: 'Intermediate',\n   484→    description: 'Standard tolerance bands - balanced feedback',\n   485→    recommendation: 'Ideal for most club-level players',\n   486→  },\n   487→  advanced: {\n   488→    label: 'Advanced',\n   489→    description: 'Strict tolerance bands - precision feedback',\n   490→    recommendation: 'For competitive players seeking fine-tuning',\n   491→  },\n   492→};\n   493→\n   494→// ============================================\n   495→// PHASE 3: Session-Level Validation\n   496→// ============================================\n   497→\n   498→// Minimum thresholds for valid analysis\n   499→export const VALIDATION_THRESHOLDS = {\n   500→  // Minimum ratio of frames with valid pose detection\n   501→  MIN_POSE_COVERAGE: 0.7, // 70%\n   502→  // Minimum average confidence across valid frames\n   503→  MIN_CONFIDENCE: 0.5,\n   504→  // Minimum number of consecutive frames to confirm an issue\n   505→  MIN_ISSUE_PERSISTENCE: 3,\n   506→  // Minimum number of frames with a deviation to report it\n   507→  MIN_DEVIATION_FRAMES: 5,\n   508→};\n   509→\n   510→export interface SessionValidationResult {\n   511→  isValid: boolean;\n   512→  validPoseRatio: number;\n   513→  avgConfidence: number;\n   514→  totalFrames: number;\n   515→  validPoseFrames: number;\n   516→  lowConfidenceFrames: number;\n   517→  noPoseFrames: number;\n   518→  message: string;\n   519→}\n   520→\n   521→/**\n   522→ * PHASE 3: Validate that a session has sufficient pose data for reliable analysis\n   523→ * Returns validation result with coverage stats and whether \"Great form\" can be shown\n   524→ */\n   525→export function validateSessionPoseData(\n   526→  poseData: (PoseLandmark[] | null)[],\n   527→  minCoverage: number = VALIDATION_THRESHOLDS.MIN_POSE_COVERAGE,\n   528→  minConfidence: number = VALIDATION_THRESHOLDS.MIN_CONFIDENCE\n   529→): SessionValidationResult {\n   530→  const totalFrames = poseData.length;\n   531→  let validPoseFrames = 0;\n   532→  let lowConfidenceFrames = 0;\n   533→  let noPoseFrames = 0;\n   534→  let totalConfidence = 0;\n   535→\n   536→  for (const landmarks of poseData) {\n   537→    if (!landmarks || landmarks.length === 0) {\n   538→      noPoseFrames++;\n   539→      continue;\n   540→    }\n   541→\n   542→    // Calculate average visibility for this frame\n   543→    const avgVisibility = landmarks.reduce((sum, lm) => sum + (lm.visibility || 0), 0) / landmarks.length;\n   544→\n   545→    if (avgVisibility >= minConfidence) {\n   546→      validPoseFrames++;\n   547→      totalConfidence += avgVisibility;\n   548→    } else {\n   549→      lowConfidenceFrames++;\n   550→      totalConfidence += avgVisibility;\n   551→    }\n   552→  }\n   553→\n   554→  const validPoseRatio = totalFrames > 0 ? validPoseFrames / totalFrames : 0;\n   555→  const avgConfidence = (validPoseFrames + lowConfidenceFrames) > 0\n   556→    ? totalConfidence / (validPoseFrames + lowConfidenceFrames)\n   557→    : 0;\n   558→\n   559→  // Determine if session is valid for scoring\n   560→  const isValid = validPoseRatio >= minCoverage && avgConfidence >= minConfidence;\n   561→\n   562→  // Generate appropriate message\n   563→  let message: string;\n   564→  if (isValid) {\n   565→    message = 'Sufficient pose data for reliable analysis';\n   566→  } else if (validPoseRatio < minCoverage && avgConfidence < minConfidence) {\n   567→    message = `Low pose coverage (${(validPoseRatio * 100).toFixed(0)}%) and low confidence (${(avgConfidence * 100).toFixed(0)}%). Results may not be accurate.`;\n   568→  } else if (validPoseRatio < minCoverage) {\n   569→    message = `Low pose coverage (${(validPoseRatio * 100).toFixed(0)}%). Ensure player is visible throughout the video.`;\n   570→  } else {\n   571→    message = `Low detection confidence (${(avgConfidence * 100).toFixed(0)}%). Check lighting and camera angle.`;\n   572→  }\n   573→\n   574→  return {\n   575→    isValid,\n   576→    validPoseRatio,\n   577→    avgConfidence,\n   578→    totalFrames,\n   579→    validPoseFrames,\n   580→    lowConfidenceFrames,\n   581→    noPoseFrames,\n   582→    message,\n   583→  };\n   584→}\n   585→\n   586→export interface SessionScoringResult {\n   587→  validation: SessionValidationResult;\n   588→  overall_band: ScoreBand;\n   589→  overall_score: number;\n   590→  greenFrameRatio: number;\n   591→  yellowFrameRatio: number;\n   592→  redFrameRatio: number;\n   593→  persistentIssues: string[];\n   594→  canShowGreatForm: boolean;\n   595→  displayMessage: string;\n   596→}\n   597→\n   598→/**\n   599→ * PHASE 3: Evaluate a full session with validation and persistence checks\n   600→ * This prevents false \"Great form!\" when pose data is insufficient\n   601→ */\n   602→export function evaluateSessionWithValidation(\n   603→  poseData: (PoseLandmark[] | null)[],\n   604→  skillLevel: 'beginner' | 'intermediate' | 'advanced' = 'intermediate'\n   605→): SessionScoringResult {\n   606→  // First validate the session has sufficient pose data\n   607→  const validation = validateSessionPoseData(poseData);\n   608→\n   609→  // If not enough valid data, return unknown with explanation\n   610→  if (!validation.isValid) {\n   611→    return {\n   612→      validation,\n   613→      overall_band: 'unknown',\n   614→      overall_score: 0,\n   615→      greenFrameRatio: 0,\n   616→      yellowFrameRatio: 0,\n   617→      redFrameRatio: 0,\n   618→      persistentIssues: [],\n   619→      canShowGreatForm: false,\n   620→      displayMessage: validation.message,\n   621→    };\n   622→  }\n   623→\n   624→  // Evaluate each valid frame\n   625→  let greenFrames = 0;\n   626→  let yellowFrames = 0;\n   627→  let redFrames = 0;\n   628→  let totalScore = 0;\n   629→  let scoredFrames = 0;\n   630→\n   631→  // Track issue persistence across frames\n   632→  const issueCounts: Record<string, number> = {};\n   633→  let consecutiveIssue: Record<string, number> = {};\n   634→\n   635→  for (const landmarks of poseData) {\n   636→    if (!landmarks || landmarks.length === 0) continue;\n   637→\n   638→    const avgVisibility = landmarks.reduce((sum, lm) => sum + (lm.visibility || 0), 0) / landmarks.length;\n   639→    if (avgVisibility < VALIDATION_THRESHOLDS.MIN_CONFIDENCE) continue;\n   640→\n   641→    const evaluation = evaluateWithBands(landmarks, skillLevel);\n   642→    scoredFrames++;\n   643→    totalScore += evaluation.overall_score;\n   644→\n   645→    switch (evaluation.overall_band) {\n   646→      case 'green':\n   647→        greenFrames++;\n   648→        // Reset consecutive issue counters\n   649→        consecutiveIssue = {};\n   650→        break;\n   651→      case 'yellow':\n   652→        yellowFrames++;\n   653→        break;\n   654→      case 'red':\n   655→        redFrames++;\n   656→        break;\n   657→    }\n   658→\n   659→    // Track issue persistence\n   660→    for (const fb of evaluation.feedback) {\n   661→      if (fb !== 'Excellent form! Keep it up!') {\n   662→        issueCounts[fb] = (issueCounts[fb] || 0) + 1;\n   663→        consecutiveIssue[fb] = (consecutiveIssue[fb] || 0) + 1;\n   664→      }\n   665→    }\n   666→  }\n   667→\n   668→  // Calculate ratios\n   669→  const greenFrameRatio = scoredFrames > 0 ? greenFrames / scoredFrames : 0;\n   670→  const yellowFrameRatio = scoredFrames > 0 ? yellowFrames / scoredFrames : 0;\n   671→  const redFrameRatio = scoredFrames > 0 ? redFrames / scoredFrames : 0;\n   672→  const avgScore = scoredFrames > 0 ? totalScore / scoredFrames : 0;\n   673→\n   674→  // Find persistent issues (appear in multiple frames)\n   675→  const persistentIssues = Object.entries(issueCounts)\n   676→    .filter(([_, count]) => count >= VALIDATION_THRESHOLDS.MIN_DEVIATION_FRAMES)\n   677→    .sort((a, b) => b[1] - a[1])\n   678→    .map(([issue, _]) => issue);\n   679→\n   680→  // Determine overall band\n   681→  let overall_band: ScoreBand;\n   682→  if (greenFrameRatio >= 0.7) {\n   683→    overall_band = 'green';\n   684→  } else if (greenFrameRatio >= 0.5 || yellowFrameRatio >= 0.5) {\n   685→    overall_band = 'yellow';\n   686→  } else {\n   687→    overall_band = 'red';\n   688→  }\n   689→\n   690→  // PHASE 3 FIX: Can only show \"Great form\" if:\n   691→  // 1. Session validation passed (70%+ coverage, 50%+ confidence)\n   692→  // 2. 70%+ of frames are green\n   693→  // 3. No persistent red-level issues\n   694→  const canShowGreatForm = validation.isValid &&\n   695→    greenFrameRatio >= 0.7 &&\n   696→    persistentIssues.length === 0;\n   697→\n   698→  // Generate appropriate display message\n   699→  let displayMessage: string;\n   700→  if (canShowGreatForm) {\n   701→    displayMessage = 'Great form! No major issues detected.';\n   702→  } else if (!validation.isValid) {\n   703→    displayMessage = validation.message;\n   704→  } else if (persistentIssues.length > 0) {\n   705→    displayMessage = `${persistentIssues.length} issue${persistentIssues.length > 1 ? 's' : ''} detected. Focus on: ${persistentIssues[0]}`;\n   706→  } else if (overall_band === 'yellow') {\n   707→    displayMessage = 'Minor adjustments needed - review the highlighted areas.';\n   708→  } else {\n   709→    displayMessage = 'Form needs work - watch the tutorial videos for guidance.';\n   710→  }\n   711→\n   712→  return {\n   713→    validation,\n   714→    overall_band,\n   715→    overall_score: avgScore,\n   716→    greenFrameRatio,\n   717→    yellowFrameRatio,\n   718→    redFrameRatio,\n   719→    persistentIssues,\n   720→    canShowGreatForm,\n   721→    displayMessage,\n   722→  };\n   723→}\n   724→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"43c41ac6-bcd4-491d-a902-9f879683d6a4","timestamp":"2026-01-28T05:06:37.545Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\scoring-rules.ts","content":"/**\n * Banded Scoring Rules Configuration\n *\n * This module provides configurable scoring rules with:\n * - Skill level-based tolerance bands (beginner/intermediate/advanced)\n * - Three-tier scoring: Green (good), Yellow (minor deviation), Red (major deviation)\n * - Confidence gating: Low confidence poses are marked as \"unknown\" instead of red\n * - Phase-aware checks: Different rules for ready vs lunge vs recovery phases\n *\n * Version: v1\n */\n\nimport type {\n  ScoringRulesConfig,\n  ScoreBand,\n  BandedScore,\n  PoseLandmark,\n  PoseMetrics\n} from './types';\nimport { calculateAngle, calculateDistance, POSE_LANDMARKS } from './pose-utils';\n\n// ============================================\n// Rules Configuration (versioned)\n// ============================================\n\nexport const SCORING_RULES_CONFIG: ScoringRulesConfig = {\n  version: 'v1',\n\n  // How much wider the acceptable bands are for each skill level\n  skill_bands: {\n    beginner: {\n      green_tolerance: 0.40, // 40% wider green band\n      yellow_tolerance: 0.60, // 60% wider than ideal for yellow\n    },\n    intermediate: {\n      green_tolerance: 0.25, // 25% wider green band\n      yellow_tolerance: 0.40, // 40% wider for yellow\n    },\n    advanced: {\n      green_tolerance: 0.10, // 10% wider green band (strict)\n      yellow_tolerance: 0.20, // 20% wider for yellow\n    },\n  },\n\n  // Minimum confidence threshold - below this, mark as \"unknown\"\n  confidence_threshold: 0.5,\n\n  // Phase-specific rules\n  phase_rules: {\n    ready: {\n      name: 'Ready Position',\n      applicable_metrics: ['knee_angle', 'stance_width'],\n      thresholds: {\n        knee_angle: { min: 130, max: 160 },\n        stance_width: { min: 0.8, max: 1.3 },\n      },\n    },\n    lunge: {\n      name: 'Lunge/Reach',\n      applicable_metrics: ['knee_angle', 'stance_width', 'elbow_angle'],\n      thresholds: {\n        knee_angle: { min: 90, max: 140 },\n        stance_width: { min: 1.0, max: 2.0 },\n        elbow_angle: { min: 100, max: 160 },\n      },\n    },\n    overhead: {\n      name: 'Overhead Shot',\n      applicable_metrics: ['elbow_angle', 'body_rotation'],\n      thresholds: {\n        elbow_angle: { min: 150, max: 180 },\n        body_rotation: { min: 15, max: 50 },\n      },\n    },\n    recovery: {\n      name: 'Recovery',\n      applicable_metrics: ['knee_angle', 'stance_width'],\n      thresholds: {\n        knee_angle: { min: 120, max: 155 },\n        stance_width: { min: 0.7, max: 1.4 },\n      },\n    },\n  },\n};\n\n// ============================================\n// Metric Definitions with Ideal Ranges\n// ============================================\n\nexport interface MetricDefinition {\n  code: string;\n  name: string;\n  unit: string;\n  ideal: { min: number; max: number };\n  description: string;\n  feedback: {\n    green: string;\n    yellow_low: string;\n    yellow_high: string;\n    red_low: string;\n    red_high: string;\n  };\n}\n\nexport const METRIC_DEFINITIONS: Record<string, MetricDefinition> = {\n  elbow_angle: {\n    code: 'elbow_angle',\n    name: 'Elbow Angle',\n    unit: 'degrees',\n    ideal: { min: 90, max: 130 }, // General ideal for most shots\n    description: 'Angle at the elbow joint during stroke',\n    feedback: {\n      green: 'Good elbow position!',\n      yellow_low: 'Try extending your elbow a bit more',\n      yellow_high: 'Slight over-extension, maintain control',\n      red_low: 'Elbow too bent - extend more for power',\n      red_high: 'Elbow locked - keep slight flex for control',\n    },\n  },\n  knee_angle: {\n    code: 'knee_angle',\n    name: 'Knee Bend',\n    unit: 'degrees',\n    ideal: { min: 120, max: 155 },\n    description: 'Angle at the knee for athletic stance',\n    feedback: {\n      green: 'Great knee position!',\n      yellow_low: 'Knees slightly too bent',\n      yellow_high: 'Could bend knees more',\n      red_low: 'Too deep - may slow recovery',\n      red_high: 'Legs too straight - bend for explosiveness',\n    },\n  },\n  stance_width: {\n    code: 'stance_width',\n    name: 'Stance Width',\n    unit: 'ratio',\n    ideal: { min: 0.8, max: 1.4 }, // Ratio of ankle width to shoulder width\n    description: 'Foot separation relative to shoulder width',\n    feedback: {\n      green: 'Good stance width!',\n      yellow_low: 'Stance slightly narrow',\n      yellow_high: 'Stance slightly wide',\n      red_low: 'Feet too close - widen for stability',\n      red_high: 'Overly wide stance - may limit mobility',\n    },\n  },\n  body_rotation: {\n    code: 'body_rotation',\n    name: 'Body Rotation',\n    unit: 'degrees',\n    ideal: { min: 10, max: 40 },\n    description: 'Hip-shoulder separation for power generation',\n    feedback: {\n      green: 'Excellent rotation!',\n      yellow_low: 'Could rotate more for power',\n      yellow_high: 'Slight over-rotation',\n      red_low: 'Not enough rotation - use your hips',\n      red_high: 'Too much rotation - control your swing',\n    },\n  },\n};\n\n// ============================================\n// Banded Scoring Functions\n// ============================================\n\n/**\n * Calculate the score band for a given metric value\n */\nexport function calculateBand(\n  value: number,\n  ideal: { min: number; max: number },\n  skillLevel: 'beginner' | 'intermediate' | 'advanced' = 'intermediate',\n  confidence: number = 1.0\n): BandedScore {\n  const config = SCORING_RULES_CONFIG;\n  const skillConfig = config.skill_bands[skillLevel];\n\n  // Confidence gating - if too low, return unknown\n  if (confidence < config.confidence_threshold) {\n    return {\n      band: 'unknown',\n      value,\n      confidence,\n      feedback: 'Pose confidence too low to evaluate',\n    };\n  }\n\n  const idealRange = ideal.max - ideal.min;\n  const idealMid = (ideal.min + ideal.max) / 2;\n\n  // Calculate tolerance ranges\n  const greenTolerance = idealRange * skillConfig.green_tolerance;\n  const yellowTolerance = idealRange * skillConfig.yellow_tolerance;\n\n  const greenMin = ideal.min - greenTolerance / 2;\n  const greenMax = ideal.max + greenTolerance / 2;\n  const yellowMin = ideal.min - yellowTolerance / 2;\n  const yellowMax = ideal.max + yellowTolerance / 2;\n\n  // Determine band\n  if (value >= greenMin && value <= greenMax) {\n    return {\n      band: 'green',\n      value,\n      confidence,\n    };\n  } else if (value >= yellowMin && value <= yellowMax) {\n    return {\n      band: 'yellow',\n      value,\n      confidence,\n    };\n  } else {\n    return {\n      band: 'red',\n      value,\n      confidence,\n    };\n  }\n}\n\n/**\n * Get feedback message for a banded score\n */\nexport function getBandedFeedback(\n  metricCode: string,\n  score: BandedScore\n): string {\n  const metric = METRIC_DEFINITIONS[metricCode];\n  if (!metric) return '';\n\n  const { band, value } = score;\n  const { ideal, feedback } = metric;\n  const mid = (ideal.min + ideal.max) / 2;\n\n  switch (band) {\n    case 'green':\n      return feedback.green;\n    case 'yellow':\n      return value < mid ? feedback.yellow_low : feedback.yellow_high;\n    case 'red':\n      return value < ideal.min ? feedback.red_low : feedback.red_high;\n    case 'unknown':\n    default:\n      return 'Unable to evaluate - check camera position';\n  }\n}\n\n// ============================================\n// Phase Detection\n// ============================================\n\nexport type MovementPhase = 'ready' | 'lunge' | 'overhead' | 'recovery' | 'general';\n\n/**\n * Detect the current movement phase from pose landmarks\n */\nexport function detectPhase(landmarks: PoseLandmark[]): MovementPhase {\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const rightElbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n  const rightKnee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n  const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n\n  // Check if arm is raised (overhead shot)\n  if (rightWrist.y < rightShoulder.y - 0.1) {\n    return 'overhead';\n  }\n\n  // Check knee angle for lunge detection\n  const kneeAngle = calculateAngle(rightHip, rightKnee, landmarks[POSE_LANDMARKS.RIGHT_ANKLE]);\n  if (kneeAngle < 120) {\n    return 'lunge';\n  }\n\n  // Check if in ready position (knees slightly bent, centered)\n  if (kneeAngle >= 130 && kneeAngle <= 160) {\n    return 'ready';\n  }\n\n  // Default to general\n  return 'general';\n}\n\n// ============================================\n// Comprehensive Banded Evaluation\n// ============================================\n\nexport interface BandedEvaluationResult {\n  phase: MovementPhase;\n  overall_band: ScoreBand;\n  overall_score: number; // 0-100\n  metrics: Record<string, BandedScore>;\n  feedback: string[];\n  highlight_joints: number[];\n}\n\n/**\n * Evaluate pose with banded scoring\n */\nexport function evaluateWithBands(\n  landmarks: PoseLandmark[],\n  skillLevel: 'beginner' | 'intermediate' | 'advanced' = 'intermediate',\n  forcePhase?: MovementPhase\n): BandedEvaluationResult {\n  // Calculate average confidence\n  const avgConfidence = landmarks.reduce((sum, l) => sum + (l.visibility || 0), 0) / landmarks.length;\n\n  // Detect phase\n  const phase = forcePhase || detectPhase(landmarks);\n  const phaseRule = SCORING_RULES_CONFIG.phase_rules[phase];\n\n  // Calculate metrics\n  const metrics: Record<string, BandedScore> = {};\n  const feedback: string[] = [];\n  const highlightJoints: number[] = [];\n  let totalScore = 0;\n  let metricCount = 0;\n\n  // Elbow angle\n  const shoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const elbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n  const wrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n  const elbowAngle = calculateAngle(shoulder, elbow, wrist);\n  const elbowConfidence = Math.min(shoulder.visibility, elbow.visibility, wrist.visibility);\n\n  const elbowIdeal = phaseRule?.thresholds?.elbow_angle || METRIC_DEFINITIONS.elbow_angle.ideal;\n  metrics.elbow_angle = calculateBand(elbowAngle, elbowIdeal, skillLevel, elbowConfidence);\n  metrics.elbow_angle.feedback = getBandedFeedback('elbow_angle', metrics.elbow_angle);\n\n  if (metrics.elbow_angle.band !== 'green' && metrics.elbow_angle.band !== 'unknown') {\n    feedback.push(metrics.elbow_angle.feedback!);\n    highlightJoints.push(POSE_LANDMARKS.RIGHT_ELBOW, POSE_LANDMARKS.RIGHT_WRIST);\n  }\n\n  // Knee angle\n  const hip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const knee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n  const ankle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n  const kneeAngle = calculateAngle(hip, knee, ankle);\n  const kneeConfidence = Math.min(hip.visibility, knee.visibility, ankle.visibility);\n\n  const kneeIdeal = phaseRule?.thresholds?.knee_angle || METRIC_DEFINITIONS.knee_angle.ideal;\n  metrics.knee_angle = calculateBand(kneeAngle, kneeIdeal, skillLevel, kneeConfidence);\n  metrics.knee_angle.feedback = getBandedFeedback('knee_angle', metrics.knee_angle);\n\n  if (metrics.knee_angle.band !== 'green' && metrics.knee_angle.band !== 'unknown') {\n    feedback.push(metrics.knee_angle.feedback!);\n    highlightJoints.push(POSE_LANDMARKS.RIGHT_KNEE, POSE_LANDMARKS.LEFT_KNEE);\n  }\n\n  // Stance width\n  const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n  const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n  const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n  const stanceWidth = shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n  const stanceConfidence = Math.min(leftAnkle.visibility, rightAnkle.visibility);\n\n  const stanceIdeal = phaseRule?.thresholds?.stance_width || METRIC_DEFINITIONS.stance_width.ideal;\n  metrics.stance_width = calculateBand(stanceWidth, stanceIdeal, skillLevel, stanceConfidence);\n  metrics.stance_width.feedback = getBandedFeedback('stance_width', metrics.stance_width);\n\n  if (metrics.stance_width.band !== 'green' && metrics.stance_width.band !== 'unknown') {\n    feedback.push(metrics.stance_width.feedback!);\n    highlightJoints.push(POSE_LANDMARKS.LEFT_ANKLE, POSE_LANDMARKS.RIGHT_ANKLE);\n  }\n\n  // Body rotation (for overhead phase)\n  if (phase === 'overhead' || !phaseRule) {\n    const leftHip = landmarks[POSE_LANDMARKS.LEFT_HIP];\n    const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n    const shoulderAngle = Math.atan2(\n      rightShoulder.y - leftShoulder.y,\n      rightShoulder.x - leftShoulder.x\n    );\n    const hipAngle = Math.atan2(rightHip.y - leftHip.y, rightHip.x - leftHip.x);\n    const rotation = Math.abs(shoulderAngle - hipAngle) * (180 / Math.PI);\n    const rotationConfidence = Math.min(\n      leftShoulder.visibility, rightShoulder.visibility,\n      leftHip.visibility, rightHip.visibility\n    );\n\n    const rotationIdeal = phaseRule?.thresholds?.body_rotation || METRIC_DEFINITIONS.body_rotation.ideal;\n    metrics.body_rotation = calculateBand(rotation, rotationIdeal, skillLevel, rotationConfidence);\n    metrics.body_rotation.feedback = getBandedFeedback('body_rotation', metrics.body_rotation);\n\n    if (metrics.body_rotation.band !== 'green' && metrics.body_rotation.band !== 'unknown') {\n      feedback.push(metrics.body_rotation.feedback!);\n    }\n  }\n\n  // Calculate overall score\n  const bandScores: Record<ScoreBand, number> = {\n    green: 100,\n    yellow: 70,\n    red: 30,\n    unknown: 50, // Neutral\n  };\n\n  Object.values(metrics).forEach(m => {\n    if (m.band !== 'unknown') {\n      totalScore += bandScores[m.band];\n      metricCount++;\n    }\n  });\n\n  const overallScore = metricCount > 0 ? totalScore / metricCount : 50;\n\n  // Determine overall band\n  let overallBand: ScoreBand;\n  const greenCount = Object.values(metrics).filter(m => m.band === 'green').length;\n  const redCount = Object.values(metrics).filter(m => m.band === 'red').length;\n  const validCount = Object.values(metrics).filter(m => m.band !== 'unknown').length;\n\n  if (validCount === 0) {\n    overallBand = 'unknown';\n  } else if (redCount > 0) {\n    overallBand = redCount > 1 ? 'red' : 'yellow';\n  } else if (greenCount === validCount) {\n    overallBand = 'green';\n  } else {\n    overallBand = 'yellow';\n  }\n\n  // Add encouraging feedback if all green\n  if (overallBand === 'green' && feedback.length === 0) {\n    feedback.push('Excellent form! Keep it up!');\n  }\n\n  return {\n    phase,\n    overall_band: overallBand,\n    overall_score: overallScore,\n    metrics,\n    feedback,\n    highlight_joints: highlightJoints,\n  };\n}\n\n// ============================================\n// Legend/Documentation for UI\n// ============================================\n\nexport const SCORING_LEGEND = {\n  green: {\n    label: 'Good',\n    description: 'Within coach-approved range for your skill level',\n    color: '#22c55e',\n    bgColor: '#dcfce7',\n  },\n  yellow: {\n    label: 'Minor Deviation',\n    description: 'Slightly outside ideal range - minor adjustment needed',\n    color: '#eab308',\n    bgColor: '#fef9c3',\n  },\n  red: {\n    label: 'Major Deviation',\n    description: 'Significantly outside ideal range - focus on this area',\n    color: '#ef4444',\n    bgColor: '#fee2e2',\n  },\n  unknown: {\n    label: 'Unknown',\n    description: 'Pose confidence too low to evaluate accurately',\n    color: '#9ca3af',\n    bgColor: '#f3f4f6',\n  },\n};\n\nexport const SKILL_LEVEL_DESCRIPTIONS = {\n  beginner: {\n    label: 'Beginner',\n    description: 'Wider tolerance bands - focus on basic form',\n    recommendation: 'Good for learning fundamentals without frustration',\n  },\n  intermediate: {\n    label: 'Intermediate',\n    description: 'Standard tolerance bands - balanced feedback',\n    recommendation: 'Ideal for most club-level players',\n  },\n  advanced: {\n    label: 'Advanced',\n    description: 'Strict tolerance bands - precision feedback',\n    recommendation: 'For competitive players seeking fine-tuning',\n  },\n};\n\n// ============================================\n// PHASE 3: Session-Level Validation\n// ============================================\n\n// Minimum thresholds for valid analysis\nexport const VALIDATION_THRESHOLDS = {\n  // Minimum ratio of frames with valid pose detection\n  MIN_POSE_COVERAGE: 0.7, // 70%\n  // Minimum average confidence across valid frames\n  MIN_CONFIDENCE: 0.5,\n  // Minimum number of consecutive frames to confirm an issue\n  MIN_ISSUE_PERSISTENCE: 3,\n  // Minimum number of frames with a deviation to report it\n  MIN_DEVIATION_FRAMES: 5,\n};\n\nexport interface SessionValidationResult {\n  isValid: boolean;\n  validPoseRatio: number;\n  avgConfidence: number;\n  totalFrames: number;\n  validPoseFrames: number;\n  lowConfidenceFrames: number;\n  noPoseFrames: number;\n  message: string;\n}\n\n/**\n * PHASE 3: Validate that a session has sufficient pose data for reliable analysis\n * Returns validation result with coverage stats and whether \"Great form\" can be shown\n */\nexport function validateSessionPoseData(\n  poseData: (PoseLandmark[] | null)[],\n  minCoverage: number = VALIDATION_THRESHOLDS.MIN_POSE_COVERAGE,\n  minConfidence: number = VALIDATION_THRESHOLDS.MIN_CONFIDENCE\n): SessionValidationResult {\n  const totalFrames = poseData.length;\n  let validPoseFrames = 0;\n  let lowConfidenceFrames = 0;\n  let noPoseFrames = 0;\n  let totalConfidence = 0;\n\n  for (const landmarks of poseData) {\n    if (!landmarks || landmarks.length === 0) {\n      noPoseFrames++;\n      continue;\n    }\n\n    // Calculate average visibility for this frame\n    const avgVisibility = landmarks.reduce((sum, lm) => sum + (lm.visibility || 0), 0) / landmarks.length;\n\n    if (avgVisibility >= minConfidence) {\n      validPoseFrames++;\n      totalConfidence += avgVisibility;\n    } else {\n      lowConfidenceFrames++;\n      totalConfidence += avgVisibility;\n    }\n  }\n\n  const validPoseRatio = totalFrames > 0 ? validPoseFrames / totalFrames : 0;\n  const avgConfidence = (validPoseFrames + lowConfidenceFrames) > 0\n    ? totalConfidence / (validPoseFrames + lowConfidenceFrames)\n    : 0;\n\n  // Determine if session is valid for scoring\n  const isValid = validPoseRatio >= minCoverage && avgConfidence >= minConfidence;\n\n  // Generate appropriate message\n  let message: string;\n  if (isValid) {\n    message = 'Sufficient pose data for reliable analysis';\n  } else if (validPoseRatio < minCoverage && avgConfidence < minConfidence) {\n    message = `Low pose coverage (${(validPoseRatio * 100).toFixed(0)}%) and low confidence (${(avgConfidence * 100).toFixed(0)}%). Results may not be accurate.`;\n  } else if (validPoseRatio < minCoverage) {\n    message = `Low pose coverage (${(validPoseRatio * 100).toFixed(0)}%). Ensure player is visible throughout the video.`;\n  } else {\n    message = `Low detection confidence (${(avgConfidence * 100).toFixed(0)}%). Check lighting and camera angle.`;\n  }\n\n  return {\n    isValid,\n    validPoseRatio,\n    avgConfidence,\n    totalFrames,\n    validPoseFrames,\n    lowConfidenceFrames,\n    noPoseFrames,\n    message,\n  };\n}\n\nexport interface SessionScoringResult {\n  validation: SessionValidationResult;\n  overall_band: ScoreBand;\n  overall_score: number;\n  greenFrameRatio: number;\n  yellowFrameRatio: number;\n  redFrameRatio: number;\n  persistentIssues: string[];\n  canShowGreatForm: boolean;\n  displayMessage: string;\n}\n\n/**\n * PHASE 3: Evaluate a full session with validation and persistence checks\n * This prevents false \"Great form!\" when pose data is insufficient\n */\nexport function evaluateSessionWithValidation(\n  poseData: (PoseLandmark[] | null)[],\n  skillLevel: 'beginner' | 'intermediate' | 'advanced' = 'intermediate'\n): SessionScoringResult {\n  // First validate the session has sufficient pose data\n  const validation = validateSessionPoseData(poseData);\n\n  // If not enough valid data, return unknown with explanation\n  if (!validation.isValid) {\n    return {\n      validation,\n      overall_band: 'unknown',\n      overall_score: 0,\n      greenFrameRatio: 0,\n      yellowFrameRatio: 0,\n      redFrameRatio: 0,\n      persistentIssues: [],\n      canShowGreatForm: false,\n      displayMessage: validation.message,\n    };\n  }\n\n  // Evaluate each valid frame\n  let greenFrames = 0;\n  let yellowFrames = 0;\n  let redFrames = 0;\n  let totalScore = 0;\n  let scoredFrames = 0;\n\n  // Track issue persistence across frames\n  const issueCounts: Record<string, number> = {};\n  let consecutiveIssue: Record<string, number> = {};\n\n  for (const landmarks of poseData) {\n    if (!landmarks || landmarks.length === 0) continue;\n\n    const avgVisibility = landmarks.reduce((sum, lm) => sum + (lm.visibility || 0), 0) / landmarks.length;\n    if (avgVisibility < VALIDATION_THRESHOLDS.MIN_CONFIDENCE) continue;\n\n    const evaluation = evaluateWithBands(landmarks, skillLevel);\n    scoredFrames++;\n    totalScore += evaluation.overall_score;\n\n    switch (evaluation.overall_band) {\n      case 'green':\n        greenFrames++;\n        // Reset consecutive issue counters\n        consecutiveIssue = {};\n        break;\n      case 'yellow':\n        yellowFrames++;\n        break;\n      case 'red':\n        redFrames++;\n        break;\n    }\n\n    // Track issue persistence\n    for (const fb of evaluation.feedback) {\n      if (fb !== 'Excellent form! Keep it up!') {\n        issueCounts[fb] = (issueCounts[fb] || 0) + 1;\n        consecutiveIssue[fb] = (consecutiveIssue[fb] || 0) + 1;\n      }\n    }\n  }\n\n  // Calculate ratios\n  const greenFrameRatio = scoredFrames > 0 ? greenFrames / scoredFrames : 0;\n  const yellowFrameRatio = scoredFrames > 0 ? yellowFrames / scoredFrames : 0;\n  const redFrameRatio = scoredFrames > 0 ? redFrames / scoredFrames : 0;\n  const avgScore = scoredFrames > 0 ? totalScore / scoredFrames : 0;\n\n  // Find persistent issues (appear in multiple frames)\n  const persistentIssues = Object.entries(issueCounts)\n    .filter(([_, count]) => count >= VALIDATION_THRESHOLDS.MIN_DEVIATION_FRAMES)\n    .sort((a, b) => b[1] - a[1])\n    .map(([issue, _]) => issue);\n\n  // Determine overall band\n  let overall_band: ScoreBand;\n  if (greenFrameRatio >= 0.7) {\n    overall_band = 'green';\n  } else if (greenFrameRatio >= 0.5 || yellowFrameRatio >= 0.5) {\n    overall_band = 'yellow';\n  } else {\n    overall_band = 'red';\n  }\n\n  // PHASE 3 FIX: Can only show \"Great form\" if:\n  // 1. Session validation passed (70%+ coverage, 50%+ confidence)\n  // 2. 70%+ of frames are green\n  // 3. No persistent red-level issues\n  const canShowGreatForm = validation.isValid &&\n    greenFrameRatio >= 0.7 &&\n    persistentIssues.length === 0;\n\n  // Generate appropriate display message\n  let displayMessage: string;\n  if (canShowGreatForm) {\n    displayMessage = 'Great form! No major issues detected.';\n  } else if (!validation.isValid) {\n    displayMessage = validation.message;\n  } else if (persistentIssues.length > 0) {\n    displayMessage = `${persistentIssues.length} issue${persistentIssues.length > 1 ? 's' : ''} detected. Focus on: ${persistentIssues[0]}`;\n  } else if (overall_band === 'yellow') {\n    displayMessage = 'Minor adjustments needed - review the highlighted areas.';\n  } else {\n    displayMessage = 'Form needs work - watch the tutorial videos for guidance.';\n  }\n\n  return {\n    validation,\n    overall_band,\n    overall_score: avgScore,\n    greenFrameRatio,\n    yellowFrameRatio,\n    redFrameRatio,\n    persistentIssues,\n    canShowGreatForm,\n    displayMessage,\n  };\n}\n","numLines":724,"startLine":1,"totalLines":724}},"sourceToolAssistantUUID":"d075fe5b-575d-463b-98b1-92b3f1c14426"}
{"parentUuid":"0a1cf767-e7fe-47cb-9d33-9cbfcc5f0972","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MK54ePpzPAK4EKpmBvDDu9","type":"tool_result","content":"     1→// Database types - supports both old and new schema\n     2→export interface Session {\n     3→  id: string;\n     4→  user_id: string;\n     5→  // Old schema\n     6→  mode?: string;\n     7→  started_at?: string;\n     8→  ended_at?: string | null;\n     9→  score_summary?: ScoreSummary;\n    10→  // New schema (from supabase-migration-v2)\n    11→  type?: 'analytics' | 'practice' | 'strategy';\n    12→  created_at: string;\n    13→  video_path?: string;\n    14→  video_url?: string;\n    15→  filename?: string;\n    16→  duration_seconds?: number;\n    17→  overall_score?: number;\n    18→  summary?: ScoreSummary;\n    19→  pose_data?: any[];\n    20→  frame_count?: number;\n    21→  // v3 enhanced schema\n    22→  status?: 'processing' | 'ready' | 'error';\n    23→  match_format?: 'singles' | 'doubles';\n    24→  event_type?: 'MS' | 'WS' | 'MD' | 'WD' | 'XD';\n    25→  selected_tracks?: number[];\n    26→  summary_score?: number;\n    27→  skill_level?: 'beginner' | 'intermediate' | 'advanced';\n    28→  rules_version?: string;\n    29→  tracks_data?: PlayerTrackData[];\n    30→  // Practice recording fields (v4)\n    31→  practice_video_path?: string;\n    32→  practice_video_mime?: string;\n    33→  practice_video_duration_sec?: number;\n    34→  practice_video_size_bytes?: number;\n    35→}\n    36→\n    37→export interface ScoreSummary {\n    38→  green_count?: number;\n    39→  green_frames?: number;\n    40→  red_count?: number;\n    41→  red_frames?: number;\n    42→  total_frames: number;\n    43→  average_score?: number;\n    44→  green_ratio?: number;\n    45→  drill_id?: string;\n    46→  drill_type?: string;\n    47→  metrics_avg?: PoseMetrics;\n    48→  shot_count?: number;\n    49→  error_count?: number;\n    50→  feedback?: any;\n    51→}\n    52→\n    53→export interface AnalysisResult {\n    54→  id: string;\n    55→  user_id: string;\n    56→  video_path: string;\n    57→  result_json: AnalysisResultJson | null;\n    58→  status: 'processing' | 'completed' | 'error';\n    59→  created_at: string;\n    60→}\n    61→\n    62→export interface AnalysisResultJson {\n    63→  top_issues: Issue[];\n    64→  drills: Drill[];\n    65→  technique_summary: string;\n    66→  strategy_summary: string;\n    67→  training_plan: TrainingPlanItem[];\n    68→  drill_visuals?: string[]; // URLs to generated drill images\n    69→}\n    70→\n    71→export interface Issue {\n    72→  id: string;\n    73→  title: string;\n    74→  severity: 'high' | 'medium' | 'low';\n    75→  description: string;\n    76→  affected_metrics: string[];\n    77→}\n    78→\n    79→export interface Drill {\n    80→  id: string;\n    81→  name: string;\n    82→  description: string;\n    83→  duration_minutes: number;\n    84→  target_metrics: string[];\n    85→  instructions: string[];\n    86→}\n    87→\n    88→export interface TrainingPlanItem {\n    89→  day: number;\n    90→  focus: string;\n    91→  drills: string[];\n    92→  duration_minutes: number;\n    93→}\n    94→\n    95→export interface RacketFavorite {\n    96→  id: string;\n    97→  user_id: string;\n    98→  racket_id: string;\n    99→  created_at: string;\n   100→}\n   101→\n   102→// Pose estimation types\n   103→export interface PoseMetrics {\n   104→  elbow_angle: number;\n   105→  knee_angle: number;\n   106→  stance_width_norm: number;\n   107→  shoulder_hip_rotation_proxy: number;\n   108→  timestamp?: number;\n   109→}\n   110→\n   111→export interface PoseLandmark {\n   112→  x: number;\n   113→  y: number;\n   114→  z: number;\n   115→  visibility: number;\n   116→}\n   117→\n   118→// API types\n   119→export interface TickRequest {\n   120→  metrics_snapshot: PoseMetrics;\n   121→  drill_id?: string;\n   122→  session_id?: string;\n   123→}\n   124→\n   125→export interface TickResponse {\n   126→  cue: string;\n   127→  focus_metric: string;\n   128→  green_thresholds: {\n   129→    [key: string]: { min: number; max: number };\n   130→  };\n   131→  is_green: boolean;\n   132→}\n   133→\n   134→export interface RacketRecommendRequest {\n   135→  level: 'beginner' | 'intermediate' | 'advanced';\n   136→  weaknesses: string[];\n   137→  style_pref?: 'power' | 'control' | 'all-round';\n   138→}\n   139→\n   140→export interface Racket {\n   141→  id: string;\n   142→  name: string;\n   143→  brand: string;\n   144→  price_band: 'budget' | 'mid-range' | 'premium';\n   145→  price_range: string;\n   146→  play_style: string[];\n   147→  skill_level: string[];\n   148→  weight: string;\n   149→  balance: string;\n   150→  flexibility: string;\n   151→  description: string;\n   152→  image_url: string;\n   153→  ebay_search_query: string;\n   154→}\n   155→\n   156→export interface RacketRecommendation extends Racket {\n   157→  match_score: number;\n   158→  match_reason: string;\n   159→}\n   160→\n   161→// Chart data types\n   162→export interface ChartDataPoint {\n   163→  date: string;\n   164→  score: number;\n   165→  greenRatio?: number;\n   166→  checkIns?: number;\n   167→}\n   168→\n   169→// User profile\n   170→export interface UserProfile {\n   171→  id: string;\n   172→  email: string;\n   173→  created_at: string;\n   174→}\n   175→\n   176→// ============================================\n   177→// V3 Enhanced Types\n   178→// ============================================\n   179→\n   180→// Session assets for persistent storage\n   181→export interface SessionAsset {\n   182→  id: string;\n   183→  session_id: string;\n   184→  kind: 'video' | 'analysis_json' | 'pose_json' | 'keyframe1' | 'keyframe2' | 'keyframe3' | 'trajectory_json' | 'trajectory_video' | 'tracks_thumbnail';\n   185→  storage_path: string;\n   186→  storage_bucket: string;\n   187→  metadata?: Record<string, any>;\n   188→  created_at: string;\n   189→}\n   190→\n   191→// Player track data for multi-person tracking\n   192→export interface PlayerTrackData {\n   193→  track_id: number;\n   194→  thumbnail_url?: string;\n   195→  bbox_samples: BoundingBoxSample[];\n   196→  side?: 'near' | 'far';\n   197→  is_selected: boolean;\n   198→  confidence_avg: number;\n   199→  frame_count: number;\n   200→}\n   201→\n   202→export interface BoundingBoxSample {\n   203→  frame: number;\n   204→  x: number;\n   205→  y: number;\n   206→  w: number;\n   207→  h: number;\n   208→  confidence?: number;\n   209→}\n   210→\n   211→// Strategy mode types\n   212→export interface StrategyResult {\n   213→  id: string;\n   214→  session_id: string;\n   215→  original_trajectory: TrajectoryPoint[];\n   216→  refined_trajectory: TrajectoryPoint[];\n   217→  coaching_points: string[];\n   218→  court_homography?: number[][];\n   219→  shuttle_detections?: ShuttleDetection[];\n   220→  created_at: string;\n   221→}\n   222→\n   223→export interface TrajectoryPoint {\n   224→  x: number;\n   225→  y: number;\n   226→  timestamp: number;\n   227→  court_x?: number; // Court-mapped x coordinate (0-1)\n   228→  court_y?: number; // Court-mapped y coordinate (0-1)\n   229→}\n   230→\n   231→export interface ShuttleDetection {\n   232→  frame: number;\n   233→  x: number;\n   234→  y: number;\n   235→  confidence: number;\n   236→}\n   237→\n   238→// Banded scoring types\n   239→export type ScoreBand = 'green' | 'yellow' | 'red' | 'unknown';\n   240→\n   241→export interface BandedScore {\n   242→  band: ScoreBand;\n   243→  value: number;\n   244→  confidence: number;\n   245→  feedback?: string;\n   246→}\n   247→\n   248→export interface ScoringRulesConfig {\n   249→  version: string;\n   250→  skill_bands: {\n   251→    beginner: SkillBandConfig;\n   252→    intermediate: SkillBandConfig;\n   253→    advanced: SkillBandConfig;\n   254→  };\n   255→  confidence_threshold: number;\n   256→  phase_rules: Record<string, PhaseRule>;\n   257→}\n   258→\n   259→export interface SkillBandConfig {\n   260→  green_tolerance: number; // Percentage wider than ideal\n   261→  yellow_tolerance: number; // Percentage wider than green\n   262→}\n   263→\n   264→export interface PhaseRule {\n   265→  name: string;\n   266→  applicable_metrics: string[];\n   267→  thresholds: Record<string, { min: number; max: number }>;\n   268→}\n   269→\n   270→// Multi-pose detection result\n   271→export interface MultiPoseResult {\n   272→  poses: DetectedPose[];\n   273→  timestamp: number;\n   274→}\n   275→\n   276→export interface DetectedPose {\n   277→  track_id: number;\n   278→  landmarks: PoseLandmark[];\n   279→  bbox: { x: number; y: number; w: number; h: number };\n   280→  confidence: number;\n   281→}\n   282→\n   283→// Event type labels\n   284→export const EVENT_TYPE_LABELS: Record<string, string> = {\n   285→  MS: \"Men's Singles\",\n   286→  WS: \"Women's Singles\",\n   287→  MD: \"Men's Doubles\",\n   288→  WD: \"Women's Doubles\",\n   289→  XD: 'Mixed Doubles',\n   290→};\n   291→\n   292→// 3D Skeleton animation types\n   293→export interface SkeletonKeyframe {\n   294→  label: string;\n   295→  landmarks: { x: number; y: number; z: number }[];\n   296→  timestamp: number;\n   297→}\n   298→\n   299→export interface AnimatedDrill {\n   300→  id: string;\n   301→  name: string;\n   302→  phases: DrillPhase[];\n   303→  loop: boolean;\n   304→  duration_ms: number;\n   305→}\n   306→\n   307→export interface DrillPhase {\n   308→  name: string;\n   309→  keyframes: SkeletonKeyframe[];\n   310→  duration_ms: number;\n   311→}\n   312→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"fa2d635c-6457-493a-a7b4-ea9295995f7a","timestamp":"2026-01-28T05:06:37.545Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\types.ts","content":"// Database types - supports both old and new schema\nexport interface Session {\n  id: string;\n  user_id: string;\n  // Old schema\n  mode?: string;\n  started_at?: string;\n  ended_at?: string | null;\n  score_summary?: ScoreSummary;\n  // New schema (from supabase-migration-v2)\n  type?: 'analytics' | 'practice' | 'strategy';\n  created_at: string;\n  video_path?: string;\n  video_url?: string;\n  filename?: string;\n  duration_seconds?: number;\n  overall_score?: number;\n  summary?: ScoreSummary;\n  pose_data?: any[];\n  frame_count?: number;\n  // v3 enhanced schema\n  status?: 'processing' | 'ready' | 'error';\n  match_format?: 'singles' | 'doubles';\n  event_type?: 'MS' | 'WS' | 'MD' | 'WD' | 'XD';\n  selected_tracks?: number[];\n  summary_score?: number;\n  skill_level?: 'beginner' | 'intermediate' | 'advanced';\n  rules_version?: string;\n  tracks_data?: PlayerTrackData[];\n  // Practice recording fields (v4)\n  practice_video_path?: string;\n  practice_video_mime?: string;\n  practice_video_duration_sec?: number;\n  practice_video_size_bytes?: number;\n}\n\nexport interface ScoreSummary {\n  green_count?: number;\n  green_frames?: number;\n  red_count?: number;\n  red_frames?: number;\n  total_frames: number;\n  average_score?: number;\n  green_ratio?: number;\n  drill_id?: string;\n  drill_type?: string;\n  metrics_avg?: PoseMetrics;\n  shot_count?: number;\n  error_count?: number;\n  feedback?: any;\n}\n\nexport interface AnalysisResult {\n  id: string;\n  user_id: string;\n  video_path: string;\n  result_json: AnalysisResultJson | null;\n  status: 'processing' | 'completed' | 'error';\n  created_at: string;\n}\n\nexport interface AnalysisResultJson {\n  top_issues: Issue[];\n  drills: Drill[];\n  technique_summary: string;\n  strategy_summary: string;\n  training_plan: TrainingPlanItem[];\n  drill_visuals?: string[]; // URLs to generated drill images\n}\n\nexport interface Issue {\n  id: string;\n  title: string;\n  severity: 'high' | 'medium' | 'low';\n  description: string;\n  affected_metrics: string[];\n}\n\nexport interface Drill {\n  id: string;\n  name: string;\n  description: string;\n  duration_minutes: number;\n  target_metrics: string[];\n  instructions: string[];\n}\n\nexport interface TrainingPlanItem {\n  day: number;\n  focus: string;\n  drills: string[];\n  duration_minutes: number;\n}\n\nexport interface RacketFavorite {\n  id: string;\n  user_id: string;\n  racket_id: string;\n  created_at: string;\n}\n\n// Pose estimation types\nexport interface PoseMetrics {\n  elbow_angle: number;\n  knee_angle: number;\n  stance_width_norm: number;\n  shoulder_hip_rotation_proxy: number;\n  timestamp?: number;\n}\n\nexport interface PoseLandmark {\n  x: number;\n  y: number;\n  z: number;\n  visibility: number;\n}\n\n// API types\nexport interface TickRequest {\n  metrics_snapshot: PoseMetrics;\n  drill_id?: string;\n  session_id?: string;\n}\n\nexport interface TickResponse {\n  cue: string;\n  focus_metric: string;\n  green_thresholds: {\n    [key: string]: { min: number; max: number };\n  };\n  is_green: boolean;\n}\n\nexport interface RacketRecommendRequest {\n  level: 'beginner' | 'intermediate' | 'advanced';\n  weaknesses: string[];\n  style_pref?: 'power' | 'control' | 'all-round';\n}\n\nexport interface Racket {\n  id: string;\n  name: string;\n  brand: string;\n  price_band: 'budget' | 'mid-range' | 'premium';\n  price_range: string;\n  play_style: string[];\n  skill_level: string[];\n  weight: string;\n  balance: string;\n  flexibility: string;\n  description: string;\n  image_url: string;\n  ebay_search_query: string;\n}\n\nexport interface RacketRecommendation extends Racket {\n  match_score: number;\n  match_reason: string;\n}\n\n// Chart data types\nexport interface ChartDataPoint {\n  date: string;\n  score: number;\n  greenRatio?: number;\n  checkIns?: number;\n}\n\n// User profile\nexport interface UserProfile {\n  id: string;\n  email: string;\n  created_at: string;\n}\n\n// ============================================\n// V3 Enhanced Types\n// ============================================\n\n// Session assets for persistent storage\nexport interface SessionAsset {\n  id: string;\n  session_id: string;\n  kind: 'video' | 'analysis_json' | 'pose_json' | 'keyframe1' | 'keyframe2' | 'keyframe3' | 'trajectory_json' | 'trajectory_video' | 'tracks_thumbnail';\n  storage_path: string;\n  storage_bucket: string;\n  metadata?: Record<string, any>;\n  created_at: string;\n}\n\n// Player track data for multi-person tracking\nexport interface PlayerTrackData {\n  track_id: number;\n  thumbnail_url?: string;\n  bbox_samples: BoundingBoxSample[];\n  side?: 'near' | 'far';\n  is_selected: boolean;\n  confidence_avg: number;\n  frame_count: number;\n}\n\nexport interface BoundingBoxSample {\n  frame: number;\n  x: number;\n  y: number;\n  w: number;\n  h: number;\n  confidence?: number;\n}\n\n// Strategy mode types\nexport interface StrategyResult {\n  id: string;\n  session_id: string;\n  original_trajectory: TrajectoryPoint[];\n  refined_trajectory: TrajectoryPoint[];\n  coaching_points: string[];\n  court_homography?: number[][];\n  shuttle_detections?: ShuttleDetection[];\n  created_at: string;\n}\n\nexport interface TrajectoryPoint {\n  x: number;\n  y: number;\n  timestamp: number;\n  court_x?: number; // Court-mapped x coordinate (0-1)\n  court_y?: number; // Court-mapped y coordinate (0-1)\n}\n\nexport interface ShuttleDetection {\n  frame: number;\n  x: number;\n  y: number;\n  confidence: number;\n}\n\n// Banded scoring types\nexport type ScoreBand = 'green' | 'yellow' | 'red' | 'unknown';\n\nexport interface BandedScore {\n  band: ScoreBand;\n  value: number;\n  confidence: number;\n  feedback?: string;\n}\n\nexport interface ScoringRulesConfig {\n  version: string;\n  skill_bands: {\n    beginner: SkillBandConfig;\n    intermediate: SkillBandConfig;\n    advanced: SkillBandConfig;\n  };\n  confidence_threshold: number;\n  phase_rules: Record<string, PhaseRule>;\n}\n\nexport interface SkillBandConfig {\n  green_tolerance: number; // Percentage wider than ideal\n  yellow_tolerance: number; // Percentage wider than green\n}\n\nexport interface PhaseRule {\n  name: string;\n  applicable_metrics: string[];\n  thresholds: Record<string, { min: number; max: number }>;\n}\n\n// Multi-pose detection result\nexport interface MultiPoseResult {\n  poses: DetectedPose[];\n  timestamp: number;\n}\n\nexport interface DetectedPose {\n  track_id: number;\n  landmarks: PoseLandmark[];\n  bbox: { x: number; y: number; w: number; h: number };\n  confidence: number;\n}\n\n// Event type labels\nexport const EVENT_TYPE_LABELS: Record<string, string> = {\n  MS: \"Men's Singles\",\n  WS: \"Women's Singles\",\n  MD: \"Men's Doubles\",\n  WD: \"Women's Doubles\",\n  XD: 'Mixed Doubles',\n};\n\n// 3D Skeleton animation types\nexport interface SkeletonKeyframe {\n  label: string;\n  landmarks: { x: number; y: number; z: number }[];\n  timestamp: number;\n}\n\nexport interface AnimatedDrill {\n  id: string;\n  name: string;\n  phases: DrillPhase[];\n  loop: boolean;\n  duration_ms: number;\n}\n\nexport interface DrillPhase {\n  name: string;\n  keyframes: SkeletonKeyframe[];\n  duration_ms: number;\n}\n","numLines":312,"startLine":1,"totalLines":312}},"sourceToolAssistantUUID":"0a1cf767-e7fe-47cb-9d33-9cbfcc5f0972"}
{"parentUuid":"115a176d-9ca9-40cf-8b4d-48b96b5fcd51","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012MKSpx34F4UfpDfeCCtvL3","type":"tool_result","content":"     1→import os\n     2→import requests\n     3→import json\n     4→from dotenv import load_dotenv\n     5→\n     6→load_dotenv()\n     7→\n     8→def generate_coaching_feedback(analysis_summary, user_lang=\"en\"):\n     9→    \"\"\"\n    10→    Call Gemini 3 API to generate coaching feedback.\n    11→\n    12→    Args:\n    13→        analysis_summary: Text summary of shot analysis\n    14→        user_lang: User's preferred language (\"en\" or \"zh\")\n    15→\n    16→    Returns:\n    17→        Structured feedback from Gemini\n    18→    \"\"\"\n    19→    api_key = os.getenv(\"GEMINI_API_KEY\")\n    20→\n    21→    if not api_key or api_key == \"your-gemini-api-key-here\":\n    22→        return {\n    23→            \"technique\": \"Please configure your Gemini API key to get AI-generated feedback.\",\n    24→            \"strategy\": \"Set GEMINI_API_KEY in your .env file.\",\n    25→            \"training_plan\": [\"Configure API key\", \"Upload video\", \"Get real feedback\"]\n    26→        }\n    27→\n    28→    prompt = f\"\"\"\n    29→You are a professional badminton coach. Analyze the following performance data and provide coaching feedback.\n    30→\n    31→{analysis_summary}\n    32→\n    33→Provide feedback in the following format:\n    34→\n    35→Technique: <Explain what the player can improve in their form, focusing on specific issues found>\n    36→\n    37→Strategy: <Suggest in-game strategy improvements based on shot patterns>\n    38→\n    39→Training Plan:\n    40→- <Drill 1 to address weaknesses>\n    41→- <Drill 2 to address weaknesses>\n    42→- <Drill 3 to address weaknesses>\n    43→\n    44→Respond in {'Chinese' if user_lang.startswith('zh') else 'English'}.\n    45→\"\"\"\n    46→\n    47→    GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent\"\n    48→    headers = { \"Content-Type\": \"application/json\" }\n    49→    payload = {\n    50→        \"contents\": [{\"parts\": [{\"text\": prompt}]}]\n    51→    }\n    52→\n    53→    try:\n    54→        response = requests.post(\n    55→            f\"{GEMINI_API_URL}?key={api_key}\",\n    56→            headers=headers,\n    57→            data=json.dumps(payload)\n    58→        )\n    59→\n    60→        if response.status_code != 200:\n    61→            raise Exception(f\"Gemini API Error {response.status_code}: {response.text}\")\n    62→\n    63→        output_text = response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"].strip()\n    64→        feedback = parse_feedback(output_text)\n    65→        return feedback\n    66→\n    67→    except Exception as e:\n    68→        print(f\"Error calling Gemini API: {e}\")\n    69→        return {\n    70→            \"technique\": f\"Error generating feedback: {str(e)}\",\n    71→            \"strategy\": \"Please check your API key and try again.\",\n    72→            \"training_plan\": [\"Check API configuration\", \"Retry analysis\"]\n    73→        }\n    74→\n    75→\n    76→def parse_feedback(output_text):\n    77→    \"\"\"Parse Gemini output into structured feedback.\"\"\"\n    78→    feedback = {\n    79→        \"technique\": \"\",\n    80→        \"strategy\": \"\",\n    81→        \"training_plan\": []\n    82→    }\n    83→\n    84→    lines = output_text.split('\\n')\n    85→    current_section = None\n    86→\n    87→    for line in lines:\n    88→        line_lower = line.lower().strip()\n    89→\n    90→        if line_lower.startswith(\"technique:\"):\n    91→            current_section = \"technique\"\n    92→            feedback[\"technique\"] = line.split(\":\", 1)[1].strip()\n    93→        elif line_lower.startswith(\"strategy:\"):\n    94→            current_section = \"strategy\"\n    95→            feedback[\"strategy\"] = line.split(\":\", 1)[1].strip()\n    96→        elif line_lower.startswith(\"training plan\"):\n    97→            current_section = \"training_plan\"\n    98→        elif current_section == \"training_plan\" and line.strip().startswith(\"-\"):\n    99→            feedback[\"training_plan\"].append(line.strip().lstrip(\"-\").strip())\n   100→        elif current_section and line.strip() and not line.strip().startswith(\"#\"):\n   101→            if current_section != \"training_plan\":\n   102→                feedback[current_section] += \" \" + line.strip()\n   103→\n   104→    return feedback\n   105→\n   106→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"6c988e9b-70a2-4dd7-89dd-49480eea505b","timestamp":"2026-01-28T05:06:37.545Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\gemini_client.py","content":"import os\nimport requests\nimport json\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ndef generate_coaching_feedback(analysis_summary, user_lang=\"en\"):\n    \"\"\"\n    Call Gemini 3 API to generate coaching feedback.\n\n    Args:\n        analysis_summary: Text summary of shot analysis\n        user_lang: User's preferred language (\"en\" or \"zh\")\n\n    Returns:\n        Structured feedback from Gemini\n    \"\"\"\n    api_key = os.getenv(\"GEMINI_API_KEY\")\n\n    if not api_key or api_key == \"your-gemini-api-key-here\":\n        return {\n            \"technique\": \"Please configure your Gemini API key to get AI-generated feedback.\",\n            \"strategy\": \"Set GEMINI_API_KEY in your .env file.\",\n            \"training_plan\": [\"Configure API key\", \"Upload video\", \"Get real feedback\"]\n        }\n\n    prompt = f\"\"\"\nYou are a professional badminton coach. Analyze the following performance data and provide coaching feedback.\n\n{analysis_summary}\n\nProvide feedback in the following format:\n\nTechnique: <Explain what the player can improve in their form, focusing on specific issues found>\n\nStrategy: <Suggest in-game strategy improvements based on shot patterns>\n\nTraining Plan:\n- <Drill 1 to address weaknesses>\n- <Drill 2 to address weaknesses>\n- <Drill 3 to address weaknesses>\n\nRespond in {'Chinese' if user_lang.startswith('zh') else 'English'}.\n\"\"\"\n\n    GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent\"\n    headers = { \"Content-Type\": \"application/json\" }\n    payload = {\n        \"contents\": [{\"parts\": [{\"text\": prompt}]}]\n    }\n\n    try:\n        response = requests.post(\n            f\"{GEMINI_API_URL}?key={api_key}\",\n            headers=headers,\n            data=json.dumps(payload)\n        )\n\n        if response.status_code != 200:\n            raise Exception(f\"Gemini API Error {response.status_code}: {response.text}\")\n\n        output_text = response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"].strip()\n        feedback = parse_feedback(output_text)\n        return feedback\n\n    except Exception as e:\n        print(f\"Error calling Gemini API: {e}\")\n        return {\n            \"technique\": f\"Error generating feedback: {str(e)}\",\n            \"strategy\": \"Please check your API key and try again.\",\n            \"training_plan\": [\"Check API configuration\", \"Retry analysis\"]\n        }\n\n\ndef parse_feedback(output_text):\n    \"\"\"Parse Gemini output into structured feedback.\"\"\"\n    feedback = {\n        \"technique\": \"\",\n        \"strategy\": \"\",\n        \"training_plan\": []\n    }\n\n    lines = output_text.split('\\n')\n    current_section = None\n\n    for line in lines:\n        line_lower = line.lower().strip()\n\n        if line_lower.startswith(\"technique:\"):\n            current_section = \"technique\"\n            feedback[\"technique\"] = line.split(\":\", 1)[1].strip()\n        elif line_lower.startswith(\"strategy:\"):\n            current_section = \"strategy\"\n            feedback[\"strategy\"] = line.split(\":\", 1)[1].strip()\n        elif line_lower.startswith(\"training plan\"):\n            current_section = \"training_plan\"\n        elif current_section == \"training_plan\" and line.strip().startswith(\"-\"):\n            feedback[\"training_plan\"].append(line.strip().lstrip(\"-\").strip())\n        elif current_section and line.strip() and not line.strip().startswith(\"#\"):\n            if current_section != \"training_plan\":\n                feedback[current_section] += \" \" + line.strip()\n\n    return feedback\n\n","numLines":106,"startLine":1,"totalLines":106}},"sourceToolAssistantUUID":"115a176d-9ca9-40cf-8b4d-48b96b5fcd51"}
{"parentUuid":"7d166515-38d4-4c0a-b656-6784f381506f","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01F4ctpnmsTTbsnfmX8iDpHx","type":"tool_result","content":"     1→import cv2\n     2→import numpy as np\n     3→import mediapipe as mp\n     4→\n     5→class VideoAnnotator:\n     6→    def __init__(self):\n     7→        self.mp_pose = mp.solutions.pose\n     8→        self.mp_drawing = mp.solutions.drawing_utils\n     9→        self.mp_drawing_styles = mp.solutions.drawing_styles\n    10→        \n    11→        # Colors (BGR)\n    12→        self.COLOR_GOOD = (0, 255, 0)    # Green\n    13→        self.COLOR_BAD = (0, 0, 255)     # Red\n    14→        self.COLOR_TEXT = (255, 255, 255) # White\n    15→        self.COLOR_GHOST = (255, 200, 100) # Light Blue for ghost\n    16→\n    17→    def draw_text_with_background(self, img, text, pos, font_scale=0.6, thickness=1, color=(255, 255, 255), bg_color=(0, 0, 0)):\n    18→        \"\"\"Helper to draw text with a contrasting background\"\"\"\n    19→        font = cv2.FONT_HERSHEY_SIMPLEX\n    20→        (text_w, text_h), _ = cv2.getTextSize(text, font, font_scale, thickness)\n    21→        x, y = pos\n    22→        cv2.rectangle(img, (x - 5, y - text_h - 5), (x + text_w + 5, y + 5), bg_color, -1)\n    23→        cv2.putText(img, text, (x, y), font, font_scale, color, thickness)\n    24→\n    25→    def add_ideal_pose_ghost(self, frame, current_pose_landmarks):\n    26→        \"\"\"\n    27→        Draws a semi-transparent 'Ghost' pose. \n    28→        In a real app, 'ideal_pose' would come from a database of pro shots.\n    29→        For now, we visualize the current pose as a ghost for style.\n    30→        \"\"\"\n    31→        overlay = frame.copy()\n    32→        if current_pose_landmarks:\n    33→            self.mp_drawing.draw_landmarks(\n    34→                overlay,\n    35→                current_pose_landmarks,\n    36→                self.mp_pose.POSE_CONNECTIONS,\n    37→                landmark_drawing_spec=self.mp_drawing.DrawingSpec(color=self.COLOR_GHOST, thickness=2, circle_radius=2),\n    38→                connection_drawing_spec=self.mp_drawing.DrawingSpec(color=self.COLOR_GHOST, thickness=2)\n    39→            )\n    40→        return cv2.addWeighted(frame, 1.0, overlay, 0.3, 0)\n    41→\n    42→    def create_annotated_video(self, input_path, output_path, analysis_result):\n    43→        \"\"\"\n    44→        Generates the final video with Iron-Man style overlays.\n    45→        \"\"\"\n    46→        cap = cv2.VideoCapture(input_path)\n    47→        if not cap.isOpened():\n    48→            return None\n    49→\n    50→        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    51→        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    52→        fps = int(cap.get(cv2.CAP_PROP_FPS))\n    53→        \n    54→        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    55→        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n    56→\n    57→        # Data lookups\n    58→        shots = analysis_result.get('shots', [])\n    59→        # Map frame number to specific shot data for O(1) lookup\n    60→        shot_map = {shot['frame']: shot for shot in shots}\n    61→        \n    62→        frame_idx = 0\n    63→        \n    64→        with self.mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n    65→            while cap.isOpened():\n    66→                ret, frame = cap.read()\n    67→                if not ret:\n    68→                    break\n    69→\n    70→                # 1. Process Pose\n    71→                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    72→                results = pose.process(image_rgb)\n    73→\n    74→                # 2. Check for Shot Event\n    75→                current_shot = None\n    76→                # Check within a small window (e.g., 5 frames) to keep text on screen longer\n    77→                for f_key in shot_map:\n    78→                    if 0 <= frame_idx - f_key < 30: # Show shot info for 1 second (30 frames)\n    79→                        current_shot = shot_map[f_key]\n    80→                        break\n    81→\n    82→                # 3. Draw Overlays\n    83→                if results.pose_landmarks:\n    84→                    # Draw Ghost (Optional - nice visual touch)\n    85→                    # frame = self.add_ideal_pose_ghost(frame, results.pose_landmarks)\n    86→\n    87→                    # Draw Main Skeleton\n    88→                    # Color based on quality if inside a shot event\n    89→                    connection_color = self.COLOR_GOOD\n    90→                    if current_shot and current_shot.get('pose_errors'):\n    91→                        connection_color = self.COLOR_BAD\n    92→\n    93→                    self.mp_drawing.draw_landmarks(\n    94→                        frame,\n    95→                        results.pose_landmarks,\n    96→                        self.mp_pose.POSE_CONNECTIONS,\n    97→                        landmark_drawing_spec=self.mp_drawing.DrawingSpec(color=connection_color, thickness=2, circle_radius=2),\n    98→                        connection_drawing_spec=self.mp_drawing.DrawingSpec(color=connection_color, thickness=2)\n    99→                    )\n   100→\n   101→                # 4. Draw HUD / Text Info\n   102→                if current_shot:\n   103→                    # Top Left: Shot Type\n   104→                    self.draw_text_with_background(frame, f\"SHOT: {current_shot['shot_type']}\", (20, 50), 1.2, 2)\n   105→                    \n   106→                    # Bottom Left: Errors or Good Form\n   107→                    if current_shot.get('pose_errors'):\n   108→                        y_pos = 100\n   109→                        for err in current_shot['pose_errors']:\n   110→                            self.draw_text_with_background(frame, f\"FIX: {err}\", (20, y_pos), 0.7, 1, self.COLOR_BAD)\n   111→                            y_pos += 30\n   112→                    else:\n   113→                        self.draw_text_with_background(frame, \"PERFECT FORM\", (20, 100), 0.8, 2, self.COLOR_GOOD)\n   114→\n   115→                    # Top Right: Tactical Suggestion (from CoachAI logic)\n   116→                    if 'suggestion' in current_shot:\n   117→                        self.draw_text_with_background(frame, f\"COACH: {current_shot['suggestion']}\", (width - 400, 50), 0.7, 1, (0, 255, 255))\n   118→\n   119→                # Frame Counter\n   120→                cv2.putText(frame, f\"Frame: {frame_idx}\", (width - 150, height - 30), \n   121→                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n   122→\n   123→                out.write(frame)\n   124→                frame_idx += 1\n   125→\n   126→        cap.release()\n   127→        out.release()\n   128→        return output_path\n   129→\n   130→\n   131→# Standalone function for compatibility with main.py\n   132→def create_annotated_video_with_analysis(input_path, output_path, pose_data, shot_events):\n   133→    \"\"\"\n   134→    Wrapper function that creates annotated video using pose_data and shot_events.\n   135→    This matches the interface expected by main.py\n   136→    \"\"\"\n   137→    from video_processing import draw_skeleton_on_frame\n   138→\n   139→    cap = cv2.VideoCapture(input_path)\n   140→    if not cap.isOpened():\n   141→        print(f\"Error: Could not open video {input_path}\")\n   142→        return None\n   143→\n   144→    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n   145→    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n   146→    fps = int(cap.get(cv2.CAP_PROP_FPS))\n   147→    if fps == 0:\n   148→        fps = 30  # Default fallback\n   149→\n   150→    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n   151→    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n   152→\n   153→    # Map frame numbers to shots for quick lookup\n   154→    shot_map = {shot['frame']: shot for shot in shot_events}\n   155→\n   156→    frame_idx = 0\n   157→\n   158→    while True:\n   159→        ret, frame = cap.read()\n   160→        if not ret:\n   161→            break\n   162→\n   163→        # Get pose for this frame\n   164→        pose = pose_data[frame_idx] if frame_idx < len(pose_data) else None\n   165→\n   166→        # Check if this frame has a shot event (with 30 frame window)\n   167→        current_shot = None\n   168→        for shot_frame in shot_map:\n   169→            if 0 <= frame_idx - shot_frame < 30:\n   170→                current_shot = shot_map[shot_frame]\n   171→                break\n   172→\n   173→        # Draw skeleton if pose data exists\n   174→        if pose:\n   175→            is_good_form = True\n   176→            if current_shot and current_shot.get('pose_errors'):\n   177→                is_good_form = False\n   178→\n   179→            frame = draw_skeleton_on_frame(frame, pose, None, is_good_form)\n   180→\n   181→        # Add shot information overlay\n   182→        if current_shot:\n   183→            shot_type = current_shot.get('shot_type', 'SHOT')\n   184→            cv2.putText(frame, f\"SHOT: {shot_type}\", (20, 50),\n   185→                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 2)\n   186→\n   187→            # Show errors or good form message\n   188→            if current_shot.get('pose_errors'):\n   189→                y_pos = 100\n   190→                for error in current_shot['pose_errors'][:3]:  # Max 3 errors\n   191→                    cv2.putText(frame, f\"FIX: {error}\", (20, y_pos),\n   192→                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n   193→                    y_pos += 30\n   194→            else:\n   195→                cv2.putText(frame, \"GOOD FORM\", (20, 100),\n   196→                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n   197→\n   198→        # Frame counter\n   199→        cv2.putText(frame, f\"Frame: {frame_idx}\", (width - 150, height - 30),\n   200→                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n   201→\n   202→        out.write(frame)\n   203→        frame_idx += 1\n   204→\n   205→    cap.release()\n   206→    out.release()\n   207→    print(f\"Annotated video created: {output_path}\")\n   208→    return output_path\n   209→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"847fe94a-dbc2-42a4-aef7-0dc2529da74d","timestamp":"2026-01-28T05:06:37.545Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\backend\\video_annotator.py","content":"import cv2\nimport numpy as np\nimport mediapipe as mp\n\nclass VideoAnnotator:\n    def __init__(self):\n        self.mp_pose = mp.solutions.pose\n        self.mp_drawing = mp.solutions.drawing_utils\n        self.mp_drawing_styles = mp.solutions.drawing_styles\n        \n        # Colors (BGR)\n        self.COLOR_GOOD = (0, 255, 0)    # Green\n        self.COLOR_BAD = (0, 0, 255)     # Red\n        self.COLOR_TEXT = (255, 255, 255) # White\n        self.COLOR_GHOST = (255, 200, 100) # Light Blue for ghost\n\n    def draw_text_with_background(self, img, text, pos, font_scale=0.6, thickness=1, color=(255, 255, 255), bg_color=(0, 0, 0)):\n        \"\"\"Helper to draw text with a contrasting background\"\"\"\n        font = cv2.FONT_HERSHEY_SIMPLEX\n        (text_w, text_h), _ = cv2.getTextSize(text, font, font_scale, thickness)\n        x, y = pos\n        cv2.rectangle(img, (x - 5, y - text_h - 5), (x + text_w + 5, y + 5), bg_color, -1)\n        cv2.putText(img, text, (x, y), font, font_scale, color, thickness)\n\n    def add_ideal_pose_ghost(self, frame, current_pose_landmarks):\n        \"\"\"\n        Draws a semi-transparent 'Ghost' pose. \n        In a real app, 'ideal_pose' would come from a database of pro shots.\n        For now, we visualize the current pose as a ghost for style.\n        \"\"\"\n        overlay = frame.copy()\n        if current_pose_landmarks:\n            self.mp_drawing.draw_landmarks(\n                overlay,\n                current_pose_landmarks,\n                self.mp_pose.POSE_CONNECTIONS,\n                landmark_drawing_spec=self.mp_drawing.DrawingSpec(color=self.COLOR_GHOST, thickness=2, circle_radius=2),\n                connection_drawing_spec=self.mp_drawing.DrawingSpec(color=self.COLOR_GHOST, thickness=2)\n            )\n        return cv2.addWeighted(frame, 1.0, overlay, 0.3, 0)\n\n    def create_annotated_video(self, input_path, output_path, analysis_result):\n        \"\"\"\n        Generates the final video with Iron-Man style overlays.\n        \"\"\"\n        cap = cv2.VideoCapture(input_path)\n        if not cap.isOpened():\n            return None\n\n        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        fps = int(cap.get(cv2.CAP_PROP_FPS))\n        \n        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n        # Data lookups\n        shots = analysis_result.get('shots', [])\n        # Map frame number to specific shot data for O(1) lookup\n        shot_map = {shot['frame']: shot for shot in shots}\n        \n        frame_idx = 0\n        \n        with self.mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n            while cap.isOpened():\n                ret, frame = cap.read()\n                if not ret:\n                    break\n\n                # 1. Process Pose\n                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                results = pose.process(image_rgb)\n\n                # 2. Check for Shot Event\n                current_shot = None\n                # Check within a small window (e.g., 5 frames) to keep text on screen longer\n                for f_key in shot_map:\n                    if 0 <= frame_idx - f_key < 30: # Show shot info for 1 second (30 frames)\n                        current_shot = shot_map[f_key]\n                        break\n\n                # 3. Draw Overlays\n                if results.pose_landmarks:\n                    # Draw Ghost (Optional - nice visual touch)\n                    # frame = self.add_ideal_pose_ghost(frame, results.pose_landmarks)\n\n                    # Draw Main Skeleton\n                    # Color based on quality if inside a shot event\n                    connection_color = self.COLOR_GOOD\n                    if current_shot and current_shot.get('pose_errors'):\n                        connection_color = self.COLOR_BAD\n\n                    self.mp_drawing.draw_landmarks(\n                        frame,\n                        results.pose_landmarks,\n                        self.mp_pose.POSE_CONNECTIONS,\n                        landmark_drawing_spec=self.mp_drawing.DrawingSpec(color=connection_color, thickness=2, circle_radius=2),\n                        connection_drawing_spec=self.mp_drawing.DrawingSpec(color=connection_color, thickness=2)\n                    )\n\n                # 4. Draw HUD / Text Info\n                if current_shot:\n                    # Top Left: Shot Type\n                    self.draw_text_with_background(frame, f\"SHOT: {current_shot['shot_type']}\", (20, 50), 1.2, 2)\n                    \n                    # Bottom Left: Errors or Good Form\n                    if current_shot.get('pose_errors'):\n                        y_pos = 100\n                        for err in current_shot['pose_errors']:\n                            self.draw_text_with_background(frame, f\"FIX: {err}\", (20, y_pos), 0.7, 1, self.COLOR_BAD)\n                            y_pos += 30\n                    else:\n                        self.draw_text_with_background(frame, \"PERFECT FORM\", (20, 100), 0.8, 2, self.COLOR_GOOD)\n\n                    # Top Right: Tactical Suggestion (from CoachAI logic)\n                    if 'suggestion' in current_shot:\n                        self.draw_text_with_background(frame, f\"COACH: {current_shot['suggestion']}\", (width - 400, 50), 0.7, 1, (0, 255, 255))\n\n                # Frame Counter\n                cv2.putText(frame, f\"Frame: {frame_idx}\", (width - 150, height - 30), \n                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n\n                out.write(frame)\n                frame_idx += 1\n\n        cap.release()\n        out.release()\n        return output_path\n\n\n# Standalone function for compatibility with main.py\ndef create_annotated_video_with_analysis(input_path, output_path, pose_data, shot_events):\n    \"\"\"\n    Wrapper function that creates annotated video using pose_data and shot_events.\n    This matches the interface expected by main.py\n    \"\"\"\n    from video_processing import draw_skeleton_on_frame\n\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(f\"Error: Could not open video {input_path}\")\n        return None\n\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    if fps == 0:\n        fps = 30  # Default fallback\n\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    # Map frame numbers to shots for quick lookup\n    shot_map = {shot['frame']: shot for shot in shot_events}\n\n    frame_idx = 0\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Get pose for this frame\n        pose = pose_data[frame_idx] if frame_idx < len(pose_data) else None\n\n        # Check if this frame has a shot event (with 30 frame window)\n        current_shot = None\n        for shot_frame in shot_map:\n            if 0 <= frame_idx - shot_frame < 30:\n                current_shot = shot_map[shot_frame]\n                break\n\n        # Draw skeleton if pose data exists\n        if pose:\n            is_good_form = True\n            if current_shot and current_shot.get('pose_errors'):\n                is_good_form = False\n\n            frame = draw_skeleton_on_frame(frame, pose, None, is_good_form)\n\n        # Add shot information overlay\n        if current_shot:\n            shot_type = current_shot.get('shot_type', 'SHOT')\n            cv2.putText(frame, f\"SHOT: {shot_type}\", (20, 50),\n                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 2)\n\n            # Show errors or good form message\n            if current_shot.get('pose_errors'):\n                y_pos = 100\n                for error in current_shot['pose_errors'][:3]:  # Max 3 errors\n                    cv2.putText(frame, f\"FIX: {error}\", (20, y_pos),\n                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n                    y_pos += 30\n            else:\n                cv2.putText(frame, \"GOOD FORM\", (20, 100),\n                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n\n        # Frame counter\n        cv2.putText(frame, f\"Frame: {frame_idx}\", (width - 150, height - 30),\n                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n\n        out.write(frame)\n        frame_idx += 1\n\n    cap.release()\n    out.release()\n    print(f\"Annotated video created: {output_path}\")\n    return output_path\n","numLines":209,"startLine":1,"totalLines":209}},"sourceToolAssistantUUID":"7d166515-38d4-4c0a-b656-6784f381506f"}
{"parentUuid":"847fe94a-dbc2-42a4-aef7-0dc2529da74d","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01WJkwHb8ijGfqVqYsgC7bvA","toolUseID":"toolu_01WJkwHb8ijGfqVqYsgC7bvA","timestamp":"2026-01-28T05:06:37.566Z","uuid":"01c194cf-790f-4647-94d7-9fab427c85ff"}
{"parentUuid":"01c194cf-790f-4647-94d7-9fab427c85ff","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01MK54ePpzPAK4EKpmBvDDu9","toolUseID":"toolu_01MK54ePpzPAK4EKpmBvDDu9","timestamp":"2026-01-28T05:06:37.567Z","uuid":"9aea5d90-f5e6-4413-9dff-46e798a1d6e9"}
{"parentUuid":"9aea5d90-f5e6-4413-9dff-46e798a1d6e9","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_012MKSpx34F4UfpDfeCCtvL3","toolUseID":"toolu_012MKSpx34F4UfpDfeCCtvL3","timestamp":"2026-01-28T05:06:37.567Z","uuid":"909b7847-5ab2-4fa9-ae80-1fce608e2e90"}
{"parentUuid":"909b7847-5ab2-4fa9-ae80-1fce608e2e90","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01F4ctpnmsTTbsnfmX8iDpHx","toolUseID":"toolu_01F4ctpnmsTTbsnfmX8iDpHx","timestamp":"2026-01-28T05:06:37.567Z","uuid":"a850e59b-1cbd-4fed-b22c-3c845152b192"}
{"parentUuid":"a850e59b-1cbd-4fed-b22c-3c845152b192","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QdnTuhkVmn64R43C4aMQjZ","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me read the Supabase schema files and additional components:\n1. supabase-migration-v2.sql - for the database schema\n2. DrillCard.tsx - existing component for displaying issues\n3. GuidanceAnimation.tsx - existing component4. API routes for auto-level","signature":"EqkDCkYICxgCKkAyBLxilUToHTS1nwBUVvwYZyNQIx4WwLsG6TRGZEW+519hdE/98Rj1GItR/mjTlUcMc46o29tz/N5WwmsViuAwEgwcJOVEAa5BRceCIycaDNbt/48WBzxcJ5w/ByIwtqik4AAS6ZLZftHUHqWbvAqdq9nH3CfXTihHZ/bYC7liZM1UFAIRHmwnHjkF2mZyKpACXoqRoGixmg1u4ynytpZ2vpjd6fJyz+zTJs454bkPGO7df4O/haA4pUWtsIKeo8XPddGTuOg3mLj0vut0xRZMsKaD2X4y2KouyH7fjwjPts11MBGVqmpHP3YzgMCv+LXZ+DfIxScxQQ9tBFQzIBkC1KadlIpwYQFZUFSIEA0mIXHbra+BjgRqZ0rtG+VHq1KtKWL4RLiwroTAWfPY2o9R67pFBzK2JVO4BYuwK9hrsmszVgaszEWnSI6NKeXmu8khNRwRgjbQAFYXo6KxcK/JxNKrHmMiR7jqRgRMzHcQtYnWtXSESGR+qajlQnmWfS+o/Iq3+H9gAIXypGg1mz7HSfF6H6Gc2YYaY3igkyKoXAoYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":30256,"cache_read_input_tokens":102756,"cache_creation":{"ephemeral_5m_input_tokens":30256,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCH5u8tsvp4iRkqjW4f","type":"assistant","uuid":"92c9364d-0b41-474d-a6b6-84e7763cd384","timestamp":"2026-01-28T05:06:42.131Z"}
{"parentUuid":"92c9364d-0b41-474d-a6b6-84e7763cd384","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QdnTuhkVmn64R43C4aMQjZ","type":"message","role":"assistant","content":[{"type":"text","text":"Let me read a few more critical files - the database schema and some key components."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":30256,"cache_read_input_tokens":102756,"cache_creation":{"ephemeral_5m_input_tokens":30256,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCH5u8tsvp4iRkqjW4f","type":"assistant","uuid":"2c7c1e13-82dc-4c67-994c-fc40b31026d8","timestamp":"2026-01-28T05:06:42.597Z"}
{"parentUuid":"2c7c1e13-82dc-4c67-994c-fc40b31026d8","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QdnTuhkVmn64R43C4aMQjZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SqsTJPM4P6WN7aejBWMCZi","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\supabase-migration-v2.sql"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":30256,"cache_read_input_tokens":102756,"cache_creation":{"ephemeral_5m_input_tokens":30256,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCH5u8tsvp4iRkqjW4f","type":"assistant","uuid":"0db8980c-7780-46e7-a14c-731439c1d4ca","timestamp":"2026-01-28T05:06:43.393Z"}
{"parentUuid":"0db8980c-7780-46e7-a14c-731439c1d4ca","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QdnTuhkVmn64R43C4aMQjZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CFRL92XjKvWBtDx8NyVCQ9","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\DrillCard.tsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":30256,"cache_read_input_tokens":102756,"cache_creation":{"ephemeral_5m_input_tokens":30256,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCH5u8tsvp4iRkqjW4f","type":"assistant","uuid":"ddea4ddd-11f1-4d1e-9de0-cd28873bb1bd","timestamp":"2026-01-28T05:06:43.978Z"}
{"parentUuid":"ddea4ddd-11f1-4d1e-9de0-cd28873bb1bd","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QdnTuhkVmn64R43C4aMQjZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01V567iNe6TKMJVDApojhzjP","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\GuidanceAnimation.tsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":30256,"cache_read_input_tokens":102756,"cache_creation":{"ephemeral_5m_input_tokens":30256,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCH5u8tsvp4iRkqjW4f","type":"assistant","uuid":"393e8c6b-ec71-4b0f-a802-341048848789","timestamp":"2026-01-28T05:06:44.452Z"}
{"parentUuid":"393e8c6b-ec71-4b0f-a802-341048848789","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QdnTuhkVmn64R43C4aMQjZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VcMi7WUbSrPQ2Rb5Du9be1","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\api\\analysis\\auto-level\\route.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":30256,"cache_read_input_tokens":102756,"cache_creation":{"ephemeral_5m_input_tokens":30256,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCH5u8tsvp4iRkqjW4f","type":"assistant","uuid":"db60836f-837d-4c59-90b6-5673887a87a3","timestamp":"2026-01-28T05:06:45.036Z"}
{"parentUuid":"0db8980c-7780-46e7-a14c-731439c1d4ca","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SqsTJPM4P6WN7aejBWMCZi","type":"tool_result","content":"     1→-- RallyCoach V2 Database Migration\n     2→-- Run these SQL commands in your Supabase SQL Editor\n     3→-- This adds support for: Sessions, Issues, Events, Practice Stats\n     4→\n     5→-- ============================================\n     6→-- 1. CREATE SESSIONS TABLE\n     7→-- ============================================\n     8→-- Stores both Analytics and Practice sessions\n     9→CREATE TABLE IF NOT EXISTS sessions (\n    10→    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    11→    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n    12→    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    13→    type TEXT NOT NULL CHECK (type IN ('analytics', 'practice')),\n    14→    video_path TEXT,  -- Storage path for uploaded video (analytics only)\n    15→    video_url TEXT,   -- Public URL for video playback\n    16→    filename TEXT,    -- Original filename\n    17→    duration_seconds NUMERIC,\n    18→    overall_score NUMERIC DEFAULT 0,  -- 0-100 score\n    19→    summary JSONB DEFAULT '{}'::jsonb,  -- {top_issues: [], notes: \"\"}\n    20→    pose_data JSONB DEFAULT '[]'::jsonb,  -- Array of landmarks per frame (for overlay)\n    21→    frame_count INTEGER DEFAULT 0\n    22→);\n    23→\n    24→COMMENT ON TABLE sessions IS 'Stores both Analytics (video upload) and Practice (webcam) sessions';\n    25→\n    26→-- ============================================\n    27→-- 2. CREATE ISSUES TABLE\n    28→-- ============================================\n    29→-- Detected issues per session with drill recommendations\n    30→CREATE TABLE IF NOT EXISTS issues (\n    31→    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    32→    session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,\n    33→    code TEXT NOT NULL,  -- e.g., 'ELBOW_LOW_BACKHAND', 'STANCE_TOO_NARROW'\n    34→    title TEXT NOT NULL,\n    35→    severity TEXT NOT NULL CHECK (severity IN ('low', 'medium', 'high')),\n    36→    description TEXT,\n    37→    drill JSONB DEFAULT '{}'::jsonb,  -- {steps: [], tips: [], duration_minutes: 5}\n    38→    keyframes JSONB DEFAULT '[]'::jsonb,  -- [{svg: \"...\", label: \"Setup\"}, ...]\n    39→    timestamps JSONB DEFAULT '[]'::jsonb,  -- [1.2, 3.5, 7.8] seconds where issue occurred\n    40→    occurrence_count INTEGER DEFAULT 1,\n    41→    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n    42→);\n    43→\n    44→COMMENT ON TABLE issues IS 'Form issues detected in a session with associated drills';\n    45→\n    46→-- ============================================\n    47→-- 3. CREATE EVENTS TABLE\n    48→-- ============================================\n    49→-- Per-frame events for detailed analysis\n    50→CREATE TABLE IF NOT EXISTS events (\n    51→    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    52→    session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,\n    53→    t NUMERIC NOT NULL,  -- Timestamp in seconds\n    54→    frame_number INTEGER,\n    55→    code TEXT NOT NULL,  -- Rule code e.g., 'ELBOW_ANGLE'\n    56→    value NUMERIC,  -- Measured value\n    57→    threshold_min NUMERIC,\n    58→    threshold_max NUMERIC,\n    59→    passed BOOLEAN DEFAULT true,\n    60→    severity TEXT CHECK (severity IN ('low', 'medium', 'high')),\n    61→    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n    62→);\n    63→\n    64→COMMENT ON TABLE events IS 'Per-frame rule evaluation results';\n    65→\n    66→-- ============================================\n    67→-- 4. CREATE PRACTICE_STATS TABLE\n    68→-- ============================================\n    69→-- Aggregated stats for practice sessions\n    70→CREATE TABLE IF NOT EXISTS practice_stats (\n    71→    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    72→    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n    73→    session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,\n    74→    drill_type TEXT,  -- 'smash', 'clear', 'netshot', 'footwork'\n    75→    total_frames INTEGER DEFAULT 0,\n    76→    green_frames INTEGER DEFAULT 0,\n    77→    red_frames INTEGER DEFAULT 0,\n    78→    green_ratio NUMERIC GENERATED ALWAYS AS (\n    79→        CASE WHEN total_frames > 0 THEN green_frames::NUMERIC / total_frames ELSE 0 END\n    80→    ) STORED,\n    81→    avg_elbow_angle NUMERIC,\n    82→    avg_stance_width NUMERIC,\n    83→    peak_form_score NUMERIC DEFAULT 0,\n    84→    duration_seconds NUMERIC DEFAULT 0,\n    85→    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n    86→);\n    87→\n    88→COMMENT ON TABLE practice_stats IS 'Aggregated statistics for practice sessions';\n    89→\n    90→-- ============================================\n    91→-- 5. CREATE DAILY_AGGREGATES TABLE\n    92→-- ============================================\n    93→-- Daily aggregated metrics for dashboard charts\n    94→CREATE TABLE IF NOT EXISTS daily_aggregates (\n    95→    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    96→    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n    97→    date DATE NOT NULL,\n    98→    analytics_sessions INTEGER DEFAULT 0,\n    99→    practice_sessions INTEGER DEFAULT 0,\n   100→    total_practice_minutes NUMERIC DEFAULT 0,\n   101→    avg_technique_score NUMERIC DEFAULT 0,\n   102→    avg_green_ratio NUMERIC DEFAULT 0,\n   103→    top_issues JSONB DEFAULT '[]'::jsonb,  -- [{code: \"...\", count: 5}, ...]\n   104→    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n   105→    UNIQUE(user_id, date)\n   106→);\n   107→\n   108→COMMENT ON TABLE daily_aggregates IS 'Daily aggregated metrics for dashboard charts';\n   109→\n   110→-- ============================================\n   111→-- 6. ENABLE ROW LEVEL SECURITY\n   112→-- ============================================\n   113→ALTER TABLE sessions ENABLE ROW LEVEL SECURITY;\n   114→ALTER TABLE issues ENABLE ROW LEVEL SECURITY;\n   115→ALTER TABLE events ENABLE ROW LEVEL SECURITY;\n   116→ALTER TABLE practice_stats ENABLE ROW LEVEL SECURITY;\n   117→ALTER TABLE daily_aggregates ENABLE ROW LEVEL SECURITY;\n   118→\n   119→-- ============================================\n   120→-- 7. RLS POLICIES FOR SESSIONS\n   121→-- ============================================\n   122→DROP POLICY IF EXISTS \"Users can view their own sessions\" ON sessions;\n   123→CREATE POLICY \"Users can view their own sessions\"\n   124→    ON sessions FOR SELECT\n   125→    USING (auth.uid() = user_id);\n   126→\n   127→DROP POLICY IF EXISTS \"Users can insert their own sessions\" ON sessions;\n   128→CREATE POLICY \"Users can insert their own sessions\"\n   129→    ON sessions FOR INSERT\n   130→    WITH CHECK (auth.uid() = user_id);\n   131→\n   132→DROP POLICY IF EXISTS \"Users can update their own sessions\" ON sessions;\n   133→CREATE POLICY \"Users can update their own sessions\"\n   134→    ON sessions FOR UPDATE\n   135→    USING (auth.uid() = user_id);\n   136→\n   137→DROP POLICY IF EXISTS \"Users can delete their own sessions\" ON sessions;\n   138→CREATE POLICY \"Users can delete their own sessions\"\n   139→    ON sessions FOR DELETE\n   140→    USING (auth.uid() = user_id);\n   141→\n   142→-- ============================================\n   143→-- 8. RLS POLICIES FOR ISSUES\n   144→-- ============================================\n   145→DROP POLICY IF EXISTS \"Users can view issues for their sessions\" ON issues;\n   146→CREATE POLICY \"Users can view issues for their sessions\"\n   147→    ON issues FOR SELECT\n   148→    USING (\n   149→        EXISTS (\n   150→            SELECT 1 FROM sessions\n   151→            WHERE sessions.id = issues.session_id\n   152→            AND sessions.user_id = auth.uid()\n   153→        )\n   154→    );\n   155→\n   156→DROP POLICY IF EXISTS \"Users can insert issues for their sessions\" ON issues;\n   157→CREATE POLICY \"Users can insert issues for their sessions\"\n   158→    ON issues FOR INSERT\n   159→    WITH CHECK (\n   160→        EXISTS (\n   161→            SELECT 1 FROM sessions\n   162→            WHERE sessions.id = issues.session_id\n   163→            AND sessions.user_id = auth.uid()\n   164→        )\n   165→    );\n   166→\n   167→DROP POLICY IF EXISTS \"Users can delete issues for their sessions\" ON issues;\n   168→CREATE POLICY \"Users can delete issues for their sessions\"\n   169→    ON issues FOR DELETE\n   170→    USING (\n   171→        EXISTS (\n   172→            SELECT 1 FROM sessions\n   173→            WHERE sessions.id = issues.session_id\n   174→            AND sessions.user_id = auth.uid()\n   175→        )\n   176→    );\n   177→\n   178→-- ============================================\n   179→-- 9. RLS POLICIES FOR EVENTS\n   180→-- ============================================\n   181→DROP POLICY IF EXISTS \"Users can view events for their sessions\" ON events;\n   182→CREATE POLICY \"Users can view events for their sessions\"\n   183→    ON events FOR SELECT\n   184→    USING (\n   185→        EXISTS (\n   186→            SELECT 1 FROM sessions\n   187→            WHERE sessions.id = events.session_id\n   188→            AND sessions.user_id = auth.uid()\n   189→        )\n   190→    );\n   191→\n   192→DROP POLICY IF EXISTS \"Users can insert events for their sessions\" ON events;\n   193→CREATE POLICY \"Users can insert events for their sessions\"\n   194→    ON events FOR INSERT\n   195→    WITH CHECK (\n   196→        EXISTS (\n   197→            SELECT 1 FROM sessions\n   198→            WHERE sessions.id = events.session_id\n   199→            AND sessions.user_id = auth.uid()\n   200→        )\n   201→    );\n   202→\n   203→-- ============================================\n   204→-- 10. RLS POLICIES FOR PRACTICE_STATS\n   205→-- ============================================\n   206→DROP POLICY IF EXISTS \"Users can view their own practice stats\" ON practice_stats;\n   207→CREATE POLICY \"Users can view their own practice stats\"\n   208→    ON practice_stats FOR SELECT\n   209→    USING (auth.uid() = user_id);\n   210→\n   211→DROP POLICY IF EXISTS \"Users can insert their own practice stats\" ON practice_stats;\n   212→CREATE POLICY \"Users can insert their own practice stats\"\n   213→    ON practice_stats FOR INSERT\n   214→    WITH CHECK (auth.uid() = user_id);\n   215→\n   216→-- ============================================\n   217→-- 11. RLS POLICIES FOR DAILY_AGGREGATES\n   218→-- ============================================\n   219→DROP POLICY IF EXISTS \"Users can view their own daily aggregates\" ON daily_aggregates;\n   220→CREATE POLICY \"Users can view their own daily aggregates\"\n   221→    ON daily_aggregates FOR SELECT\n   222→    USING (auth.uid() = user_id);\n   223→\n   224→DROP POLICY IF EXISTS \"Users can upsert their own daily aggregates\" ON daily_aggregates;\n   225→CREATE POLICY \"Users can upsert their own daily aggregates\"\n   226→    ON daily_aggregates FOR INSERT\n   227→    WITH CHECK (auth.uid() = user_id);\n   228→\n   229→DROP POLICY IF EXISTS \"Users can update their own daily aggregates\" ON daily_aggregates;\n   230→CREATE POLICY \"Users can update their own daily aggregates\"\n   231→    ON daily_aggregates FOR UPDATE\n   232→    USING (auth.uid() = user_id);\n   233→\n   234→-- ============================================\n   235→-- 12. CREATE INDEXES\n   236→-- ============================================\n   237→CREATE INDEX IF NOT EXISTS idx_sessions_user_created ON sessions(user_id, created_at DESC);\n   238→CREATE INDEX IF NOT EXISTS idx_sessions_type ON sessions(type);\n   239→CREATE INDEX IF NOT EXISTS idx_issues_session ON issues(session_id);\n   240→CREATE INDEX IF NOT EXISTS idx_issues_code ON issues(code);\n   241→CREATE INDEX IF NOT EXISTS idx_events_session ON events(session_id);\n   242→CREATE INDEX IF NOT EXISTS idx_events_session_code ON events(session_id, code);\n   243→CREATE INDEX IF NOT EXISTS idx_events_t ON events(t);\n   244→CREATE INDEX IF NOT EXISTS idx_practice_stats_user ON practice_stats(user_id);\n   245→CREATE INDEX IF NOT EXISTS idx_practice_stats_session ON practice_stats(session_id);\n   246→CREATE INDEX IF NOT EXISTS idx_daily_aggregates_user_date ON daily_aggregates(user_id, date DESC);\n   247→\n   248→-- ============================================\n   249→-- 13. SERVICE ROLE BYPASS POLICIES\n   250→-- ============================================\n   251→-- These allow the backend (using service role key) to insert data for any user\n   252→\n   253→DROP POLICY IF EXISTS \"Service role can insert sessions\" ON sessions;\n   254→CREATE POLICY \"Service role can insert sessions\"\n   255→    ON sessions FOR INSERT\n   256→    WITH CHECK (true);\n   257→\n   258→DROP POLICY IF EXISTS \"Service role can insert issues\" ON issues;\n   259→CREATE POLICY \"Service role can insert issues\"\n   260→    ON issues FOR INSERT\n   261→    WITH CHECK (true);\n   262→\n   263→DROP POLICY IF EXISTS \"Service role can insert events\" ON events;\n   264→CREATE POLICY \"Service role can insert events\"\n   265→    ON events FOR INSERT\n   266→    WITH CHECK (true);\n   267→\n   268→DROP POLICY IF EXISTS \"Service role can insert practice_stats\" ON practice_stats;\n   269→CREATE POLICY \"Service role can insert practice_stats\"\n   270→    ON practice_stats FOR INSERT\n   271→    WITH CHECK (true);\n   272→\n   273→DROP POLICY IF EXISTS \"Service role can insert daily_aggregates\" ON daily_aggregates;\n   274→CREATE POLICY \"Service role can insert daily_aggregates\"\n   275→    ON daily_aggregates FOR INSERT\n   276→    WITH CHECK (true);\n   277→\n   278→-- ============================================\n   279→-- 14. HELPER FUNCTIONS\n   280→-- ============================================\n   281→\n   282→-- Function to update daily aggregates after session insert\n   283→CREATE OR REPLACE FUNCTION update_daily_aggregates()\n   284→RETURNS TRIGGER AS $$\n   285→BEGIN\n   286→    INSERT INTO daily_aggregates (user_id, date, analytics_sessions, practice_sessions, avg_technique_score)\n   287→    VALUES (\n   288→        NEW.user_id,\n   289→        DATE(NEW.created_at),\n   290→        CASE WHEN NEW.type = 'analytics' THEN 1 ELSE 0 END,\n   291→        CASE WHEN NEW.type = 'practice' THEN 1 ELSE 0 END,\n   292→        NEW.overall_score\n   293→    )\n   294→    ON CONFLICT (user_id, date)\n   295→    DO UPDATE SET\n   296→        analytics_sessions = daily_aggregates.analytics_sessions +\n   297→            CASE WHEN NEW.type = 'analytics' THEN 1 ELSE 0 END,\n   298→        practice_sessions = daily_aggregates.practice_sessions +\n   299→            CASE WHEN NEW.type = 'practice' THEN 1 ELSE 0 END,\n   300→        avg_technique_score = (daily_aggregates.avg_technique_score + NEW.overall_score) / 2;\n   301→\n   302→    RETURN NEW;\n   303→END;\n   304→$$ LANGUAGE plpgsql SECURITY DEFINER;\n   305→\n   306→-- Create trigger for daily aggregates\n   307→DROP TRIGGER IF EXISTS trigger_update_daily_aggregates ON sessions;\n   308→CREATE TRIGGER trigger_update_daily_aggregates\n   309→    AFTER INSERT ON sessions\n   310→    FOR EACH ROW\n   311→    EXECUTE FUNCTION update_daily_aggregates();\n   312→\n   313→-- ============================================\n   314→-- 15. STORAGE BUCKET (Run in Dashboard)\n   315→-- ============================================\n   316→-- Create a \"keyframes\" bucket for storing generated keyframe images\n   317→-- 1. Go to Storage in Supabase Dashboard\n   318→-- 2. Create bucket named \"keyframes\" (private)\n   319→-- 3. Add policy: Authenticated users can read/write their own folder\n   320→\n   321→-- ============================================\n   322→-- MIGRATION COMPLETE\n   323→-- ============================================\n   324→-- After running this migration:\n   325→-- 1. Update your backend to use these new tables\n   326→-- 2. Update frontend to query sessions instead of analysis_results\n   327→-- 3. Run the storage bucket setup manually in Dashboard\n   328→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"202601ae-2073-486c-b3f4-4839bb88d573","timestamp":"2026-01-28T05:06:48.283Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\supabase-migration-v2.sql","content":"-- RallyCoach V2 Database Migration\n-- Run these SQL commands in your Supabase SQL Editor\n-- This adds support for: Sessions, Issues, Events, Practice Stats\n\n-- ============================================\n-- 1. CREATE SESSIONS TABLE\n-- ============================================\n-- Stores both Analytics and Practice sessions\nCREATE TABLE IF NOT EXISTS sessions (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    type TEXT NOT NULL CHECK (type IN ('analytics', 'practice')),\n    video_path TEXT,  -- Storage path for uploaded video (analytics only)\n    video_url TEXT,   -- Public URL for video playback\n    filename TEXT,    -- Original filename\n    duration_seconds NUMERIC,\n    overall_score NUMERIC DEFAULT 0,  -- 0-100 score\n    summary JSONB DEFAULT '{}'::jsonb,  -- {top_issues: [], notes: \"\"}\n    pose_data JSONB DEFAULT '[]'::jsonb,  -- Array of landmarks per frame (for overlay)\n    frame_count INTEGER DEFAULT 0\n);\n\nCOMMENT ON TABLE sessions IS 'Stores both Analytics (video upload) and Practice (webcam) sessions';\n\n-- ============================================\n-- 2. CREATE ISSUES TABLE\n-- ============================================\n-- Detected issues per session with drill recommendations\nCREATE TABLE IF NOT EXISTS issues (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,\n    code TEXT NOT NULL,  -- e.g., 'ELBOW_LOW_BACKHAND', 'STANCE_TOO_NARROW'\n    title TEXT NOT NULL,\n    severity TEXT NOT NULL CHECK (severity IN ('low', 'medium', 'high')),\n    description TEXT,\n    drill JSONB DEFAULT '{}'::jsonb,  -- {steps: [], tips: [], duration_minutes: 5}\n    keyframes JSONB DEFAULT '[]'::jsonb,  -- [{svg: \"...\", label: \"Setup\"}, ...]\n    timestamps JSONB DEFAULT '[]'::jsonb,  -- [1.2, 3.5, 7.8] seconds where issue occurred\n    occurrence_count INTEGER DEFAULT 1,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCOMMENT ON TABLE issues IS 'Form issues detected in a session with associated drills';\n\n-- ============================================\n-- 3. CREATE EVENTS TABLE\n-- ============================================\n-- Per-frame events for detailed analysis\nCREATE TABLE IF NOT EXISTS events (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,\n    t NUMERIC NOT NULL,  -- Timestamp in seconds\n    frame_number INTEGER,\n    code TEXT NOT NULL,  -- Rule code e.g., 'ELBOW_ANGLE'\n    value NUMERIC,  -- Measured value\n    threshold_min NUMERIC,\n    threshold_max NUMERIC,\n    passed BOOLEAN DEFAULT true,\n    severity TEXT CHECK (severity IN ('low', 'medium', 'high')),\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCOMMENT ON TABLE events IS 'Per-frame rule evaluation results';\n\n-- ============================================\n-- 4. CREATE PRACTICE_STATS TABLE\n-- ============================================\n-- Aggregated stats for practice sessions\nCREATE TABLE IF NOT EXISTS practice_stats (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n    session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,\n    drill_type TEXT,  -- 'smash', 'clear', 'netshot', 'footwork'\n    total_frames INTEGER DEFAULT 0,\n    green_frames INTEGER DEFAULT 0,\n    red_frames INTEGER DEFAULT 0,\n    green_ratio NUMERIC GENERATED ALWAYS AS (\n        CASE WHEN total_frames > 0 THEN green_frames::NUMERIC / total_frames ELSE 0 END\n    ) STORED,\n    avg_elbow_angle NUMERIC,\n    avg_stance_width NUMERIC,\n    peak_form_score NUMERIC DEFAULT 0,\n    duration_seconds NUMERIC DEFAULT 0,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCOMMENT ON TABLE practice_stats IS 'Aggregated statistics for practice sessions';\n\n-- ============================================\n-- 5. CREATE DAILY_AGGREGATES TABLE\n-- ============================================\n-- Daily aggregated metrics for dashboard charts\nCREATE TABLE IF NOT EXISTS daily_aggregates (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n    date DATE NOT NULL,\n    analytics_sessions INTEGER DEFAULT 0,\n    practice_sessions INTEGER DEFAULT 0,\n    total_practice_minutes NUMERIC DEFAULT 0,\n    avg_technique_score NUMERIC DEFAULT 0,\n    avg_green_ratio NUMERIC DEFAULT 0,\n    top_issues JSONB DEFAULT '[]'::jsonb,  -- [{code: \"...\", count: 5}, ...]\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    UNIQUE(user_id, date)\n);\n\nCOMMENT ON TABLE daily_aggregates IS 'Daily aggregated metrics for dashboard charts';\n\n-- ============================================\n-- 6. ENABLE ROW LEVEL SECURITY\n-- ============================================\nALTER TABLE sessions ENABLE ROW LEVEL SECURITY;\nALTER TABLE issues ENABLE ROW LEVEL SECURITY;\nALTER TABLE events ENABLE ROW LEVEL SECURITY;\nALTER TABLE practice_stats ENABLE ROW LEVEL SECURITY;\nALTER TABLE daily_aggregates ENABLE ROW LEVEL SECURITY;\n\n-- ============================================\n-- 7. RLS POLICIES FOR SESSIONS\n-- ============================================\nDROP POLICY IF EXISTS \"Users can view their own sessions\" ON sessions;\nCREATE POLICY \"Users can view their own sessions\"\n    ON sessions FOR SELECT\n    USING (auth.uid() = user_id);\n\nDROP POLICY IF EXISTS \"Users can insert their own sessions\" ON sessions;\nCREATE POLICY \"Users can insert their own sessions\"\n    ON sessions FOR INSERT\n    WITH CHECK (auth.uid() = user_id);\n\nDROP POLICY IF EXISTS \"Users can update their own sessions\" ON sessions;\nCREATE POLICY \"Users can update their own sessions\"\n    ON sessions FOR UPDATE\n    USING (auth.uid() = user_id);\n\nDROP POLICY IF EXISTS \"Users can delete their own sessions\" ON sessions;\nCREATE POLICY \"Users can delete their own sessions\"\n    ON sessions FOR DELETE\n    USING (auth.uid() = user_id);\n\n-- ============================================\n-- 8. RLS POLICIES FOR ISSUES\n-- ============================================\nDROP POLICY IF EXISTS \"Users can view issues for their sessions\" ON issues;\nCREATE POLICY \"Users can view issues for their sessions\"\n    ON issues FOR SELECT\n    USING (\n        EXISTS (\n            SELECT 1 FROM sessions\n            WHERE sessions.id = issues.session_id\n            AND sessions.user_id = auth.uid()\n        )\n    );\n\nDROP POLICY IF EXISTS \"Users can insert issues for their sessions\" ON issues;\nCREATE POLICY \"Users can insert issues for their sessions\"\n    ON issues FOR INSERT\n    WITH CHECK (\n        EXISTS (\n            SELECT 1 FROM sessions\n            WHERE sessions.id = issues.session_id\n            AND sessions.user_id = auth.uid()\n        )\n    );\n\nDROP POLICY IF EXISTS \"Users can delete issues for their sessions\" ON issues;\nCREATE POLICY \"Users can delete issues for their sessions\"\n    ON issues FOR DELETE\n    USING (\n        EXISTS (\n            SELECT 1 FROM sessions\n            WHERE sessions.id = issues.session_id\n            AND sessions.user_id = auth.uid()\n        )\n    );\n\n-- ============================================\n-- 9. RLS POLICIES FOR EVENTS\n-- ============================================\nDROP POLICY IF EXISTS \"Users can view events for their sessions\" ON events;\nCREATE POLICY \"Users can view events for their sessions\"\n    ON events FOR SELECT\n    USING (\n        EXISTS (\n            SELECT 1 FROM sessions\n            WHERE sessions.id = events.session_id\n            AND sessions.user_id = auth.uid()\n        )\n    );\n\nDROP POLICY IF EXISTS \"Users can insert events for their sessions\" ON events;\nCREATE POLICY \"Users can insert events for their sessions\"\n    ON events FOR INSERT\n    WITH CHECK (\n        EXISTS (\n            SELECT 1 FROM sessions\n            WHERE sessions.id = events.session_id\n            AND sessions.user_id = auth.uid()\n        )\n    );\n\n-- ============================================\n-- 10. RLS POLICIES FOR PRACTICE_STATS\n-- ============================================\nDROP POLICY IF EXISTS \"Users can view their own practice stats\" ON practice_stats;\nCREATE POLICY \"Users can view their own practice stats\"\n    ON practice_stats FOR SELECT\n    USING (auth.uid() = user_id);\n\nDROP POLICY IF EXISTS \"Users can insert their own practice stats\" ON practice_stats;\nCREATE POLICY \"Users can insert their own practice stats\"\n    ON practice_stats FOR INSERT\n    WITH CHECK (auth.uid() = user_id);\n\n-- ============================================\n-- 11. RLS POLICIES FOR DAILY_AGGREGATES\n-- ============================================\nDROP POLICY IF EXISTS \"Users can view their own daily aggregates\" ON daily_aggregates;\nCREATE POLICY \"Users can view their own daily aggregates\"\n    ON daily_aggregates FOR SELECT\n    USING (auth.uid() = user_id);\n\nDROP POLICY IF EXISTS \"Users can upsert their own daily aggregates\" ON daily_aggregates;\nCREATE POLICY \"Users can upsert their own daily aggregates\"\n    ON daily_aggregates FOR INSERT\n    WITH CHECK (auth.uid() = user_id);\n\nDROP POLICY IF EXISTS \"Users can update their own daily aggregates\" ON daily_aggregates;\nCREATE POLICY \"Users can update their own daily aggregates\"\n    ON daily_aggregates FOR UPDATE\n    USING (auth.uid() = user_id);\n\n-- ============================================\n-- 12. CREATE INDEXES\n-- ============================================\nCREATE INDEX IF NOT EXISTS idx_sessions_user_created ON sessions(user_id, created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_sessions_type ON sessions(type);\nCREATE INDEX IF NOT EXISTS idx_issues_session ON issues(session_id);\nCREATE INDEX IF NOT EXISTS idx_issues_code ON issues(code);\nCREATE INDEX IF NOT EXISTS idx_events_session ON events(session_id);\nCREATE INDEX IF NOT EXISTS idx_events_session_code ON events(session_id, code);\nCREATE INDEX IF NOT EXISTS idx_events_t ON events(t);\nCREATE INDEX IF NOT EXISTS idx_practice_stats_user ON practice_stats(user_id);\nCREATE INDEX IF NOT EXISTS idx_practice_stats_session ON practice_stats(session_id);\nCREATE INDEX IF NOT EXISTS idx_daily_aggregates_user_date ON daily_aggregates(user_id, date DESC);\n\n-- ============================================\n-- 13. SERVICE ROLE BYPASS POLICIES\n-- ============================================\n-- These allow the backend (using service role key) to insert data for any user\n\nDROP POLICY IF EXISTS \"Service role can insert sessions\" ON sessions;\nCREATE POLICY \"Service role can insert sessions\"\n    ON sessions FOR INSERT\n    WITH CHECK (true);\n\nDROP POLICY IF EXISTS \"Service role can insert issues\" ON issues;\nCREATE POLICY \"Service role can insert issues\"\n    ON issues FOR INSERT\n    WITH CHECK (true);\n\nDROP POLICY IF EXISTS \"Service role can insert events\" ON events;\nCREATE POLICY \"Service role can insert events\"\n    ON events FOR INSERT\n    WITH CHECK (true);\n\nDROP POLICY IF EXISTS \"Service role can insert practice_stats\" ON practice_stats;\nCREATE POLICY \"Service role can insert practice_stats\"\n    ON practice_stats FOR INSERT\n    WITH CHECK (true);\n\nDROP POLICY IF EXISTS \"Service role can insert daily_aggregates\" ON daily_aggregates;\nCREATE POLICY \"Service role can insert daily_aggregates\"\n    ON daily_aggregates FOR INSERT\n    WITH CHECK (true);\n\n-- ============================================\n-- 14. HELPER FUNCTIONS\n-- ============================================\n\n-- Function to update daily aggregates after session insert\nCREATE OR REPLACE FUNCTION update_daily_aggregates()\nRETURNS TRIGGER AS $$\nBEGIN\n    INSERT INTO daily_aggregates (user_id, date, analytics_sessions, practice_sessions, avg_technique_score)\n    VALUES (\n        NEW.user_id,\n        DATE(NEW.created_at),\n        CASE WHEN NEW.type = 'analytics' THEN 1 ELSE 0 END,\n        CASE WHEN NEW.type = 'practice' THEN 1 ELSE 0 END,\n        NEW.overall_score\n    )\n    ON CONFLICT (user_id, date)\n    DO UPDATE SET\n        analytics_sessions = daily_aggregates.analytics_sessions +\n            CASE WHEN NEW.type = 'analytics' THEN 1 ELSE 0 END,\n        practice_sessions = daily_aggregates.practice_sessions +\n            CASE WHEN NEW.type = 'practice' THEN 1 ELSE 0 END,\n        avg_technique_score = (daily_aggregates.avg_technique_score + NEW.overall_score) / 2;\n\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Create trigger for daily aggregates\nDROP TRIGGER IF EXISTS trigger_update_daily_aggregates ON sessions;\nCREATE TRIGGER trigger_update_daily_aggregates\n    AFTER INSERT ON sessions\n    FOR EACH ROW\n    EXECUTE FUNCTION update_daily_aggregates();\n\n-- ============================================\n-- 15. STORAGE BUCKET (Run in Dashboard)\n-- ============================================\n-- Create a \"keyframes\" bucket for storing generated keyframe images\n-- 1. Go to Storage in Supabase Dashboard\n-- 2. Create bucket named \"keyframes\" (private)\n-- 3. Add policy: Authenticated users can read/write their own folder\n\n-- ============================================\n-- MIGRATION COMPLETE\n-- ============================================\n-- After running this migration:\n-- 1. Update your backend to use these new tables\n-- 2. Update frontend to query sessions instead of analysis_results\n-- 3. Run the storage bucket setup manually in Dashboard\n","numLines":328,"startLine":1,"totalLines":328}},"sourceToolAssistantUUID":"0db8980c-7780-46e7-a14c-731439c1d4ca"}
{"parentUuid":"ddea4ddd-11f1-4d1e-9de0-cd28873bb1bd","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CFRL92XjKvWBtDx8NyVCQ9","type":"tool_result","content":"     1→'use client';\n     2→\n     3→import { useState } from 'react';\n     4→import Link from 'next/link';\n     5→import { getKeyframeSVGs, type DrillDefinition } from '@/lib/rules-engine';\n     6→import Skeleton3D from './Skeleton3D';\n     7→\n     8→interface DrillCardProps {\n     9→  issue: {\n    10→    code: string;\n    11→    title: string;\n    12→    severity: 'low' | 'medium' | 'high';\n    13→    description?: string;\n    14→    timestamps?: number[];\n    15→    drill?: DrillDefinition;\n    16→  };\n    17→  onTimestampClick?: (timestamp: number) => void;\n    18→  onPracticeClick?: (drillId: string) => void;\n    19→  currentTime?: number;\n    20→}\n    21→\n    22→export default function DrillCard({\n    23→  issue,\n    24→  onTimestampClick,\n    25→  onPracticeClick,\n    26→  currentTime = 0,\n    27→}: DrillCardProps) {\n    28→  const [activeKeyframe, setActiveKeyframe] = useState(0);\n    29→\n    30→  // Get drill info\n    31→  const drill = issue.drill;\n    32→  const drillType = (drill?.keyframeType || 'footwork') as 'smash' | 'clear' | 'netshot' | 'footwork' | 'drive';\n    33→  const keyframes = getKeyframeSVGs(drillType, { width: 100, height: 150 });\n    34→\n    35→  // Get severity color\n    36→  const getSeverityColor = (severity: string) => {\n    37→    switch (severity) {\n    38→      case 'high':\n    39→        return 'bg-red-50 border-red-200 text-red-800';\n    40→      case 'medium':\n    41→        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n    42→      case 'low':\n    43→        return 'bg-green-50 border-green-200 text-green-800';\n    44→      default:\n    45→        return 'bg-gray-50 border-gray-200 text-gray-800';\n    46→    }\n    47→  };\n    48→\n    49→  const getSeverityBadgeColor = (severity: string) => {\n    50→    switch (severity) {\n    51→      case 'high':\n    52→        return 'bg-red-500';\n    53→      case 'medium':\n    54→        return 'bg-yellow-500';\n    55→      case 'low':\n    56→        return 'bg-green-500';\n    57→      default:\n    58→        return 'bg-gray-500';\n    59→    }\n    60→  };\n    61→\n    62→  // Format timestamp for display\n    63→  const formatTimestamp = (seconds: number) => {\n    64→    const mins = Math.floor(seconds / 60);\n    65→    const secs = Math.floor(seconds % 60);\n    66→    return `${mins}:${secs.toString().padStart(2, '0')}`;\n    67→  };\n    68→\n    69→  // Check if a timestamp is currently playing\n    70→  const isTimestampActive = (timestamp: number) => {\n    71→    return Math.abs(currentTime - timestamp) < 0.5;\n    72→  };\n    73→\n    74→  return (\n    75→    <div className={`rounded-xl border-2 overflow-hidden ${getSeverityColor(issue.severity)}`}>\n    76→      {/* Header */}\n    77→      <div className=\"p-4 border-b border-current/10\">\n    78→        <div className=\"flex items-start justify-between\">\n    79→          <div className=\"flex-1\">\n    80→            <div className=\"flex items-center gap-2 mb-1\">\n    81→              <span className={`w-2 h-2 rounded-full ${getSeverityBadgeColor(issue.severity)}`}></span>\n    82→              <h3 className=\"font-semibold\">{issue.title}</h3>\n    83→            </div>\n    84→            {issue.description && (\n    85→              <p className=\"text-sm opacity-80\">{issue.description}</p>\n    86→            )}\n    87→          </div>\n    88→          <span className=\"text-xs uppercase font-bold px-2 py-1 rounded bg-current/10\">\n    89→            {issue.severity}\n    90→          </span>\n    91→        </div>\n    92→      </div>\n    93→\n    94→      {/* 3D Skeleton Animation or Keyframe Carousel */}\n    95→      <div className=\"p-4 bg-white/50\">\n    96→        <p className=\"text-xs font-medium text-gray-600 mb-2\">Correct Form:</p>\n    97→\n    98→        {/* 3D Animation (default) */}\n    99→        <div className=\"flex justify-center\">\n   100→          <Skeleton3D\n   101→            drillType={drillType}\n   102→            activePhase={activeKeyframe}\n   103→            isPlaying={true}\n   104→            showLabels={true}\n   105→            width={200}\n   106→            height={250}\n   107→          />\n   108→        </div>\n   109→\n   110→        {/* Phase selector tabs */}\n   111→        <div className=\"flex justify-center gap-2 mt-2\">\n   112→          {keyframes.map((keyframe, index) => (\n   113→            <button\n   114→              key={index}\n   115→              onClick={() => setActiveKeyframe(index)}\n   116→              className={`px-3 py-1.5 text-xs font-medium rounded-full transition ${\n   117→                activeKeyframe === index\n   118→                  ? 'bg-primary-500 text-white'\n   119→                  : 'bg-gray-100 text-gray-600 hover:bg-gray-200'\n   120→              }`}\n   121→            >\n   122→              {keyframe.label}\n   123→            </button>\n   124→          ))}\n   125→        </div>\n   126→      </div>\n   127→\n   128→      {/* Timestamps */}\n   129→      {issue.timestamps && issue.timestamps.length > 0 && (\n   130→        <div className=\"px-4 py-3 bg-white/30 border-t border-current/10\">\n   131→          <p className=\"text-xs font-medium text-gray-600 mb-2\">\n   132→            Occurred at ({issue.timestamps.length}x):\n   133→          </p>\n   134→          <div className=\"flex flex-wrap gap-2\">\n   135→            {issue.timestamps.slice(0, 8).map((timestamp, index) => (\n   136→              <button\n   137→                key={index}\n   138→                onClick={() => onTimestampClick?.(timestamp)}\n   139→                className={`px-2 py-1 text-xs font-mono rounded transition ${\n   140→                  isTimestampActive(timestamp)\n   141→                    ? 'bg-primary-500 text-white'\n   142→                    : 'bg-gray-100 text-gray-700 hover:bg-gray-200'\n   143→                }`}\n   144→              >\n   145→                {formatTimestamp(timestamp)}\n   146→              </button>\n   147→            ))}\n   148→            {issue.timestamps.length > 8 && (\n   149→              <span className=\"px-2 py-1 text-xs text-gray-500\">\n   150→                +{issue.timestamps.length - 8} more\n   151→              </span>\n   152→            )}\n   153→          </div>\n   154→        </div>\n   155→      )}\n   156→\n   157→      {/* Drill Info */}\n   158→      {drill && (\n   159→        <div className=\"p-4 bg-white/30 border-t border-current/10\">\n   160→          <div className=\"flex items-center justify-between mb-3\">\n   161→            <div>\n   162→              <p className=\"text-xs font-medium text-gray-600\">Recommended Drill:</p>\n   163→              <p className=\"font-semibold text-gray-900\">{drill.name}</p>\n   164→            </div>\n   165→            <span className=\"text-sm text-gray-500\">{drill.durationMinutes} min</span>\n   166→          </div>\n   167→\n   168→          {/* Drill Steps */}\n   169→          <div className=\"mb-3\">\n   170→            <ol className=\"list-decimal list-inside space-y-1 text-sm text-gray-700\">\n   171→              {drill.steps.slice(0, 3).map((step, index) => (\n   172→                <li key={index}>{step}</li>\n   173→              ))}\n   174→            </ol>\n   175→          </div>\n   176→\n   177→          {/* Tips */}\n   178→          {drill.tips.length > 0 && (\n   179→            <div className=\"flex flex-wrap gap-1 mb-3\">\n   180→              {drill.tips.map((tip, index) => (\n   181→                <span\n   182→                  key={index}\n   183→                  className=\"text-xs px-2 py-1 bg-primary-50 text-primary-700 rounded\"\n   184→                >\n   185→                  {tip}\n   186→                </span>\n   187→              ))}\n   188→            </div>\n   189→          )}\n   190→\n   191→          {/* Practice Button */}\n   192→          <Link\n   193→            href={`/practice?drill=${drill.id}`}\n   194→            className=\"block w-full py-2 bg-primary-500 text-white text-center rounded-lg font-medium hover:bg-primary-600 transition\"\n   195→          >\n   196→            Practice This Drill\n   197→          </Link>\n   198→        </div>\n   199→      )}\n   200→    </div>\n   201→  );\n   202→}\n   203→\n   204→// Mini version for lists\n   205→export function DrillCardMini({\n   206→  issue,\n   207→  onClick,\n   208→}: {\n   209→  issue: { code: string; title: string; severity: string; count?: number };\n   210→  onClick?: () => void;\n   211→}) {\n   212→  const getSeverityColor = (severity: string) => {\n   213→    switch (severity) {\n   214→      case 'high':\n   215→        return 'border-red-300 bg-red-50';\n   216→      case 'medium':\n   217→        return 'border-yellow-300 bg-yellow-50';\n   218→      default:\n   219→        return 'border-green-300 bg-green-50';\n   220→    }\n   221→  };\n   222→\n   223→  return (\n   224→    <button\n   225→      onClick={onClick}\n   226→      className={`w-full text-left p-3 rounded-lg border-2 transition hover:shadow-md ${getSeverityColor(issue.severity)}`}\n   227→    >\n   228→      <div className=\"flex items-center justify-between\">\n   229→        <span className=\"font-medium text-gray-900\">{issue.title}</span>\n   230→        {issue.count && (\n   231→          <span className=\"text-xs text-gray-500\">{issue.count}x</span>\n   232→        )}\n   233→      </div>\n   234→    </button>\n   235→  );\n   236→}\n   237→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"3dc1a113-b5c6-4567-8e07-dad72ad49ca0","timestamp":"2026-01-28T05:06:48.283Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\DrillCard.tsx","content":"'use client';\n\nimport { useState } from 'react';\nimport Link from 'next/link';\nimport { getKeyframeSVGs, type DrillDefinition } from '@/lib/rules-engine';\nimport Skeleton3D from './Skeleton3D';\n\ninterface DrillCardProps {\n  issue: {\n    code: string;\n    title: string;\n    severity: 'low' | 'medium' | 'high';\n    description?: string;\n    timestamps?: number[];\n    drill?: DrillDefinition;\n  };\n  onTimestampClick?: (timestamp: number) => void;\n  onPracticeClick?: (drillId: string) => void;\n  currentTime?: number;\n}\n\nexport default function DrillCard({\n  issue,\n  onTimestampClick,\n  onPracticeClick,\n  currentTime = 0,\n}: DrillCardProps) {\n  const [activeKeyframe, setActiveKeyframe] = useState(0);\n\n  // Get drill info\n  const drill = issue.drill;\n  const drillType = (drill?.keyframeType || 'footwork') as 'smash' | 'clear' | 'netshot' | 'footwork' | 'drive';\n  const keyframes = getKeyframeSVGs(drillType, { width: 100, height: 150 });\n\n  // Get severity color\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const getSeverityBadgeColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-500';\n      case 'medium':\n        return 'bg-yellow-500';\n      case 'low':\n        return 'bg-green-500';\n      default:\n        return 'bg-gray-500';\n    }\n  };\n\n  // Format timestamp for display\n  const formatTimestamp = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Check if a timestamp is currently playing\n  const isTimestampActive = (timestamp: number) => {\n    return Math.abs(currentTime - timestamp) < 0.5;\n  };\n\n  return (\n    <div className={`rounded-xl border-2 overflow-hidden ${getSeverityColor(issue.severity)}`}>\n      {/* Header */}\n      <div className=\"p-4 border-b border-current/10\">\n        <div className=\"flex items-start justify-between\">\n          <div className=\"flex-1\">\n            <div className=\"flex items-center gap-2 mb-1\">\n              <span className={`w-2 h-2 rounded-full ${getSeverityBadgeColor(issue.severity)}`}></span>\n              <h3 className=\"font-semibold\">{issue.title}</h3>\n            </div>\n            {issue.description && (\n              <p className=\"text-sm opacity-80\">{issue.description}</p>\n            )}\n          </div>\n          <span className=\"text-xs uppercase font-bold px-2 py-1 rounded bg-current/10\">\n            {issue.severity}\n          </span>\n        </div>\n      </div>\n\n      {/* 3D Skeleton Animation or Keyframe Carousel */}\n      <div className=\"p-4 bg-white/50\">\n        <p className=\"text-xs font-medium text-gray-600 mb-2\">Correct Form:</p>\n\n        {/* 3D Animation (default) */}\n        <div className=\"flex justify-center\">\n          <Skeleton3D\n            drillType={drillType}\n            activePhase={activeKeyframe}\n            isPlaying={true}\n            showLabels={true}\n            width={200}\n            height={250}\n          />\n        </div>\n\n        {/* Phase selector tabs */}\n        <div className=\"flex justify-center gap-2 mt-2\">\n          {keyframes.map((keyframe, index) => (\n            <button\n              key={index}\n              onClick={() => setActiveKeyframe(index)}\n              className={`px-3 py-1.5 text-xs font-medium rounded-full transition ${\n                activeKeyframe === index\n                  ? 'bg-primary-500 text-white'\n                  : 'bg-gray-100 text-gray-600 hover:bg-gray-200'\n              }`}\n            >\n              {keyframe.label}\n            </button>\n          ))}\n        </div>\n      </div>\n\n      {/* Timestamps */}\n      {issue.timestamps && issue.timestamps.length > 0 && (\n        <div className=\"px-4 py-3 bg-white/30 border-t border-current/10\">\n          <p className=\"text-xs font-medium text-gray-600 mb-2\">\n            Occurred at ({issue.timestamps.length}x):\n          </p>\n          <div className=\"flex flex-wrap gap-2\">\n            {issue.timestamps.slice(0, 8).map((timestamp, index) => (\n              <button\n                key={index}\n                onClick={() => onTimestampClick?.(timestamp)}\n                className={`px-2 py-1 text-xs font-mono rounded transition ${\n                  isTimestampActive(timestamp)\n                    ? 'bg-primary-500 text-white'\n                    : 'bg-gray-100 text-gray-700 hover:bg-gray-200'\n                }`}\n              >\n                {formatTimestamp(timestamp)}\n              </button>\n            ))}\n            {issue.timestamps.length > 8 && (\n              <span className=\"px-2 py-1 text-xs text-gray-500\">\n                +{issue.timestamps.length - 8} more\n              </span>\n            )}\n          </div>\n        </div>\n      )}\n\n      {/* Drill Info */}\n      {drill && (\n        <div className=\"p-4 bg-white/30 border-t border-current/10\">\n          <div className=\"flex items-center justify-between mb-3\">\n            <div>\n              <p className=\"text-xs font-medium text-gray-600\">Recommended Drill:</p>\n              <p className=\"font-semibold text-gray-900\">{drill.name}</p>\n            </div>\n            <span className=\"text-sm text-gray-500\">{drill.durationMinutes} min</span>\n          </div>\n\n          {/* Drill Steps */}\n          <div className=\"mb-3\">\n            <ol className=\"list-decimal list-inside space-y-1 text-sm text-gray-700\">\n              {drill.steps.slice(0, 3).map((step, index) => (\n                <li key={index}>{step}</li>\n              ))}\n            </ol>\n          </div>\n\n          {/* Tips */}\n          {drill.tips.length > 0 && (\n            <div className=\"flex flex-wrap gap-1 mb-3\">\n              {drill.tips.map((tip, index) => (\n                <span\n                  key={index}\n                  className=\"text-xs px-2 py-1 bg-primary-50 text-primary-700 rounded\"\n                >\n                  {tip}\n                </span>\n              ))}\n            </div>\n          )}\n\n          {/* Practice Button */}\n          <Link\n            href={`/practice?drill=${drill.id}`}\n            className=\"block w-full py-2 bg-primary-500 text-white text-center rounded-lg font-medium hover:bg-primary-600 transition\"\n          >\n            Practice This Drill\n          </Link>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// Mini version for lists\nexport function DrillCardMini({\n  issue,\n  onClick,\n}: {\n  issue: { code: string; title: string; severity: string; count?: number };\n  onClick?: () => void;\n}) {\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'border-red-300 bg-red-50';\n      case 'medium':\n        return 'border-yellow-300 bg-yellow-50';\n      default:\n        return 'border-green-300 bg-green-50';\n    }\n  };\n\n  return (\n    <button\n      onClick={onClick}\n      className={`w-full text-left p-3 rounded-lg border-2 transition hover:shadow-md ${getSeverityColor(issue.severity)}`}\n    >\n      <div className=\"flex items-center justify-between\">\n        <span className=\"font-medium text-gray-900\">{issue.title}</span>\n        {issue.count && (\n          <span className=\"text-xs text-gray-500\">{issue.count}x</span>\n        )}\n      </div>\n    </button>\n  );\n}\n","numLines":237,"startLine":1,"totalLines":237}},"sourceToolAssistantUUID":"ddea4ddd-11f1-4d1e-9de0-cd28873bb1bd"}
{"parentUuid":"393e8c6b-ec71-4b0f-a802-341048848789","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01V567iNe6TKMJVDApojhzjP","type":"tool_result","content":"     1→'use client';\n     2→\n     3→import { useState, useEffect, useCallback, useRef } from 'react';\n     4→import type { PoseLandmark } from '@/lib/types';\n     5→\n     6→// Interface matching page.tsx expectations\n     7→export interface GuidanceKeyframe {\n     8→  name: string;\n     9→  description: string;\n    10→  landmarks: PoseLandmark[] | null;\n    11→  targetLandmarks?: PoseLandmark[] | null;\n    12→  correction?: string;\n    13→}\n    14→\n    15→interface GuidanceAnimationProps {\n    16→  keyframes: GuidanceKeyframe[];\n    17→  primaryIssue?: {\n    18→    code: string;\n    19→    title: string;\n    20→    severity: string;\n    21→    description?: string;\n    22→  } | null;\n    23→  width?: number;\n    24→  height?: number;\n    25→}\n    26→\n    27→// Skeleton connection pairs for drawing\n    28→const POSE_CONNECTIONS = [\n    29→  // Torso\n    30→  [11, 12], [11, 23], [12, 24], [23, 24],\n    31→  // Left arm\n    32→  [11, 13], [13, 15],\n    33→  // Right arm\n    34→  [12, 14], [14, 16],\n    35→  // Left leg\n    36→  [23, 25], [25, 27],\n    37→  // Right leg\n    38→  [24, 26], [26, 28],\n    39→  // Wrists to hands\n    40→  [15, 17], [15, 19], [15, 21],\n    41→  [16, 18], [16, 20], [16, 22],\n    42→];\n    43→\n    44→// Colors for different states\n    45→const COLORS = {\n    46→  current: { stroke: '#EF4444', fill: '#FEE2E2', joint: '#DC2626' }, // Red for current form\n    47→  target: { stroke: '#22C55E', fill: '#DCFCE7', joint: '#16A34A' }, // Green for target form\n    48→  transition: { stroke: '#3B82F6', fill: '#DBEAFE', joint: '#2563EB' }, // Blue for transition\n    49→};\n    50→\n    51→export default function GuidanceAnimation({\n    52→  keyframes,\n    53→  primaryIssue,\n    54→  width = 280,\n    55→  height = 220,\n    56→}: GuidanceAnimationProps) {\n    57→  const [activeIndex, setActiveIndex] = useState(0);\n    58→  const [animationPhase, setAnimationPhase] = useState<'current' | 'target' | 'transition'>('current');\n    59→  const [interpolation, setInterpolation] = useState(0);\n    60→  const canvasRef = useRef<HTMLCanvasElement>(null);\n    61→  const animationRef = useRef<number | null>(null);\n    62→\n    63→  // Auto-cycle through keyframes\n    64→  useEffect(() => {\n    65→    if (keyframes.length === 0) return;\n    66→\n    67→    const interval = setInterval(() => {\n    68→      setActiveIndex((prev) => (prev + 1) % keyframes.length);\n    69→    }, 3000);\n    70→\n    71→    return () => clearInterval(interval);\n    72→  }, [keyframes.length]);\n    73→\n    74→  // Animation loop for smooth interpolation\n    75→  useEffect(() => {\n    76→    if (keyframes.length === 0) return;\n    77→\n    78→    const activeKeyframe = keyframes[activeIndex];\n    79→    const hasTarget = activeKeyframe?.targetLandmarks && activeKeyframe.landmarks;\n    80→\n    81→    if (!hasTarget) {\n    82→      setAnimationPhase('current');\n    83→      setInterpolation(0);\n    84→      return;\n    85→    }\n    86→\n    87→    let startTime: number | null = null;\n    88→    const duration = 2000; // 2 seconds per cycle\n    89→\n    90→    const animate = (timestamp: number) => {\n    91→      if (!startTime) startTime = timestamp;\n    92→      const elapsed = timestamp - startTime;\n    93→      const progress = (elapsed % duration) / duration;\n    94→\n    95→      // Ping-pong animation: 0 -> 1 -> 0\n    96→      const pingPong = progress < 0.5\n    97→        ? progress * 2\n    98→        : 2 - progress * 2;\n    99→\n   100→      setInterpolation(pingPong);\n   101→      setAnimationPhase(pingPong < 0.3 ? 'current' : pingPong > 0.7 ? 'target' : 'transition');\n   102→\n   103→      animationRef.current = requestAnimationFrame(animate);\n   104→    };\n   105→\n   106→    animationRef.current = requestAnimationFrame(animate);\n   107→\n   108→    return () => {\n   109→      if (animationRef.current) {\n   110→        cancelAnimationFrame(animationRef.current);\n   111→      }\n   112→    };\n   113→  }, [keyframes, activeIndex]);\n   114→\n   115→  // Draw skeleton on canvas\n   116→  const drawSkeleton = useCallback(\n   117→    (\n   118→      ctx: CanvasRenderingContext2D,\n   119→      landmarks: PoseLandmark[],\n   120→      colors: typeof COLORS.current,\n   121→      alpha: number = 1\n   122→    ) => {\n   123→      if (!landmarks || landmarks.length === 0) return;\n   124→\n   125→      const padding = 20;\n   126→      const drawWidth = width - padding * 2;\n   127→      const drawHeight = height - padding * 2;\n   128→\n   129→      ctx.globalAlpha = alpha;\n   130→\n   131→      // Draw connections\n   132→      ctx.strokeStyle = colors.stroke;\n   133→      ctx.lineWidth = 3;\n   134→      ctx.lineCap = 'round';\n   135→\n   136→      POSE_CONNECTIONS.forEach(([startIdx, endIdx]) => {\n   137→        const start = landmarks[startIdx];\n   138→        const end = landmarks[endIdx];\n   139→        if (!start || !end) return;\n   140→        if ((start.visibility || 0) < 0.3 || (end.visibility || 0) < 0.3) return;\n   141→\n   142→        ctx.beginPath();\n   143→        ctx.moveTo(\n   144→          padding + start.x * drawWidth,\n   145→          padding + start.y * drawHeight\n   146→        );\n   147→        ctx.lineTo(\n   148→          padding + end.x * drawWidth,\n   149→          padding + end.y * drawHeight\n   150→        );\n   151→        ctx.stroke();\n   152→      });\n   153→\n   154→      // Draw joints\n   155→      landmarks.forEach((landmark, idx) => {\n   156→        if ((landmark.visibility || 0) < 0.3) return;\n   157→\n   158→        const x = padding + landmark.x * drawWidth;\n   159→        const y = padding + landmark.y * drawHeight;\n   160→\n   161→        // Key joints are larger\n   162→        const isKeyJoint = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28].includes(idx);\n   163→        const radius = isKeyJoint ? 5 : 3;\n   164→\n   165→        ctx.beginPath();\n   166→        ctx.arc(x, y, radius, 0, Math.PI * 2);\n   167→        ctx.fillStyle = colors.joint;\n   168→        ctx.fill();\n   169→        ctx.strokeStyle = '#fff';\n   170→        ctx.lineWidth = 1.5;\n   171→        ctx.stroke();\n   172→      });\n   173→\n   174→      ctx.globalAlpha = 1;\n   175→    },\n   176→    [width, height]\n   177→  );\n   178→\n   179→  // Interpolate between two landmark sets\n   180→  const interpolateLandmarks = useCallback(\n   181→    (from: PoseLandmark[], to: PoseLandmark[], t: number): PoseLandmark[] => {\n   182→      return from.map((landmark, idx) => {\n   183→        const target = to[idx];\n   184→        if (!target) return landmark;\n   185→\n   186→        return {\n   187→          x: landmark.x + (target.x - landmark.x) * t,\n   188→          y: landmark.y + (target.y - landmark.y) * t,\n   189→          z: landmark.z + (target.z - landmark.z) * t,\n   190→          visibility: Math.max(landmark.visibility || 0, target.visibility || 0),\n   191→        };\n   192→      });\n   193→    },\n   194→    []\n   195→  );\n   196→\n   197→  // Render canvas\n   198→  useEffect(() => {\n   199→    const canvas = canvasRef.current;\n   200→    if (!canvas) return;\n   201→\n   202→    const ctx = canvas.getContext('2d');\n   203→    if (!ctx) return;\n   204→\n   205→    // Clear canvas\n   206→    ctx.clearRect(0, 0, width, height);\n   207→\n   208→    // Background\n   209→    const gradient = ctx.createLinearGradient(0, 0, 0, height);\n   210→    gradient.addColorStop(0, '#F8FAFC');\n   211→    gradient.addColorStop(1, '#F1F5F9');\n   212→    ctx.fillStyle = gradient;\n   213→    ctx.fillRect(0, 0, width, height);\n   214→\n   215→    const activeKeyframe = keyframes[activeIndex];\n   216→    if (!activeKeyframe) return;\n   217→\n   218→    const { landmarks, targetLandmarks } = activeKeyframe;\n   219→\n   220→    if (landmarks && targetLandmarks) {\n   221→      // Draw interpolated skeleton\n   222→      const interpolated = interpolateLandmarks(\n   223→        landmarks,\n   224→        targetLandmarks,\n   225→        interpolation\n   226→      );\n   227→\n   228→      // Ghost of current form (faded)\n   229→      if (animationPhase !== 'current') {\n   230→        drawSkeleton(ctx, landmarks, COLORS.current, 0.2);\n   231→      }\n   232→\n   233→      // Ghost of target form (faded)\n   234→      if (animationPhase !== 'target') {\n   235→        drawSkeleton(ctx, targetLandmarks, COLORS.target, 0.2);\n   236→      }\n   237→\n   238→      // Main interpolated skeleton\n   239→      const mainColors = animationPhase === 'current'\n   240→        ? COLORS.current\n   241→        : animationPhase === 'target'\n   242→          ? COLORS.target\n   243→          : COLORS.transition;\n   244→\n   245→      drawSkeleton(ctx, interpolated, mainColors, 1);\n   246→\n   247→      // Draw arrows showing correction direction at key joints\n   248→      if (animationPhase === 'transition') {\n   249→        ctx.strokeStyle = '#3B82F680';\n   250→        ctx.lineWidth = 2;\n   251→        ctx.setLineDash([4, 4]);\n   252→\n   253→        const keyJoints = [13, 14, 15, 16, 25, 26]; // Elbows, wrists, knees\n   254→        const padding = 20;\n   255→        const drawWidth = width - padding * 2;\n   256→        const drawHeight = height - padding * 2;\n   257→\n   258→        keyJoints.forEach((idx) => {\n   259→          const from = landmarks[idx];\n   260→          const to = targetLandmarks[idx];\n   261→          if (!from || !to) return;\n   262→          if ((from.visibility || 0) < 0.5) return;\n   263→\n   264→          const startX = padding + from.x * drawWidth;\n   265→          const startY = padding + from.y * drawHeight;\n   266→          const endX = padding + to.x * drawWidth;\n   267→          const endY = padding + to.y * drawHeight;\n   268→\n   269→          // Only draw if there's significant movement\n   270→          const dist = Math.sqrt(Math.pow(endX - startX, 2) + Math.pow(endY - startY, 2));\n   271→          if (dist < 5) return;\n   272→\n   273→          ctx.beginPath();\n   274→          ctx.moveTo(startX, startY);\n   275→          ctx.lineTo(endX, endY);\n   276→          ctx.stroke();\n   277→\n   278→          // Arrowhead\n   279→          const angle = Math.atan2(endY - startY, endX - startX);\n   280→          ctx.beginPath();\n   281→          ctx.moveTo(endX, endY);\n   282→          ctx.lineTo(\n   283→            endX - 8 * Math.cos(angle - Math.PI / 6),\n   284→            endY - 8 * Math.sin(angle - Math.PI / 6)\n   285→          );\n   286→          ctx.moveTo(endX, endY);\n   287→          ctx.lineTo(\n   288→            endX - 8 * Math.cos(angle + Math.PI / 6),\n   289→            endY - 8 * Math.sin(angle + Math.PI / 6)\n   290→          );\n   291→          ctx.stroke();\n   292→        });\n   293→\n   294→        ctx.setLineDash([]);\n   295→      }\n   296→    } else if (landmarks) {\n   297→      // Only current landmarks, draw static\n   298→      drawSkeleton(ctx, landmarks, COLORS.current, 1);\n   299→    } else {\n   300→      // No landmarks, draw placeholder\n   301→      drawPlaceholder(ctx, width, height);\n   302→    }\n   303→  }, [keyframes, activeIndex, interpolation, animationPhase, width, height, drawSkeleton, interpolateLandmarks]);\n   304→\n   305→  // Draw placeholder skeleton when no landmarks\n   306→  const drawPlaceholder = (ctx: CanvasRenderingContext2D, w: number, h: number) => {\n   307→    const centerX = w / 2;\n   308→    const baseY = h * 0.2;\n   309→\n   310→    ctx.strokeStyle = '#CBD5E1';\n   311→    ctx.lineWidth = 3;\n   312→    ctx.lineCap = 'round';\n   313→\n   314→    // Head\n   315→    ctx.beginPath();\n   316→    ctx.arc(centerX, baseY, 12, 0, Math.PI * 2);\n   317→    ctx.stroke();\n   318→\n   319→    // Spine\n   320→    ctx.beginPath();\n   321→    ctx.moveTo(centerX, baseY + 12);\n   322→    ctx.lineTo(centerX, baseY + 55);\n   323→    ctx.stroke();\n   324→\n   325→    // Shoulders\n   326→    ctx.beginPath();\n   327→    ctx.moveTo(centerX - 25, baseY + 20);\n   328→    ctx.lineTo(centerX + 25, baseY + 20);\n   329→    ctx.stroke();\n   330→\n   331→    // Arms\n   332→    ctx.beginPath();\n   333→    ctx.moveTo(centerX - 25, baseY + 20);\n   334→    ctx.lineTo(centerX - 40, baseY + 45);\n   335→    ctx.lineTo(centerX - 35, baseY + 70);\n   336→    ctx.stroke();\n   337→\n   338→    ctx.beginPath();\n   339→    ctx.moveTo(centerX + 25, baseY + 20);\n   340→    ctx.lineTo(centerX + 40, baseY + 45);\n   341→    ctx.lineTo(centerX + 35, baseY + 70);\n   342→    ctx.stroke();\n   343→\n   344→    // Hips\n   345→    ctx.beginPath();\n   346→    ctx.moveTo(centerX - 15, baseY + 55);\n   347→    ctx.lineTo(centerX + 15, baseY + 55);\n   348→    ctx.stroke();\n   349→\n   350→    // Legs\n   351→    ctx.beginPath();\n   352→    ctx.moveTo(centerX - 15, baseY + 55);\n   353→    ctx.lineTo(centerX - 20, baseY + 90);\n   354→    ctx.lineTo(centerX - 20, baseY + 120);\n   355→    ctx.stroke();\n   356→\n   357→    ctx.beginPath();\n   358→    ctx.moveTo(centerX + 15, baseY + 55);\n   359→    ctx.lineTo(centerX + 20, baseY + 90);\n   360→    ctx.lineTo(centerX + 20, baseY + 120);\n   361→    ctx.stroke();\n   362→\n   363→    // Text\n   364→    ctx.fillStyle = '#94A3B8';\n   365→    ctx.font = '12px system-ui';\n   366→    ctx.textAlign = 'center';\n   367→    ctx.fillText('Analyzing form...', centerX, h - 15);\n   368→  };\n   369→\n   370→  if (keyframes.length === 0) {\n   371→    return (\n   372→      <div\n   373→        className=\"flex flex-col items-center justify-center bg-slate-100 rounded-xl\"\n   374→        style={{ width, height: height + 80 }}\n   375→      >\n   376→        <div className=\"text-slate-400 text-sm\">No guidance available</div>\n   377→        <div className=\"text-slate-300 text-xs mt-1\">Complete analysis first</div>\n   378→      </div>\n   379→    );\n   380→  }\n   381→\n   382→  const activeKeyframe = keyframes[activeIndex];\n   383→\n   384→  return (\n   385→    <div className=\"flex flex-col gap-3\" style={{ width }}>\n   386→      {/* Issue header */}\n   387→      {primaryIssue && (\n   388→        <div className=\"flex items-center gap-2 px-3 py-2 bg-red-50 border border-red-200 rounded-lg\">\n   389→          <span className=\"w-2 h-2 rounded-full bg-red-500 animate-pulse\" />\n   390→          <span className=\"text-sm font-medium text-red-800 truncate\">\n   391→            {primaryIssue.title}\n   392→          </span>\n   393→        </div>\n   394→      )}\n   395→\n   396→      {/* Canvas with animation */}\n   397→      <div\n   398→        className=\"relative rounded-xl overflow-hidden border border-slate-200\"\n   399→        style={{ width, height }}\n   400→      >\n   401→        <canvas\n   402→          ref={canvasRef}\n   403→          width={width}\n   404→          height={height}\n   405→          className=\"w-full h-full\"\n   406→        />\n   407→\n   408→        {/* Legend overlay */}\n   409→        <div className=\"absolute top-2 right-2 flex flex-col gap-1\">\n   410→          <div className=\"flex items-center gap-1.5 px-2 py-1 bg-white/90 rounded text-xs\">\n   411→            <span\n   412→              className=\"w-2.5 h-2.5 rounded-full\"\n   413→              style={{ backgroundColor: COLORS.current.joint }}\n   414→            />\n   415→            <span className=\"text-slate-600\">Current</span>\n   416→          </div>\n   417→          <div className=\"flex items-center gap-1.5 px-2 py-1 bg-white/90 rounded text-xs\">\n   418→            <span\n   419→              className=\"w-2.5 h-2.5 rounded-full\"\n   420→              style={{ backgroundColor: COLORS.target.joint }}\n   421→            />\n   422→            <span className=\"text-slate-600\">Target</span>\n   423→          </div>\n   424→        </div>\n   425→\n   426→        {/* Phase indicator */}\n   427→        <div className=\"absolute bottom-2 left-2 px-2 py-1 bg-white/90 rounded text-xs font-medium\">\n   428→          {activeKeyframe?.name || 'Form Analysis'}\n   429→        </div>\n   430→      </div>\n   431→\n   432→      {/* Correction text */}\n   433→      {activeKeyframe?.correction && (\n   434→        <div className=\"px-3 py-2 bg-blue-50 border border-blue-200 rounded-lg\">\n   435→          <p className=\"text-sm text-blue-800 font-medium flex items-start gap-2\">\n   436→            <svg className=\"w-4 h-4 mt-0.5 flex-shrink-0\" fill=\"none\" viewBox=\"0 0 24 24\" stroke=\"currentColor\">\n   437→              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n   438→            </svg>\n   439→            {activeKeyframe.correction}\n   440→          </p>\n   441→        </div>\n   442→      )}\n   443→\n   444→      {/* Keyframe selector */}\n   445→      {keyframes.length > 1 && (\n   446→        <div className=\"flex justify-center gap-2\">\n   447→          {keyframes.map((kf, index) => (\n   448→            <button\n   449→              key={index}\n   450→              onClick={() => setActiveIndex(index)}\n   451→              className={`px-3 py-1.5 text-xs font-medium rounded-full transition-all ${\n   452→                activeIndex === index\n   453→                  ? 'bg-slate-800 text-white shadow-md'\n   454→                  : 'bg-slate-100 text-slate-600 hover:bg-slate-200'\n   455→              }`}\n   456→            >\n   457→              {kf.name}\n   458→            </button>\n   459→          ))}\n   460→        </div>\n   461→      )}\n   462→\n   463→      {/* Description */}\n   464→      {activeKeyframe?.description && (\n   465→        <p className=\"text-xs text-slate-500 text-center px-2\">\n   466→          {activeKeyframe.description}\n   467→        </p>\n   468→      )}\n   469→    </div>\n   470→  );\n   471→}\n   472→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"22271277-b1ed-49de-9f15-4b3c9bce7d22","timestamp":"2026-01-28T05:06:48.283Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\GuidanceAnimation.tsx","content":"'use client';\n\nimport { useState, useEffect, useCallback, useRef } from 'react';\nimport type { PoseLandmark } from '@/lib/types';\n\n// Interface matching page.tsx expectations\nexport interface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\ninterface GuidanceAnimationProps {\n  keyframes: GuidanceKeyframe[];\n  primaryIssue?: {\n    code: string;\n    title: string;\n    severity: string;\n    description?: string;\n  } | null;\n  width?: number;\n  height?: number;\n}\n\n// Skeleton connection pairs for drawing\nconst POSE_CONNECTIONS = [\n  // Torso\n  [11, 12], [11, 23], [12, 24], [23, 24],\n  // Left arm\n  [11, 13], [13, 15],\n  // Right arm\n  [12, 14], [14, 16],\n  // Left leg\n  [23, 25], [25, 27],\n  // Right leg\n  [24, 26], [26, 28],\n  // Wrists to hands\n  [15, 17], [15, 19], [15, 21],\n  [16, 18], [16, 20], [16, 22],\n];\n\n// Colors for different states\nconst COLORS = {\n  current: { stroke: '#EF4444', fill: '#FEE2E2', joint: '#DC2626' }, // Red for current form\n  target: { stroke: '#22C55E', fill: '#DCFCE7', joint: '#16A34A' }, // Green for target form\n  transition: { stroke: '#3B82F6', fill: '#DBEAFE', joint: '#2563EB' }, // Blue for transition\n};\n\nexport default function GuidanceAnimation({\n  keyframes,\n  primaryIssue,\n  width = 280,\n  height = 220,\n}: GuidanceAnimationProps) {\n  const [activeIndex, setActiveIndex] = useState(0);\n  const [animationPhase, setAnimationPhase] = useState<'current' | 'target' | 'transition'>('current');\n  const [interpolation, setInterpolation] = useState(0);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Auto-cycle through keyframes\n  useEffect(() => {\n    if (keyframes.length === 0) return;\n\n    const interval = setInterval(() => {\n      setActiveIndex((prev) => (prev + 1) % keyframes.length);\n    }, 3000);\n\n    return () => clearInterval(interval);\n  }, [keyframes.length]);\n\n  // Animation loop for smooth interpolation\n  useEffect(() => {\n    if (keyframes.length === 0) return;\n\n    const activeKeyframe = keyframes[activeIndex];\n    const hasTarget = activeKeyframe?.targetLandmarks && activeKeyframe.landmarks;\n\n    if (!hasTarget) {\n      setAnimationPhase('current');\n      setInterpolation(0);\n      return;\n    }\n\n    let startTime: number | null = null;\n    const duration = 2000; // 2 seconds per cycle\n\n    const animate = (timestamp: number) => {\n      if (!startTime) startTime = timestamp;\n      const elapsed = timestamp - startTime;\n      const progress = (elapsed % duration) / duration;\n\n      // Ping-pong animation: 0 -> 1 -> 0\n      const pingPong = progress < 0.5\n        ? progress * 2\n        : 2 - progress * 2;\n\n      setInterpolation(pingPong);\n      setAnimationPhase(pingPong < 0.3 ? 'current' : pingPong > 0.7 ? 'target' : 'transition');\n\n      animationRef.current = requestAnimationFrame(animate);\n    };\n\n    animationRef.current = requestAnimationFrame(animate);\n\n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current);\n      }\n    };\n  }, [keyframes, activeIndex]);\n\n  // Draw skeleton on canvas\n  const drawSkeleton = useCallback(\n    (\n      ctx: CanvasRenderingContext2D,\n      landmarks: PoseLandmark[],\n      colors: typeof COLORS.current,\n      alpha: number = 1\n    ) => {\n      if (!landmarks || landmarks.length === 0) return;\n\n      const padding = 20;\n      const drawWidth = width - padding * 2;\n      const drawHeight = height - padding * 2;\n\n      ctx.globalAlpha = alpha;\n\n      // Draw connections\n      ctx.strokeStyle = colors.stroke;\n      ctx.lineWidth = 3;\n      ctx.lineCap = 'round';\n\n      POSE_CONNECTIONS.forEach(([startIdx, endIdx]) => {\n        const start = landmarks[startIdx];\n        const end = landmarks[endIdx];\n        if (!start || !end) return;\n        if ((start.visibility || 0) < 0.3 || (end.visibility || 0) < 0.3) return;\n\n        ctx.beginPath();\n        ctx.moveTo(\n          padding + start.x * drawWidth,\n          padding + start.y * drawHeight\n        );\n        ctx.lineTo(\n          padding + end.x * drawWidth,\n          padding + end.y * drawHeight\n        );\n        ctx.stroke();\n      });\n\n      // Draw joints\n      landmarks.forEach((landmark, idx) => {\n        if ((landmark.visibility || 0) < 0.3) return;\n\n        const x = padding + landmark.x * drawWidth;\n        const y = padding + landmark.y * drawHeight;\n\n        // Key joints are larger\n        const isKeyJoint = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28].includes(idx);\n        const radius = isKeyJoint ? 5 : 3;\n\n        ctx.beginPath();\n        ctx.arc(x, y, radius, 0, Math.PI * 2);\n        ctx.fillStyle = colors.joint;\n        ctx.fill();\n        ctx.strokeStyle = '#fff';\n        ctx.lineWidth = 1.5;\n        ctx.stroke();\n      });\n\n      ctx.globalAlpha = 1;\n    },\n    [width, height]\n  );\n\n  // Interpolate between two landmark sets\n  const interpolateLandmarks = useCallback(\n    (from: PoseLandmark[], to: PoseLandmark[], t: number): PoseLandmark[] => {\n      return from.map((landmark, idx) => {\n        const target = to[idx];\n        if (!target) return landmark;\n\n        return {\n          x: landmark.x + (target.x - landmark.x) * t,\n          y: landmark.y + (target.y - landmark.y) * t,\n          z: landmark.z + (target.z - landmark.z) * t,\n          visibility: Math.max(landmark.visibility || 0, target.visibility || 0),\n        };\n      });\n    },\n    []\n  );\n\n  // Render canvas\n  useEffect(() => {\n    const canvas = canvasRef.current;\n    if (!canvas) return;\n\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // Clear canvas\n    ctx.clearRect(0, 0, width, height);\n\n    // Background\n    const gradient = ctx.createLinearGradient(0, 0, 0, height);\n    gradient.addColorStop(0, '#F8FAFC');\n    gradient.addColorStop(1, '#F1F5F9');\n    ctx.fillStyle = gradient;\n    ctx.fillRect(0, 0, width, height);\n\n    const activeKeyframe = keyframes[activeIndex];\n    if (!activeKeyframe) return;\n\n    const { landmarks, targetLandmarks } = activeKeyframe;\n\n    if (landmarks && targetLandmarks) {\n      // Draw interpolated skeleton\n      const interpolated = interpolateLandmarks(\n        landmarks,\n        targetLandmarks,\n        interpolation\n      );\n\n      // Ghost of current form (faded)\n      if (animationPhase !== 'current') {\n        drawSkeleton(ctx, landmarks, COLORS.current, 0.2);\n      }\n\n      // Ghost of target form (faded)\n      if (animationPhase !== 'target') {\n        drawSkeleton(ctx, targetLandmarks, COLORS.target, 0.2);\n      }\n\n      // Main interpolated skeleton\n      const mainColors = animationPhase === 'current'\n        ? COLORS.current\n        : animationPhase === 'target'\n          ? COLORS.target\n          : COLORS.transition;\n\n      drawSkeleton(ctx, interpolated, mainColors, 1);\n\n      // Draw arrows showing correction direction at key joints\n      if (animationPhase === 'transition') {\n        ctx.strokeStyle = '#3B82F680';\n        ctx.lineWidth = 2;\n        ctx.setLineDash([4, 4]);\n\n        const keyJoints = [13, 14, 15, 16, 25, 26]; // Elbows, wrists, knees\n        const padding = 20;\n        const drawWidth = width - padding * 2;\n        const drawHeight = height - padding * 2;\n\n        keyJoints.forEach((idx) => {\n          const from = landmarks[idx];\n          const to = targetLandmarks[idx];\n          if (!from || !to) return;\n          if ((from.visibility || 0) < 0.5) return;\n\n          const startX = padding + from.x * drawWidth;\n          const startY = padding + from.y * drawHeight;\n          const endX = padding + to.x * drawWidth;\n          const endY = padding + to.y * drawHeight;\n\n          // Only draw if there's significant movement\n          const dist = Math.sqrt(Math.pow(endX - startX, 2) + Math.pow(endY - startY, 2));\n          if (dist < 5) return;\n\n          ctx.beginPath();\n          ctx.moveTo(startX, startY);\n          ctx.lineTo(endX, endY);\n          ctx.stroke();\n\n          // Arrowhead\n          const angle = Math.atan2(endY - startY, endX - startX);\n          ctx.beginPath();\n          ctx.moveTo(endX, endY);\n          ctx.lineTo(\n            endX - 8 * Math.cos(angle - Math.PI / 6),\n            endY - 8 * Math.sin(angle - Math.PI / 6)\n          );\n          ctx.moveTo(endX, endY);\n          ctx.lineTo(\n            endX - 8 * Math.cos(angle + Math.PI / 6),\n            endY - 8 * Math.sin(angle + Math.PI / 6)\n          );\n          ctx.stroke();\n        });\n\n        ctx.setLineDash([]);\n      }\n    } else if (landmarks) {\n      // Only current landmarks, draw static\n      drawSkeleton(ctx, landmarks, COLORS.current, 1);\n    } else {\n      // No landmarks, draw placeholder\n      drawPlaceholder(ctx, width, height);\n    }\n  }, [keyframes, activeIndex, interpolation, animationPhase, width, height, drawSkeleton, interpolateLandmarks]);\n\n  // Draw placeholder skeleton when no landmarks\n  const drawPlaceholder = (ctx: CanvasRenderingContext2D, w: number, h: number) => {\n    const centerX = w / 2;\n    const baseY = h * 0.2;\n\n    ctx.strokeStyle = '#CBD5E1';\n    ctx.lineWidth = 3;\n    ctx.lineCap = 'round';\n\n    // Head\n    ctx.beginPath();\n    ctx.arc(centerX, baseY, 12, 0, Math.PI * 2);\n    ctx.stroke();\n\n    // Spine\n    ctx.beginPath();\n    ctx.moveTo(centerX, baseY + 12);\n    ctx.lineTo(centerX, baseY + 55);\n    ctx.stroke();\n\n    // Shoulders\n    ctx.beginPath();\n    ctx.moveTo(centerX - 25, baseY + 20);\n    ctx.lineTo(centerX + 25, baseY + 20);\n    ctx.stroke();\n\n    // Arms\n    ctx.beginPath();\n    ctx.moveTo(centerX - 25, baseY + 20);\n    ctx.lineTo(centerX - 40, baseY + 45);\n    ctx.lineTo(centerX - 35, baseY + 70);\n    ctx.stroke();\n\n    ctx.beginPath();\n    ctx.moveTo(centerX + 25, baseY + 20);\n    ctx.lineTo(centerX + 40, baseY + 45);\n    ctx.lineTo(centerX + 35, baseY + 70);\n    ctx.stroke();\n\n    // Hips\n    ctx.beginPath();\n    ctx.moveTo(centerX - 15, baseY + 55);\n    ctx.lineTo(centerX + 15, baseY + 55);\n    ctx.stroke();\n\n    // Legs\n    ctx.beginPath();\n    ctx.moveTo(centerX - 15, baseY + 55);\n    ctx.lineTo(centerX - 20, baseY + 90);\n    ctx.lineTo(centerX - 20, baseY + 120);\n    ctx.stroke();\n\n    ctx.beginPath();\n    ctx.moveTo(centerX + 15, baseY + 55);\n    ctx.lineTo(centerX + 20, baseY + 90);\n    ctx.lineTo(centerX + 20, baseY + 120);\n    ctx.stroke();\n\n    // Text\n    ctx.fillStyle = '#94A3B8';\n    ctx.font = '12px system-ui';\n    ctx.textAlign = 'center';\n    ctx.fillText('Analyzing form...', centerX, h - 15);\n  };\n\n  if (keyframes.length === 0) {\n    return (\n      <div\n        className=\"flex flex-col items-center justify-center bg-slate-100 rounded-xl\"\n        style={{ width, height: height + 80 }}\n      >\n        <div className=\"text-slate-400 text-sm\">No guidance available</div>\n        <div className=\"text-slate-300 text-xs mt-1\">Complete analysis first</div>\n      </div>\n    );\n  }\n\n  const activeKeyframe = keyframes[activeIndex];\n\n  return (\n    <div className=\"flex flex-col gap-3\" style={{ width }}>\n      {/* Issue header */}\n      {primaryIssue && (\n        <div className=\"flex items-center gap-2 px-3 py-2 bg-red-50 border border-red-200 rounded-lg\">\n          <span className=\"w-2 h-2 rounded-full bg-red-500 animate-pulse\" />\n          <span className=\"text-sm font-medium text-red-800 truncate\">\n            {primaryIssue.title}\n          </span>\n        </div>\n      )}\n\n      {/* Canvas with animation */}\n      <div\n        className=\"relative rounded-xl overflow-hidden border border-slate-200\"\n        style={{ width, height }}\n      >\n        <canvas\n          ref={canvasRef}\n          width={width}\n          height={height}\n          className=\"w-full h-full\"\n        />\n\n        {/* Legend overlay */}\n        <div className=\"absolute top-2 right-2 flex flex-col gap-1\">\n          <div className=\"flex items-center gap-1.5 px-2 py-1 bg-white/90 rounded text-xs\">\n            <span\n              className=\"w-2.5 h-2.5 rounded-full\"\n              style={{ backgroundColor: COLORS.current.joint }}\n            />\n            <span className=\"text-slate-600\">Current</span>\n          </div>\n          <div className=\"flex items-center gap-1.5 px-2 py-1 bg-white/90 rounded text-xs\">\n            <span\n              className=\"w-2.5 h-2.5 rounded-full\"\n              style={{ backgroundColor: COLORS.target.joint }}\n            />\n            <span className=\"text-slate-600\">Target</span>\n          </div>\n        </div>\n\n        {/* Phase indicator */}\n        <div className=\"absolute bottom-2 left-2 px-2 py-1 bg-white/90 rounded text-xs font-medium\">\n          {activeKeyframe?.name || 'Form Analysis'}\n        </div>\n      </div>\n\n      {/* Correction text */}\n      {activeKeyframe?.correction && (\n        <div className=\"px-3 py-2 bg-blue-50 border border-blue-200 rounded-lg\">\n          <p className=\"text-sm text-blue-800 font-medium flex items-start gap-2\">\n            <svg className=\"w-4 h-4 mt-0.5 flex-shrink-0\" fill=\"none\" viewBox=\"0 0 24 24\" stroke=\"currentColor\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n            </svg>\n            {activeKeyframe.correction}\n          </p>\n        </div>\n      )}\n\n      {/* Keyframe selector */}\n      {keyframes.length > 1 && (\n        <div className=\"flex justify-center gap-2\">\n          {keyframes.map((kf, index) => (\n            <button\n              key={index}\n              onClick={() => setActiveIndex(index)}\n              className={`px-3 py-1.5 text-xs font-medium rounded-full transition-all ${\n                activeIndex === index\n                  ? 'bg-slate-800 text-white shadow-md'\n                  : 'bg-slate-100 text-slate-600 hover:bg-slate-200'\n              }`}\n            >\n              {kf.name}\n            </button>\n          ))}\n        </div>\n      )}\n\n      {/* Description */}\n      {activeKeyframe?.description && (\n        <p className=\"text-xs text-slate-500 text-center px-2\">\n          {activeKeyframe.description}\n        </p>\n      )}\n    </div>\n  );\n}\n","numLines":472,"startLine":1,"totalLines":472}},"sourceToolAssistantUUID":"393e8c6b-ec71-4b0f-a802-341048848789"}
{"parentUuid":"db60836f-837d-4c59-90b6-5673887a87a3","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VcMi7WUbSrPQ2Rb5Du9be1","type":"tool_result","content":"     1→import { NextResponse } from 'next/server';\n     2→import { GoogleGenAI, Type } from '@google/genai';\n     3→\n     4→// Initialize Gemini client\n     5→const genAI = new GoogleGenAI({\n     6→  apiKey: process.env.GEMINI_API_KEY!,\n     7→});\n     8→\n     9→const FLASH_MODEL = 'gemini-2.0-flash';\n    10→\n    11→// Schema for auto-level response\n    12→const autoLevelSchema = {\n    13→  type: Type.OBJECT,\n    14→  properties: {\n    15→    level: {\n    16→      type: Type.STRING,\n    17→      description: 'Detected skill level: beginner, intermediate, or advanced',\n    18→    },\n    19→    confidence: {\n    20→      type: Type.NUMBER,\n    21→      description: 'Confidence score from 0 to 1',\n    22→    },\n    23→    rationaleBullets: {\n    24→      type: Type.ARRAY,\n    25→      items: { type: Type.STRING },\n    26→      description: 'Array of 2-4 bullet points explaining the assessment',\n    27→    },\n    28→  },\n    29→  required: ['level', 'confidence', 'rationaleBullets'],\n    30→};\n    31→\n    32→interface AutoLevelRequest {\n    33→  metrics: {\n    34→    avgElbowAngle: number;\n    35→    avgKneeAngle: number;\n    36→    avgStanceWidth: number;\n    37→    movementIntensity: number;\n    38→    frameCount: number;\n    39→    consistencyScore: number;\n    40→  };\n    41→  issues: Array<{\n    42→    code: string;\n    43→    severity: string;\n    44→    count: number;\n    45→  }>;\n    46→}\n    47→\n    48→export async function POST(request: Request) {\n    49→  try {\n    50→    const body: AutoLevelRequest = await request.json();\n    51→    const { metrics, issues } = body;\n    52→\n    53→    if (!metrics) {\n    54→      return NextResponse.json(\n    55→        { error: 'metrics object is required' },\n    56→        { status: 400 }\n    57→      );\n    58→    }\n    59→\n    60→    // Build the prompt for Gemini\n    61→    const prompt = `You are an expert badminton coach assessing a player's skill level from pose analysis data.\n    62→\n    63→POSE METRICS FROM VIDEO:\n    64→- Average elbow angle: ${metrics.avgElbowAngle.toFixed(1)}° (ideal for clears: 90-120°)\n    65→- Average knee angle: ${metrics.avgKneeAngle.toFixed(1)}° (ideal ready position: 120-150°)\n    66→- Average stance width (normalized): ${metrics.avgStanceWidth.toFixed(3)} (ideal: 0.3-0.5)\n    67→- Movement intensity: ${metrics.movementIntensity.toFixed(2)} (higher = more dynamic movement)\n    68→- Frames analyzed: ${metrics.frameCount}\n    69→- Consistency score: ${(metrics.consistencyScore * 100).toFixed(0)}% (how stable form is across frames)\n    70→\n    71→DETECTED ISSUES:\n    72→${issues.length > 0\n    73→  ? issues.map(i => `- ${i.code} (${i.severity}): occurred ${i.count}x`).join('\\n')\n    74→  : '- No significant issues detected'}\n    75→\n    76→SKILL LEVEL CRITERIA:\n    77→- BEGINNER: Inconsistent form, multiple high-severity issues, limited movement, elbow/knee angles far from ideal\n    78→- INTERMEDIATE: Some consistency, mostly medium-severity issues, decent movement patterns, angles approaching ideal ranges\n    79→- ADVANCED: High consistency (>80%), few low-severity issues, dynamic movement, angles within ideal ranges\n    80→\n    81→Based on this data, determine the player's skill level.`;\n    82→\n    83→    try {\n    84→      const response = await genAI.models.generateContent({\n    85→        model: FLASH_MODEL,\n    86→        contents: prompt,\n    87→        config: {\n    88→          responseMimeType: 'application/json',\n    89→          responseSchema: autoLevelSchema,\n    90→          temperature: 0.2,\n    91→          maxOutputTokens: 300,\n    92→        },\n    93→      });\n    94→\n    95→      const result = JSON.parse(response.text || '{}');\n    96→\n    97→      // Validate and normalize the response\n    98→      const level = ['beginner', 'intermediate', 'advanced'].includes(result.level?.toLowerCase())\n    99→        ? result.level.toLowerCase()\n   100→        : determineRuleBasedLevel(metrics, issues);\n   101→\n   102→      const confidence = typeof result.confidence === 'number'\n   103→        ? Math.max(0, Math.min(1, result.confidence))\n   104→        : 0.7;\n   105→\n   106→      const rationaleBullets = Array.isArray(result.rationaleBullets) && result.rationaleBullets.length > 0\n   107→        ? result.rationaleBullets.slice(0, 4)\n   108→        : getRuleBasedRationale(metrics, issues, level);\n   109→\n   110→      return NextResponse.json({\n   111→        level,\n   112→        confidence,\n   113→        rationaleBullets,\n   114→      });\n   115→    } catch (geminiError) {\n   116→      console.error('Gemini auto-level error:', geminiError);\n   117→\n   118→      // Fallback to rule-based detection\n   119→      const level = determineRuleBasedLevel(metrics, issues);\n   120→      const rationale = getRuleBasedRationale(metrics, issues, level);\n   121→\n   122→      return NextResponse.json({\n   123→        level,\n   124→        confidence: 0.6,\n   125→        rationaleBullets: rationale,\n   126→      });\n   127→    }\n   128→  } catch (error) {\n   129→    console.error('Auto-level API error:', error);\n   130→    return NextResponse.json(\n   131→      { error: 'Failed to determine skill level' },\n   132→      { status: 500 }\n   133→    );\n   134→  }\n   135→}\n   136→\n   137→// Rule-based fallback for skill level detection\n   138→function determineRuleBasedLevel(\n   139→  metrics: AutoLevelRequest['metrics'],\n   140→  issues: AutoLevelRequest['issues']\n   141→): string {\n   142→  let score = 0;\n   143→\n   144→  // Consistency score (0-30 points)\n   145→  score += metrics.consistencyScore * 30;\n   146→\n   147→  // Elbow angle (0-20 points) - ideal is 90-120\n   148→  const elbowDiff = Math.min(\n   149→    Math.abs(metrics.avgElbowAngle - 90),\n   150→    Math.abs(metrics.avgElbowAngle - 120)\n   151→  );\n   152→  score += Math.max(0, 20 - elbowDiff);\n   153→\n   154→  // Knee angle (0-20 points) - ideal is 120-150\n   155→  const kneeDiff = Math.min(\n   156→    Math.abs(metrics.avgKneeAngle - 120),\n   157→    Math.abs(metrics.avgKneeAngle - 150)\n   158→  );\n   159→  score += Math.max(0, 20 - kneeDiff);\n   160→\n   161→  // Movement intensity (0-15 points)\n   162→  score += Math.min(15, metrics.movementIntensity * 30);\n   163→\n   164→  // Issue penalty (subtract points based on severity)\n   165→  const highIssues = issues.filter(i => i.severity === 'high').length;\n   166→  const mediumIssues = issues.filter(i => i.severity === 'medium').length;\n   167→  score -= highIssues * 10;\n   168→  score -= mediumIssues * 5;\n   169→\n   170→  // Normalize to 0-100\n   171→  score = Math.max(0, Math.min(100, score));\n   172→\n   173→  if (score >= 70) return 'advanced';\n   174→  if (score >= 40) return 'intermediate';\n   175→  return 'beginner';\n   176→}\n   177→\n   178→// Generate rationale bullets based on rules\n   179→function getRuleBasedRationale(\n   180→  metrics: AutoLevelRequest['metrics'],\n   181→  issues: AutoLevelRequest['issues'],\n   182→  level: string\n   183→): string[] {\n   184→  const bullets: string[] = [];\n   185→\n   186→  // Consistency assessment\n   187→  if (metrics.consistencyScore >= 0.8) {\n   188→    bullets.push(`High form consistency (${(metrics.consistencyScore * 100).toFixed(0)}%) indicates practiced technique`);\n   189→  } else if (metrics.consistencyScore >= 0.5) {\n   190→    bullets.push(`Moderate form consistency (${(metrics.consistencyScore * 100).toFixed(0)}%) shows developing technique`);\n   191→  } else {\n   192→    bullets.push(`Low form consistency (${(metrics.consistencyScore * 100).toFixed(0)}%) suggests need for fundamental work`);\n   193→  }\n   194→\n   195→  // Elbow angle assessment\n   196→  if (metrics.avgElbowAngle >= 90 && metrics.avgElbowAngle <= 120) {\n   197→    bullets.push(`Good elbow positioning (${metrics.avgElbowAngle.toFixed(0)}°) for power shots`);\n   198→  } else if (metrics.avgElbowAngle < 90) {\n   199→    bullets.push(`Elbow angle too tight (${metrics.avgElbowAngle.toFixed(0)}°) - limits power generation`);\n   200→  } else {\n   201→    bullets.push(`Elbow angle too open (${metrics.avgElbowAngle.toFixed(0)}°) - affects control`);\n   202→  }\n   203→\n   204→  // Issue summary\n   205→  const highCount = issues.filter(i => i.severity === 'high').length;\n   206→  const totalIssues = issues.length;\n   207→\n   208→  if (totalIssues === 0) {\n   209→    bullets.push('No significant form issues detected');\n   210→  } else if (highCount > 0) {\n   211→    bullets.push(`${highCount} high-priority issue${highCount > 1 ? 's' : ''} requiring attention`);\n   212→  } else {\n   213→    bullets.push(`${totalIssues} minor issue${totalIssues > 1 ? 's' : ''} to refine`);\n   214→  }\n   215→\n   216→  // Movement assessment\n   217→  if (metrics.movementIntensity > 0.5) {\n   218→    bullets.push('Dynamic movement patterns show athletic foundation');\n   219→  } else if (metrics.movementIntensity > 0.2) {\n   220→    bullets.push('Moderate movement - work on explosive transitions');\n   221→  }\n   222→\n   223→  return bullets.slice(0, 4);\n   224→}\n   225→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"131215ad-84e8-4131-a55d-88ca1d53380e","timestamp":"2026-01-28T05:06:48.284Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\api\\analysis\\auto-level\\route.ts","content":"import { NextResponse } from 'next/server';\nimport { GoogleGenAI, Type } from '@google/genai';\n\n// Initialize Gemini client\nconst genAI = new GoogleGenAI({\n  apiKey: process.env.GEMINI_API_KEY!,\n});\n\nconst FLASH_MODEL = 'gemini-2.0-flash';\n\n// Schema for auto-level response\nconst autoLevelSchema = {\n  type: Type.OBJECT,\n  properties: {\n    level: {\n      type: Type.STRING,\n      description: 'Detected skill level: beginner, intermediate, or advanced',\n    },\n    confidence: {\n      type: Type.NUMBER,\n      description: 'Confidence score from 0 to 1',\n    },\n    rationaleBullets: {\n      type: Type.ARRAY,\n      items: { type: Type.STRING },\n      description: 'Array of 2-4 bullet points explaining the assessment',\n    },\n  },\n  required: ['level', 'confidence', 'rationaleBullets'],\n};\n\ninterface AutoLevelRequest {\n  metrics: {\n    avgElbowAngle: number;\n    avgKneeAngle: number;\n    avgStanceWidth: number;\n    movementIntensity: number;\n    frameCount: number;\n    consistencyScore: number;\n  };\n  issues: Array<{\n    code: string;\n    severity: string;\n    count: number;\n  }>;\n}\n\nexport async function POST(request: Request) {\n  try {\n    const body: AutoLevelRequest = await request.json();\n    const { metrics, issues } = body;\n\n    if (!metrics) {\n      return NextResponse.json(\n        { error: 'metrics object is required' },\n        { status: 400 }\n      );\n    }\n\n    // Build the prompt for Gemini\n    const prompt = `You are an expert badminton coach assessing a player's skill level from pose analysis data.\n\nPOSE METRICS FROM VIDEO:\n- Average elbow angle: ${metrics.avgElbowAngle.toFixed(1)}° (ideal for clears: 90-120°)\n- Average knee angle: ${metrics.avgKneeAngle.toFixed(1)}° (ideal ready position: 120-150°)\n- Average stance width (normalized): ${metrics.avgStanceWidth.toFixed(3)} (ideal: 0.3-0.5)\n- Movement intensity: ${metrics.movementIntensity.toFixed(2)} (higher = more dynamic movement)\n- Frames analyzed: ${metrics.frameCount}\n- Consistency score: ${(metrics.consistencyScore * 100).toFixed(0)}% (how stable form is across frames)\n\nDETECTED ISSUES:\n${issues.length > 0\n  ? issues.map(i => `- ${i.code} (${i.severity}): occurred ${i.count}x`).join('\\n')\n  : '- No significant issues detected'}\n\nSKILL LEVEL CRITERIA:\n- BEGINNER: Inconsistent form, multiple high-severity issues, limited movement, elbow/knee angles far from ideal\n- INTERMEDIATE: Some consistency, mostly medium-severity issues, decent movement patterns, angles approaching ideal ranges\n- ADVANCED: High consistency (>80%), few low-severity issues, dynamic movement, angles within ideal ranges\n\nBased on this data, determine the player's skill level.`;\n\n    try {\n      const response = await genAI.models.generateContent({\n        model: FLASH_MODEL,\n        contents: prompt,\n        config: {\n          responseMimeType: 'application/json',\n          responseSchema: autoLevelSchema,\n          temperature: 0.2,\n          maxOutputTokens: 300,\n        },\n      });\n\n      const result = JSON.parse(response.text || '{}');\n\n      // Validate and normalize the response\n      const level = ['beginner', 'intermediate', 'advanced'].includes(result.level?.toLowerCase())\n        ? result.level.toLowerCase()\n        : determineRuleBasedLevel(metrics, issues);\n\n      const confidence = typeof result.confidence === 'number'\n        ? Math.max(0, Math.min(1, result.confidence))\n        : 0.7;\n\n      const rationaleBullets = Array.isArray(result.rationaleBullets) && result.rationaleBullets.length > 0\n        ? result.rationaleBullets.slice(0, 4)\n        : getRuleBasedRationale(metrics, issues, level);\n\n      return NextResponse.json({\n        level,\n        confidence,\n        rationaleBullets,\n      });\n    } catch (geminiError) {\n      console.error('Gemini auto-level error:', geminiError);\n\n      // Fallback to rule-based detection\n      const level = determineRuleBasedLevel(metrics, issues);\n      const rationale = getRuleBasedRationale(metrics, issues, level);\n\n      return NextResponse.json({\n        level,\n        confidence: 0.6,\n        rationaleBullets: rationale,\n      });\n    }\n  } catch (error) {\n    console.error('Auto-level API error:', error);\n    return NextResponse.json(\n      { error: 'Failed to determine skill level' },\n      { status: 500 }\n    );\n  }\n}\n\n// Rule-based fallback for skill level detection\nfunction determineRuleBasedLevel(\n  metrics: AutoLevelRequest['metrics'],\n  issues: AutoLevelRequest['issues']\n): string {\n  let score = 0;\n\n  // Consistency score (0-30 points)\n  score += metrics.consistencyScore * 30;\n\n  // Elbow angle (0-20 points) - ideal is 90-120\n  const elbowDiff = Math.min(\n    Math.abs(metrics.avgElbowAngle - 90),\n    Math.abs(metrics.avgElbowAngle - 120)\n  );\n  score += Math.max(0, 20 - elbowDiff);\n\n  // Knee angle (0-20 points) - ideal is 120-150\n  const kneeDiff = Math.min(\n    Math.abs(metrics.avgKneeAngle - 120),\n    Math.abs(metrics.avgKneeAngle - 150)\n  );\n  score += Math.max(0, 20 - kneeDiff);\n\n  // Movement intensity (0-15 points)\n  score += Math.min(15, metrics.movementIntensity * 30);\n\n  // Issue penalty (subtract points based on severity)\n  const highIssues = issues.filter(i => i.severity === 'high').length;\n  const mediumIssues = issues.filter(i => i.severity === 'medium').length;\n  score -= highIssues * 10;\n  score -= mediumIssues * 5;\n\n  // Normalize to 0-100\n  score = Math.max(0, Math.min(100, score));\n\n  if (score >= 70) return 'advanced';\n  if (score >= 40) return 'intermediate';\n  return 'beginner';\n}\n\n// Generate rationale bullets based on rules\nfunction getRuleBasedRationale(\n  metrics: AutoLevelRequest['metrics'],\n  issues: AutoLevelRequest['issues'],\n  level: string\n): string[] {\n  const bullets: string[] = [];\n\n  // Consistency assessment\n  if (metrics.consistencyScore >= 0.8) {\n    bullets.push(`High form consistency (${(metrics.consistencyScore * 100).toFixed(0)}%) indicates practiced technique`);\n  } else if (metrics.consistencyScore >= 0.5) {\n    bullets.push(`Moderate form consistency (${(metrics.consistencyScore * 100).toFixed(0)}%) shows developing technique`);\n  } else {\n    bullets.push(`Low form consistency (${(metrics.consistencyScore * 100).toFixed(0)}%) suggests need for fundamental work`);\n  }\n\n  // Elbow angle assessment\n  if (metrics.avgElbowAngle >= 90 && metrics.avgElbowAngle <= 120) {\n    bullets.push(`Good elbow positioning (${metrics.avgElbowAngle.toFixed(0)}°) for power shots`);\n  } else if (metrics.avgElbowAngle < 90) {\n    bullets.push(`Elbow angle too tight (${metrics.avgElbowAngle.toFixed(0)}°) - limits power generation`);\n  } else {\n    bullets.push(`Elbow angle too open (${metrics.avgElbowAngle.toFixed(0)}°) - affects control`);\n  }\n\n  // Issue summary\n  const highCount = issues.filter(i => i.severity === 'high').length;\n  const totalIssues = issues.length;\n\n  if (totalIssues === 0) {\n    bullets.push('No significant form issues detected');\n  } else if (highCount > 0) {\n    bullets.push(`${highCount} high-priority issue${highCount > 1 ? 's' : ''} requiring attention`);\n  } else {\n    bullets.push(`${totalIssues} minor issue${totalIssues > 1 ? 's' : ''} to refine`);\n  }\n\n  // Movement assessment\n  if (metrics.movementIntensity > 0.5) {\n    bullets.push('Dynamic movement patterns show athletic foundation');\n  } else if (metrics.movementIntensity > 0.2) {\n    bullets.push('Moderate movement - work on explosive transitions');\n  }\n\n  return bullets.slice(0, 4);\n}\n","numLines":225,"startLine":1,"totalLines":225}},"sourceToolAssistantUUID":"db60836f-837d-4c59-90b6-5673887a87a3"}
{"parentUuid":"131215ad-84e8-4131-a55d-88ca1d53380e","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01SqsTJPM4P6WN7aejBWMCZi","toolUseID":"toolu_01SqsTJPM4P6WN7aejBWMCZi","timestamp":"2026-01-28T05:06:48.304Z","uuid":"3534c40e-681d-472d-bd34-d401ddfe4448"}
{"parentUuid":"3534c40e-681d-472d-bd34-d401ddfe4448","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01CFRL92XjKvWBtDx8NyVCQ9","toolUseID":"toolu_01CFRL92XjKvWBtDx8NyVCQ9","timestamp":"2026-01-28T05:06:48.304Z","uuid":"e670d7dd-783b-41b4-a12e-2a9abd395094"}
{"parentUuid":"e670d7dd-783b-41b4-a12e-2a9abd395094","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01V567iNe6TKMJVDApojhzjP","toolUseID":"toolu_01V567iNe6TKMJVDApojhzjP","timestamp":"2026-01-28T05:06:48.304Z","uuid":"45244ac9-c9f6-43fb-bd4b-9c2baf99c1b9"}
{"parentUuid":"45244ac9-c9f6-43fb-bd4b-9c2baf99c1b9","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01VcMi7WUbSrPQ2Rb5Du9be1","toolUseID":"toolu_01VcMi7WUbSrPQ2Rb5Du9be1","timestamp":"2026-01-28T05:06:48.304Z","uuid":"0c5efaca-b35e-41ed-a8a2-b3b798de32de"}
{"parentUuid":"0c5efaca-b35e-41ed-a8a2-b3b798de32de","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VAi1VUK7GzgGZkyoywHb9T","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I now have a complete understanding of the RallyCoach codebase. Let me create a comprehensive file map and implementation plan.\n\n## PHASE 1 - PLANNER: Complete File Map & Architecture Analysis\n\n### Current Data Flow:\n1. **Upload**: Video uploaded via form in analytics/page.tsx\n2. **Processing**: Frontend uses MediaPipe Tasks-Vision in-browser for pose detection (processVideoWithPose)\n3. **Analysis**: Frame-by-frame analysis with rules-engine.ts + scoring-rules.ts\n4. **Auto-Level**: Gemini API called via /api/analysis/auto-level for skill assessment\n5. **DB Save**: Results saved to Supabase sessions + issues tables\n6. **Display**: Video + skeleton overlay rendered via canvas overlay\n\n### Key Files to Modify:\n\n**BACKEND (Python)**:\n- `backend/analysis.py` - Add best-rep detection + ghost data\n- `backend/pose_estimation.py` - Add visibility/confidence extraction\n- `backend/main.py` - Extend API to return confidence data\n- `backend/gemini_client.py` - Update prompts to use computed scores\n\n**FRONTEND (TypeScript/React)**:\n- `rallycoach/src/app/analytics/page.tsx` - Main analytics page\n- `rallycoach/src/lib/pose-utils.ts` - Add ghost overlay rendering\n- `rallycoach/src/lib/scoring-rules.ts` - Add confidence metrics\n- `rallycoach/src/lib/types.ts` - Add new types for ghost, timeline, skill\n\n**NEW COMPONENTS**:\n- `rallycoach/src/components/MistakeTimeline.tsx` - Timeline with segments\n- `rallycoach/src/components/FixItCard.tsx` - Animated fix-it card\n- `rallycoach/src/components/GhostOverlay.tsx` - Ghost skeleton overlay\n\n\n- `rallycoach/src/components/SkillMeter.tsx` - Confidence meters + skill badge\n\n### Current State Analysis:\nThe AutoLevelResult component already handles skill assessment via Gemini, and skeleton overlays are functional but lack ghost comparison capability. Issues are timestamped but need proper timeline visualization. The visibility field in PoseLandmark can drive confidence scoring, and GuidanceAnimation provides a foundation for enhanced FixIt cards.\n\n### What's Missing:\nGhost rival overlay requires best-rep selection and dual skeleton rendering. Timeline UI needs to display mistake segments with proper positioning.\n\n## Implementation Plan:\n\n### FEATURE 1: Ghost Rival Overlay\nModify scoring-rules.ts to identify the highest form quality segment, store the ghost pose sequence in session state, then build a GhostOverlay component that renders both skeletons simultaneously. Add a toggle in analytics and sync playback with video timestamps.\n\n### FEATURE 2: Mistake Timeline\nCreate MistakeTimeline.tsx to visualize timestamped issues as clickable segments. Implement seek functionality using HTMLVideoElement.currentTime, add a playhead that updates on timeupdate events, and build FixItCard.tsx with animated stick figures for each mistake.\n\n### FEATURE 3: Auto Skill Estimation + Confidence\nDerive skill score directly from pose metrics rather than relying on Gemini, leverage landmark visibility data to calculate confidence levels, and display both as a skill badge with confidence meter. Remove the manual level selection interface and update the Gemini prompt to reference the computed score instead.\n\nNow ready to start building these features.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":17675,"cache_read_input_tokens":133012,"cache_creation":{"ephemeral_5m_input_tokens":17675,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCHstc8F97pmwBzfo5E","type":"assistant","uuid":"affc216c-186a-439f-ab2e-ae8a036c7a70","timestamp":"2026-01-28T05:07:11.347Z"}
{"parentUuid":"affc216c-186a-439f-ab2e-ae8a036c7a70","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VAi1VUK7GzgGZkyoywHb9T","type":"message","role":"assistant","content":[{"type":"text","text":"I now have a complete understanding of the codebase. Let me create a structured implementation plan and begin coding.\n\n## PHASE 1 - PLANNER: Complete File Map & Implementation Plan\n\n### Current Architecture Summary:\n\n**Data Flow:**\n```\nUpload → In-browser MediaPipe → rules-engine scoring → Gemini auto-level → Supabase save → Canvas overlay render\n```\n\n**Key Files:**\n| File | Purpose |\n|------|---------|\n| `rallycoach/src/app/analytics/page.tsx` | Main analytics page with video player + overlay |\n| `rallycoach/src/lib/pose-utils.ts` | Pose processing + skeleton drawing |\n| `rallycoach/src/lib/scoring-rules.ts` | Banded scoring with skill levels |\n| `rallycoach/src/lib/rules-engine.ts` | Form rules + drill definitions |\n| `rallycoach/src/components/DrillCard.tsx` | Issue card with drill info |\n| `rallycoach/src/components/GuidanceAnimation.tsx` | Animated skeleton guidance |\n| `rallycoach/src/app/api/analysis/auto-level/route.ts` | Gemini skill assessment |\n\n**Current State Analysis:**\n- Auto-level detection exists but relies on Gemini (not pose metrics)\n- Skeleton overlay works but no ghost rival capability\n- Issues have timestamps but no proper timeline UI\n- `visibility` field exists on landmarks but not used for confidence\n\nLet me create the tasks and begin implementation."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":17675,"cache_read_input_tokens":133012,"cache_creation":{"ephemeral_5m_input_tokens":17675,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCHstc8F97pmwBzfo5E","type":"assistant","uuid":"fd2784cb-f4e8-4553-af12-70a0830a03f6","timestamp":"2026-01-28T05:07:15.718Z"}
{"parentUuid":"fd2784cb-f4e8-4553-af12-70a0830a03f6","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VAi1VUK7GzgGZkyoywHb9T","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WGh3nGWEhHoFCaZiJp5RPB","name":"TaskCreate","input":{"subject":"Feature 1: Ghost Rival Overlay","description":"Implement ghost skeleton overlay showing \"My Best Rep\" from the same video:\n1. Add best-rep detection in scoring-rules.ts (find highest quality segment)\n2. Create GhostOverlay logic in pose-utils.ts\n3. Add ghost toggle + selector in analytics page\n4. Render dual skeletons (user + ghost) with time sync","activeForm":"Implementing Ghost Rival Overlay"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":17675,"cache_read_input_tokens":133012,"cache_creation":{"ephemeral_5m_input_tokens":17675,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCHstc8F97pmwBzfo5E","type":"assistant","uuid":"2a620c79-6176-4c78-ac24-de61aedd1196","timestamp":"2026-01-28T05:07:18.409Z"}
{"parentUuid":"2a620c79-6176-4c78-ac24-de61aedd1196","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VAi1VUK7GzgGZkyoywHb9T","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UmnC3TdgnmcufkMi6uXzSY","name":"TaskCreate","input":{"subject":"Feature 2: Mistake Timeline + Click-to-Jump","description":"Implement horizontal timeline under video:\n1. Create MistakeTimeline.tsx component\n2. Show colored segments by severity (red/orange)\n3. Add playhead synced with video currentTime\n4. Implement click-to-seek with HTMLVideoElement.currentTime\n5. Create FixItCard.tsx with animated stick figure corrections","activeForm":"Implementing Mistake Timeline"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":17675,"cache_read_input_tokens":133012,"cache_creation":{"ephemeral_5m_input_tokens":17675,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCHstc8F97pmwBzfo5E","type":"assistant","uuid":"e1ac4465-00f6-4955-b948-4806f6481b4c","timestamp":"2026-01-28T05:07:20.305Z"}
{"parentUuid":"e1ac4465-00f6-4955-b948-4806f6481b4c","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VAi1VUK7GzgGZkyoywHb9T","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FtybAxovkJuUUZiToZkDzL","name":"TaskCreate","input":{"subject":"Feature 3: Auto Skill Score + Confidence Meters","description":"Implement real skill scoring from pose metrics:\n1. Compute skillScore (0-100) from pose consistency, recovery speed, form quality\n2. Derive confidence from landmark visibility (not invented numbers)\n3. Add SkillMeter component with badge + confidence bar\n4. Remove manual level selection UI\n5. Update Gemini prompts to reference computed metrics","activeForm":"Implementing Auto Skill Scoring"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":17675,"cache_read_input_tokens":133012,"cache_creation":{"ephemeral_5m_input_tokens":17675,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCHstc8F97pmwBzfo5E","type":"assistant","uuid":"053de904-0b64-4d99-b3fb-21be66713a12","timestamp":"2026-01-28T05:07:22.359Z"}
{"parentUuid":"053de904-0b64-4d99-b3fb-21be66713a12","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VAi1VUK7GzgGZkyoywHb9T","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JHPPRkkiXfEChGNSun2fHJ","name":"TaskCreate","input":{"subject":"Database Schema + Integration","description":"Add new fields to Supabase schema:\n1. Add skill_score, confidence_percent, level_label to sessions table\n2. Add ghost_pose_sequence or best_rep_window to sessions\n3. Ensure mistake events with proper timestamps are stored\n4. Create migration SQL file","activeForm":"Updating database schema"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":17675,"cache_read_input_tokens":133012,"cache_creation":{"ephemeral_5m_input_tokens":17675,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCHstc8F97pmwBzfo5E","type":"assistant","uuid":"d0c4b0d8-9089-4f14-a1b1-8aa65f695a47","timestamp":"2026-01-28T05:07:24.583Z"}
{"parentUuid":"d0c4b0d8-9089-4f14-a1b1-8aa65f695a47","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VAi1VUK7GzgGZkyoywHb9T","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013soALp8ubXtAXSt91vV96w","name":"TaskCreate","input":{"subject":"Polish + Verification","description":"Final polish and verification:\n1. Add loading animation during analysis\n2. Ensure skeleton overlay stays synced during seek\n3. Update README with new features\n4. Create test checklist\n5. Verify no mocked confidence numbers","activeForm":"Polishing and verifying implementation"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":17675,"cache_read_input_tokens":133012,"cache_creation":{"ephemeral_5m_input_tokens":17675,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCHstc8F97pmwBzfo5E","type":"assistant","uuid":"afa72021-99a0-466c-a6bf-c8bbaeb03ebf","timestamp":"2026-01-28T05:07:26.569Z"}
{"parentUuid":"2a620c79-6176-4c78-ac24-de61aedd1196","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WGh3nGWEhHoFCaZiJp5RPB","type":"tool_result","content":"Task #1 created successfully: Feature 1: Ghost Rival Overlay"}]},"uuid":"af45b87c-f21b-4831-a952-f145dbb4d272","timestamp":"2026-01-28T05:07:26.624Z","toolUseResult":{"task":{"id":"1","subject":"Feature 1: Ghost Rival Overlay"}},"sourceToolAssistantUUID":"2a620c79-6176-4c78-ac24-de61aedd1196"}
{"parentUuid":"e1ac4465-00f6-4955-b948-4806f6481b4c","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UmnC3TdgnmcufkMi6uXzSY","type":"tool_result","content":"Task #2 created successfully: Feature 2: Mistake Timeline + Click-to-Jump"}]},"uuid":"aa13a453-c46b-4274-9f9e-eb8c6ed3634b","timestamp":"2026-01-28T05:07:26.624Z","toolUseResult":{"task":{"id":"2","subject":"Feature 2: Mistake Timeline + Click-to-Jump"}},"sourceToolAssistantUUID":"e1ac4465-00f6-4955-b948-4806f6481b4c"}
{"parentUuid":"053de904-0b64-4d99-b3fb-21be66713a12","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FtybAxovkJuUUZiToZkDzL","type":"tool_result","content":"Task #3 created successfully: Feature 3: Auto Skill Score + Confidence Meters"}]},"uuid":"91cd9c34-7975-43cf-866a-189f0d09d017","timestamp":"2026-01-28T05:07:26.624Z","toolUseResult":{"task":{"id":"3","subject":"Feature 3: Auto Skill Score + Confidence Meters"}},"sourceToolAssistantUUID":"053de904-0b64-4d99-b3fb-21be66713a12"}
{"parentUuid":"d0c4b0d8-9089-4f14-a1b1-8aa65f695a47","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JHPPRkkiXfEChGNSun2fHJ","type":"tool_result","content":"Task #4 created successfully: Database Schema + Integration"}]},"uuid":"35cd255b-98b7-4e26-b704-8b3ffecf60d0","timestamp":"2026-01-28T05:07:26.624Z","toolUseResult":{"task":{"id":"4","subject":"Database Schema + Integration"}},"sourceToolAssistantUUID":"d0c4b0d8-9089-4f14-a1b1-8aa65f695a47"}
{"parentUuid":"afa72021-99a0-466c-a6bf-c8bbaeb03ebf","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013soALp8ubXtAXSt91vV96w","type":"tool_result","content":"Task #5 created successfully: Polish + Verification"}]},"uuid":"e32c159e-8dba-4ead-86ba-ee4b25609867","timestamp":"2026-01-28T05:07:26.625Z","toolUseResult":{"task":{"id":"5","subject":"Polish + Verification"}},"sourceToolAssistantUUID":"afa72021-99a0-466c-a6bf-c8bbaeb03ebf"}
{"parentUuid":"e32c159e-8dba-4ead-86ba-ee4b25609867","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"system","subtype":"microcompact_boundary","content":"Context microcompacted","isMeta":false,"timestamp":"2026-01-28T05:07:26.734Z","uuid":"5dc4f285-140f-405b-84b8-5f292fffe57c","level":"info","microcompactMetadata":{"trigger":"auto","preTokens":78476,"tokensSaved":44419,"compactedToolIds":["toolu_01WGwx6VrMxv8fCPx3iMqbJY","toolu_01PK2z3JLY1rxD8EciF17nbS","toolu_01E7hvZV5FD9PuHNDAdg5GL2","toolu_01G1McDGmsTGGJeEXfkp6B5r","toolu_017kP578Pm8ZCWnbbie5o4U4","toolu_01H5FQrNPLEHPmJDaRhPishm","toolu_01Hb9uzUxE1hUkYSBb8ynBPd","toolu_012Euhfxtd5UMyguERSd2Lbv","toolu_01XU8LuqRxtuaaQGF47xECq2","toolu_01C3Gj7smCDBoVNbgLaTMaE4","toolu_013cBTiYfRMpEzDXgVfw59jj","toolu_016SmTVPNZ4r1MTn8vt1FPsg","toolu_01DdTmdNqnCu6vc1ysXD4bN9"],"clearedAttachmentUUIDs":[]}}
{"parentUuid":"5dc4f285-140f-405b-84b8-5f292fffe57c","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01WW7pPVtnGuKGP3TBasVJo9","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me read the analytics page to understand the current implementation before modifying it.","signature":"EogCCkYICxgCKkAj1BDM14EJcIV6jF1WRd1vWW02lXuy2hOEzoU6Ix2fMbUv9Inl1mZMf5S2OcWv12gzNkGO7PQaNQo3nTeAHMF6EgzUYd7WNXWbCochMVUaDEwDDh8kRcFti+SmHyIw4qbA+Soiy/xJ/UxdR8ll42qDLGca3hWboKltNySnrAMgaEn+eeJf2CGuYUaKkuHmKnBDXiQ0Q5Bm+SdA4MMg2fyeKtXB9PpGiYK0+YUjhOmIlC0x+8xeKC2FSprvnv6RbmeKbDWk0MKv3cUKIFU/mCWq8hj5E4XVsvmCXtb3dkeYQci4ywv9thoAbA/ZSZbmvP/uQ16cDAKAPadkgiej+DlzGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":57276,"cache_read_input_tokens":36802,"cache_creation":{"ephemeral_5m_input_tokens":57276,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCLgYZXSh2TTPW6DDuJ","type":"assistant","uuid":"ae22f53e-274f-4702-8434-e1cc272a018c","timestamp":"2026-01-28T05:07:29.362Z"}
{"parentUuid":"ae22f53e-274f-4702-8434-e1cc272a018c","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01WW7pPVtnGuKGP3TBasVJo9","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me read the current analytics page completely to understand its structure before implementing."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":57276,"cache_read_input_tokens":36802,"cache_creation":{"ephemeral_5m_input_tokens":57276,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCLgYZXSh2TTPW6DDuJ","type":"assistant","uuid":"ad6f9193-2e41-4ce5-8547-fc85444b8f11","timestamp":"2026-01-28T05:07:29.770Z"}
{"parentUuid":"ad6f9193-2e41-4ce5-8547-fc85444b8f11","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01WW7pPVtnGuKGP3TBasVJo9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PiJSzHVKSnnPaaK8R4woua","name":"Read","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":57276,"cache_read_input_tokens":36802,"cache_creation":{"ephemeral_5m_input_tokens":57276,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCLgYZXSh2TTPW6DDuJ","type":"assistant","uuid":"ddcd379d-043e-4840-bd2b-09de31cf9c9b","timestamp":"2026-01-28T05:07:30.618Z"}
{"parentUuid":"ddcd379d-043e-4840-bd2b-09de31cf9c9b","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PiJSzHVKSnnPaaK8R4woua","type":"tool_result","content":"     1→'use client';\n     2→\n     3→import { useState, useEffect, useRef, useCallback, Suspense } from 'react';\n     4→import { useSearchParams } from 'next/navigation';\n     5→import Link from 'next/link';\n     6→import DashboardNav from '@/components/DashboardNav';\n     7→import DrillCard from '@/components/DrillCard';\n     8→import { TabbedDrillAnimation } from '@/components/Skeleton3D';\n     9→import PlayerSelectionModal from '@/components/PlayerSelectionModal';\n    10→import GuidanceAnimation from '@/components/GuidanceAnimation';\n    11→import { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\n    12→import {\n    13→  drawSkeleton,\n    14→  extractMetrics,\n    15→  POSE_CONNECTIONS,\n    16→  POSE_LANDMARKS\n    17→} from '@/lib/pose-utils';\n    18→import {\n    19→  DRILLS,\n    20→  FORM_RULES,\n    21→  evaluateForm,\n    22→  findViolationTimestamps,\n    23→  type EvaluationResult\n    24→} from '@/lib/rules-engine';\n    25→import {\n    26→  evaluateWithBands,\n    27→  SCORING_LEGEND,\n    28→  SKILL_LEVEL_DESCRIPTIONS,\n    29→  validateSessionPoseData,\n    30→} from '@/lib/scoring-rules';\n    31→import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData } from '@/lib/types';\n    32→\n    33→// MediaPipe Types\n    34→type PoseLandmarker = any;\n    35→\n    36→interface FrameAnalysis {\n    37→  timestamp: number;\n    38→  landmarks: PoseLandmark[] | null;\n    39→  evaluation: EvaluationResult | null;\n    40→  metrics: PoseMetrics | null;\n    41→}\n    42→\n    43→interface DetectedIssue {\n    44→  code: string;\n    45→  title: string;\n    46→  severity: 'low' | 'medium' | 'high';\n    47→  description?: string;\n    48→  timestamps: number[];\n    49→  drill?: any;\n    50→}\n    51→\n    52→// PHASE 5: Analysis state machine\n    53→type AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n    54→\n    55→// PHASE 3: Auto-level detection result from Gemini\n    56→interface AutoLevelResult {\n    57→  level: 'Beginner' | 'Intermediate' | 'Advanced';\n    58→  confidence: number;\n    59→  rationaleBullets: string[];\n    60→  guidanceKeyframes?: GuidanceKeyframe[];\n    61→}\n    62→\n    63→// PHASE 4: Guidance keyframe for animation\n    64→interface GuidanceKeyframe {\n    65→  name: string;\n    66→  description: string;\n    67→  landmarks: PoseLandmark[] | null;\n    68→  targetLandmarks?: PoseLandmark[] | null;\n    69→  correction?: string;\n    70→}\n    71→\n    72→function AnalyticsContent() {\n    73→  const searchParams = useSearchParams();\n    74→  const sessionId = searchParams.get('session');\n    75→\n    76→  // State\n    77→  const [uploading, setUploading] = useState(false);\n    78→  const [analyzing, setAnalyzing] = useState(false);\n    79→  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n    80→  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n    81→  const [analysisId, setAnalysisId] = useState<string | null>(null);\n    82→  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n    83→  const [error, setError] = useState<string | null>(null);\n    84→  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n    85→  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n    86→\n    87→  // Multi-pose and player selection state\n    88→  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n    89→  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n    90→  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n    91→  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n    92→  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n    93→  const [eventType, setEventType] = useState<string>('');\n    94→\n    95→  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n    96→  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n    97→  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n    98→\n    99→  // PHASE 4: Guidance animation state\n   100→  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n   101→  const [showGuidance, setShowGuidance] = useState(false);\n   102→\n   103→  // Video playback state\n   104→  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n   105→  const [videoFile, setVideoFile] = useState<File | null>(null);\n   106→  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n   107→  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n   108→  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n   109→  const [currentTime, setCurrentTime] = useState(0);\n   110→  const [duration, setDuration] = useState(0);\n   111→  const [isPlaying, setIsPlaying] = useState(false);\n   112→  const [showSkeleton, setShowSkeleton] = useState(true);\n   113→  const [fps, setFps] = useState(30);\n   114→\n   115→  // PHASE 2: Canvas overlay alignment state\n   116→  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n   117→\n   118→  // Pose detection\n   119→  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n   120→  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n   121→\n   122→  // PHASE 1: Timestamp tracking for monotonic enforcement\n   123→  const lastTimestampMsRef = useRef<number>(-1);\n   124→  const timestampBaseOffsetRef = useRef<number>(0);\n   125→  const isProcessingRef = useRef<boolean>(false);\n   126→\n   127→  // Refs\n   128→  const fileInputRef = useRef<HTMLInputElement>(null);\n   129→  const videoRef = useRef<HTMLVideoElement>(null);\n   130→  const canvasRef = useRef<HTMLCanvasElement>(null);\n   131→  const videoContainerRef = useRef<HTMLDivElement>(null);\n   132→  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n   133→  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n   134→  const animationRef = useRef<number | null>(null);\n   135→\n   136→  // Initialize MediaPipe Pose Landmarker\n   137→  useEffect(() => {\n   138→    initializePoseLandmarker();\n   139→    return () => {\n   140→      cleanup();\n   141→    };\n   142→  }, []);\n   143→\n   144→  // Load session if ID provided\n   145→  useEffect(() => {\n   146→    if (sessionId) {\n   147→      loadSession(sessionId);\n   148→    }\n   149→  }, [sessionId]);\n   150→\n   151→  // PHASE 2: Update canvas size on video resize\n   152→  useEffect(() => {\n   153→    const updateVideoRect = () => {\n   154→      if (videoRef.current && videoContainerRef.current) {\n   155→        const video = videoRef.current;\n   156→        const container = videoContainerRef.current;\n   157→\n   158→        // Calculate the actual rendered video rectangle (accounting for object-contain)\n   159→        const containerRect = container.getBoundingClientRect();\n   160→        const videoAspect = video.videoWidth / video.videoHeight;\n   161→        const containerAspect = containerRect.width / containerRect.height;\n   162→\n   163→        let renderWidth, renderHeight, offsetX, offsetY;\n   164→\n   165→        if (videoAspect > containerAspect) {\n   166→          // Video is wider - letterbox top/bottom\n   167→          renderWidth = containerRect.width;\n   168→          renderHeight = containerRect.width / videoAspect;\n   169→          offsetX = 0;\n   170→          offsetY = (containerRect.height - renderHeight) / 2;\n   171→        } else {\n   172→          // Video is taller - letterbox left/right\n   173→          renderHeight = containerRect.height;\n   174→          renderWidth = containerRect.height * videoAspect;\n   175→          offsetX = (containerRect.width - renderWidth) / 2;\n   176→          offsetY = 0;\n   177→        }\n   178→\n   179→        setVideoRect({\n   180→          x: offsetX,\n   181→          y: offsetY,\n   182→          width: renderWidth,\n   183→          height: renderHeight,\n   184→          top: offsetY,\n   185→          left: offsetX,\n   186→          right: offsetX + renderWidth,\n   187→          bottom: offsetY + renderHeight,\n   188→          toJSON: () => ({})\n   189→        } as DOMRect);\n   190→      }\n   191→    };\n   192→\n   193→    updateVideoRect();\n   194→    window.addEventListener('resize', updateVideoRect);\n   195→\n   196→    return () => window.removeEventListener('resize', updateVideoRect);\n   197→  }, [videoUrl]);\n   198→\n   199→  const initializePoseLandmarker = async () => {\n   200→    try {\n   201→      const vision = await import('@mediapipe/tasks-vision');\n   202→      const { PoseLandmarker, FilesetResolver } = vision;\n   203→\n   204→      const filesetResolver = await FilesetResolver.forVisionTasks(\n   205→        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n   206→      );\n   207→\n   208→      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n   209→        baseOptions: {\n   210→          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n   211→          delegate: 'GPU',\n   212→        },\n   213→        runningMode: 'VIDEO',\n   214→        numPoses: 4, // Support up to 4 players for doubles\n   215→        minPoseDetectionConfidence: 0.5,\n   216→        minPosePresenceConfidence: 0.5,\n   217→        minTrackingConfidence: 0.5,\n   218→      });\n   219→\n   220→      setPoseLandmarkerReady(true);\n   221→    } catch (error) {\n   222→      console.error('Failed to load MediaPipe Pose:', error);\n   223→      // Continue without pose detection - will use fallback\n   224→    }\n   225→  };\n   226→\n   227→  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n   228→  const recreatePoseLandmarker = async () => {\n   229→    if (poseLandmarkerRef.current) {\n   230→      poseLandmarkerRef.current.close();\n   231→    }\n   232→    lastTimestampMsRef.current = -1;\n   233→    timestampBaseOffsetRef.current = 0;\n   234→    await initializePoseLandmarker();\n   235→  };\n   236→\n   237→  const cleanup = () => {\n   238→    if (pollIntervalRef.current) {\n   239→      clearInterval(pollIntervalRef.current);\n   240→    }\n   241→    if (animationRef.current) {\n   242→      cancelAnimationFrame(animationRef.current);\n   243→    }\n   244→    if (poseLandmarkerRef.current) {\n   245→      poseLandmarkerRef.current.close();\n   246→    }\n   247→  };\n   248→\n   249→  const loadSession = async (id: string) => {\n   250→    try {\n   251→      setAnalyzing(true);\n   252→      setAnalysisState('EXTRACTING_POSE');\n   253→\n   254→      // Try new sessions table first\n   255→      const { data: sessionData, error: sessionError } = await supabase\n   256→        .from('sessions')\n   257→        .select('*')\n   258→        .eq('id', id)\n   259→        .single();\n   260→\n   261→      if (sessionError) {\n   262→        // Try legacy table\n   263→        const { data: legacyData, error: legacyError } = await supabase\n   264→          .from('analysis_results')\n   265→          .select('*')\n   266→          .eq('id', id)\n   267→          .single();\n   268→\n   269→        if (legacyError) throw legacyError;\n   270→        if (legacyData?.result_json) {\n   271→          setResult(legacyData.result_json);\n   272→          if (legacyData.result_json.video_url) {\n   273→            setVideoUrl(legacyData.result_json.video_url);\n   274→          }\n   275→        }\n   276→      } else if (sessionData) {\n   277→        // New session format\n   278→        setVideoUrl(sessionData.video_url);\n   279→\n   280→        if (sessionData.pose_data) {\n   281→          setPoseData(sessionData.pose_data);\n   282→        }\n   283→\n   284→        // Fetch issues\n   285→        const { data: issuesData } = await supabase\n   286→          .from('issues')\n   287→          .select('*')\n   288→          .eq('session_id', id);\n   289→\n   290→        if (issuesData && issuesData.length > 0) {\n   291→          setIssues(issuesData.map((issue: any) => ({\n   292→            code: issue.code,\n   293→            title: issue.title,\n   294→            severity: issue.severity,\n   295→            description: issue.description,\n   296→            timestamps: issue.timestamps || [],\n   297→            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n   298→          })));\n   299→        }\n   300→\n   301→        // Build result from session summary\n   302→        const summary = sessionData.summary || {};\n   303→        setResult({\n   304→          top_issues: issuesData?.map((i: any) => ({\n   305→            id: i.id,\n   306→            title: i.title,\n   307→            severity: i.severity,\n   308→            description: i.description,\n   309→            affected_metrics: [],\n   310→          })) || [],\n   311→          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n   312→            id: d.id,\n   313→            name: d.name,\n   314→            description: d.description,\n   315→            duration_minutes: d.durationMinutes,\n   316→            target_metrics: d.targetMetrics,\n   317→            instructions: d.steps,\n   318→          })) || [],\n   319→          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n   320→          strategy_summary: summary.feedback?.strategy_summary || '',\n   321→          training_plan: [],\n   322→        });\n   323→      }\n   324→      setAnalysisState('DONE');\n   325→    } catch (err) {\n   326→      console.error('Error loading session:', err);\n   327→      setError('Failed to load session');\n   328→      setAnalysisState('ERROR');\n   329→    } finally {\n   330→      setAnalyzing(false);\n   331→    }\n   332→  };\n   333→\n   334→  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n   335→  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n   336→  const processVideoWithPose = async (\n   337→    videoElement: HTMLVideoElement,\n   338→    selectedTracks: number[] = [0]\n   339→  ): Promise<FrameAnalysis[]> => {\n   340→    if (!poseLandmarkerRef.current) {\n   341→      console.warn('Pose landmarker not ready');\n   342→      return [];\n   343→    }\n   344→\n   345→    // Prevent concurrent processing\n   346→    if (isProcessingRef.current) {\n   347→      console.warn('Already processing video, skipping');\n   348→      return [];\n   349→    }\n   350→    isProcessingRef.current = true;\n   351→\n   352→    const analyses: FrameAnalysis[] = [];\n   353→    const videoDuration = videoElement.duration;\n   354→    const sampleRate = 10; // Process 10 frames per second\n   355→    const totalFrames = Math.floor(videoDuration * sampleRate);\n   356→\n   357→    // PHASE 1: Reset timestamp tracking for fresh processing\n   358→    // Use base offset approach so timestamps always increase even if we restart\n   359→    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n   360→    let localLastTimestamp = timestampBaseOffsetRef.current;\n   361→\n   362→    let validPoseFrames = 0;\n   363→    let lowConfidenceFrames = 0;\n   364→    let noPoseFrames = 0;\n   365→\n   366→    setAnalyzeProgress(10); // Start at 10% after track detection\n   367→\n   368→    for (let i = 0; i <= totalFrames; i++) {\n   369→      const timestamp = i / sampleRate;\n   370→      videoElement.currentTime = timestamp;\n   371→\n   372→      // Wait for video to seek\n   373→      await new Promise<void>((resolve) => {\n   374→        const onSeeked = () => {\n   375→          videoElement.removeEventListener('seeked', onSeeked);\n   376→          resolve();\n   377→        };\n   378→        videoElement.addEventListener('seeked', onSeeked);\n   379→      });\n   380→\n   381→      // Give the video a moment to render the frame\n   382→      await new Promise(resolve => setTimeout(resolve, 50));\n   383→\n   384→      try {\n   385→        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n   386→        // Use base offset + local timestamp to guarantee monotonic increase\n   387→        const rawTimestampMs = Math.floor(timestamp * 1000);\n   388→        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n   389→\n   390→        // Double-check monotonicity\n   391→        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n   392→        localLastTimestamp = safeTimestampMs;\n   393→        lastTimestampMsRef.current = safeTimestampMs;\n   394→\n   395→        const results = poseLandmarkerRef.current.detectForVideo(\n   396→          videoElement,\n   397→          safeTimestampMs\n   398→        );\n   399→\n   400→        let landmarks: PoseLandmark[] | null = null;\n   401→        let evaluation: EvaluationResult | null = null;\n   402→        let metrics: PoseMetrics | null = null;\n   403→\n   404→        if (results.landmarks && results.landmarks.length > 0) {\n   405→          // Only use the selected player's landmarks\n   406→          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n   407→            ? selectedTracks[0]\n   408→            : 0;\n   409→\n   410→          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n   411→            x: lm.x,\n   412→            y: lm.y,\n   413→            z: lm.z,\n   414→            visibility: lm.visibility ?? 1.0,\n   415→          }));\n   416→\n   417→          if (landmarks && landmarks.length > 0) {\n   418→            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n   419→\n   420→            if (avgVisibility < 0.5) {\n   421→              lowConfidenceFrames++;\n   422→            } else {\n   423→              validPoseFrames++;\n   424→            }\n   425→            metrics = extractMetrics(landmarks);\n   426→\n   427→            // Use intermediate level for initial processing (auto-level will adjust later)\n   428→            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n   429→            evaluation = {\n   430→              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n   431→              score: bandedResult.overall_score,\n   432→              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n   433→                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n   434→                value: 0,\n   435→                feedback: f,\n   436→              })) : [],\n   437→              passedRules: [],\n   438→              highlightJoints: bandedResult.highlight_joints,\n   439→              recommendedDrills: [],\n   440→            };\n   441→          }\n   442→        } else {\n   443→          noPoseFrames++;\n   444→        }\n   445→\n   446→        analyses.push({\n   447→          timestamp,\n   448→          landmarks,\n   449→          evaluation,\n   450→          metrics,\n   451→        });\n   452→      } catch (err) {\n   453→        const errorMsg = err instanceof Error ? err.message : String(err);\n   454→        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n   455→          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n   456→          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n   457→          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n   458→          localLastTimestamp = timestampBaseOffsetRef.current;\n   459→        } else {\n   460→          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n   461→        }\n   462→        analyses.push({\n   463→          timestamp,\n   464→          landmarks: null,\n   465→          evaluation: null,\n   466→          metrics: null,\n   467→        });\n   468→      }\n   469→\n   470→      // Update progress (10-70%)\n   471→      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n   472→    }\n   473→\n   474→    // PHASE 1: Log pose detection statistics\n   475→    const totalProcessed = totalFrames + 1;\n   476→    const validRatio = validPoseFrames / totalProcessed;\n   477→    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n   478→\n   479→    if (validRatio < 0.3) {\n   480→      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n   481→    }\n   482→\n   483→    isProcessingRef.current = false;\n   484→    return analyses;\n   485→  };\n   486→\n   487→  // Detect issues from frame analyses\n   488→  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n   489→    const issueMap: Map<string, {\n   490→      rule: any;\n   491→      timestamps: number[];\n   492→      count: number;\n   493→    }> = new Map();\n   494→\n   495→    for (const frame of analyses) {\n   496→      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n   497→        for (const failed of frame.evaluation.failedRules) {\n   498→          const code = failed.rule.code;\n   499→          if (!issueMap.has(code)) {\n   500→            issueMap.set(code, {\n   501→              rule: failed.rule,\n   502→              timestamps: [],\n   503→              count: 0,\n   504→            });\n   505→          }\n   506→          const issue = issueMap.get(code)!;\n   507→          issue.timestamps.push(frame.timestamp);\n   508→          issue.count++;\n   509→        }\n   510→      }\n   511→    }\n   512→\n   513→    // Convert to array and sort by count\n   514→    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n   515→      .map(([code, data]) => ({\n   516→        code,\n   517→        title: data.rule.name,\n   518→        severity: data.rule.severity,\n   519→        description: data.rule.description,\n   520→        timestamps: data.timestamps,\n   521→        drill: DRILLS[data.rule.drillId],\n   522→      }))\n   523→      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n   524→      .slice(0, 5); // Top 5 issues\n   525→\n   526→    return issues;\n   527→  };\n   528→\n   529→  // PHASE 3: Auto-detect skill level using Gemini\n   530→  const detectSkillLevelWithGemini = async (\n   531→    analyses: FrameAnalysis[],\n   532→    detectedIssues: DetectedIssue[]\n   533→  ): Promise<AutoLevelResult> => {\n   534→    setAnalysisState('GEMINI_SCORING');\n   535→    setAnalyzeProgress(75);\n   536→\n   537→    try {\n   538→      // Extract features for Gemini analysis\n   539→      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n   540→\n   541→      if (validAnalyses.length < 5) {\n   542→        // Fallback if not enough data\n   543→        return {\n   544→          level: 'Intermediate',\n   545→          confidence: 0.5,\n   546→          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n   547→        };\n   548→      }\n   549→\n   550→      // Calculate aggregate metrics\n   551→      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n   552→      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n   553→      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n   554→      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n   555→\n   556→      // Calculate consistency (standard deviation proxy)\n   557→      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n   558→      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n   559→\n   560→      // Calculate movement intensity (velocity proxy from position changes)\n   561→      let totalMovement = 0;\n   562→      for (let i = 1; i < validAnalyses.length; i++) {\n   563→        const prev = validAnalyses[i - 1].landmarks;\n   564→        const curr = validAnalyses[i].landmarks;\n   565→        if (prev && curr) {\n   566→          const hipMovement = Math.sqrt(\n   567→            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n   568→            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n   569→          );\n   570→          totalMovement += hipMovement;\n   571→        }\n   572→      }\n   573→      const avgMovement = totalMovement / (validAnalyses.length - 1);\n   574→\n   575→      // Issue frequency\n   576→      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n   577→\n   578→      // Call Gemini API for skill level detection\n   579→      const response = await fetch('/api/analysis/auto-level', {\n   580→        method: 'POST',\n   581→        headers: { 'Content-Type': 'application/json' },\n   582→        body: JSON.stringify({\n   583→          metrics: {\n   584→            avgElbowAngle,\n   585→            avgKneeAngle,\n   586→            avgStanceWidth,\n   587→            avgRotation,\n   588→            elbowConsistency: Math.sqrt(elbowVariance),\n   589→            kneeConsistency: Math.sqrt(kneeVariance),\n   590→            movementIntensity: avgMovement,\n   591→            issueFrequency,\n   592→            totalFrames: validAnalyses.length,\n   593→            issueCount: detectedIssues.length,\n   594→          },\n   595→          issues: detectedIssues.map(i => ({\n   596→            code: i.code,\n   597→            title: i.title,\n   598→            frequency: i.timestamps.length / validAnalyses.length,\n   599→          })),\n   600→        }),\n   601→      });\n   602→\n   603→      if (response.ok) {\n   604→        const result = await response.json();\n   605→        setAnalyzeProgress(90);\n   606→        return {\n   607→          level: result.level || 'Intermediate',\n   608→          confidence: result.confidence || 0.7,\n   609→          rationaleBullets: result.rationaleBullets || [],\n   610→          guidanceKeyframes: result.guidanceKeyframes,\n   611→        };\n   612→      }\n   613→    } catch (err) {\n   614→      console.error('Gemini auto-level detection failed:', err);\n   615→    }\n   616→\n   617→    // Fallback rule-based detection\n   618→    setAnalyzeProgress(90);\n   619→    return fallbackSkillLevelDetection(analyses, detectedIssues);\n   620→  };\n   621→\n   622→  // Fallback rule-based skill level detection\n   623→  const fallbackSkillLevelDetection = (\n   624→    analyses: FrameAnalysis[],\n   625→    detectedIssues: DetectedIssue[]\n   626→  ): AutoLevelResult => {\n   627→    const validAnalyses = analyses.filter(a => a.evaluation);\n   628→    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n   629→    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n   630→    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n   631→\n   632→    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n   633→      return {\n   634→        level: 'Advanced',\n   635→        confidence: 0.75,\n   636→        rationaleBullets: [\n   637→          'Consistent form across frames',\n   638→          'No major technique issues detected',\n   639→          'Good body mechanics observed',\n   640→        ],\n   641→      };\n   642→    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n   643→      return {\n   644→        level: 'Intermediate',\n   645→        confidence: 0.7,\n   646→        rationaleBullets: [\n   647→          'Moderate consistency in technique',\n   648→          `${highSeverityIssues} area(s) need focused improvement`,\n   649→          'Foundations are solid with room to refine',\n   650→        ],\n   651→      };\n   652→    } else {\n   653→      return {\n   654→        level: 'Beginner',\n   655→        confidence: 0.8,\n   656→        rationaleBullets: [\n   657→          'Multiple technique areas need development',\n   658→          'Focus on fundamentals before advancing',\n   659→          'Regular practice will show rapid improvement',\n   660→        ],\n   661→      };\n   662→    }\n   663→  };\n   664→\n   665→  // PHASE 4: Generate guidance keyframes from analysis\n   666→  const generateGuidanceKeyframes = (\n   667→    analyses: FrameAnalysis[],\n   668→    detectedIssues: DetectedIssue[]\n   669→  ): GuidanceKeyframe[] => {\n   670→    const keyframes: GuidanceKeyframe[] = [];\n   671→    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n   672→\n   673→    if (validAnalyses.length < 3) return keyframes;\n   674→\n   675→    // Find key moments: Setup, Contact/Action, Recovery\n   676→    // Setup: Early stable frame\n   677→    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n   678→    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n   679→    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n   680→\n   681→    const setupFrame = validAnalyses[setupIdx];\n   682→    const contactFrame = validAnalyses[contactIdx];\n   683→    const recoveryFrame = validAnalyses[recoveryIdx];\n   684→\n   685→    // Determine primary issue for corrections\n   686→    const primaryIssue = detectedIssues[0];\n   687→    let correction = '';\n   688→    if (primaryIssue) {\n   689→      if (primaryIssue.code.includes('ELBOW')) {\n   690→        correction = 'Extend elbow more at contact';\n   691→      } else if (primaryIssue.code.includes('KNEE')) {\n   692→        correction = 'Maintain athletic knee bend';\n   693→      } else if (primaryIssue.code.includes('STANCE')) {\n   694→        correction = 'Widen stance for stability';\n   695→      } else if (primaryIssue.code.includes('ROTATION')) {\n   696→        correction = 'Rotate hips before shoulders';\n   697→      }\n   698→    }\n   699→\n   700→    keyframes.push({\n   701→      name: 'Setup',\n   702→      description: 'Preparation phase',\n   703→      landmarks: setupFrame?.landmarks || null,\n   704→      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n   705→    });\n   706→\n   707→    keyframes.push({\n   708→      name: 'Contact',\n   709→      description: 'Point of contact',\n   710→      landmarks: contactFrame?.landmarks || null,\n   711→      correction: correction || undefined,\n   712→    });\n   713→\n   714→    keyframes.push({\n   715→      name: 'Recovery',\n   716→      description: 'Return to ready',\n   717→      landmarks: recoveryFrame?.landmarks || null,\n   718→      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n   719→    });\n   720→\n   721→    return keyframes;\n   722→  };\n   723→\n   724→  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n   725→    const file = e.target.files?.[0];\n   726→    if (!file) return;\n   727→\n   728→    if (!file.type.startsWith('video/')) {\n   729→      setError('Please select a video file');\n   730→      return;\n   731→    }\n   732→\n   733→    if (file.size > 100 * 1024 * 1024) {\n   734→      setError('File size must be less than 100MB. Please compress your video before uploading.');\n   735→      return;\n   736→    }\n   737→\n   738→    setError(null);\n   739→    setVideoFile(file);\n   740→    setResult(null);\n   741→    setIssues([]);\n   742→    setPoseData([]);\n   743→    setFrameAnalyses([]);\n   744→    setAutoLevelResult(null);\n   745→    setGuidanceKeyframes([]);\n   746→\n   747→    // Create object URL for video preview\n   748→    const objectUrl = URL.createObjectURL(file);\n   749→    setVideoUrl(objectUrl);\n   750→\n   751→    // Start analysis\n   752→    await analyzeVideo(file, objectUrl);\n   753→  };\n   754→\n   755→  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n   756→  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n   757→    if (!poseLandmarkerRef.current) return [];\n   758→\n   759→    const tracks: Map<number, PlayerTrackData> = new Map();\n   760→    const sampleFrames = 5;\n   761→    const duration = videoElement.duration;\n   762→\n   763→    // Use separate timestamp tracking for track detection\n   764→    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n   765→\n   766→    for (let i = 0; i < sampleFrames; i++) {\n   767→      const timestamp = (i / sampleFrames) * duration;\n   768→      videoElement.currentTime = timestamp;\n   769→\n   770→      await new Promise<void>((resolve) => {\n   771→        const onSeeked = () => {\n   772→          videoElement.removeEventListener('seeked', onSeeked);\n   773→          resolve();\n   774→        };\n   775→        videoElement.addEventListener('seeked', onSeeked);\n   776→      });\n   777→\n   778→      await new Promise(resolve => setTimeout(resolve, 50));\n   779→\n   780→      try {\n   781→        // PHASE 1 FIX: Ensure monotonic timestamp\n   782→        trackDetectionTimestamp += 100; // 100ms between samples\n   783→        const safeTimestamp = trackDetectionTimestamp;\n   784→        lastTimestampMsRef.current = safeTimestamp;\n   785→\n   786→        const results = poseLandmarkerRef.current.detectForVideo(\n   787→          videoElement,\n   788→          safeTimestamp\n   789→        );\n   790→\n   791→        if (results.landmarks && results.landmarks.length > 0) {\n   792→          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n   793→            const landmarks = results.landmarks[poseIdx];\n   794→            const bbox = calculateBoundingBox(landmarks);\n   795→\n   796→            if (!tracks.has(poseIdx)) {\n   797→              tracks.set(poseIdx, {\n   798→                track_id: poseIdx,\n   799→                bbox_samples: [],\n   800→                is_selected: false,\n   801→                confidence_avg: 0,\n   802→                frame_count: 0,\n   803→                side: bbox.y < 0.5 ? 'far' : 'near',\n   804→              });\n   805→            }\n   806→\n   807→            const track = tracks.get(poseIdx)!;\n   808→            track.bbox_samples.push({\n   809→              frame: i,\n   810→              x: bbox.x,\n   811→              y: bbox.y,\n   812→              w: bbox.w,\n   813→              h: bbox.h,\n   814→              confidence: landmarks[0].visibility || 0.5,\n   815→            });\n   816→            track.frame_count++;\n   817→            track.confidence_avg =\n   818→              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n   819→              track.frame_count;\n   820→          }\n   821→        }\n   822→      } catch (err) {\n   823→        console.warn('Error detecting poses in frame:', err);\n   824→      }\n   825→    }\n   826→\n   827→    // Generate thumbnails\n   828→    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n   829→\n   830→    if (tracksArray.length > 0) {\n   831→      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n   832→      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n   833→      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n   834→\n   835→      await new Promise<void>((resolve) => {\n   836→        const onSeeked = () => {\n   837→          videoElement.removeEventListener('seeked', onSeeked);\n   838→          resolve();\n   839→        };\n   840→        videoElement.addEventListener('seeked', onSeeked);\n   841→      });\n   842→      await new Promise(resolve => setTimeout(resolve, 100));\n   843→\n   844→      for (const track of tracksArray) {\n   845→        if (track.bbox_samples.length > 0) {\n   846→          const bestBbox = track.bbox_samples.reduce((best, current) =>\n   847→            (current.confidence || 0) > (best.confidence || 0) ? current : best\n   848→          );\n   849→\n   850→          const thumbnail = generateThumbnail(videoElement, {\n   851→            x: bestBbox.x,\n   852→            y: bestBbox.y,\n   853→            w: bestBbox.w,\n   854→            h: bestBbox.h,\n   855→          });\n   856→\n   857→          if (thumbnail) {\n   858→            track.thumbnail_url = thumbnail;\n   859→          }\n   860→        }\n   861→      }\n   862→    }\n   863→\n   864→    return tracksArray;\n   865→  };\n   866→\n   867→  // Calculate bounding box from landmarks\n   868→  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n   869→    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n   870→    for (const lm of landmarks) {\n   871→      if (lm.visibility > 0.5) {\n   872→        minX = Math.min(minX, lm.x);\n   873→        minY = Math.min(minY, lm.y);\n   874→        maxX = Math.max(maxX, lm.x);\n   875→        maxY = Math.max(maxY, lm.y);\n   876→      }\n   877→    }\n   878→    return {\n   879→      x: minX,\n   880→      y: minY,\n   881→      w: maxX - minX,\n   882→      h: maxY - minY,\n   883→    };\n   884→  };\n   885→\n   886→  // Generate thumbnail from video at specific bounding box\n   887→  const generateThumbnail = (\n   888→    video: HTMLVideoElement,\n   889→    bbox: { x: number; y: number; w: number; h: number },\n   890→    padding: number = 0.1\n   891→  ): string | null => {\n   892→    try {\n   893→      const canvas = document.createElement('canvas');\n   894→      const ctx = canvas.getContext('2d');\n   895→      if (!ctx) return null;\n   896→\n   897→      const vw = video.videoWidth;\n   898→      const vh = video.videoHeight;\n   899→\n   900→      const padX = bbox.w * padding;\n   901→      const padY = bbox.h * padding;\n   902→\n   903→      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n   904→      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n   905→      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n   906→      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n   907→\n   908→      if (cropW <= 0 || cropH <= 0) return null;\n   909→\n   910→      const maxSize = 150;\n   911→      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n   912→      canvas.width = Math.floor(cropW * scale);\n   913→      canvas.height = Math.floor(cropH * scale);\n   914→\n   915→      ctx.drawImage(\n   916→        video,\n   917→        cropX, cropY, cropW, cropH,\n   918→        0, 0, canvas.width, canvas.height\n   919→      );\n   920→\n   921→      return canvas.toDataURL('image/jpeg', 0.8);\n   922→    } catch (err) {\n   923→      console.warn('Error generating thumbnail:', err);\n   924→      return null;\n   925→    }\n   926→  };\n   927→\n   928→  // Handle player selection confirmation\n   929→  const handlePlayerSelectionConfirm = (\n   930→    selectedTracks: number[],\n   931→    format: 'singles' | 'doubles',\n   932→    event: string\n   933→  ) => {\n   934→    setSelectedTrackIds(selectedTracks);\n   935→    setMatchFormat(format);\n   936→    setEventType(event);\n   937→    setShowPlayerSelection(false);\n   938→\n   939→    if (processVideoRef.current && videoFile) {\n   940→      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n   941→    }\n   942→  };\n   943→\n   944→  // Continue analysis after player selection\n   945→  const continueAnalysisWithSelection = async (\n   946→    processVideo: HTMLVideoElement,\n   947→    selectedTracks: number[]\n   948→  ) => {\n   949→    setAnalysisState('EXTRACTING_POSE');\n   950→    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n   951→    setFrameAnalyses(analyses);\n   952→\n   953→    const poseArray = analyses.map(a => a.landmarks);\n   954→    setPoseData(poseArray);\n   955→\n   956→    const detectedIssues = detectIssuesFromAnalyses(analyses);\n   957→    setIssues(detectedIssues);\n   958→\n   959→    // PHASE 3: Auto-detect skill level\n   960→    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n   961→    setAutoLevelResult(levelResult);\n   962→\n   963→    // PHASE 4: Generate guidance keyframes\n   964→    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n   965→    setGuidanceKeyframes(guidance);\n   966→\n   967→    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n   968→    const totalFrames = analyses.filter(a => a.evaluation).length;\n   969→    const avgScore = totalFrames > 0\n   970→      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n   971→      : 0;\n   972→\n   973→    setResult({\n   974→      top_issues: detectedIssues.map(issue => ({\n   975→        id: issue.code,\n   976→        title: issue.title,\n   977→        severity: issue.severity,\n   978→        description: issue.description || '',\n   979→        affected_metrics: [],\n   980→      })),\n   981→      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n   982→        id: d.id,\n   983→        name: d.name,\n   984→        description: d.description,\n   985→        duration_minutes: d.durationMinutes,\n   986→        target_metrics: d.targetMetrics,\n   987→        instructions: d.steps,\n   988→      })),\n   989→      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n   990→      strategy_summary: passedFrames > totalFrames * 0.7\n   991→        ? 'Your form is generally good. Focus on the specific issues identified.'\n   992→        : 'Work on maintaining consistent form throughout your movements.',\n   993→      training_plan: [],\n   994→    });\n   995→\n   996→    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);\n   997→    if (!saveResult.success) {\n   998→      setError(saveResult.error || 'Failed to save analysis');\n   999→    }\n  1000→    setAnalyzing(false);\n  1001→    setAnalysisState('DONE');\n  1002→    setAnalyzeProgress(100);\n  1003→  };\n  1004→\n  1005→  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n  1006→    setAnalyzing(true);\n  1007→    setAnalyzeProgress(0);\n  1008→    setAnalysisState('DETECTING_PLAYERS');\n  1009→\n  1010→    try {\n  1011→      const processVideo = document.createElement('video');\n  1012→      processVideo.src = videoObjectUrl;\n  1013→      processVideo.muted = true;\n  1014→      processVideo.playsInline = true;\n  1015→      processVideoRef.current = processVideo;\n  1016→\n  1017→      await new Promise<void>((resolve, reject) => {\n  1018→        processVideo.onloadedmetadata = () => {\n  1019→          setDuration(processVideo.duration);\n  1020→          setFps(30);\n  1021→          resolve();\n  1022→        };\n  1023→        processVideo.onerror = () => reject(new Error('Failed to load video'));\n  1024→      });\n  1025→\n  1026→      await new Promise<void>((resolve) => {\n  1027→        if (processVideo.readyState >= 2) {\n  1028→          resolve();\n  1029→        } else {\n  1030→          processVideo.oncanplay = () => resolve();\n  1031→        }\n  1032→      });\n  1033→\n  1034→      // Detect player tracks first\n  1035→      setAnalyzeProgress(5);\n  1036→      const tracks = await detectPlayerTracks(processVideo);\n  1037→      setDetectedTracks(tracks);\n  1038→\n  1039→      const uniquePlayers = tracks.length;\n  1040→      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n  1041→      setDetectedMatchFormat(detectedFormat);\n  1042→\n  1043→      if (tracks.length > 1) {\n  1044→        setShowPlayerSelection(true);\n  1045→        return;\n  1046→      }\n  1047→\n  1048→      if (tracks.length === 1) {\n  1049→        setSelectedTrackIds([tracks[0].track_id]);\n  1050→      }\n  1051→\n  1052→      // Process video with pose detection\n  1053→      let analyses: FrameAnalysis[] = [];\n  1054→\n  1055→      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n  1056→        setAnalysisState('EXTRACTING_POSE');\n  1057→        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n  1058→        setFrameAnalyses(analyses);\n  1059→\n  1060→        const poseArray = analyses.map(a => a.landmarks);\n  1061→        setPoseData(poseArray);\n  1062→\n  1063→        const detectedIssues = detectIssuesFromAnalyses(analyses);\n  1064→        setIssues(detectedIssues);\n  1065→\n  1066→        // PHASE 3: Auto-detect skill level\n  1067→        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n  1068→        setAutoLevelResult(levelResult);\n  1069→\n  1070→        // PHASE 4: Generate guidance keyframes\n  1071→        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n  1072→        setGuidanceKeyframes(guidance);\n  1073→\n  1074→        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n  1075→        const totalFrames = analyses.filter(a => a.evaluation).length;\n  1076→        const avgScore = totalFrames > 0\n  1077→          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n  1078→          : 0;\n  1079→\n  1080→        setResult({\n  1081→          top_issues: detectedIssues.map(issue => ({\n  1082→            id: issue.code,\n  1083→            title: issue.title,\n  1084→            severity: issue.severity,\n  1085→            description: issue.description || '',\n  1086→            affected_metrics: [],\n  1087→          })),\n  1088→          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n  1089→            id: d.id,\n  1090→            name: d.name,\n  1091→            description: d.description,\n  1092→            duration_minutes: d.durationMinutes,\n  1093→            target_metrics: d.targetMetrics,\n  1094→            instructions: d.steps,\n  1095→          })),\n  1096→          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n  1097→          strategy_summary: passedFrames > totalFrames * 0.7\n  1098→            ? 'Your form is generally good. Focus on the specific issues identified.'\n  1099→            : 'Work on maintaining consistent form throughout your movements.',\n  1100→          training_plan: [],\n  1101→        });\n  1102→\n  1103→        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n  1104→        if (!saveResult.success) {\n  1105→          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n  1106→        }\n  1107→        setAnalysisState('DONE');\n  1108→      } else {\n  1109→        setError('Pose detection not available. Using demo mode.');\n  1110→        setAnalysisState('ERROR');\n  1111→\n  1112→        const demoIssues: DetectedIssue[] = [\n  1113→          {\n  1114→            code: 'ELBOW_ANGLE_OVERHEAD',\n  1115→            title: 'Elbow Extension (Overhead)',\n  1116→            severity: 'high',\n  1117→            description: 'Elbow should be nearly straight at contact point',\n  1118→            timestamps: [1.2, 3.5, 7.8],\n  1119→            drill: DRILLS['elbow-extension'],\n  1120→          },\n  1121→          {\n  1122→            code: 'KNEE_BEND',\n  1123→            title: 'Knee Bend',\n  1124→            severity: 'medium',\n  1125→            description: 'Bend knees more for power',\n  1126→            timestamps: [2.1, 5.3],\n  1127→            drill: DRILLS['lunge-practice'],\n  1128→          },\n  1129→        ];\n  1130→        setIssues(demoIssues);\n  1131→        setAutoLevelResult({\n  1132→          level: 'Intermediate',\n  1133→          confidence: 0.5,\n  1134→          rationaleBullets: ['Demo mode - upload video for real analysis'],\n  1135→        });\n  1136→        setResult({\n  1137→          top_issues: demoIssues.map(i => ({\n  1138→            id: i.code,\n  1139→            title: i.title,\n  1140→            severity: i.severity,\n  1141→            description: i.description || '',\n  1142→            affected_metrics: [],\n  1143→          })),\n  1144→          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n  1145→            id: d!.id,\n  1146→            name: d!.name,\n  1147→            description: d!.description,\n  1148→            duration_minutes: d!.durationMinutes,\n  1149→            target_metrics: d!.targetMetrics,\n  1150→            instructions: d!.steps,\n  1151→          })),\n  1152→          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n  1153→          strategy_summary: '',\n  1154→          training_plan: [],\n  1155→        });\n  1156→      }\n  1157→\n  1158→    } catch (err) {\n  1159→      console.error('Analysis error:', err);\n  1160→      setError('Failed to analyze video. Please try again.');\n  1161→      setAnalysisState('ERROR');\n  1162→    } finally {\n  1163→      setAnalyzing(false);\n  1164→      setAnalyzeProgress(100);\n  1165→    }\n  1166→  };\n  1167→\n  1168→  const saveAnalysisToDatabase = async (\n  1169→    file: File,\n  1170→    analyses: FrameAnalysis[],\n  1171→    detectedIssues: DetectedIssue[],\n  1172→    avgScore: number,\n  1173→    levelResult?: AutoLevelResult\n  1174→  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n  1175→    try {\n  1176→      const { data: { user } } = await supabase.auth.getUser();\n  1177→      if (!user) {\n  1178→        return { success: false, error: 'Not authenticated' };\n  1179→      }\n  1180→\n  1181→      let videoPath: string | null = null;\n  1182→      let publicVideoUrl = '';\n  1183→\n  1184→      try {\n  1185→        videoPath = await uploadVideo(file, user.id, (progress) => {\n  1186→          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n  1187→        });\n  1188→\n  1189→        if (!videoPath) {\n  1190→          throw new Error('Upload returned empty path');\n  1191→        }\n  1192→\n  1193→        publicVideoUrl = getVideoUrl(videoPath);\n  1194→        console.log('Video uploaded successfully:', videoPath);\n  1195→\n  1196→      } catch (uploadError) {\n  1197→        console.error('Video upload failed:', uploadError);\n  1198→        const errorMessage = uploadError instanceof Error\n  1199→          ? uploadError.message\n  1200→          : 'Failed to upload video. Please try again.';\n  1201→        setError(errorMessage);\n  1202→        return { success: false, error: errorMessage };\n  1203→      }\n  1204→\n  1205→      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n  1206→      const totalFrames = analyses.filter(a => a.evaluation).length;\n  1207→\n  1208→      const { data: session, error: sessionError } = await supabase\n  1209→        .from('sessions')\n  1210→        .insert({\n  1211→          user_id: user.id,\n  1212→          type: 'analytics',\n  1213→          video_path: videoPath,\n  1214→          video_url: publicVideoUrl,\n  1215→          filename: file.name,\n  1216→          frame_count: analyses.length,\n  1217→          overall_score: Math.round(avgScore),\n  1218→          pose_data: analyses.map(a => a.landmarks),\n  1219→          status: 'ready',\n  1220→          match_format: matchFormat,\n  1221→          event_type: eventType || null,\n  1222→          selected_tracks: selectedTrackIds,\n  1223→          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n  1224→          rules_version: 'v1',\n  1225→          summary: {\n  1226→            total_frames: totalFrames,\n  1227→            green_frames: passedFrames,\n  1228→            red_frames: totalFrames - passedFrames,\n  1229→            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n  1230→            average_score: avgScore,\n  1231→            duration_seconds: duration,\n  1232→            auto_level: levelResult,\n  1233→          },\n  1234→        })\n  1235→        .select()\n  1236→        .single();\n  1237→\n  1238→      if (sessionError) {\n  1239→        console.error('Session save error:', sessionError);\n  1240→        return { success: false, error: 'Failed to save session data' };\n  1241→      }\n  1242→\n  1243→      if (session && detectedIssues.length > 0) {\n  1244→        const issueInserts = detectedIssues.map(issue => ({\n  1245→          session_id: session.id,\n  1246→          code: issue.code,\n  1247→          title: issue.title,\n  1248→          severity: issue.severity,\n  1249→          description: issue.description,\n  1250→          timestamps: issue.timestamps,\n  1251→          drill: issue.drill,\n  1252→        }));\n  1253→\n  1254→        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n  1255→        if (issuesError) {\n  1256→          console.warn('Issues save warning:', issuesError);\n  1257→        }\n  1258→      }\n  1259→\n  1260→      setAnalyzeProgress(100);\n  1261→      return { success: true, sessionId: session.id };\n  1262→\n  1263→    } catch (err) {\n  1264→      console.error('Error saving to database:', err);\n  1265→      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n  1266→      return { success: false, error: errorMessage };\n  1267→    }\n  1268→  };\n  1269→\n  1270→  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  1271→  const renderFrame = useCallback(() => {\n  1272→    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n  1273→\n  1274→    const video = videoRef.current;\n  1275→    const canvas = canvasRef.current;\n  1276→    const ctx = canvas.getContext('2d');\n  1277→    if (!ctx) return;\n  1278→\n  1279→    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n  1280→    const container = videoContainerRef.current;\n  1281→    const containerRect = container.getBoundingClientRect();\n  1282→\n  1283→    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n  1284→\n  1285→    const videoAspect = video.videoWidth / video.videoHeight;\n  1286→    const containerAspect = containerRect.width / containerRect.height;\n  1287→\n  1288→    let renderWidth, renderHeight, offsetX, offsetY;\n  1289→\n  1290→    if (videoAspect > containerAspect) {\n  1291→      // Video is wider - letterbox top/bottom\n  1292→      renderWidth = containerRect.width;\n  1293→      renderHeight = containerRect.width / videoAspect;\n  1294→      offsetX = 0;\n  1295→      offsetY = (containerRect.height - renderHeight) / 2;\n  1296→    } else {\n  1297→      // Video is taller - letterbox left/right\n  1298→      renderHeight = containerRect.height;\n  1299→      renderWidth = containerRect.height * videoAspect;\n  1300→      offsetX = (containerRect.width - renderWidth) / 2;\n  1301→      offsetY = 0;\n  1302→    }\n  1303→\n  1304→    // Set canvas to match container size\n  1305→    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n  1306→      canvas.width = containerRect.width;\n  1307→      canvas.height = containerRect.height;\n  1308→    }\n  1309→\n  1310→    // Clear canvas\n  1311→    ctx.clearRect(0, 0, canvas.width, canvas.height);\n  1312→\n  1313→    if (!showSkeleton) return;\n  1314→\n  1315→    // Find the closest frame analysis\n  1316→    let closestFrame: FrameAnalysis | null = null;\n  1317→    let minDiff = Infinity;\n  1318→\n  1319→    for (const frame of frameAnalyses) {\n  1320→      const diff = Math.abs(frame.timestamp - video.currentTime);\n  1321→      if (diff < minDiff) {\n  1322→        minDiff = diff;\n  1323→        closestFrame = frame;\n  1324→      }\n  1325→    }\n  1326→\n  1327→    // Also check raw poseData array (for loaded sessions)\n  1328→    if (!closestFrame && poseData.length > 0) {\n  1329→      const frameIndex = Math.floor(video.currentTime * 10);\n  1330→      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n  1331→      if (landmarks) {\n  1332→        closestFrame = {\n  1333→          timestamp: video.currentTime,\n  1334→          landmarks,\n  1335→          evaluation: evaluateForm(landmarks, 'general'),\n  1336→          metrics: extractMetrics(landmarks),\n  1337→        };\n  1338→      }\n  1339→    }\n  1340→\n  1341→    if (closestFrame?.landmarks) {\n  1342→      // Get skill level from auto-detection or default to intermediate\n  1343→      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n  1344→      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n  1345→      setCurrentBandedScore(bandedResult);\n  1346→\n  1347→      const isGreen = bandedResult.overall_band === 'green';\n  1348→      const isYellow = bandedResult.overall_band === 'yellow';\n  1349→      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n  1350→\n  1351→      ctx.strokeStyle = color;\n  1352→      ctx.lineWidth = 3;\n  1353→      ctx.fillStyle = color;\n  1354→\n  1355→      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n  1356→      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n  1357→        const start = closestFrame.landmarks[startIdx];\n  1358→        const end = closestFrame.landmarks[endIdx];\n  1359→        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n  1360→          ctx.beginPath();\n  1361→          // Apply offset and scale to match actual video render position\n  1362→          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n  1363→          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n  1364→          ctx.stroke();\n  1365→        }\n  1366→      }\n  1367→\n  1368→      // Draw joints\n  1369→      for (const landmark of closestFrame.landmarks) {\n  1370→        if (landmark.visibility > 0.5) {\n  1371→          ctx.beginPath();\n  1372→          ctx.arc(\n  1373→            offsetX + landmark.x * renderWidth,\n  1374→            offsetY + landmark.y * renderHeight,\n  1375→            5,\n  1376→            0,\n  1377→            2 * Math.PI\n  1378→          );\n  1379→          ctx.fill();\n  1380→        }\n  1381→      }\n  1382→    }\n  1383→\n  1384→    if (!video.paused) {\n  1385→      animationRef.current = requestAnimationFrame(renderFrame);\n  1386→    }\n  1387→  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);\n  1388→\n  1389→  // Trigger skeleton render when poseData is loaded\n  1390→  useEffect(() => {\n  1391→    if (poseData.length > 0 && videoRef.current) {\n  1392→      const tryRender = () => {\n  1393→        if (videoRef.current && videoRef.current.readyState >= 2) {\n  1394→          renderFrame();\n  1395→        } else {\n  1396→          setTimeout(tryRender, 100);\n  1397→        }\n  1398→      };\n  1399→      tryRender();\n  1400→    }\n  1401→  }, [poseData, renderFrame]);\n  1402→\n  1403→  // Handle video time updates\n  1404→  const handleTimeUpdate = useCallback(() => {\n  1405→    if (videoRef.current) {\n  1406→      setCurrentTime(videoRef.current.currentTime);\n  1407→      renderFrame();\n  1408→    }\n  1409→  }, [renderFrame]);\n  1410→\n  1411→  // Handle video play/pause\n  1412→  const togglePlayPause = useCallback(() => {\n  1413→    if (videoRef.current) {\n  1414→      if (videoRef.current.paused) {\n  1415→        videoRef.current.play();\n  1416→        setIsPlaying(true);\n  1417→        animationRef.current = requestAnimationFrame(renderFrame);\n  1418→      } else {\n  1419→        videoRef.current.pause();\n  1420→        setIsPlaying(false);\n  1421→        if (animationRef.current) {\n  1422→          cancelAnimationFrame(animationRef.current);\n  1423→        }\n  1424→      }\n  1425→    }\n  1426→  }, [renderFrame]);\n  1427→\n  1428→  // Jump to timestamp\n  1429→  const jumpToTimestamp = useCallback((timestamp: number) => {\n  1430→    if (videoRef.current) {\n  1431→      videoRef.current.currentTime = timestamp;\n  1432→      videoRef.current.pause();\n  1433→      setIsPlaying(false);\n  1434→      setCurrentTime(timestamp);\n  1435→      setTimeout(renderFrame, 50);\n  1436→    }\n  1437→  }, [renderFrame]);\n  1438→\n  1439→  // Find next mistake\n  1440→  const goToNextMistake = useCallback(() => {\n  1441→    const allTimestamps = issues\n  1442→      .flatMap((i) => i.timestamps || [])\n  1443→      .sort((a, b) => a - b);\n  1444→\n  1445→    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n  1446→    if (nextTimestamp !== undefined) {\n  1447→      jumpToTimestamp(nextTimestamp);\n  1448→    } else if (allTimestamps.length > 0) {\n  1449→      jumpToTimestamp(allTimestamps[0]);\n  1450→    }\n  1451→  }, [issues, currentTime, jumpToTimestamp]);\n  1452→\n  1453→  // Handle video metadata loaded\n  1454→  const handleLoadedMetadata = useCallback(() => {\n  1455→    if (videoRef.current) {\n  1456→      setDuration(videoRef.current.duration);\n  1457→      setTimeout(renderFrame, 100);\n  1458→    }\n  1459→  }, [renderFrame]);\n  1460→\n  1461→  const getSeverityColor = (severity: string) => {\n  1462→    switch (severity) {\n  1463→      case 'high':\n  1464→        return 'bg-red-50 border-red-200 text-red-800';\n  1465→      case 'medium':\n  1466→        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n  1467→      case 'low':\n  1468→        return 'bg-green-50 border-green-200 text-green-800';\n  1469→      default:\n  1470→        return 'bg-gray-50 border-gray-200 text-gray-800';\n  1471→    }\n  1472→  };\n  1473→\n  1474→  const formatTime = (seconds: number) => {\n  1475→    const mins = Math.floor(seconds / 60);\n  1476→    const secs = Math.floor(seconds % 60);\n  1477→    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  1478→  };\n  1479→\n  1480→  // Get current frame info for display\n  1481→  const getCurrentFrameInfo = () => {\n  1482→    if (frameAnalyses.length === 0) return null;\n  1483→\n  1484→    let closestFrame: FrameAnalysis | null = null;\n  1485→    let minDiff = Infinity;\n  1486→\n  1487→    for (const frame of frameAnalyses) {\n  1488→      const diff = Math.abs(frame.timestamp - currentTime);\n  1489→      if (diff < minDiff) {\n  1490→        minDiff = diff;\n  1491→        closestFrame = frame;\n  1492→      }\n  1493→    }\n  1494→\n  1495→    return closestFrame;\n  1496→  };\n  1497→\n  1498→  const currentFrameInfo = getCurrentFrameInfo();\n  1499→\n  1500→  // PHASE 5: Get analysis state message\n  1501→  const getAnalysisStateMessage = () => {\n  1502→    switch (analysisState) {\n  1503→      case 'DETECTING_PLAYERS':\n  1504→        return 'Detecting players in video...';\n  1505→      case 'EXTRACTING_POSE':\n  1506→        return 'Extracting pose data from frames...';\n  1507→      case 'GEMINI_SCORING':\n  1508→        return 'AI analyzing skill level...';\n  1509→      case 'DONE':\n  1510→        return 'Analysis complete!';\n  1511→      case 'ERROR':\n  1512→        return 'Analysis failed';\n  1513→      default:\n  1514→        return 'Ready to analyze';\n  1515→    }\n  1516→  };\n  1517→\n  1518→  return (\n  1519→    <div className=\"min-h-screen bg-gray-50\">\n  1520→      <DashboardNav />\n  1521→\n  1522→      <main className=\"ml-64 p-8\">\n  1523→        <div className=\"max-w-7xl mx-auto\">\n  1524→          {/* Header */}\n  1525→          <div className=\"mb-8\">\n  1526→            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n  1527→            <p className=\"text-gray-600 mt-1\">\n  1528→              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n  1529→            </p>\n  1530→          </div>\n  1531→\n  1532→          {/* Upload Section */}\n  1533→          {!result && !videoUrl && (\n  1534→            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n  1535→              <div\n  1536→                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n  1537→                  uploading || analyzing\n  1538→                    ? 'border-primary-300 bg-primary-50'\n  1539→                    : 'border-gray-300 hover:border-primary-400'\n  1540→                }`}\n  1541→              >\n  1542→                {uploading ? (\n  1543→                  <div className=\"space-y-4\">\n  1544→                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n  1545→                    <p className=\"text-gray-600\">Uploading video...</p>\n  1546→                  </div>\n  1547→                ) : analyzing ? (\n  1548→                  // PHASE 5: Enhanced loading state with state machine\n  1549→                  <div className=\"space-y-4\">\n  1550→                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n  1551→                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1552→                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n  1553→                      </svg>\n  1554→                      {/* Spinning ring */}\n  1555→                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n  1556→                    </div>\n  1557→                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n  1558→\n  1559→                    {/* Progress steps */}\n  1560→                    <div className=\"flex justify-center gap-2 mt-4\">\n  1561→                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n  1562→                        <div\n  1563→                          key={state}\n  1564→                          className={`w-3 h-3 rounded-full transition-colors ${\n  1565→                            analysisState === state\n  1566→                              ? 'bg-primary-500 animate-pulse'\n  1567→                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n  1568→                              ? 'bg-green-500'\n  1569→                              : 'bg-gray-300'\n  1570→                          }`}\n  1571→                        />\n  1572→                      ))}\n  1573→                    </div>\n  1574→                    <p className=\"text-gray-500 text-sm\">\n  1575→                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n  1576→                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n  1577→                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n  1578→                    </p>\n  1579→\n  1580→                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n  1581→                      <div\n  1582→                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n  1583→                        style={{ width: `${analyzeProgress}%` }}\n  1584→                      ></div>\n  1585→                    </div>\n  1586→                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n  1587→                  </div>\n  1588→                ) : (\n  1589→                  <>\n  1590→                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n  1591→                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1592→                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n  1593→                      </svg>\n  1594→                    </div>\n  1595→                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n  1596→                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n  1597→                    {poseLandmarkerReady && (\n  1598→                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n  1599→                    )}\n  1600→                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n  1601→                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n  1602→                      Select Video\n  1603→                    </button>\n  1604→                  </>\n  1605→                )}\n  1606→              </div>\n  1607→\n  1608→              {error && (\n  1609→                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n  1610→              )}\n  1611→            </div>\n  1612→          )}\n  1613→\n  1614→          {/* Video Player with Overlay */}\n  1615→          {videoUrl && (\n  1616→            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n  1617→              <div className=\"lg:col-span-2\">\n  1618→                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n  1619→                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n  1620→                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n  1621→                    <video\n  1622→                      ref={videoRef}\n  1623→                      src={videoUrl}\n  1624→                      className=\"absolute inset-0 w-full h-full object-contain\"\n  1625→                      onTimeUpdate={handleTimeUpdate}\n  1626→                      onLoadedMetadata={handleLoadedMetadata}\n  1627→                      onEnded={() => setIsPlaying(false)}\n  1628→                      playsInline\n  1629→                    />\n  1630→                    <canvas\n  1631→                      ref={canvasRef}\n  1632→                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n  1633→                        showSkeleton ? '' : 'hidden'\n  1634→                      }`}\n  1635→                    />\n  1636→\n  1637→                    {/* Status indicator with auto-detected level */}\n  1638→                    {currentBandedScore && (\n  1639→                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n  1640→                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n  1641→                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n  1642→                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n  1643→                        'bg-gray-500 text-white'\n  1644→                      }`}>\n  1645→                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n  1646→                        <span className=\"ml-2 opacity-75\">\n  1647→                          {Math.round(currentBandedScore.overall_score)}%\n  1648→                        </span>\n  1649→                      </div>\n  1650→                    )}\n  1651→\n  1652→                    {/* Time display */}\n  1653→                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n  1654→                      {formatTime(currentTime)} / {formatTime(duration)}\n  1655→                    </div>\n  1656→\n  1657→                    {/* Current metrics display */}\n  1658→                    {currentFrameInfo?.metrics && (\n  1659→                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n  1660→                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n  1661→                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n  1662→                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n  1663→                      </div>\n  1664→                    )}\n  1665→                  </div>\n  1666→\n  1667→                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n  1668→                  <div className=\"p-4 flex items-center justify-between\">\n  1669→                    <div className=\"flex items-center gap-2\">\n  1670→                      <button\n  1671→                        onClick={togglePlayPause}\n  1672→                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n  1673→                      >\n  1674→                        {isPlaying ? (\n  1675→                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1676→                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n  1677→                          </svg>\n  1678→                        ) : (\n  1679→                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1680→                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n  1681→                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n  1682→                          </svg>\n  1683→                        )}\n  1684→                      </button>\n  1685→\n  1686→                      <button\n  1687→                        onClick={goToNextMistake}\n  1688→                        disabled={issues.length === 0 || analyzing}\n  1689→                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n  1690→                      >\n  1691→                        Next Mistake\n  1692→                      </button>\n  1693→                    </div>\n  1694→\n  1695→                    <div className=\"flex items-center gap-4\">\n  1696→                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n  1697→                      {autoLevelResult && (\n  1698→                        <div className=\"flex items-center gap-2 text-white text-sm\">\n  1699→                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n  1700→                            {autoLevelResult.level}\n  1701→                          </span>\n  1702→                          <span className=\"text-gray-400 text-xs\">\n  1703→                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n  1704→                          </span>\n  1705→                        </div>\n  1706→                      )}\n  1707→\n  1708→                      <label className=\"flex items-center gap-2 text-white text-sm\">\n  1709→                        <input\n  1710→                          type=\"checkbox\"\n  1711→                          checked={showSkeleton}\n  1712→                          onChange={(e) => {\n  1713→                            setShowSkeleton(e.target.checked);\n  1714→                            if (e.target.checked) {\n  1715→                              setTimeout(renderFrame, 50);\n  1716→                            }\n  1717→                          }}\n  1718→                          className=\"rounded\"\n  1719→                        />\n  1720→                        Show Skeleton\n  1721→                      </label>\n  1722→                    </div>\n  1723→                  </div>\n  1724→\n  1725→                  {/* Timeline scrubber */}\n  1726→                  <div className=\"px-4 pb-4\">\n  1727→                    <input\n  1728→                      type=\"range\"\n  1729→                      min={0}\n  1730→                      max={duration || 100}\n  1731→                      step={0.1}\n  1732→                      value={currentTime}\n  1733→                      onChange={(e) => {\n  1734→                        const time = parseFloat(e.target.value);\n  1735→                        if (videoRef.current) {\n  1736→                          videoRef.current.currentTime = time;\n  1737→                          setCurrentTime(time);\n  1738→                          setTimeout(renderFrame, 50);\n  1739→                        }\n  1740→                      }}\n  1741→                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n  1742→                    />\n  1743→                  </div>\n  1744→                </div>\n  1745→\n  1746→                {/* PHASE 3: Auto-level detection result panel */}\n  1747→                {autoLevelResult && (\n  1748→                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n  1749→                    <div className=\"flex items-center justify-between mb-4\">\n  1750→                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n  1751→                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n  1752→                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n  1753→                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n  1754→                        'bg-blue-100 text-blue-800'\n  1755→                      }`}>\n  1756→                        {autoLevelResult.level}\n  1757→                      </span>\n  1758→                    </div>\n  1759→                    <div className=\"space-y-2\">\n  1760→                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n  1761→                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n  1762→                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n  1763→                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n  1764→                          </svg>\n  1765→                          <span>{bullet}</span>\n  1766→                        </div>\n  1767→                      ))}\n  1768→                    </div>\n  1769→                  </div>\n  1770→                )}\n  1771→\n  1772→                {/* PHASE 4: Guidance Animation */}\n  1773→                {guidanceKeyframes.length > 0 && (\n  1774→                  <div className=\"mt-6\">\n  1775→                    <div className=\"flex items-center justify-between mb-4\">\n  1776→                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n  1777→                      <button\n  1778→                        onClick={() => setShowGuidance(!showGuidance)}\n  1779→                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n  1780→                      >\n  1781→                        {showGuidance ? 'Hide' : 'Show'} Animation\n  1782→                      </button>\n  1783→                    </div>\n  1784→                    {showGuidance && (\n  1785→                      <GuidanceAnimation\n  1786→                        keyframes={guidanceKeyframes}\n  1787→                        primaryIssue={issues[0]}\n  1788→                      />\n  1789→                    )}\n  1790→                  </div>\n  1791→                )}\n  1792→\n  1793→                {/* Analysis Summary */}\n  1794→                {result && (\n  1795→                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n  1796→                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n  1797→                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n  1798→                    {result.strategy_summary && (\n  1799→                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n  1800→                    )}\n  1801→                  </div>\n  1802→                )}\n  1803→              </div>\n  1804→\n  1805→              {/* Issues Panel */}\n  1806→              <div className=\"space-y-4\">\n  1807→                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n  1808→                {analyzing ? (\n  1809→                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1810→                    {/* Shimmer loading animation */}\n  1811→                    <div className=\"animate-pulse space-y-4\">\n  1812→                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n  1813→                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n  1814→                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n  1815→                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n  1816→                    </div>\n  1817→                  </div>\n  1818→                ) : issues.length > 0 ? (\n  1819→                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n  1820→                    {issues.map((issue, index) => (\n  1821→                      <DrillCard\n  1822→                        key={index}\n  1823→                        issue={issue}\n  1824→                        onTimestampClick={jumpToTimestamp}\n  1825→                        currentTime={currentTime}\n  1826→                      />\n  1827→                    ))}\n  1828→                  </div>\n  1829→                ) : (\n  1830→                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n  1831→                    <p className=\"font-medium\">Great form!</p>\n  1832→                    <p className=\"text-sm\">No major issues detected in this video.</p>\n  1833→                  </div>\n  1834→                )}\n  1835→\n  1836→                {/* Reset button */}\n  1837→                {videoUrl && !analyzing && (\n  1838→                  <button\n  1839→                    onClick={() => {\n  1840→                      setResult(null);\n  1841→                      setVideoUrl(null);\n  1842→                      setVideoFile(null);\n  1843→                      setIssues([]);\n  1844→                      setPoseData([]);\n  1845→                      setFrameAnalyses([]);\n  1846→                      setCurrentTime(0);\n  1847→                      setDuration(0);\n  1848→                      setAutoLevelResult(null);\n  1849→                      setGuidanceKeyframes([]);\n  1850→                      setAnalysisState('IDLE');\n  1851→                    }}\n  1852→                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n  1853→                  >\n  1854→                    Analyze Another Video\n  1855→                  </button>\n  1856→                )}\n  1857→              </div>\n  1858→            </div>\n  1859→          )}\n  1860→\n  1861→          {/* Results Section (legacy format without video) */}\n  1862→          {result && !videoUrl && (\n  1863→            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n  1864→              {/* Left Column - Issues */}\n  1865→              <div className=\"space-y-6\">\n  1866→                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1867→                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n  1868→                  <div className=\"space-y-3\">\n  1869→                    {result.top_issues.map((issue) => (\n  1870→                      <button\n  1871→                        key={issue.id}\n  1872→                        onClick={() => setSelectedIssue(issue)}\n  1873→                        className={`w-full text-left p-4 rounded-lg border transition ${\n  1874→                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n  1875→                        } ${getSeverityColor(issue.severity)}`}\n  1876→                      >\n  1877→                        <div className=\"flex items-center justify-between mb-1\">\n  1878→                          <span className=\"font-medium\">{issue.title}</span>\n  1879→                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n  1880→                        </div>\n  1881→                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n  1882→                      </button>\n  1883→                    ))}\n  1884→                  </div>\n  1885→                </div>\n  1886→\n  1887→                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1888→                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n  1889→                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n  1890→                </div>\n  1891→              </div>\n  1892→\n  1893→              {/* Right Column - Drills */}\n  1894→              <div className=\"space-y-6\">\n  1895→                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1896→                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n  1897→                  <div className=\"space-y-3\">\n  1898→                    {result.drills.map((drill) => (\n  1899→                      <button\n  1900→                        key={drill.id}\n  1901→                        onClick={() => setSelectedDrill(drill)}\n  1902→                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n  1903→                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n  1904→                        }`}\n  1905→                      >\n  1906→                        <div className=\"flex items-center justify-between mb-1\">\n  1907→                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n  1908→                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n  1909→                        </div>\n  1910→                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n  1911→                      </button>\n  1912→                    ))}\n  1913→                  </div>\n  1914→                </div>\n  1915→\n  1916→                {selectedDrill && (\n  1917→                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n  1918→                    <div className=\"flex items-center justify-between mb-4\">\n  1919→                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n  1920→                      <Link\n  1921→                        href={`/practice?drill=${selectedDrill.id}`}\n  1922→                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n  1923→                      >\n  1924→                        Let&apos;s Practice\n  1925→                      </Link>\n  1926→                    </div>\n  1927→                    <div className=\"space-y-3\">\n  1928→                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n  1929→                      <div>\n  1930→                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n  1931→                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n  1932→                          {selectedDrill.instructions.map((instruction, i) => (\n  1933→                            <li key={i}>{instruction}</li>\n  1934→                          ))}\n  1935→                        </ol>\n  1936→                      </div>\n  1937→                    </div>\n  1938→                  </div>\n  1939→                )}\n  1940→\n  1941→                <button\n  1942→                  onClick={() => {\n  1943→                    setResult(null);\n  1944→                    setSelectedIssue(null);\n  1945→                    setSelectedDrill(null);\n  1946→                    setVideoUrl(null);\n  1947→                    setPoseData([]);\n  1948→                    setIssues([]);\n  1949→                    setAutoLevelResult(null);\n  1950→                    setGuidanceKeyframes([]);\n  1951→                    setAnalysisState('IDLE');\n  1952→                  }}\n  1953→                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n  1954→                >\n  1955→                  Analyze Another Video\n  1956→                </button>\n  1957→              </div>\n  1958→            </div>\n  1959→          )}\n  1960→        </div>\n  1961→      </main>\n  1962→\n  1963→      {/* Player Selection Modal */}\n  1964→      <PlayerSelectionModal\n  1965→        isOpen={showPlayerSelection}\n  1966→        onClose={() => {\n  1967→          setShowPlayerSelection(false);\n  1968→          setAnalyzing(false);\n  1969→          setVideoUrl(null);\n  1970→          setVideoFile(null);\n  1971→          setAnalysisState('IDLE');\n  1972→        }}\n  1973→        onConfirm={handlePlayerSelectionConfirm}\n  1974→        tracks={detectedTracks}\n  1975→        detectedFormat={detectedMatchFormat}\n  1976→      />\n  1977→    </div>\n  1978→  );\n  1979→}\n  1980→\n  1981→function AnalyticsLoading() {\n  1982→  return (\n  1983→    <div className=\"min-h-screen bg-gray-50\">\n  1984→      <DashboardNav />\n  1985→      <main className=\"ml-64 p-8\">\n  1986→        <div className=\"max-w-7xl mx-auto\">\n  1987→          <div className=\"animate-pulse\">\n  1988→            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n  1989→            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n  1990→            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n  1991→          </div>\n  1992→        </div>\n  1993→      </main>\n  1994→    </div>\n  1995→  );\n  1996→}\n  1997→\n  1998→export default function AnalyticsPage() {\n  1999→  return (\n  2000→    <Suspense fallback={<AnalyticsLoading />}>\n  2001→      <AnalyticsContent />\n  2002→    </Suspense>\n  2003→  );\n  2004→}\n  2005→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"fe26b27e-07f6-403a-aadd-a5002f98d248","timestamp":"2026-01-28T05:07:31.665Z","toolUseResult":{"type":"text","file":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","content":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // PHASE 3: Auto-detect skill level\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    setAutoLevelResult(levelResult);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n    const avgScore = totalFrames > 0\n      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n      : 0;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","numLines":2005,"startLine":1,"totalLines":2005}},"sourceToolAssistantUUID":"ddcd379d-043e-4840-bd2b-09de31cf9c9b"}
{"parentUuid":"fe26b27e-07f6-403a-aadd-a5002f98d248","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01PiJSzHVKSnnPaaK8R4woua","toolUseID":"toolu_01PiJSzHVKSnnPaaK8R4woua","timestamp":"2026-01-28T05:07:31.671Z","uuid":"89ba5def-88ca-45ca-b9c9-3785ea7aa4d4"}
{"parentUuid":"89ba5def-88ca-45ca-b9c9-3785ea7aa4d4","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01DtzmWNCLCDCxRYjtZPqwVC","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a complete understanding of the analytics page. Let me start implementing the three features. I'll begin with:\n\n## PHASE 2 - BUILDER\n\n### Task Sequence:\n\n1. **Database Migration** - Add new fields for skill_score, confidence, ghost data, and mistake events\n2. **Feature 3** - Auto Skill Score from pose metrics (this affects backend and needs to be done first)\n3. **Feature 1** - Ghost Rival Overlay (depends on pose data being ready)\n4. **Feature 2** - Mistake Timeline + FixIt Cards (depends on issues with timestamps)\n\nLet me start implementing:","signature":"EtEFCkYICxgCKkBeaV3xQpc8IiRklQeI/726GN06wy3N7VrTYxX9ERlsUcQIOPYe7E+wV9D9lctkEu4C5Ry1wBl+rQsMDXKdR5L2EgxWFSOWSRifGr1j48UaDN6+r5gSKLjkxx24iyIwdu2NH+8/giZ84+QoL79/XusAPbwqLEInUmdtQk7nBQXBUudAn383+zfElE5mNu++KrgElSCI5rhf87eQl4cwgRPIWYP+bCJgA0FL1VHt65IQGHKywblOEQJBS9cxx5G1mhkp5fqazW36+HG6sOrK0Lq6klqM8MyVygii1eZ/BczfVQbDWdkVekWS662EjGncW1GJZFGCafuCxBEFVuLK1wDMbIin6/sIFYQAi7IS/1iITcsQ9N6fQyy8efMdEJ6GofLkp4RC4Lo/Ri0ku0TuAfOBP4f+CusxisANyWovISqLuiH7r82iJwBbF48d/BOILZxzb61UnnKvS1m/Tfo2mmXlnP8E6e4QZ/GJvi9pfJfrxgELnkDZrWbeRZWUD0iVTZx+gbIZXloZ2QoALJdV7+hmMR6M6iNSFaYkJhakGPDXI1dx4+vi0FfPuMK/2Xy6OoKfr4OG0vFBzgWu4LlfIEq2UbYhkuekIdxpG23mQC3AnZ7U/RHnhaxLiUfJKgySmTr1ihzNKe1jrZixwbD5J3FsJvNsKUavEM+wcQ7kXkfU9wg7C/CNfKdYp6fTLky7Vqqta2+fDWhIKjKncUp7mm/i0W3VjMxbcW0IQbrOAhQXGCu11Cd8gqpqSOh6G+B4SEo5ayAMPTm1G9lPr1V2A52ijTnKfQV+5QXTWmGrlEiIhgrM0TgpUl7rCtZX4m+G+0VHgCPQZmukXfJQZlykegtcAVOU41CYlIefVHojnP7i7GVBjMTUNdzD4oFAQOAJV6qiAAtp77FRTctyByVXx2OAqYbC31mBGY/3/T3ItTeCntmZjj+GVJ4b6BgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":29632,"cache_read_input_tokens":94078,"cache_creation":{"ephemeral_5m_input_tokens":29632,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCM4Coe5VuGzVvs4xQN","type":"assistant","uuid":"c255e5b4-d9ed-4ad8-8520-4e9f4610b6d8","timestamp":"2026-01-28T05:07:38.048Z"}
{"parentUuid":"c255e5b4-d9ed-4ad8-8520-4e9f4610b6d8","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01DtzmWNCLCDCxRYjtZPqwVC","type":"message","role":"assistant","content":[{"type":"text","text":"Now I have a complete understanding. Let me start **PHASE 2 - BUILDER** by implementing all three features systematically."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":29632,"cache_read_input_tokens":94078,"cache_creation":{"ephemeral_5m_input_tokens":29632,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCM4Coe5VuGzVvs4xQN","type":"assistant","uuid":"465fc7ad-9a21-40db-bebe-282e3ac12d0c","timestamp":"2026-01-28T05:07:38.803Z"}
{"parentUuid":"465fc7ad-9a21-40db-bebe-282e3ac12d0c","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01DtzmWNCLCDCxRYjtZPqwVC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EfvnLJGFD1P8Q7HLnvfXHW","name":"TaskUpdate","input":{"taskId":"4","status":"in_progress"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":29632,"cache_read_input_tokens":94078,"cache_creation":{"ephemeral_5m_input_tokens":29632,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCM4Coe5VuGzVvs4xQN","type":"assistant","uuid":"3c926482-8392-45f4-a346-f8f4f062ece7","timestamp":"2026-01-28T05:07:39.264Z"}
{"parentUuid":"3c926482-8392-45f4-a346-f8f4f062ece7","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EfvnLJGFD1P8Q7HLnvfXHW","type":"tool_result","content":"Updated task #4 status"}]},"uuid":"27e40a70-a55a-4026-bc16-462d79d95a77","timestamp":"2026-01-28T05:07:39.321Z","toolUseResult":{"success":true,"taskId":"4","updatedFields":["status"],"statusChange":{"from":"pending","to":"in_progress"}},"sourceToolAssistantUUID":"3c926482-8392-45f4-a346-f8f4f062ece7"}
{"parentUuid":"27e40a70-a55a-4026-bc16-462d79d95a77","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01HPZ4CicJmvzs4wKcw356Ms","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I'll start by creating the database migration file first, then implement the features. Let me create the migration SQL file with all the new fields needed.","signature":"EsQCCkYICxgCKkAZc1Fd+TFhNv9c3vmjJx3JhOMsRJvNJrvNbKTAVfm0qqWHVyF96FFHIZ5H6ZMhvuW1xcRUHmTee2DdcTK6LHPSEgx3Z6uXrqA13Fxn82QaDNT6J/aBU58L9HdmKCIwetJzPH+o+qwIVPr+e8YPagQeHp2wpXRZTsBXLkkjmHhXjT8T9UutquzKajF3RC8RKqsBAhEtlN3t0HArmTfEdeSCrRFhWDPFH+CmWYAt9rDLdKmuoL8z6TtZjQKn+S/owgMnU8KQNX9Fti9vZncAvoiohBB3BOMXsiHwFjR8ZfczRm2iPI/WQsIpRMOkqQckH0ijnyuVtafdnMGZYV7bG8i9OSS1S1/Jn0egk2u6wm/1FrHZbUgft64BWp24T5tmJYImPwdJ/CewXtXTjzZbd/tvi3i+K0b/lRsXtMFaGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":273,"cache_read_input_tokens":123710,"cache_creation":{"ephemeral_5m_input_tokens":273,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCMcdhEFcwCA6yZYMww","type":"assistant","uuid":"e134b292-fa14-451a-a136-126240774f36","timestamp":"2026-01-28T05:07:42.026Z"}
{"parentUuid":"e134b292-fa14-451a-a136-126240774f36","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01HPZ4CicJmvzs4wKcw356Ms","type":"message","role":"assistant","content":[{"type":"text","text":"Let me start by creating the database migration file with all new fields needed."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":273,"cache_read_input_tokens":123710,"cache_creation":{"ephemeral_5m_input_tokens":273,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCMcdhEFcwCA6yZYMww","type":"assistant","uuid":"1c2b7650-f686-4e53-8d64-8d3b33723a23","timestamp":"2026-01-28T05:07:42.522Z"}
{"parentUuid":"1c2b7650-f686-4e53-8d64-8d3b33723a23","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01HPZ4CicJmvzs4wKcw356Ms","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LPCPhTX87ZBCfFRYpHFRNo","name":"Write","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\supabase-migration-v3-features.sql","content":"-- RallyCoach V3 Features Migration\n-- Adds: Ghost Rival, Mistake Timeline, Auto Skill Score + Confidence\n-- Run these SQL commands in your Supabase SQL Editor\n\n-- ============================================\n-- 1. ADD SKILL SCORE & CONFIDENCE FIELDS TO SESSIONS\n-- ============================================\nALTER TABLE sessions\nADD COLUMN IF NOT EXISTS skill_score NUMERIC DEFAULT 0,\nADD COLUMN IF NOT EXISTS skill_confidence NUMERIC DEFAULT 0,\nADD COLUMN IF NOT EXISTS confidence_reasons JSONB DEFAULT '[]'::jsonb;\n\nCOMMENT ON COLUMN sessions.skill_score IS 'Computed skill score 0-100 from pose metrics (not Gemini)';\nCOMMENT ON COLUMN sessions.skill_confidence IS 'Confidence 0-100 derived from landmark visibility';\nCOMMENT ON COLUMN sessions.confidence_reasons IS 'Array of reasons affecting confidence';\n\n-- ============================================\n-- 2. ADD GHOST/BEST REP FIELDS TO SESSIONS\n-- ============================================\nALTER TABLE sessions\nADD COLUMN IF NOT EXISTS best_rep_window JSONB DEFAULT NULL,\nADD COLUMN IF NOT EXISTS ghost_pose_sequence JSONB DEFAULT NULL;\n\nCOMMENT ON COLUMN sessions.best_rep_window IS 'Best rep window: {startTime, endTime, score, shotType}';\nCOMMENT ON COLUMN sessions.ghost_pose_sequence IS 'Downsampled pose frames for ghost overlay (15fps)';\n\n-- ============================================\n-- 3. ENHANCE ISSUES TABLE FOR MISTAKE TIMELINE\n-- ============================================\n-- Add more detailed mistake event fields\nALTER TABLE issues\nADD COLUMN IF NOT EXISTS start_time_sec NUMERIC DEFAULT 0,\nADD COLUMN IF NOT EXISTS end_time_sec NUMERIC DEFAULT 0,\nADD COLUMN IF NOT EXISTS confidence NUMERIC DEFAULT 0,\nADD COLUMN IF NOT EXISTS affected_joints JSONB DEFAULT '[]'::jsonb,\nADD COLUMN IF NOT EXISTS fix_keyframes JSONB DEFAULT NULL;\n\nCOMMENT ON COLUMN issues.start_time_sec IS 'Start time of mistake segment in seconds';\nCOMMENT ON COLUMN issues.end_time_sec IS 'End time of mistake segment in seconds';\nCOMMENT ON COLUMN issues.confidence IS 'Confidence of detection from visibility (0-1)';\nCOMMENT ON COLUMN issues.affected_joints IS 'Array of landmark indices affected by this issue';\nCOMMENT ON COLUMN issues.fix_keyframes IS 'Keyframes for animated fix-it card';\n\n-- ============================================\n-- 4. CREATE MISTAKE_EVENTS TABLE (Granular Timeline)\n-- ============================================\n-- More granular mistake events for timeline segments\nCREATE TABLE IF NOT EXISTS mistake_events (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,\n    issue_id UUID REFERENCES issues(id) ON DELETE CASCADE,\n    start_time_sec NUMERIC NOT NULL,\n    end_time_sec NUMERIC NOT NULL,\n    severity NUMERIC DEFAULT 0.5 CHECK (severity >= 0 AND severity <= 1),\n    confidence NUMERIC DEFAULT 0.5 CHECK (confidence >= 0 AND confidence <= 1),\n    joints JSONB DEFAULT '[]'::jsonb,\n    summary_title TEXT,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCOMMENT ON TABLE mistake_events IS 'Granular mistake segments for timeline visualization';\n\n-- ============================================\n-- 5. RLS FOR MISTAKE_EVENTS\n-- ============================================\nALTER TABLE mistake_events ENABLE ROW LEVEL SECURITY;\n\nDROP POLICY IF EXISTS \"Users can view mistake events for their sessions\" ON mistake_events;\nCREATE POLICY \"Users can view mistake events for their sessions\"\n    ON mistake_events FOR SELECT\n    USING (\n        EXISTS (\n            SELECT 1 FROM sessions\n            WHERE sessions.id = mistake_events.session_id\n            AND sessions.user_id = auth.uid()\n        )\n    );\n\nDROP POLICY IF EXISTS \"Users can insert mistake events for their sessions\" ON mistake_events;\nCREATE POLICY \"Users can insert mistake events for their sessions\"\n    ON mistake_events FOR INSERT\n    WITH CHECK (\n        EXISTS (\n            SELECT 1 FROM sessions\n            WHERE sessions.id = mistake_events.session_id\n            AND sessions.user_id = auth.uid()\n        )\n    );\n\nDROP POLICY IF EXISTS \"Service role can insert mistake_events\" ON mistake_events;\nCREATE POLICY \"Service role can insert mistake_events\"\n    ON mistake_events FOR INSERT\n    WITH CHECK (true);\n\n-- ============================================\n-- 6. CREATE INDEXES\n-- ============================================\nCREATE INDEX IF NOT EXISTS idx_mistake_events_session ON mistake_events(session_id);\nCREATE INDEX IF NOT EXISTS idx_mistake_events_time ON mistake_events(start_time_sec, end_time_sec);\nCREATE INDEX IF NOT EXISTS idx_sessions_skill_score ON sessions(skill_score);\n\n-- ============================================\n-- MIGRATION COMPLETE\n-- ============================================\n-- After running this migration:\n-- 1. Frontend will compute skill_score from pose metrics\n-- 2. Ghost overlay uses best_rep_window + ghost_pose_sequence\n-- 3. Mistake timeline uses mistake_events table\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":273,"cache_read_input_tokens":123710,"cache_creation":{"ephemeral_5m_input_tokens":273,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCMcdhEFcwCA6yZYMww","type":"assistant","uuid":"9b09d19a-caa9-4720-8f2f-e0e91d1289f9","timestamp":"2026-01-28T05:07:59.706Z"}
{"type":"file-history-snapshot","messageId":"9b09d19a-caa9-4720-8f2f-e0e91d1289f9","snapshot":{"messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","trackedFileBackups":{"supabase-migration-v3-features.sql":{"backupFileName":null,"version":1,"backupTime":"2026-01-28T05:08:12.613Z"}},"timestamp":"2026-01-28T05:05:21.590Z"},"isSnapshotUpdate":true}
{"parentUuid":"9b09d19a-caa9-4720-8f2f-e0e91d1289f9","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LPCPhTX87ZBCfFRYpHFRNo","type":"tool_result","content":"File created successfully at: C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\supabase-migration-v3-features.sql"}]},"uuid":"83565f5d-ca96-40d3-a220-95eb00fc0112","timestamp":"2026-01-28T05:08:13.623Z","toolUseResult":{"type":"create","filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\supabase-migration-v3-features.sql","content":"-- RallyCoach V3 Features Migration\n-- Adds: Ghost Rival, Mistake Timeline, Auto Skill Score + Confidence\n-- Run these SQL commands in your Supabase SQL Editor\n\n-- ============================================\n-- 1. ADD SKILL SCORE & CONFIDENCE FIELDS TO SESSIONS\n-- ============================================\nALTER TABLE sessions\nADD COLUMN IF NOT EXISTS skill_score NUMERIC DEFAULT 0,\nADD COLUMN IF NOT EXISTS skill_confidence NUMERIC DEFAULT 0,\nADD COLUMN IF NOT EXISTS confidence_reasons JSONB DEFAULT '[]'::jsonb;\n\nCOMMENT ON COLUMN sessions.skill_score IS 'Computed skill score 0-100 from pose metrics (not Gemini)';\nCOMMENT ON COLUMN sessions.skill_confidence IS 'Confidence 0-100 derived from landmark visibility';\nCOMMENT ON COLUMN sessions.confidence_reasons IS 'Array of reasons affecting confidence';\n\n-- ============================================\n-- 2. ADD GHOST/BEST REP FIELDS TO SESSIONS\n-- ============================================\nALTER TABLE sessions\nADD COLUMN IF NOT EXISTS best_rep_window JSONB DEFAULT NULL,\nADD COLUMN IF NOT EXISTS ghost_pose_sequence JSONB DEFAULT NULL;\n\nCOMMENT ON COLUMN sessions.best_rep_window IS 'Best rep window: {startTime, endTime, score, shotType}';\nCOMMENT ON COLUMN sessions.ghost_pose_sequence IS 'Downsampled pose frames for ghost overlay (15fps)';\n\n-- ============================================\n-- 3. ENHANCE ISSUES TABLE FOR MISTAKE TIMELINE\n-- ============================================\n-- Add more detailed mistake event fields\nALTER TABLE issues\nADD COLUMN IF NOT EXISTS start_time_sec NUMERIC DEFAULT 0,\nADD COLUMN IF NOT EXISTS end_time_sec NUMERIC DEFAULT 0,\nADD COLUMN IF NOT EXISTS confidence NUMERIC DEFAULT 0,\nADD COLUMN IF NOT EXISTS affected_joints JSONB DEFAULT '[]'::jsonb,\nADD COLUMN IF NOT EXISTS fix_keyframes JSONB DEFAULT NULL;\n\nCOMMENT ON COLUMN issues.start_time_sec IS 'Start time of mistake segment in seconds';\nCOMMENT ON COLUMN issues.end_time_sec IS 'End time of mistake segment in seconds';\nCOMMENT ON COLUMN issues.confidence IS 'Confidence of detection from visibility (0-1)';\nCOMMENT ON COLUMN issues.affected_joints IS 'Array of landmark indices affected by this issue';\nCOMMENT ON COLUMN issues.fix_keyframes IS 'Keyframes for animated fix-it card';\n\n-- ============================================\n-- 4. CREATE MISTAKE_EVENTS TABLE (Granular Timeline)\n-- ============================================\n-- More granular mistake events for timeline segments\nCREATE TABLE IF NOT EXISTS mistake_events (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,\n    issue_id UUID REFERENCES issues(id) ON DELETE CASCADE,\n    start_time_sec NUMERIC NOT NULL,\n    end_time_sec NUMERIC NOT NULL,\n    severity NUMERIC DEFAULT 0.5 CHECK (severity >= 0 AND severity <= 1),\n    confidence NUMERIC DEFAULT 0.5 CHECK (confidence >= 0 AND confidence <= 1),\n    joints JSONB DEFAULT '[]'::jsonb,\n    summary_title TEXT,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCOMMENT ON TABLE mistake_events IS 'Granular mistake segments for timeline visualization';\n\n-- ============================================\n-- 5. RLS FOR MISTAKE_EVENTS\n-- ============================================\nALTER TABLE mistake_events ENABLE ROW LEVEL SECURITY;\n\nDROP POLICY IF EXISTS \"Users can view mistake events for their sessions\" ON mistake_events;\nCREATE POLICY \"Users can view mistake events for their sessions\"\n    ON mistake_events FOR SELECT\n    USING (\n        EXISTS (\n            SELECT 1 FROM sessions\n            WHERE sessions.id = mistake_events.session_id\n            AND sessions.user_id = auth.uid()\n        )\n    );\n\nDROP POLICY IF EXISTS \"Users can insert mistake events for their sessions\" ON mistake_events;\nCREATE POLICY \"Users can insert mistake events for their sessions\"\n    ON mistake_events FOR INSERT\n    WITH CHECK (\n        EXISTS (\n            SELECT 1 FROM sessions\n            WHERE sessions.id = mistake_events.session_id\n            AND sessions.user_id = auth.uid()\n        )\n    );\n\nDROP POLICY IF EXISTS \"Service role can insert mistake_events\" ON mistake_events;\nCREATE POLICY \"Service role can insert mistake_events\"\n    ON mistake_events FOR INSERT\n    WITH CHECK (true);\n\n-- ============================================\n-- 6. CREATE INDEXES\n-- ============================================\nCREATE INDEX IF NOT EXISTS idx_mistake_events_session ON mistake_events(session_id);\nCREATE INDEX IF NOT EXISTS idx_mistake_events_time ON mistake_events(start_time_sec, end_time_sec);\nCREATE INDEX IF NOT EXISTS idx_sessions_skill_score ON sessions(skill_score);\n\n-- ============================================\n-- MIGRATION COMPLETE\n-- ============================================\n-- After running this migration:\n-- 1. Frontend will compute skill_score from pose metrics\n-- 2. Ghost overlay uses best_rep_window + ghost_pose_sequence\n-- 3. Mistake timeline uses mistake_events table\n","structuredPatch":[],"originalFile":null},"sourceToolAssistantUUID":"9b09d19a-caa9-4720-8f2f-e0e91d1289f9"}
{"parentUuid":"83565f5d-ca96-40d3-a220-95eb00fc0112","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Tn3Vk1hDqVM3KsVj2pNK3t","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Good, now let me update the types file to include the new types for:1. Skill scoring with confidence\n2. Ghost overlay data\n3. Mistake timeline events\n\nThen I'll implement the actual features in the following order:\n1. Update scoring-rules.ts with proper skill computation from pose metrics\n2. Create new components: MistakeTimeline.tsx, FixItCard.tsx, SkillMeter.tsx, GhostOverlay.tsx\n3. Update the analytics page.tsx to use the new components","signature":"EuEECkYICxgCKkBy5JfR+JXQ291k12doCJW5E+zoXYzxT7lNJndkCKRP+6yAI5nVcryTP4QYYCsgbhKkyULZsxZq9+pdAXqm4JLJEgxv8wyAVhv/Ap5ce0IaDBLz9+3PGArGIX+U0CIwsqBCDNHWW344DyJ0RZRhzsYaly29t04ORO8P0Sw6y3fYg0axqyWIr2MO6QVB86GwKsgDew/izWWJZsLdRD2odKNN/zCSv6AGm84Ucu43lKc4Sq6m1H6ViN07ZZ9V139oI+zVWQ00iDvvGhMrCAo4BjW27DJFFj5mdx4g3TktLynHOYvZwbzB0/TKpiWt17ayyHiMv8BxiND+8AXPS5Tz9SBMksAMb4jj1GaA3yXZQF8Ra9f6DEVfILDf9Tq46Fv+3xiK26nUFZl3chSreZkh5BjBTZy81J73IGEOlVO1+b0cfuKvgjpi/4zLLy44s3x7pEeGAvCusW2QLrbT3g5nDwppuyZjrodC7JlR9kSqx4l+DAWptZoJjdlCCRH4CTROCettN53iuKi7yhJxUTVkSOQjyu9W0i0+Un8+UyZD6n5D21Ff+9atTwhf6Zt0aW8Wl+51+b3I10cJgJMGKumK9PdsauSRvDo6SBV7Yb1jWef1lO5RsfSZvZ3KvVYM864LDJdW8g1nyW+vqcrXdcwa1lFMl5jHUrg1rTmBlnvKlpoTqAWOQJROe25Z7x3bN5fNRjEmrUJctoTe3DrMuD5L0g0wqID+G2UJqu1Tqxevy3WIb88QlcNvLalrFdEx1IWG3spJgXrElIoS33qMO1Fv8YW7gaS9Aw85eswmGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1446,"cache_read_input_tokens":123983,"cache_creation":{"ephemeral_5m_input_tokens":1446,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCQ9j2DxU9EbBNFz7nG","type":"assistant","uuid":"ddd59650-2322-49b9-a728-d83eefcda00a","timestamp":"2026-01-28T05:08:18.160Z"}
{"parentUuid":"ddd59650-2322-49b9-a728-d83eefcda00a","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Tn3Vk1hDqVM3KsVj2pNK3t","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me update the types file with new interfaces for all three features."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1446,"cache_read_input_tokens":123983,"cache_creation":{"ephemeral_5m_input_tokens":1446,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCQ9j2DxU9EbBNFz7nG","type":"assistant","uuid":"73f5d471-5ac0-4374-8616-21e3f7ddcaf6","timestamp":"2026-01-28T05:08:18.692Z"}
{"parentUuid":"73f5d471-5ac0-4374-8616-21e3f7ddcaf6","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Tn3Vk1hDqVM3KsVj2pNK3t","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018jkn1M5wyRD1bTvqhD66fq","name":"TaskUpdate","input":{"taskId":"4","status":"completed"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1446,"cache_read_input_tokens":123983,"cache_creation":{"ephemeral_5m_input_tokens":1446,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCQ9j2DxU9EbBNFz7nG","type":"assistant","uuid":"06d65dee-d453-484e-b747-80cd5dbc72d7","timestamp":"2026-01-28T05:08:19.072Z"}
{"parentUuid":"06d65dee-d453-484e-b747-80cd5dbc72d7","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Tn3Vk1hDqVM3KsVj2pNK3t","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CnB9f2Sqfv5DuGoB3UWBVK","name":"TaskUpdate","input":{"taskId":"3","status":"in_progress"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1446,"cache_read_input_tokens":123983,"cache_creation":{"ephemeral_5m_input_tokens":1446,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCQ9j2DxU9EbBNFz7nG","type":"assistant","uuid":"4b161270-a975-4721-97aa-467b27fb74a2","timestamp":"2026-01-28T05:08:19.416Z"}
{"parentUuid":"06d65dee-d453-484e-b747-80cd5dbc72d7","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018jkn1M5wyRD1bTvqhD66fq","type":"tool_result","content":"Updated task #4 status"}]},"uuid":"ec98170b-891c-480f-9bba-6783f504e569","timestamp":"2026-01-28T05:08:19.464Z","toolUseResult":{"success":true,"taskId":"4","updatedFields":["status"],"statusChange":{"from":"in_progress","to":"completed"}},"sourceToolAssistantUUID":"06d65dee-d453-484e-b747-80cd5dbc72d7"}
{"parentUuid":"4b161270-a975-4721-97aa-467b27fb74a2","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CnB9f2Sqfv5DuGoB3UWBVK","type":"tool_result","content":"Updated task #3 status"}]},"uuid":"6c8fe40b-e67d-48c7-a978-12f761b544a9","timestamp":"2026-01-28T05:08:19.464Z","toolUseResult":{"success":true,"taskId":"3","updatedFields":["status"],"statusChange":{"from":"pending","to":"in_progress"}},"sourceToolAssistantUUID":"4b161270-a975-4721-97aa-467b27fb74a2"}
{"parentUuid":"6c8fe40b-e67d-48c7-a978-12f761b544a9","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01M7EUZFEJYCT4vKMaD6HseN","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the types file with new interfaces and then implement the scoring logic.","signature":"EoICCkYICxgCKkBtZde6KEzCKhq/g9BpSlkFI1ETIzRke2A21yaeCoTptGQZEk1GF5KOpOfqjuIhUkP1RE4nY9jPots/r4Bx3uXREgy+nbHh7QOBxyGD62IaDEV19YLk472V1/59hCIwPwkQBsuUXjdIPEmnui3IEJg2/0JH7ozTnPaGleRw1Jbo6t/zzf0JNFYKyEvFQ22cKmpzHRGCxanUKK/TQCDbVc4C88NYdYp6l8QG+0qYQ5q2HEDlCj8tHjncs4SOyx7IAwVMyOzVuGBDzuWqRGlHwTM5N040yRCLijIe7PAWg3udoRbPHGFj41fGrsujSI4Kvl0jts8tAddtrjFBGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":344,"cache_read_input_tokens":125429,"cache_creation":{"ephemeral_5m_input_tokens":344,"ephemeral_1h_input_tokens":0},"output_tokens":8,"service_tier":"standard"}},"requestId":"req_011CXZCQaZkyeLjtDqXgaSvN","type":"assistant","uuid":"a499119e-94fc-45f3-bd86-33e6ac30f859","timestamp":"2026-01-28T05:08:21.989Z"}
{"parentUuid":"a499119e-94fc-45f3-bd86-33e6ac30f859","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01M7EUZFEJYCT4vKMaD6HseN","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01StwhVbmqKbosnRznyHCdh3","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\types.ts","old_string":"export interface DrillPhase {\n  name: string;\n  keyframes: SkeletonKeyframe[];\n  duration_ms: number;\n}","new_string":"export interface DrillPhase {\n  name: string;\n  keyframes: SkeletonKeyframe[];\n  duration_ms: number;\n}\n\n// ============================================\n// V4 Feature Types: Ghost, Timeline, Skill Score\n// ============================================\n\n// Auto Skill Score (computed from pose metrics, not Gemini)\nexport interface ComputedSkillScore {\n  skillScore: number; // 0-100\n  levelLabel: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidencePercent: number; // 0-100, derived from landmark visibility\n  confidenceReasons: string[]; // Reasons if confidence is low\n  metrics: {\n    consistencyScore: number; // How stable form is across frames\n    recoverySpeed: number; // Speed of recovery after lunges\n    formQuality: number; // Average form score\n    visibilityAvg: number; // Average landmark visibility\n    dropoutRate: number; // % frames with missing/low visibility\n  };\n}\n\n// Ghost Rival Overlay\nexport interface GhostRivalData {\n  source: 'my-best-rep' | 'pro-template';\n  enabled: boolean;\n  poseSequence: GhostPoseFrame[];\n  bestRepWindow?: {\n    startTime: number;\n    endTime: number;\n    score: number;\n    shotType?: string;\n  };\n}\n\nexport interface GhostPoseFrame {\n  timestamp: number; // Absolute time in seconds\n  normalizedTime?: number; // 0-1 within window\n  landmarks: PoseLandmark[];\n}\n\n// Mistake Timeline\nexport interface MistakeEvent {\n  id: string;\n  type: string; // e.g., 'OVERHEAD_CONTACT_LOW', 'LATE_SPLIT_STEP', 'POOR_LUNGE_RECOVERY'\n  startTimeSec: number;\n  endTimeSec: number;\n  severity: number; // 0-1\n  confidence: number; // 0-1, derived from pose visibility\n  joints: number[]; // Landmark indices affected\n  summaryTitle: string;\n  description?: string;\n  fixKeyframes?: FixKeyframe[];\n}\n\nexport interface FixKeyframe {\n  phase: 'setup' | 'contact' | 'recover';\n  landmarks: PoseLandmark[];\n  label: string;\n  correction?: string;\n}\n\n// Timeline segment for rendering\nexport interface TimelineSegment {\n  id: string;\n  startPercent: number; // 0-100\n  widthPercent: number; // Width as percentage of timeline\n  color: string; // Severity color\n  event: MistakeEvent;\n}\n\n// Confidence calculation from visibility\nexport interface VisibilityMetrics {\n  avgVisibility: number; // 0-1, mean across key joints\n  validFrameRatio: number; // % frames above threshold\n  dropoutRate: number; // % frames with missing landmarks\n  keyJointVisibility: Record<string, number>; // Per-joint visibility\n}"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":344,"cache_read_input_tokens":125429,"cache_creation":{"ephemeral_5m_input_tokens":344,"ephemeral_1h_input_tokens":0},"output_tokens":8,"service_tier":"standard"}},"requestId":"req_011CXZCQaZkyeLjtDqXgaSvN","type":"assistant","uuid":"b73e196c-29ff-45a3-ac11-56d45550c89f","timestamp":"2026-01-28T05:08:34.222Z"}
{"type":"file-history-snapshot","messageId":"b73e196c-29ff-45a3-ac11-56d45550c89f","snapshot":{"messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","trackedFileBackups":{"supabase-migration-v3-features.sql":{"backupFileName":null,"version":1,"backupTime":"2026-01-28T05:08:12.613Z"},"rallycoach\\src\\lib\\types.ts":{"backupFileName":"1048a9baa3a842fc@v1","version":1,"backupTime":"2026-01-28T05:08:34.814Z"}},"timestamp":"2026-01-28T05:05:21.590Z"},"isSnapshotUpdate":true}
{"parentUuid":"b73e196c-29ff-45a3-ac11-56d45550c89f","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01StwhVbmqKbosnRznyHCdh3","type":"tool_result","content":"The file C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\types.ts has been updated successfully."}]},"uuid":"3233fa20-9852-4875-b12d-4ada569ad511","timestamp":"2026-01-28T05:08:34.810Z","toolUseResult":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\types.ts","oldString":"export interface DrillPhase {\n  name: string;\n  keyframes: SkeletonKeyframe[];\n  duration_ms: number;\n}","newString":"export interface DrillPhase {\n  name: string;\n  keyframes: SkeletonKeyframe[];\n  duration_ms: number;\n}\n\n// ============================================\n// V4 Feature Types: Ghost, Timeline, Skill Score\n// ============================================\n\n// Auto Skill Score (computed from pose metrics, not Gemini)\nexport interface ComputedSkillScore {\n  skillScore: number; // 0-100\n  levelLabel: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidencePercent: number; // 0-100, derived from landmark visibility\n  confidenceReasons: string[]; // Reasons if confidence is low\n  metrics: {\n    consistencyScore: number; // How stable form is across frames\n    recoverySpeed: number; // Speed of recovery after lunges\n    formQuality: number; // Average form score\n    visibilityAvg: number; // Average landmark visibility\n    dropoutRate: number; // % frames with missing/low visibility\n  };\n}\n\n// Ghost Rival Overlay\nexport interface GhostRivalData {\n  source: 'my-best-rep' | 'pro-template';\n  enabled: boolean;\n  poseSequence: GhostPoseFrame[];\n  bestRepWindow?: {\n    startTime: number;\n    endTime: number;\n    score: number;\n    shotType?: string;\n  };\n}\n\nexport interface GhostPoseFrame {\n  timestamp: number; // Absolute time in seconds\n  normalizedTime?: number; // 0-1 within window\n  landmarks: PoseLandmark[];\n}\n\n// Mistake Timeline\nexport interface MistakeEvent {\n  id: string;\n  type: string; // e.g., 'OVERHEAD_CONTACT_LOW', 'LATE_SPLIT_STEP', 'POOR_LUNGE_RECOVERY'\n  startTimeSec: number;\n  endTimeSec: number;\n  severity: number; // 0-1\n  confidence: number; // 0-1, derived from pose visibility\n  joints: number[]; // Landmark indices affected\n  summaryTitle: string;\n  description?: string;\n  fixKeyframes?: FixKeyframe[];\n}\n\nexport interface FixKeyframe {\n  phase: 'setup' | 'contact' | 'recover';\n  landmarks: PoseLandmark[];\n  label: string;\n  correction?: string;\n}\n\n// Timeline segment for rendering\nexport interface TimelineSegment {\n  id: string;\n  startPercent: number; // 0-100\n  widthPercent: number; // Width as percentage of timeline\n  color: string; // Severity color\n  event: MistakeEvent;\n}\n\n// Confidence calculation from visibility\nexport interface VisibilityMetrics {\n  avgVisibility: number; // 0-1, mean across key joints\n  validFrameRatio: number; // % frames above threshold\n  dropoutRate: number; // % frames with missing landmarks\n  keyJointVisibility: Record<string, number>; // Per-joint visibility\n}","originalFile":"// Database types - supports both old and new schema\nexport interface Session {\n  id: string;\n  user_id: string;\n  // Old schema\n  mode?: string;\n  started_at?: string;\n  ended_at?: string | null;\n  score_summary?: ScoreSummary;\n  // New schema (from supabase-migration-v2)\n  type?: 'analytics' | 'practice' | 'strategy';\n  created_at: string;\n  video_path?: string;\n  video_url?: string;\n  filename?: string;\n  duration_seconds?: number;\n  overall_score?: number;\n  summary?: ScoreSummary;\n  pose_data?: any[];\n  frame_count?: number;\n  // v3 enhanced schema\n  status?: 'processing' | 'ready' | 'error';\n  match_format?: 'singles' | 'doubles';\n  event_type?: 'MS' | 'WS' | 'MD' | 'WD' | 'XD';\n  selected_tracks?: number[];\n  summary_score?: number;\n  skill_level?: 'beginner' | 'intermediate' | 'advanced';\n  rules_version?: string;\n  tracks_data?: PlayerTrackData[];\n  // Practice recording fields (v4)\n  practice_video_path?: string;\n  practice_video_mime?: string;\n  practice_video_duration_sec?: number;\n  practice_video_size_bytes?: number;\n}\n\nexport interface ScoreSummary {\n  green_count?: number;\n  green_frames?: number;\n  red_count?: number;\n  red_frames?: number;\n  total_frames: number;\n  average_score?: number;\n  green_ratio?: number;\n  drill_id?: string;\n  drill_type?: string;\n  metrics_avg?: PoseMetrics;\n  shot_count?: number;\n  error_count?: number;\n  feedback?: any;\n}\n\nexport interface AnalysisResult {\n  id: string;\n  user_id: string;\n  video_path: string;\n  result_json: AnalysisResultJson | null;\n  status: 'processing' | 'completed' | 'error';\n  created_at: string;\n}\n\nexport interface AnalysisResultJson {\n  top_issues: Issue[];\n  drills: Drill[];\n  technique_summary: string;\n  strategy_summary: string;\n  training_plan: TrainingPlanItem[];\n  drill_visuals?: string[]; // URLs to generated drill images\n}\n\nexport interface Issue {\n  id: string;\n  title: string;\n  severity: 'high' | 'medium' | 'low';\n  description: string;\n  affected_metrics: string[];\n}\n\nexport interface Drill {\n  id: string;\n  name: string;\n  description: string;\n  duration_minutes: number;\n  target_metrics: string[];\n  instructions: string[];\n}\n\nexport interface TrainingPlanItem {\n  day: number;\n  focus: string;\n  drills: string[];\n  duration_minutes: number;\n}\n\nexport interface RacketFavorite {\n  id: string;\n  user_id: string;\n  racket_id: string;\n  created_at: string;\n}\n\n// Pose estimation types\nexport interface PoseMetrics {\n  elbow_angle: number;\n  knee_angle: number;\n  stance_width_norm: number;\n  shoulder_hip_rotation_proxy: number;\n  timestamp?: number;\n}\n\nexport interface PoseLandmark {\n  x: number;\n  y: number;\n  z: number;\n  visibility: number;\n}\n\n// API types\nexport interface TickRequest {\n  metrics_snapshot: PoseMetrics;\n  drill_id?: string;\n  session_id?: string;\n}\n\nexport interface TickResponse {\n  cue: string;\n  focus_metric: string;\n  green_thresholds: {\n    [key: string]: { min: number; max: number };\n  };\n  is_green: boolean;\n}\n\nexport interface RacketRecommendRequest {\n  level: 'beginner' | 'intermediate' | 'advanced';\n  weaknesses: string[];\n  style_pref?: 'power' | 'control' | 'all-round';\n}\n\nexport interface Racket {\n  id: string;\n  name: string;\n  brand: string;\n  price_band: 'budget' | 'mid-range' | 'premium';\n  price_range: string;\n  play_style: string[];\n  skill_level: string[];\n  weight: string;\n  balance: string;\n  flexibility: string;\n  description: string;\n  image_url: string;\n  ebay_search_query: string;\n}\n\nexport interface RacketRecommendation extends Racket {\n  match_score: number;\n  match_reason: string;\n}\n\n// Chart data types\nexport interface ChartDataPoint {\n  date: string;\n  score: number;\n  greenRatio?: number;\n  checkIns?: number;\n}\n\n// User profile\nexport interface UserProfile {\n  id: string;\n  email: string;\n  created_at: string;\n}\n\n// ============================================\n// V3 Enhanced Types\n// ============================================\n\n// Session assets for persistent storage\nexport interface SessionAsset {\n  id: string;\n  session_id: string;\n  kind: 'video' | 'analysis_json' | 'pose_json' | 'keyframe1' | 'keyframe2' | 'keyframe3' | 'trajectory_json' | 'trajectory_video' | 'tracks_thumbnail';\n  storage_path: string;\n  storage_bucket: string;\n  metadata?: Record<string, any>;\n  created_at: string;\n}\n\n// Player track data for multi-person tracking\nexport interface PlayerTrackData {\n  track_id: number;\n  thumbnail_url?: string;\n  bbox_samples: BoundingBoxSample[];\n  side?: 'near' | 'far';\n  is_selected: boolean;\n  confidence_avg: number;\n  frame_count: number;\n}\n\nexport interface BoundingBoxSample {\n  frame: number;\n  x: number;\n  y: number;\n  w: number;\n  h: number;\n  confidence?: number;\n}\n\n// Strategy mode types\nexport interface StrategyResult {\n  id: string;\n  session_id: string;\n  original_trajectory: TrajectoryPoint[];\n  refined_trajectory: TrajectoryPoint[];\n  coaching_points: string[];\n  court_homography?: number[][];\n  shuttle_detections?: ShuttleDetection[];\n  created_at: string;\n}\n\nexport interface TrajectoryPoint {\n  x: number;\n  y: number;\n  timestamp: number;\n  court_x?: number; // Court-mapped x coordinate (0-1)\n  court_y?: number; // Court-mapped y coordinate (0-1)\n}\n\nexport interface ShuttleDetection {\n  frame: number;\n  x: number;\n  y: number;\n  confidence: number;\n}\n\n// Banded scoring types\nexport type ScoreBand = 'green' | 'yellow' | 'red' | 'unknown';\n\nexport interface BandedScore {\n  band: ScoreBand;\n  value: number;\n  confidence: number;\n  feedback?: string;\n}\n\nexport interface ScoringRulesConfig {\n  version: string;\n  skill_bands: {\n    beginner: SkillBandConfig;\n    intermediate: SkillBandConfig;\n    advanced: SkillBandConfig;\n  };\n  confidence_threshold: number;\n  phase_rules: Record<string, PhaseRule>;\n}\n\nexport interface SkillBandConfig {\n  green_tolerance: number; // Percentage wider than ideal\n  yellow_tolerance: number; // Percentage wider than green\n}\n\nexport interface PhaseRule {\n  name: string;\n  applicable_metrics: string[];\n  thresholds: Record<string, { min: number; max: number }>;\n}\n\n// Multi-pose detection result\nexport interface MultiPoseResult {\n  poses: DetectedPose[];\n  timestamp: number;\n}\n\nexport interface DetectedPose {\n  track_id: number;\n  landmarks: PoseLandmark[];\n  bbox: { x: number; y: number; w: number; h: number };\n  confidence: number;\n}\n\n// Event type labels\nexport const EVENT_TYPE_LABELS: Record<string, string> = {\n  MS: \"Men's Singles\",\n  WS: \"Women's Singles\",\n  MD: \"Men's Doubles\",\n  WD: \"Women's Doubles\",\n  XD: 'Mixed Doubles',\n};\n\n// 3D Skeleton animation types\nexport interface SkeletonKeyframe {\n  label: string;\n  landmarks: { x: number; y: number; z: number }[];\n  timestamp: number;\n}\n\nexport interface AnimatedDrill {\n  id: string;\n  name: string;\n  phases: DrillPhase[];\n  loop: boolean;\n  duration_ms: number;\n}\n\nexport interface DrillPhase {\n  name: string;\n  keyframes: SkeletonKeyframe[];\n  duration_ms: number;\n}\n","structuredPatch":[{"oldStart":309,"oldLines":3,"newStart":309,"newLines":79,"lines":["   keyframes: SkeletonKeyframe[];","   duration_ms: number;"," }","+","+// ============================================","+// V4 Feature Types: Ghost, Timeline, Skill Score","+// ============================================","+","+// Auto Skill Score (computed from pose metrics, not Gemini)","+export interface ComputedSkillScore {","+  skillScore: number; // 0-100","+  levelLabel: 'Beginner' | 'Intermediate' | 'Advanced';","+  confidencePercent: number; // 0-100, derived from landmark visibility","+  confidenceReasons: string[]; // Reasons if confidence is low","+  metrics: {","+    consistencyScore: number; // How stable form is across frames","+    recoverySpeed: number; // Speed of recovery after lunges","+    formQuality: number; // Average form score","+    visibilityAvg: number; // Average landmark visibility","+    dropoutRate: number; // % frames with missing/low visibility","+  };","+}","+","+// Ghost Rival Overlay","+export interface GhostRivalData {","+  source: 'my-best-rep' | 'pro-template';","+  enabled: boolean;","+  poseSequence: GhostPoseFrame[];","+  bestRepWindow?: {","+    startTime: number;","+    endTime: number;","+    score: number;","+    shotType?: string;","+  };","+}","+","+export interface GhostPoseFrame {","+  timestamp: number; // Absolute time in seconds","+  normalizedTime?: number; // 0-1 within window","+  landmarks: PoseLandmark[];","+}","+","+// Mistake Timeline","+export interface MistakeEvent {","+  id: string;","+  type: string; // e.g., 'OVERHEAD_CONTACT_LOW', 'LATE_SPLIT_STEP', 'POOR_LUNGE_RECOVERY'","+  startTimeSec: number;","+  endTimeSec: number;","+  severity: number; // 0-1","+  confidence: number; // 0-1, derived from pose visibility","+  joints: number[]; // Landmark indices affected","+  summaryTitle: string;","+  description?: string;","+  fixKeyframes?: FixKeyframe[];","+}","+","+export interface FixKeyframe {","+  phase: 'setup' | 'contact' | 'recover';","+  landmarks: PoseLandmark[];","+  label: string;","+  correction?: string;","+}","+","+// Timeline segment for rendering","+export interface TimelineSegment {","+  id: string;","+  startPercent: number; // 0-100","+  widthPercent: number; // Width as percentage of timeline","+  color: string; // Severity color","+  event: MistakeEvent;","+}","+","+// Confidence calculation from visibility","+export interface VisibilityMetrics {","+  avgVisibility: number; // 0-1, mean across key joints","+  validFrameRatio: number; // % frames above threshold","+  dropoutRate: number; // % frames with missing landmarks","+  keyJointVisibility: Record<string, number>; // Per-joint visibility","+}"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"b73e196c-29ff-45a3-ac11-56d45550c89f"}
{"parentUuid":"3233fa20-9852-4875-b12d-4ada569ad511","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01MzPETQnxjLHvgxQSTbcBqt","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me create the skill scoring module that computes skill score from real pose metrics and confidence from landmark visibility. This is critical - the skill score must NOT come from Gemini alone.","signature":"EvECCkYICxgCKkDSEhHoPa2yS5EAxJBSMIaoKkTSDai6ZWQkbDAsgU1n+BYla0K364vKEccW2Zxd6i6mHTlCAJwHyRlGN+4ubE9MEgyCWNZYnTRjtc3+26QaDJlDXWa1LgPRc8vQ0iIwpAQtXv64ssYL2YTySkDC8JYnH/Tip5j/KEh9oeNjueIJfXlAOPkbONOHnYCsZpmDKtgBfcnpcdU5Jjh7NQohbsGJE3J5rGHYjH5F4pDKn/XPa4ffosqqejEFeuTg73HTPAc7HkcCjcmLaRjnK7xMefyWZVs6dpUmxSrOs3qQ8sdovLJr6Rb4bmIfHEbLBevImC1XTdpvRiGDJwXDt1C5E4gbsLvNDnXLP5rS+foSkJWHlc6yJm0nKPRBzphbRHXW2D5KLGYmKQIzzpD78vu0JkoR2vaYlAc6LPgr3FIB0RyPW7aa52zui9kMBDIR3xpjbVLgJQZvkqSFqsW30bCzhvHU8XkkwwEQnrSPGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":986,"cache_read_input_tokens":125773,"cache_creation":{"ephemeral_5m_input_tokens":986,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXZCRikA4o1cK3oSXciMy","type":"assistant","uuid":"acdd3e67-94ce-4f21-831e-3c25e06871dc","timestamp":"2026-01-28T05:08:38.398Z"}
{"parentUuid":"acdd3e67-94ce-4f21-831e-3c25e06871dc","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01MzPETQnxjLHvgxQSTbcBqt","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me create a new module for computing skill score and confidence from real pose metrics."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":986,"cache_read_input_tokens":125773,"cache_creation":{"ephemeral_5m_input_tokens":986,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXZCRikA4o1cK3oSXciMy","type":"assistant","uuid":"bb8bd52f-19fd-4a63-84eb-2180e0e76873","timestamp":"2026-01-28T05:08:38.785Z"}
{"parentUuid":"bb8bd52f-19fd-4a63-84eb-2180e0e76873","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01MzPETQnxjLHvgxQSTbcBqt","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016fqL8dGQFtA5FET7diN8X1","name":"Write","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\skill-scoring.ts","content":"/**\n * Skill Scoring Module\n *\n * Computes skill score and confidence from REAL pose metrics.\n * This does NOT rely on Gemini for the numeric score.\n *\n * Confidence is derived from:\n * - MediaPipe landmark visibility (0-1 per landmark)\n * - Detection success rate across frames\n * - Dropout frequency (frames with missing landmarks)\n *\n * Skill Score is computed from:\n * - Consistency of key joint angles over shots\n * - Recovery speed after lunges\n * - Stance stability + split-step presence\n * - Overhead sequence quality\n */\n\nimport type {\n  PoseLandmark,\n  PoseMetrics,\n  ComputedSkillScore,\n  VisibilityMetrics,\n  MistakeEvent\n} from './types';\nimport { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n\n// Key joints for confidence calculation (most important for badminton)\nconst KEY_JOINTS = [\n  POSE_LANDMARKS.LEFT_SHOULDER,\n  POSE_LANDMARKS.RIGHT_SHOULDER,\n  POSE_LANDMARKS.LEFT_ELBOW,\n  POSE_LANDMARKS.RIGHT_ELBOW,\n  POSE_LANDMARKS.LEFT_WRIST,\n  POSE_LANDMARKS.RIGHT_WRIST,\n  POSE_LANDMARKS.LEFT_HIP,\n  POSE_LANDMARKS.RIGHT_HIP,\n  POSE_LANDMARKS.LEFT_KNEE,\n  POSE_LANDMARKS.RIGHT_KNEE,\n  POSE_LANDMARKS.LEFT_ANKLE,\n  POSE_LANDMARKS.RIGHT_ANKLE,\n];\n\nconst VISIBILITY_THRESHOLD = 0.5;\nconst MIN_VALID_FRAME_RATIO = 0.7;\n\n/**\n * Compute visibility metrics from pose data\n * This derives confidence from actual MediaPipe visibility values\n */\nexport function computeVisibilityMetrics(\n  poseData: (PoseLandmark[] | null)[]\n): VisibilityMetrics {\n  let totalVisibility = 0;\n  let validFrameCount = 0;\n  let dropoutCount = 0;\n  const jointVisibilitySum: Record<string, number> = {};\n  const jointVisibilityCount: Record<string, number> = {};\n\n  for (const landmarks of poseData) {\n    if (!landmarks || landmarks.length === 0) {\n      dropoutCount++;\n      continue;\n    }\n\n    // Calculate average visibility for key joints in this frame\n    let frameVisibilitySum = 0;\n    let keyJointCount = 0;\n\n    for (const jointIdx of KEY_JOINTS) {\n      const landmark = landmarks[jointIdx];\n      if (landmark) {\n        const visibility = landmark.visibility ?? 0;\n        frameVisibilitySum += visibility;\n        keyJointCount++;\n\n        // Track per-joint visibility\n        const jointName = Object.entries(POSE_LANDMARKS).find(([_, v]) => v === jointIdx)?.[0] || String(jointIdx);\n        jointVisibilitySum[jointName] = (jointVisibilitySum[jointName] || 0) + visibility;\n        jointVisibilityCount[jointName] = (jointVisibilityCount[jointName] || 0) + 1;\n      }\n    }\n\n    if (keyJointCount > 0) {\n      const frameAvgVisibility = frameVisibilitySum / keyJointCount;\n      totalVisibility += frameAvgVisibility;\n\n      if (frameAvgVisibility >= VISIBILITY_THRESHOLD) {\n        validFrameCount++;\n      }\n    } else {\n      dropoutCount++;\n    }\n  }\n\n  const totalFrames = poseData.length;\n  const framesWithPose = totalFrames - dropoutCount;\n\n  // Compute per-joint average visibility\n  const keyJointVisibility: Record<string, number> = {};\n  for (const [joint, sum] of Object.entries(jointVisibilitySum)) {\n    const count = jointVisibilityCount[joint] || 1;\n    keyJointVisibility[joint] = sum / count;\n  }\n\n  return {\n    avgVisibility: framesWithPose > 0 ? totalVisibility / framesWithPose : 0,\n    validFrameRatio: totalFrames > 0 ? validFrameCount / totalFrames : 0,\n    dropoutRate: totalFrames > 0 ? dropoutCount / totalFrames : 1,\n    keyJointVisibility,\n  };\n}\n\n/**\n * Calculate consistency score from pose metrics over time\n * Higher consistency = more stable form across frames\n */\nexport function computeConsistencyScore(\n  metricsHistory: (PoseMetrics | null)[]\n): number {\n  const validMetrics = metricsHistory.filter(m => m !== null) as PoseMetrics[];\n  if (validMetrics.length < 5) return 0.5; // Not enough data\n\n  // Calculate standard deviation for each metric\n  const elbowAngles = validMetrics.map(m => m.elbow_angle);\n  const kneeAngles = validMetrics.map(m => m.knee_angle);\n  const stanceWidths = validMetrics.map(m => m.stance_width_norm);\n\n  const elbowStd = standardDeviation(elbowAngles);\n  const kneeStd = standardDeviation(kneeAngles);\n  const stanceStd = standardDeviation(stanceWidths);\n\n  // Normalize standard deviations (lower is better)\n  // Ideal: elbow std < 15deg, knee std < 20deg, stance std < 0.15\n  const elbowConsistency = Math.max(0, 1 - elbowStd / 30);\n  const kneeConsistency = Math.max(0, 1 - kneeStd / 40);\n  const stanceConsistency = Math.max(0, 1 - stanceStd / 0.3);\n\n  return (elbowConsistency + kneeConsistency + stanceConsistency) / 3;\n}\n\n/**\n * Detect split-step presence from pose data\n * Returns a score 0-1 based on how well split-steps are executed\n */\nexport function detectSplitStepQuality(\n  poseData: (PoseLandmark[] | null)[]\n): number {\n  const validFrames = poseData.filter(p => p !== null) as PoseLandmark[][];\n  if (validFrames.length < 10) return 0.5;\n\n  let splitStepCount = 0;\n  let potentialSplitSteps = 0;\n\n  for (let i = 2; i < validFrames.length - 2; i++) {\n    const prev = validFrames[i - 1];\n    const curr = validFrames[i];\n    const next = validFrames[i + 1];\n\n    // Calculate stance width changes\n    const prevStance = calculateStanceWidth(prev);\n    const currStance = calculateStanceWidth(curr);\n    const nextStance = calculateStanceWidth(next);\n\n    // Split-step: quick widening then movement\n    // Check for rapid stance change\n    if (prevStance > 0 && currStance > 0) {\n      const widthChange = Math.abs(currStance - prevStance) / prevStance;\n      if (widthChange > 0.15) {\n        potentialSplitSteps++;\n        // Good split-step has controlled landing\n        if (nextStance > 0) {\n          const recovery = Math.abs(nextStance - currStance) / currStance;\n          if (recovery < 0.2) {\n            splitStepCount++;\n          }\n        }\n      }\n    }\n  }\n\n  if (potentialSplitSteps === 0) return 0.3; // No movement detected\n  return Math.min(1, splitStepCount / Math.max(1, potentialSplitSteps / 3));\n}\n\n/**\n * Compute recovery speed from lunge positions\n */\nexport function computeRecoverySpeed(\n  poseData: (PoseLandmark[] | null)[]\n): number {\n  const validFrames = poseData.filter(p => p !== null) as PoseLandmark[][];\n  if (validFrames.length < 5) return 0.5;\n\n  const kneeAngles: number[] = [];\n  for (const landmarks of validFrames) {\n    const hip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n    const knee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n    const ankle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n    if (hip && knee && ankle) {\n      kneeAngles.push(calculateAngle(hip, knee, ankle));\n    }\n  }\n\n  if (kneeAngles.length < 5) return 0.5;\n\n  // Find lunge moments (knee angle < 120)\n  const lungeIndices: number[] = [];\n  for (let i = 0; i < kneeAngles.length; i++) {\n    if (kneeAngles[i] < 120) {\n      lungeIndices.push(i);\n    }\n  }\n\n  if (lungeIndices.length === 0) return 0.7; // No deep lunges, decent baseline\n\n  // Calculate recovery time from each lunge\n  let totalRecoveryFrames = 0;\n  let recoveryCount = 0;\n\n  for (const lungeIdx of lungeIndices) {\n    // Find when knee angle returns to > 140\n    for (let j = lungeIdx + 1; j < Math.min(lungeIdx + 20, kneeAngles.length); j++) {\n      if (kneeAngles[j] > 140) {\n        totalRecoveryFrames += (j - lungeIdx);\n        recoveryCount++;\n        break;\n      }\n    }\n  }\n\n  if (recoveryCount === 0) return 0.4; // Slow recovery\n\n  const avgRecoveryFrames = totalRecoveryFrames / recoveryCount;\n  // Ideal recovery: < 5 frames at 10fps = 0.5 seconds\n  return Math.max(0, Math.min(1, 1 - (avgRecoveryFrames - 3) / 15));\n}\n\n/**\n * Compute form quality score from angle analysis\n */\nexport function computeFormQuality(\n  metricsHistory: (PoseMetrics | null)[],\n  poseData: (PoseLandmark[] | null)[]\n): number {\n  const validMetrics = metricsHistory.filter(m => m !== null) as PoseMetrics[];\n  if (validMetrics.length < 3) return 0.5;\n\n  let totalScore = 0;\n  let frameCount = 0;\n\n  for (const metrics of validMetrics) {\n    let frameScore = 0;\n    let checks = 0;\n\n    // Elbow angle check (90-130 ideal for most shots)\n    if (metrics.elbow_angle >= 80 && metrics.elbow_angle <= 140) {\n      frameScore += 1;\n    } else if (metrics.elbow_angle >= 70 && metrics.elbow_angle <= 150) {\n      frameScore += 0.7;\n    } else {\n      frameScore += 0.3;\n    }\n    checks++;\n\n    // Knee angle check (110-160 ideal)\n    if (metrics.knee_angle >= 110 && metrics.knee_angle <= 160) {\n      frameScore += 1;\n    } else if (metrics.knee_angle >= 90 && metrics.knee_angle <= 170) {\n      frameScore += 0.7;\n    } else {\n      frameScore += 0.3;\n    }\n    checks++;\n\n    // Stance width check (0.6-1.5 normalized)\n    if (metrics.stance_width_norm >= 0.6 && metrics.stance_width_norm <= 1.5) {\n      frameScore += 1;\n    } else if (metrics.stance_width_norm >= 0.4 && metrics.stance_width_norm <= 1.8) {\n      frameScore += 0.7;\n    } else {\n      frameScore += 0.3;\n    }\n    checks++;\n\n    totalScore += frameScore / checks;\n    frameCount++;\n  }\n\n  return totalScore / frameCount;\n}\n\n/**\n * Main function: Compute complete skill score from pose data\n */\nexport function computeSkillScore(\n  poseData: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[],\n  issues: MistakeEvent[] = []\n): ComputedSkillScore {\n  // 1. Calculate visibility metrics for confidence\n  const visibility = computeVisibilityMetrics(poseData);\n\n  // 2. Calculate component scores\n  const consistencyScore = computeConsistencyScore(metricsHistory);\n  const recoverySpeed = computeRecoverySpeed(poseData);\n  const formQuality = computeFormQuality(metricsHistory, poseData);\n  const splitStepQuality = detectSplitStepQuality(poseData);\n\n  // 3. Compute weighted skill score (0-100)\n  const rawScore = (\n    consistencyScore * 30 +  // Consistency is important\n    formQuality * 35 +       // Form quality matters most\n    recoverySpeed * 20 +     // Recovery speed\n    splitStepQuality * 15    // Split-step presence\n  );\n\n  // 4. Apply issue penalty\n  const highSeverityIssues = issues.filter(i => i.severity > 0.7).length;\n  const mediumSeverityIssues = issues.filter(i => i.severity > 0.4 && i.severity <= 0.7).length;\n  const issuePenalty = highSeverityIssues * 5 + mediumSeverityIssues * 2;\n\n  const skillScore = Math.max(0, Math.min(100, rawScore - issuePenalty));\n\n  // 5. Determine level label\n  let levelLabel: 'Beginner' | 'Intermediate' | 'Advanced';\n  if (skillScore >= 70) {\n    levelLabel = 'Advanced';\n  } else if (skillScore >= 40) {\n    levelLabel = 'Intermediate';\n  } else {\n    levelLabel = 'Beginner';\n  }\n\n  // 6. Calculate confidence from visibility\n  const confidencePercent = Math.round(\n    (visibility.avgVisibility * 0.4 +\n     visibility.validFrameRatio * 0.4 +\n     (1 - visibility.dropoutRate) * 0.2) * 100\n  );\n\n  // 7. Generate confidence reasons if low\n  const confidenceReasons: string[] = [];\n  if (visibility.avgVisibility < 0.6) {\n    confidenceReasons.push(`Low landmark visibility (${Math.round(visibility.avgVisibility * 100)}%)`);\n  }\n  if (visibility.validFrameRatio < MIN_VALID_FRAME_RATIO) {\n    confidenceReasons.push(`Only ${Math.round(visibility.validFrameRatio * 100)}% frames had clear pose detection`);\n  }\n  if (visibility.dropoutRate > 0.3) {\n    confidenceReasons.push(`${Math.round(visibility.dropoutRate * 100)}% of frames had missing landmarks`);\n  }\n\n  // Check specific joint visibility\n  const poorVisibilityJoints: string[] = [];\n  for (const [joint, vis] of Object.entries(visibility.keyJointVisibility)) {\n    if (vis < 0.5) {\n      poorVisibilityJoints.push(joint.replace(/_/g, ' ').toLowerCase());\n    }\n  }\n  if (poorVisibilityJoints.length > 0) {\n    confidenceReasons.push(`Poor visibility for: ${poorVisibilityJoints.slice(0, 3).join(', ')}`);\n  }\n\n  return {\n    skillScore: Math.round(skillScore),\n    levelLabel,\n    confidencePercent,\n    confidenceReasons,\n    metrics: {\n      consistencyScore: Math.round(consistencyScore * 100) / 100,\n      recoverySpeed: Math.round(recoverySpeed * 100) / 100,\n      formQuality: Math.round(formQuality * 100) / 100,\n      visibilityAvg: Math.round(visibility.avgVisibility * 100) / 100,\n      dropoutRate: Math.round(visibility.dropoutRate * 100) / 100,\n    },\n  };\n}\n\n// ============================================\n// Helper Functions\n// ============================================\n\nfunction standardDeviation(values: number[]): number {\n  if (values.length === 0) return 0;\n  const mean = values.reduce((a, b) => a + b, 0) / values.length;\n  const squaredDiffs = values.map(v => Math.pow(v - mean, 2));\n  const avgSquaredDiff = squaredDiffs.reduce((a, b) => a + b, 0) / values.length;\n  return Math.sqrt(avgSquaredDiff);\n}\n\nfunction calculateStanceWidth(landmarks: PoseLandmark[]): number {\n  const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n  const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n\n  if (!leftAnkle || !rightAnkle || !leftShoulder || !rightShoulder) return 0;\n  if ((leftAnkle.visibility ?? 0) < 0.5 || (rightAnkle.visibility ?? 0) < 0.5) return 0;\n\n  const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n  const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n\n  return shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n}\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":986,"cache_read_input_tokens":125773,"cache_creation":{"ephemeral_5m_input_tokens":986,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXZCRikA4o1cK3oSXciMy","type":"assistant","uuid":"03f095e4-5fc1-413e-8947-2f8b4769c4bb","timestamp":"2026-01-28T05:09:29.937Z"}
{"type":"file-history-snapshot","messageId":"03f095e4-5fc1-413e-8947-2f8b4769c4bb","snapshot":{"messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","trackedFileBackups":{"supabase-migration-v3-features.sql":{"backupFileName":null,"version":1,"backupTime":"2026-01-28T05:08:12.613Z"},"rallycoach\\src\\lib\\types.ts":{"backupFileName":"1048a9baa3a842fc@v1","version":1,"backupTime":"2026-01-28T05:08:34.814Z"},"rallycoach\\src\\lib\\skill-scoring.ts":{"backupFileName":"1012db229ac5a83c@v1","version":1,"backupTime":"2026-01-28T05:09:30.561Z"}},"timestamp":"2026-01-28T05:05:21.590Z"},"isSnapshotUpdate":true}
{"parentUuid":"03f095e4-5fc1-413e-8947-2f8b4769c4bb","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016fqL8dGQFtA5FET7diN8X1","type":"tool_result","content":"File created successfully at: C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\skill-scoring.ts"}]},"uuid":"b3cd05e1-1fac-4cc5-bde7-cfddad66ef17","timestamp":"2026-01-28T05:09:30.558Z","toolUseResult":{"type":"create","filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\skill-scoring.ts","content":"/**\n * Skill Scoring Module\n *\n * Computes skill score and confidence from REAL pose metrics.\n * This does NOT rely on Gemini for the numeric score.\n *\n * Confidence is derived from:\n * - MediaPipe landmark visibility (0-1 per landmark)\n * - Detection success rate across frames\n * - Dropout frequency (frames with missing landmarks)\n *\n * Skill Score is computed from:\n * - Consistency of key joint angles over shots\n * - Recovery speed after lunges\n * - Stance stability + split-step presence\n * - Overhead sequence quality\n */\n\nimport type {\n  PoseLandmark,\n  PoseMetrics,\n  ComputedSkillScore,\n  VisibilityMetrics,\n  MistakeEvent\n} from './types';\nimport { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n\n// Key joints for confidence calculation (most important for badminton)\nconst KEY_JOINTS = [\n  POSE_LANDMARKS.LEFT_SHOULDER,\n  POSE_LANDMARKS.RIGHT_SHOULDER,\n  POSE_LANDMARKS.LEFT_ELBOW,\n  POSE_LANDMARKS.RIGHT_ELBOW,\n  POSE_LANDMARKS.LEFT_WRIST,\n  POSE_LANDMARKS.RIGHT_WRIST,\n  POSE_LANDMARKS.LEFT_HIP,\n  POSE_LANDMARKS.RIGHT_HIP,\n  POSE_LANDMARKS.LEFT_KNEE,\n  POSE_LANDMARKS.RIGHT_KNEE,\n  POSE_LANDMARKS.LEFT_ANKLE,\n  POSE_LANDMARKS.RIGHT_ANKLE,\n];\n\nconst VISIBILITY_THRESHOLD = 0.5;\nconst MIN_VALID_FRAME_RATIO = 0.7;\n\n/**\n * Compute visibility metrics from pose data\n * This derives confidence from actual MediaPipe visibility values\n */\nexport function computeVisibilityMetrics(\n  poseData: (PoseLandmark[] | null)[]\n): VisibilityMetrics {\n  let totalVisibility = 0;\n  let validFrameCount = 0;\n  let dropoutCount = 0;\n  const jointVisibilitySum: Record<string, number> = {};\n  const jointVisibilityCount: Record<string, number> = {};\n\n  for (const landmarks of poseData) {\n    if (!landmarks || landmarks.length === 0) {\n      dropoutCount++;\n      continue;\n    }\n\n    // Calculate average visibility for key joints in this frame\n    let frameVisibilitySum = 0;\n    let keyJointCount = 0;\n\n    for (const jointIdx of KEY_JOINTS) {\n      const landmark = landmarks[jointIdx];\n      if (landmark) {\n        const visibility = landmark.visibility ?? 0;\n        frameVisibilitySum += visibility;\n        keyJointCount++;\n\n        // Track per-joint visibility\n        const jointName = Object.entries(POSE_LANDMARKS).find(([_, v]) => v === jointIdx)?.[0] || String(jointIdx);\n        jointVisibilitySum[jointName] = (jointVisibilitySum[jointName] || 0) + visibility;\n        jointVisibilityCount[jointName] = (jointVisibilityCount[jointName] || 0) + 1;\n      }\n    }\n\n    if (keyJointCount > 0) {\n      const frameAvgVisibility = frameVisibilitySum / keyJointCount;\n      totalVisibility += frameAvgVisibility;\n\n      if (frameAvgVisibility >= VISIBILITY_THRESHOLD) {\n        validFrameCount++;\n      }\n    } else {\n      dropoutCount++;\n    }\n  }\n\n  const totalFrames = poseData.length;\n  const framesWithPose = totalFrames - dropoutCount;\n\n  // Compute per-joint average visibility\n  const keyJointVisibility: Record<string, number> = {};\n  for (const [joint, sum] of Object.entries(jointVisibilitySum)) {\n    const count = jointVisibilityCount[joint] || 1;\n    keyJointVisibility[joint] = sum / count;\n  }\n\n  return {\n    avgVisibility: framesWithPose > 0 ? totalVisibility / framesWithPose : 0,\n    validFrameRatio: totalFrames > 0 ? validFrameCount / totalFrames : 0,\n    dropoutRate: totalFrames > 0 ? dropoutCount / totalFrames : 1,\n    keyJointVisibility,\n  };\n}\n\n/**\n * Calculate consistency score from pose metrics over time\n * Higher consistency = more stable form across frames\n */\nexport function computeConsistencyScore(\n  metricsHistory: (PoseMetrics | null)[]\n): number {\n  const validMetrics = metricsHistory.filter(m => m !== null) as PoseMetrics[];\n  if (validMetrics.length < 5) return 0.5; // Not enough data\n\n  // Calculate standard deviation for each metric\n  const elbowAngles = validMetrics.map(m => m.elbow_angle);\n  const kneeAngles = validMetrics.map(m => m.knee_angle);\n  const stanceWidths = validMetrics.map(m => m.stance_width_norm);\n\n  const elbowStd = standardDeviation(elbowAngles);\n  const kneeStd = standardDeviation(kneeAngles);\n  const stanceStd = standardDeviation(stanceWidths);\n\n  // Normalize standard deviations (lower is better)\n  // Ideal: elbow std < 15deg, knee std < 20deg, stance std < 0.15\n  const elbowConsistency = Math.max(0, 1 - elbowStd / 30);\n  const kneeConsistency = Math.max(0, 1 - kneeStd / 40);\n  const stanceConsistency = Math.max(0, 1 - stanceStd / 0.3);\n\n  return (elbowConsistency + kneeConsistency + stanceConsistency) / 3;\n}\n\n/**\n * Detect split-step presence from pose data\n * Returns a score 0-1 based on how well split-steps are executed\n */\nexport function detectSplitStepQuality(\n  poseData: (PoseLandmark[] | null)[]\n): number {\n  const validFrames = poseData.filter(p => p !== null) as PoseLandmark[][];\n  if (validFrames.length < 10) return 0.5;\n\n  let splitStepCount = 0;\n  let potentialSplitSteps = 0;\n\n  for (let i = 2; i < validFrames.length - 2; i++) {\n    const prev = validFrames[i - 1];\n    const curr = validFrames[i];\n    const next = validFrames[i + 1];\n\n    // Calculate stance width changes\n    const prevStance = calculateStanceWidth(prev);\n    const currStance = calculateStanceWidth(curr);\n    const nextStance = calculateStanceWidth(next);\n\n    // Split-step: quick widening then movement\n    // Check for rapid stance change\n    if (prevStance > 0 && currStance > 0) {\n      const widthChange = Math.abs(currStance - prevStance) / prevStance;\n      if (widthChange > 0.15) {\n        potentialSplitSteps++;\n        // Good split-step has controlled landing\n        if (nextStance > 0) {\n          const recovery = Math.abs(nextStance - currStance) / currStance;\n          if (recovery < 0.2) {\n            splitStepCount++;\n          }\n        }\n      }\n    }\n  }\n\n  if (potentialSplitSteps === 0) return 0.3; // No movement detected\n  return Math.min(1, splitStepCount / Math.max(1, potentialSplitSteps / 3));\n}\n\n/**\n * Compute recovery speed from lunge positions\n */\nexport function computeRecoverySpeed(\n  poseData: (PoseLandmark[] | null)[]\n): number {\n  const validFrames = poseData.filter(p => p !== null) as PoseLandmark[][];\n  if (validFrames.length < 5) return 0.5;\n\n  const kneeAngles: number[] = [];\n  for (const landmarks of validFrames) {\n    const hip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n    const knee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n    const ankle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n    if (hip && knee && ankle) {\n      kneeAngles.push(calculateAngle(hip, knee, ankle));\n    }\n  }\n\n  if (kneeAngles.length < 5) return 0.5;\n\n  // Find lunge moments (knee angle < 120)\n  const lungeIndices: number[] = [];\n  for (let i = 0; i < kneeAngles.length; i++) {\n    if (kneeAngles[i] < 120) {\n      lungeIndices.push(i);\n    }\n  }\n\n  if (lungeIndices.length === 0) return 0.7; // No deep lunges, decent baseline\n\n  // Calculate recovery time from each lunge\n  let totalRecoveryFrames = 0;\n  let recoveryCount = 0;\n\n  for (const lungeIdx of lungeIndices) {\n    // Find when knee angle returns to > 140\n    for (let j = lungeIdx + 1; j < Math.min(lungeIdx + 20, kneeAngles.length); j++) {\n      if (kneeAngles[j] > 140) {\n        totalRecoveryFrames += (j - lungeIdx);\n        recoveryCount++;\n        break;\n      }\n    }\n  }\n\n  if (recoveryCount === 0) return 0.4; // Slow recovery\n\n  const avgRecoveryFrames = totalRecoveryFrames / recoveryCount;\n  // Ideal recovery: < 5 frames at 10fps = 0.5 seconds\n  return Math.max(0, Math.min(1, 1 - (avgRecoveryFrames - 3) / 15));\n}\n\n/**\n * Compute form quality score from angle analysis\n */\nexport function computeFormQuality(\n  metricsHistory: (PoseMetrics | null)[],\n  poseData: (PoseLandmark[] | null)[]\n): number {\n  const validMetrics = metricsHistory.filter(m => m !== null) as PoseMetrics[];\n  if (validMetrics.length < 3) return 0.5;\n\n  let totalScore = 0;\n  let frameCount = 0;\n\n  for (const metrics of validMetrics) {\n    let frameScore = 0;\n    let checks = 0;\n\n    // Elbow angle check (90-130 ideal for most shots)\n    if (metrics.elbow_angle >= 80 && metrics.elbow_angle <= 140) {\n      frameScore += 1;\n    } else if (metrics.elbow_angle >= 70 && metrics.elbow_angle <= 150) {\n      frameScore += 0.7;\n    } else {\n      frameScore += 0.3;\n    }\n    checks++;\n\n    // Knee angle check (110-160 ideal)\n    if (metrics.knee_angle >= 110 && metrics.knee_angle <= 160) {\n      frameScore += 1;\n    } else if (metrics.knee_angle >= 90 && metrics.knee_angle <= 170) {\n      frameScore += 0.7;\n    } else {\n      frameScore += 0.3;\n    }\n    checks++;\n\n    // Stance width check (0.6-1.5 normalized)\n    if (metrics.stance_width_norm >= 0.6 && metrics.stance_width_norm <= 1.5) {\n      frameScore += 1;\n    } else if (metrics.stance_width_norm >= 0.4 && metrics.stance_width_norm <= 1.8) {\n      frameScore += 0.7;\n    } else {\n      frameScore += 0.3;\n    }\n    checks++;\n\n    totalScore += frameScore / checks;\n    frameCount++;\n  }\n\n  return totalScore / frameCount;\n}\n\n/**\n * Main function: Compute complete skill score from pose data\n */\nexport function computeSkillScore(\n  poseData: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[],\n  issues: MistakeEvent[] = []\n): ComputedSkillScore {\n  // 1. Calculate visibility metrics for confidence\n  const visibility = computeVisibilityMetrics(poseData);\n\n  // 2. Calculate component scores\n  const consistencyScore = computeConsistencyScore(metricsHistory);\n  const recoverySpeed = computeRecoverySpeed(poseData);\n  const formQuality = computeFormQuality(metricsHistory, poseData);\n  const splitStepQuality = detectSplitStepQuality(poseData);\n\n  // 3. Compute weighted skill score (0-100)\n  const rawScore = (\n    consistencyScore * 30 +  // Consistency is important\n    formQuality * 35 +       // Form quality matters most\n    recoverySpeed * 20 +     // Recovery speed\n    splitStepQuality * 15    // Split-step presence\n  );\n\n  // 4. Apply issue penalty\n  const highSeverityIssues = issues.filter(i => i.severity > 0.7).length;\n  const mediumSeverityIssues = issues.filter(i => i.severity > 0.4 && i.severity <= 0.7).length;\n  const issuePenalty = highSeverityIssues * 5 + mediumSeverityIssues * 2;\n\n  const skillScore = Math.max(0, Math.min(100, rawScore - issuePenalty));\n\n  // 5. Determine level label\n  let levelLabel: 'Beginner' | 'Intermediate' | 'Advanced';\n  if (skillScore >= 70) {\n    levelLabel = 'Advanced';\n  } else if (skillScore >= 40) {\n    levelLabel = 'Intermediate';\n  } else {\n    levelLabel = 'Beginner';\n  }\n\n  // 6. Calculate confidence from visibility\n  const confidencePercent = Math.round(\n    (visibility.avgVisibility * 0.4 +\n     visibility.validFrameRatio * 0.4 +\n     (1 - visibility.dropoutRate) * 0.2) * 100\n  );\n\n  // 7. Generate confidence reasons if low\n  const confidenceReasons: string[] = [];\n  if (visibility.avgVisibility < 0.6) {\n    confidenceReasons.push(`Low landmark visibility (${Math.round(visibility.avgVisibility * 100)}%)`);\n  }\n  if (visibility.validFrameRatio < MIN_VALID_FRAME_RATIO) {\n    confidenceReasons.push(`Only ${Math.round(visibility.validFrameRatio * 100)}% frames had clear pose detection`);\n  }\n  if (visibility.dropoutRate > 0.3) {\n    confidenceReasons.push(`${Math.round(visibility.dropoutRate * 100)}% of frames had missing landmarks`);\n  }\n\n  // Check specific joint visibility\n  const poorVisibilityJoints: string[] = [];\n  for (const [joint, vis] of Object.entries(visibility.keyJointVisibility)) {\n    if (vis < 0.5) {\n      poorVisibilityJoints.push(joint.replace(/_/g, ' ').toLowerCase());\n    }\n  }\n  if (poorVisibilityJoints.length > 0) {\n    confidenceReasons.push(`Poor visibility for: ${poorVisibilityJoints.slice(0, 3).join(', ')}`);\n  }\n\n  return {\n    skillScore: Math.round(skillScore),\n    levelLabel,\n    confidencePercent,\n    confidenceReasons,\n    metrics: {\n      consistencyScore: Math.round(consistencyScore * 100) / 100,\n      recoverySpeed: Math.round(recoverySpeed * 100) / 100,\n      formQuality: Math.round(formQuality * 100) / 100,\n      visibilityAvg: Math.round(visibility.avgVisibility * 100) / 100,\n      dropoutRate: Math.round(visibility.dropoutRate * 100) / 100,\n    },\n  };\n}\n\n// ============================================\n// Helper Functions\n// ============================================\n\nfunction standardDeviation(values: number[]): number {\n  if (values.length === 0) return 0;\n  const mean = values.reduce((a, b) => a + b, 0) / values.length;\n  const squaredDiffs = values.map(v => Math.pow(v - mean, 2));\n  const avgSquaredDiff = squaredDiffs.reduce((a, b) => a + b, 0) / values.length;\n  return Math.sqrt(avgSquaredDiff);\n}\n\nfunction calculateStanceWidth(landmarks: PoseLandmark[]): number {\n  const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n  const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n\n  if (!leftAnkle || !rightAnkle || !leftShoulder || !rightShoulder) return 0;\n  if ((leftAnkle.visibility ?? 0) < 0.5 || (rightAnkle.visibility ?? 0) < 0.5) return 0;\n\n  const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n  const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n\n  return shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n}\n","structuredPatch":[],"originalFile":null},"sourceToolAssistantUUID":"03f095e4-5fc1-413e-8947-2f8b4769c4bb"}
{"parentUuid":"b3cd05e1-1fac-4cc5-bde7-cfddad66ef17","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012bLpdv6yAdpzuvvRuSnD95","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me create the ghost-overlay module for the Ghost Rival feature. This will:\n1. Find the best rep window from the same video\n2. Store/extract ghost pose frames\n3. Provide sync logic for overlay rendering","signature":"EvcCCkYICxgCKkDS7Cqk8BS7+Zz7LtK8a4y/MecA7Bj98ZCbC0ZFr2blTQU5f8ED0hcKO9I59rBNdSsIAzKsgeogX3xwcqH9wf4XEgwtpukSFJHeqoLDHlsaDGVDsckkF7LVH9QpDSIwvPGeBZOhGr4HwP9mNYO2NmnD7hinld74rz4CkTfKfLNHSD/9Y+wyUr5M+7MGB0B4Kt4B6I2kEzhV7ksQVnaDAmIxIbZzccszMmZPvb+NGNaxvpAUDvO+RFhYHBReeOkNjWItuhah4HI2h7XcUJs9DaMMXz0Lt8e8TKSXhxVSQ2K16AdDl5L7xMCjLEuLird4PnR6Dzsgg+41ZQUuW0CHYaUwIl2BKJqHE1zZo17SJdKxEKQpSNjkbrZ4YX+esxEfo9joevKKJYTW4vEa3mctGy1ccYqT15GoxTMC6T8Jb4iAZjPBtsVhXQUP7Bhej2T4rUSp7qthZqTRw6ccyOs18OnhxThdxZy75ZAeN1Lp/qISGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":4779,"cache_read_input_tokens":126759,"cache_creation":{"ephemeral_5m_input_tokens":4779,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCVpnfKPfwDUp1uQZzh","type":"assistant","uuid":"4359bfdd-e8f4-4764-8772-e9e885d82079","timestamp":"2026-01-28T05:09:34.905Z"}
{"parentUuid":"4359bfdd-e8f4-4764-8772-e9e885d82079","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012bLpdv6yAdpzuvvRuSnD95","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me create the ghost overlay module for Feature 1."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":4779,"cache_read_input_tokens":126759,"cache_creation":{"ephemeral_5m_input_tokens":4779,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCVpnfKPfwDUp1uQZzh","type":"assistant","uuid":"7f9fd50b-d450-4742-9471-cfd95e93262a","timestamp":"2026-01-28T05:09:35.338Z"}
{"parentUuid":"7f9fd50b-d450-4742-9471-cfd95e93262a","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012bLpdv6yAdpzuvvRuSnD95","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EYUchQS2yDhG1fL3nZMD3u","name":"Write","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\ghost-overlay.ts","content":"/**\n * Ghost Rival Overlay Module\n *\n * Provides \"My Best Rep\" ghost skeleton overlay functionality:\n * 1. Finds the highest-quality segment from the same video\n * 2. Extracts pose frames for ghost rendering\n * 3. Syncs ghost playback with user video time\n */\n\nimport type {\n  PoseLandmark,\n  PoseMetrics,\n  GhostRivalData,\n  GhostPoseFrame,\n  MistakeEvent\n} from './types';\nimport { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n\n// Minimum window size for a valid \"rep\"\nconst MIN_REP_DURATION_SEC = 0.8;\nconst MAX_REP_DURATION_SEC = 3.0;\nconst GHOST_FPS = 15; // Downsample to 15fps for rendering\n\n/**\n * Shot event detected in video\n */\ninterface ShotEvent {\n  frameIndex: number;\n  timestamp: number;\n  shotType: 'overhead' | 'drive' | 'netshot' | 'footwork' | 'unknown';\n  confidence: number;\n}\n\n/**\n * Calculate form quality score for a segment of pose frames\n * Higher score = better form\n */\nexport function calculateSegmentFormScore(\n  poseFrames: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[]\n): number {\n  let totalScore = 0;\n  let validFrames = 0;\n\n  for (let i = 0; i < poseFrames.length; i++) {\n    const landmarks = poseFrames[i];\n    const metrics = metricsHistory[i];\n\n    if (!landmarks || !metrics) continue;\n\n    // Calculate average visibility\n    const avgVisibility = landmarks.reduce((sum, lm) => sum + (lm.visibility ?? 0), 0) / landmarks.length;\n    if (avgVisibility < 0.5) continue;\n\n    let frameScore = avgVisibility * 20; // Base score from visibility\n\n    // Elbow angle scoring (ideal: 90-130 for most shots)\n    const elbowScore = scoreInRange(metrics.elbow_angle, 80, 140, 60, 160);\n    frameScore += elbowScore * 25;\n\n    // Knee angle scoring (ideal: 110-160)\n    const kneeScore = scoreInRange(metrics.knee_angle, 110, 160, 80, 175);\n    frameScore += kneeScore * 25;\n\n    // Stance width scoring (ideal: 0.6-1.4 normalized)\n    const stanceScore = scoreInRange(metrics.stance_width_norm, 0.6, 1.4, 0.3, 2.0);\n    frameScore += stanceScore * 15;\n\n    // Rotation scoring (ideal: 0.1-0.4)\n    const rotationScore = scoreInRange(metrics.shoulder_hip_rotation_proxy, 0.1, 0.4, 0, 0.6);\n    frameScore += rotationScore * 15;\n\n    totalScore += frameScore;\n    validFrames++;\n  }\n\n  return validFrames > 0 ? totalScore / validFrames : 0;\n}\n\n/**\n * Score a value within ideal and acceptable ranges\n */\nfunction scoreInRange(\n  value: number,\n  idealMin: number,\n  idealMax: number,\n  acceptMin: number,\n  acceptMax: number\n): number {\n  if (value >= idealMin && value <= idealMax) {\n    return 1.0; // Perfect\n  }\n  if (value < acceptMin || value > acceptMax) {\n    return 0.2; // Poor\n  }\n  // In acceptable but not ideal range\n  if (value < idealMin) {\n    return 0.5 + 0.5 * ((value - acceptMin) / (idealMin - acceptMin));\n  }\n  return 0.5 + 0.5 * ((acceptMax - value) / (acceptMax - idealMax));\n}\n\n/**\n * Detect shot events in the video based on pose patterns\n */\nexport function detectShotEvents(\n  poseData: (PoseLandmark[] | null)[],\n  fps: number = 10\n): ShotEvent[] {\n  const events: ShotEvent[] = [];\n  const minFramesBetweenShots = Math.floor(fps * 0.5); // At least 0.5s between shots\n\n  for (let i = 5; i < poseData.length - 5; i++) {\n    const landmarks = poseData[i];\n    if (!landmarks) continue;\n\n    // Check for overhead shot (wrist above shoulder)\n    const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n    const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n    const rightElbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n\n    if (!rightWrist || !rightShoulder || !rightElbow) continue;\n    if ((rightWrist.visibility ?? 0) < 0.5) continue;\n\n    // Detect overhead position\n    if (rightWrist.y < rightShoulder.y - 0.05) {\n      // Check if this is a new shot (not too close to previous)\n      const lastEvent = events[events.length - 1];\n      if (!lastEvent || i - lastEvent.frameIndex >= minFramesBetweenShots) {\n        // Calculate elbow extension for overhead\n        const elbowAngle = calculateAngle(rightShoulder, rightElbow, rightWrist);\n\n        events.push({\n          frameIndex: i,\n          timestamp: i / fps,\n          shotType: elbowAngle > 140 ? 'overhead' : 'drive',\n          confidence: (rightWrist.visibility ?? 0.5) * (rightShoulder.visibility ?? 0.5),\n        });\n      }\n    }\n\n    // Detect lunge/netshot (deep knee bend with forward reach)\n    const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n    const rightKnee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n    const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n\n    if (rightHip && rightKnee && rightAnkle) {\n      const kneeAngle = calculateAngle(rightHip, rightKnee, rightAnkle);\n      if (kneeAngle < 100) {\n        const lastEvent = events[events.length - 1];\n        if (!lastEvent || i - lastEvent.frameIndex >= minFramesBetweenShots) {\n          events.push({\n            frameIndex: i,\n            timestamp: i / fps,\n            shotType: 'netshot',\n            confidence: Math.min(rightKnee.visibility ?? 0.5, rightAnkle.visibility ?? 0.5),\n          });\n        }\n      }\n    }\n  }\n\n  return events;\n}\n\n/**\n * Find the best rep window from the video\n * This is the highest-quality segment that can be used as ghost overlay\n */\nexport function findBestRepWindow(\n  poseData: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[],\n  shotEvents: ShotEvent[],\n  fps: number = 10\n): GhostRivalData['bestRepWindow'] | null {\n  if (shotEvents.length === 0) {\n    // No shots detected, find best continuous segment\n    return findBestContinuousSegment(poseData, metricsHistory, fps);\n  }\n\n  let bestWindow: GhostRivalData['bestRepWindow'] | null = null;\n  let bestScore = 0;\n\n  for (const shot of shotEvents) {\n    // Define window around shot: 0.8s before to 0.6s after\n    const windowStartFrame = Math.max(0, shot.frameIndex - Math.floor(fps * 0.8));\n    const windowEndFrame = Math.min(poseData.length - 1, shot.frameIndex + Math.floor(fps * 0.6));\n\n    // Extract segment\n    const segmentPoses = poseData.slice(windowStartFrame, windowEndFrame + 1);\n    const segmentMetrics = metricsHistory.slice(windowStartFrame, windowEndFrame + 1);\n\n    // Calculate form quality score\n    const score = calculateSegmentFormScore(segmentPoses, segmentMetrics);\n\n    if (score > bestScore) {\n      bestScore = score;\n      bestWindow = {\n        startTime: windowStartFrame / fps,\n        endTime: windowEndFrame / fps,\n        score,\n        shotType: shot.shotType,\n      };\n    }\n  }\n\n  return bestWindow;\n}\n\n/**\n * Find best continuous segment when no shots are detected\n */\nfunction findBestContinuousSegment(\n  poseData: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[],\n  fps: number\n): GhostRivalData['bestRepWindow'] | null {\n  const windowSize = Math.floor(fps * 1.5); // 1.5 second windows\n  const step = Math.floor(fps * 0.5); // 0.5 second steps\n\n  let bestWindow: GhostRivalData['bestRepWindow'] | null = null;\n  let bestScore = 0;\n\n  for (let start = 0; start + windowSize < poseData.length; start += step) {\n    const segmentPoses = poseData.slice(start, start + windowSize);\n    const segmentMetrics = metricsHistory.slice(start, start + windowSize);\n\n    const score = calculateSegmentFormScore(segmentPoses, segmentMetrics);\n\n    if (score > bestScore) {\n      bestScore = score;\n      bestWindow = {\n        startTime: start / fps,\n        endTime: (start + windowSize) / fps,\n        score,\n        shotType: 'footwork',\n      };\n    }\n  }\n\n  return bestWindow;\n}\n\n/**\n * Extract ghost pose sequence from best rep window\n * Downsamples to GHOST_FPS for efficient rendering\n */\nexport function extractGhostPoseSequence(\n  poseData: (PoseLandmark[] | null)[],\n  bestRepWindow: GhostRivalData['bestRepWindow'],\n  sourceFps: number = 10\n): GhostPoseFrame[] {\n  if (!bestRepWindow) return [];\n\n  const startFrame = Math.floor(bestRepWindow.startTime * sourceFps);\n  const endFrame = Math.floor(bestRepWindow.endTime * sourceFps);\n  const windowDuration = bestRepWindow.endTime - bestRepWindow.startTime;\n\n  const ghostFrames: GhostPoseFrame[] = [];\n\n  // Calculate frame step for downsampling to GHOST_FPS\n  const frameStep = Math.max(1, Math.floor(sourceFps / GHOST_FPS));\n\n  for (let i = startFrame; i <= endFrame; i += frameStep) {\n    const landmarks = poseData[i];\n    if (!landmarks) continue;\n\n    const timestamp = i / sourceFps;\n    const normalizedTime = (timestamp - bestRepWindow.startTime) / windowDuration;\n\n    ghostFrames.push({\n      timestamp,\n      normalizedTime: Math.max(0, Math.min(1, normalizedTime)),\n      landmarks,\n    });\n  }\n\n  return ghostFrames;\n}\n\n/**\n * Get ghost pose for current video time\n * Handles sync between user video time and ghost animation\n */\nexport function getGhostPoseAtTime(\n  ghostData: GhostRivalData,\n  currentTime: number\n): PoseLandmark[] | null {\n  if (!ghostData.enabled || ghostData.poseSequence.length === 0) {\n    return null;\n  }\n\n  const { poseSequence, bestRepWindow } = ghostData;\n\n  if (!bestRepWindow) {\n    // Fallback: use absolute time\n    let closestFrame = poseSequence[0];\n    let minDiff = Infinity;\n\n    for (const frame of poseSequence) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame?.landmarks ?? null;\n  }\n\n  // Use absolute time matching if within window\n  if (currentTime >= bestRepWindow.startTime && currentTime <= bestRepWindow.endTime) {\n    let closestFrame = poseSequence[0];\n    let minDiff = Infinity;\n\n    for (const frame of poseSequence) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame?.landmarks ?? null;\n  }\n\n  // Loop the ghost animation when outside window\n  const windowDuration = bestRepWindow.endTime - bestRepWindow.startTime;\n  const loopTime = ((currentTime - bestRepWindow.startTime) % windowDuration + windowDuration) % windowDuration;\n  const targetTime = bestRepWindow.startTime + loopTime;\n\n  let closestFrame = poseSequence[0];\n  let minDiff = Infinity;\n\n  for (const frame of poseSequence) {\n    const diff = Math.abs(frame.timestamp - targetTime);\n    if (diff < minDiff) {\n      minDiff = diff;\n      closestFrame = frame;\n    }\n  }\n\n  return closestFrame?.landmarks ?? null;\n}\n\n/**\n * Initialize ghost rival data from analysis\n */\nexport function initializeGhostRival(\n  poseData: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[],\n  fps: number = 10\n): GhostRivalData {\n  // Detect shot events\n  const shotEvents = detectShotEvents(poseData, fps);\n\n  // Find best rep window\n  const bestRepWindow = findBestRepWindow(poseData, metricsHistory, shotEvents, fps);\n\n  // Extract ghost pose sequence\n  const poseSequence = bestRepWindow\n    ? extractGhostPoseSequence(poseData, bestRepWindow, fps)\n    : [];\n\n  return {\n    source: 'my-best-rep',\n    enabled: false, // User must enable\n    poseSequence,\n    bestRepWindow: bestRepWindow ?? undefined,\n  };\n}\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":4779,"cache_read_input_tokens":126759,"cache_creation":{"ephemeral_5m_input_tokens":4779,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCVpnfKPfwDUp1uQZzh","type":"assistant","uuid":"ce632397-fe9e-428e-958e-1a3ab278a00f","timestamp":"2026-01-28T05:10:16.676Z"}
{"type":"file-history-snapshot","messageId":"ce632397-fe9e-428e-958e-1a3ab278a00f","snapshot":{"messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","trackedFileBackups":{"supabase-migration-v3-features.sql":{"backupFileName":null,"version":1,"backupTime":"2026-01-28T05:08:12.613Z"},"rallycoach\\src\\lib\\types.ts":{"backupFileName":"1048a9baa3a842fc@v1","version":1,"backupTime":"2026-01-28T05:08:34.814Z"},"rallycoach\\src\\lib\\skill-scoring.ts":{"backupFileName":"1012db229ac5a83c@v1","version":1,"backupTime":"2026-01-28T05:09:30.561Z"},"rallycoach\\src\\lib\\ghost-overlay.ts":{"backupFileName":"c0850482504218d5@v1","version":1,"backupTime":"2026-01-28T05:10:17.275Z"}},"timestamp":"2026-01-28T05:05:21.590Z"},"isSnapshotUpdate":true}
{"parentUuid":"ce632397-fe9e-428e-958e-1a3ab278a00f","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EYUchQS2yDhG1fL3nZMD3u","type":"tool_result","content":"File created successfully at: C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\ghost-overlay.ts"}]},"uuid":"6609b7ce-c2dc-4afb-9e7e-06660025a85f","timestamp":"2026-01-28T05:10:17.271Z","toolUseResult":{"type":"create","filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\ghost-overlay.ts","content":"/**\n * Ghost Rival Overlay Module\n *\n * Provides \"My Best Rep\" ghost skeleton overlay functionality:\n * 1. Finds the highest-quality segment from the same video\n * 2. Extracts pose frames for ghost rendering\n * 3. Syncs ghost playback with user video time\n */\n\nimport type {\n  PoseLandmark,\n  PoseMetrics,\n  GhostRivalData,\n  GhostPoseFrame,\n  MistakeEvent\n} from './types';\nimport { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n\n// Minimum window size for a valid \"rep\"\nconst MIN_REP_DURATION_SEC = 0.8;\nconst MAX_REP_DURATION_SEC = 3.0;\nconst GHOST_FPS = 15; // Downsample to 15fps for rendering\n\n/**\n * Shot event detected in video\n */\ninterface ShotEvent {\n  frameIndex: number;\n  timestamp: number;\n  shotType: 'overhead' | 'drive' | 'netshot' | 'footwork' | 'unknown';\n  confidence: number;\n}\n\n/**\n * Calculate form quality score for a segment of pose frames\n * Higher score = better form\n */\nexport function calculateSegmentFormScore(\n  poseFrames: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[]\n): number {\n  let totalScore = 0;\n  let validFrames = 0;\n\n  for (let i = 0; i < poseFrames.length; i++) {\n    const landmarks = poseFrames[i];\n    const metrics = metricsHistory[i];\n\n    if (!landmarks || !metrics) continue;\n\n    // Calculate average visibility\n    const avgVisibility = landmarks.reduce((sum, lm) => sum + (lm.visibility ?? 0), 0) / landmarks.length;\n    if (avgVisibility < 0.5) continue;\n\n    let frameScore = avgVisibility * 20; // Base score from visibility\n\n    // Elbow angle scoring (ideal: 90-130 for most shots)\n    const elbowScore = scoreInRange(metrics.elbow_angle, 80, 140, 60, 160);\n    frameScore += elbowScore * 25;\n\n    // Knee angle scoring (ideal: 110-160)\n    const kneeScore = scoreInRange(metrics.knee_angle, 110, 160, 80, 175);\n    frameScore += kneeScore * 25;\n\n    // Stance width scoring (ideal: 0.6-1.4 normalized)\n    const stanceScore = scoreInRange(metrics.stance_width_norm, 0.6, 1.4, 0.3, 2.0);\n    frameScore += stanceScore * 15;\n\n    // Rotation scoring (ideal: 0.1-0.4)\n    const rotationScore = scoreInRange(metrics.shoulder_hip_rotation_proxy, 0.1, 0.4, 0, 0.6);\n    frameScore += rotationScore * 15;\n\n    totalScore += frameScore;\n    validFrames++;\n  }\n\n  return validFrames > 0 ? totalScore / validFrames : 0;\n}\n\n/**\n * Score a value within ideal and acceptable ranges\n */\nfunction scoreInRange(\n  value: number,\n  idealMin: number,\n  idealMax: number,\n  acceptMin: number,\n  acceptMax: number\n): number {\n  if (value >= idealMin && value <= idealMax) {\n    return 1.0; // Perfect\n  }\n  if (value < acceptMin || value > acceptMax) {\n    return 0.2; // Poor\n  }\n  // In acceptable but not ideal range\n  if (value < idealMin) {\n    return 0.5 + 0.5 * ((value - acceptMin) / (idealMin - acceptMin));\n  }\n  return 0.5 + 0.5 * ((acceptMax - value) / (acceptMax - idealMax));\n}\n\n/**\n * Detect shot events in the video based on pose patterns\n */\nexport function detectShotEvents(\n  poseData: (PoseLandmark[] | null)[],\n  fps: number = 10\n): ShotEvent[] {\n  const events: ShotEvent[] = [];\n  const minFramesBetweenShots = Math.floor(fps * 0.5); // At least 0.5s between shots\n\n  for (let i = 5; i < poseData.length - 5; i++) {\n    const landmarks = poseData[i];\n    if (!landmarks) continue;\n\n    // Check for overhead shot (wrist above shoulder)\n    const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n    const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n    const rightElbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n\n    if (!rightWrist || !rightShoulder || !rightElbow) continue;\n    if ((rightWrist.visibility ?? 0) < 0.5) continue;\n\n    // Detect overhead position\n    if (rightWrist.y < rightShoulder.y - 0.05) {\n      // Check if this is a new shot (not too close to previous)\n      const lastEvent = events[events.length - 1];\n      if (!lastEvent || i - lastEvent.frameIndex >= minFramesBetweenShots) {\n        // Calculate elbow extension for overhead\n        const elbowAngle = calculateAngle(rightShoulder, rightElbow, rightWrist);\n\n        events.push({\n          frameIndex: i,\n          timestamp: i / fps,\n          shotType: elbowAngle > 140 ? 'overhead' : 'drive',\n          confidence: (rightWrist.visibility ?? 0.5) * (rightShoulder.visibility ?? 0.5),\n        });\n      }\n    }\n\n    // Detect lunge/netshot (deep knee bend with forward reach)\n    const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n    const rightKnee = landmarks[POSE_LANDMARKS.RIGHT_KNEE];\n    const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n\n    if (rightHip && rightKnee && rightAnkle) {\n      const kneeAngle = calculateAngle(rightHip, rightKnee, rightAnkle);\n      if (kneeAngle < 100) {\n        const lastEvent = events[events.length - 1];\n        if (!lastEvent || i - lastEvent.frameIndex >= minFramesBetweenShots) {\n          events.push({\n            frameIndex: i,\n            timestamp: i / fps,\n            shotType: 'netshot',\n            confidence: Math.min(rightKnee.visibility ?? 0.5, rightAnkle.visibility ?? 0.5),\n          });\n        }\n      }\n    }\n  }\n\n  return events;\n}\n\n/**\n * Find the best rep window from the video\n * This is the highest-quality segment that can be used as ghost overlay\n */\nexport function findBestRepWindow(\n  poseData: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[],\n  shotEvents: ShotEvent[],\n  fps: number = 10\n): GhostRivalData['bestRepWindow'] | null {\n  if (shotEvents.length === 0) {\n    // No shots detected, find best continuous segment\n    return findBestContinuousSegment(poseData, metricsHistory, fps);\n  }\n\n  let bestWindow: GhostRivalData['bestRepWindow'] | null = null;\n  let bestScore = 0;\n\n  for (const shot of shotEvents) {\n    // Define window around shot: 0.8s before to 0.6s after\n    const windowStartFrame = Math.max(0, shot.frameIndex - Math.floor(fps * 0.8));\n    const windowEndFrame = Math.min(poseData.length - 1, shot.frameIndex + Math.floor(fps * 0.6));\n\n    // Extract segment\n    const segmentPoses = poseData.slice(windowStartFrame, windowEndFrame + 1);\n    const segmentMetrics = metricsHistory.slice(windowStartFrame, windowEndFrame + 1);\n\n    // Calculate form quality score\n    const score = calculateSegmentFormScore(segmentPoses, segmentMetrics);\n\n    if (score > bestScore) {\n      bestScore = score;\n      bestWindow = {\n        startTime: windowStartFrame / fps,\n        endTime: windowEndFrame / fps,\n        score,\n        shotType: shot.shotType,\n      };\n    }\n  }\n\n  return bestWindow;\n}\n\n/**\n * Find best continuous segment when no shots are detected\n */\nfunction findBestContinuousSegment(\n  poseData: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[],\n  fps: number\n): GhostRivalData['bestRepWindow'] | null {\n  const windowSize = Math.floor(fps * 1.5); // 1.5 second windows\n  const step = Math.floor(fps * 0.5); // 0.5 second steps\n\n  let bestWindow: GhostRivalData['bestRepWindow'] | null = null;\n  let bestScore = 0;\n\n  for (let start = 0; start + windowSize < poseData.length; start += step) {\n    const segmentPoses = poseData.slice(start, start + windowSize);\n    const segmentMetrics = metricsHistory.slice(start, start + windowSize);\n\n    const score = calculateSegmentFormScore(segmentPoses, segmentMetrics);\n\n    if (score > bestScore) {\n      bestScore = score;\n      bestWindow = {\n        startTime: start / fps,\n        endTime: (start + windowSize) / fps,\n        score,\n        shotType: 'footwork',\n      };\n    }\n  }\n\n  return bestWindow;\n}\n\n/**\n * Extract ghost pose sequence from best rep window\n * Downsamples to GHOST_FPS for efficient rendering\n */\nexport function extractGhostPoseSequence(\n  poseData: (PoseLandmark[] | null)[],\n  bestRepWindow: GhostRivalData['bestRepWindow'],\n  sourceFps: number = 10\n): GhostPoseFrame[] {\n  if (!bestRepWindow) return [];\n\n  const startFrame = Math.floor(bestRepWindow.startTime * sourceFps);\n  const endFrame = Math.floor(bestRepWindow.endTime * sourceFps);\n  const windowDuration = bestRepWindow.endTime - bestRepWindow.startTime;\n\n  const ghostFrames: GhostPoseFrame[] = [];\n\n  // Calculate frame step for downsampling to GHOST_FPS\n  const frameStep = Math.max(1, Math.floor(sourceFps / GHOST_FPS));\n\n  for (let i = startFrame; i <= endFrame; i += frameStep) {\n    const landmarks = poseData[i];\n    if (!landmarks) continue;\n\n    const timestamp = i / sourceFps;\n    const normalizedTime = (timestamp - bestRepWindow.startTime) / windowDuration;\n\n    ghostFrames.push({\n      timestamp,\n      normalizedTime: Math.max(0, Math.min(1, normalizedTime)),\n      landmarks,\n    });\n  }\n\n  return ghostFrames;\n}\n\n/**\n * Get ghost pose for current video time\n * Handles sync between user video time and ghost animation\n */\nexport function getGhostPoseAtTime(\n  ghostData: GhostRivalData,\n  currentTime: number\n): PoseLandmark[] | null {\n  if (!ghostData.enabled || ghostData.poseSequence.length === 0) {\n    return null;\n  }\n\n  const { poseSequence, bestRepWindow } = ghostData;\n\n  if (!bestRepWindow) {\n    // Fallback: use absolute time\n    let closestFrame = poseSequence[0];\n    let minDiff = Infinity;\n\n    for (const frame of poseSequence) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame?.landmarks ?? null;\n  }\n\n  // Use absolute time matching if within window\n  if (currentTime >= bestRepWindow.startTime && currentTime <= bestRepWindow.endTime) {\n    let closestFrame = poseSequence[0];\n    let minDiff = Infinity;\n\n    for (const frame of poseSequence) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame?.landmarks ?? null;\n  }\n\n  // Loop the ghost animation when outside window\n  const windowDuration = bestRepWindow.endTime - bestRepWindow.startTime;\n  const loopTime = ((currentTime - bestRepWindow.startTime) % windowDuration + windowDuration) % windowDuration;\n  const targetTime = bestRepWindow.startTime + loopTime;\n\n  let closestFrame = poseSequence[0];\n  let minDiff = Infinity;\n\n  for (const frame of poseSequence) {\n    const diff = Math.abs(frame.timestamp - targetTime);\n    if (diff < minDiff) {\n      minDiff = diff;\n      closestFrame = frame;\n    }\n  }\n\n  return closestFrame?.landmarks ?? null;\n}\n\n/**\n * Initialize ghost rival data from analysis\n */\nexport function initializeGhostRival(\n  poseData: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[],\n  fps: number = 10\n): GhostRivalData {\n  // Detect shot events\n  const shotEvents = detectShotEvents(poseData, fps);\n\n  // Find best rep window\n  const bestRepWindow = findBestRepWindow(poseData, metricsHistory, shotEvents, fps);\n\n  // Extract ghost pose sequence\n  const poseSequence = bestRepWindow\n    ? extractGhostPoseSequence(poseData, bestRepWindow, fps)\n    : [];\n\n  return {\n    source: 'my-best-rep',\n    enabled: false, // User must enable\n    poseSequence,\n    bestRepWindow: bestRepWindow ?? undefined,\n  };\n}\n","structuredPatch":[],"originalFile":null},"sourceToolAssistantUUID":"ce632397-fe9e-428e-958e-1a3ab278a00f"}
{"parentUuid":"6609b7ce-c2dc-4afb-9e7e-06660025a85f","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01LrkkbMpki3NNQZCoLjctbT","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me create the mistake detection module for Feature 2. This will:1. Detect specific mistake types from pose data\n2. Generate timeline segments with proper timestamps\n3. Provide data for the Fix-It cards","signature":"EvgCCkYICxgCKkBlHFbmBAWVnszSg9x5qFoWVDZ/X1QEx+25afwE4mkcCsdfm9f9G0F8cjwQ2r9124kHJAM380ZoVkLdTC9lrPWpEgx9Gzf1TyIyYR9g47EaDJivWwscEfxYf7mq7SIwhcwHXDc17FbWH+TJOUp4PndYoJVG+0thDAHbHileFek8NSzO+rnN8R8VY6JIG0X2Kt8B5fzAeaTbulX8ml8LHfhqZztNQ1VBEaEpkhKh8gze7VZmaj4LjiQeSw8KUOWrOjrbKmy5Y0Kl0C5E+OTiLveX3iXYOppmEwgrWqweg0ioda1ue5+4OxmQEOAd1Pegex4rRtW9QgkTMh543J9NCe8hZ8SI0nGuLu6244SQPE0ISWDqfyn6nDCLkFbqXF7hciPjRE0RaeP1wshrYVAlQZ94/aOKBwmEI5w+2WH/E/z53ZNirexS2g48pCcYnJp1gpfWmKP4Ttj3AMK6hooR9RIGETejtCr9AeK4I5ZvfzDJ6xgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":3882,"cache_read_input_tokens":131538,"cache_creation":{"ephemeral_5m_input_tokens":3882,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCZGiDNL124hY5zFzMD","type":"assistant","uuid":"add4d60c-506f-4ed0-ab14-8ad14f665940","timestamp":"2026-01-28T05:10:20.772Z"}
{"parentUuid":"add4d60c-506f-4ed0-ab14-8ad14f665940","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01LrkkbMpki3NNQZCoLjctbT","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me create the mistake detection module for Feature 2."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":3882,"cache_read_input_tokens":131538,"cache_creation":{"ephemeral_5m_input_tokens":3882,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCZGiDNL124hY5zFzMD","type":"assistant","uuid":"6965cfe7-5a78-47c6-9ca5-4feb017efe72","timestamp":"2026-01-28T05:10:20.923Z"}
{"parentUuid":"6965cfe7-5a78-47c6-9ca5-4feb017efe72","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01LrkkbMpki3NNQZCoLjctbT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01RLGBrYncD2XASEAhhaDvN4","name":"Write","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","content":"/**\n * Mistake Detection Module\n *\n * Detects specific mistake types from pose data:\n * 1. Overhead contact too low\n * 2. Late/missing split-step\n * 3. Poor lunge recovery\n * 4. Insufficient body rotation\n * 5. Stance too narrow/wide\n *\n * Each mistake includes:\n * - Time range (startTimeSec, endTimeSec)\n * - Severity (0-1)\n * - Confidence (derived from visibility)\n * - Affected joints\n */\n\nimport type {\n  PoseLandmark,\n  PoseMetrics,\n  MistakeEvent,\n  FixKeyframe,\n  TimelineSegment\n} from './types';\nimport { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n\n// Minimum frames to persist an issue before reporting\nconst MIN_PERSISTENCE_FRAMES = 3;\n// Minimum confidence to report a mistake\nconst MIN_CONFIDENCE_THRESHOLD = 0.4;\n\n/**\n * Mistake type definitions with thresholds and feedback\n */\nconst MISTAKE_TYPES = {\n  OVERHEAD_CONTACT_LOW: {\n    code: 'OVERHEAD_CONTACT_LOW',\n    title: 'Contact Point Too Low',\n    description: 'Raise your contact point for better power and angle',\n    severity: 0.8,\n    joints: [\n      POSE_LANDMARKS.RIGHT_WRIST,\n      POSE_LANDMARKS.RIGHT_ELBOW,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n    ],\n  },\n  LATE_SPLIT_STEP: {\n    code: 'LATE_SPLIT_STEP',\n    title: 'Late or Missing Split-Step',\n    description: 'Time your split-step with opponent\\'s contact',\n    severity: 0.6,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n      POSE_LANDMARKS.LEFT_KNEE,\n      POSE_LANDMARKS.RIGHT_KNEE,\n    ],\n  },\n  POOR_LUNGE_RECOVERY: {\n    code: 'POOR_LUNGE_RECOVERY',\n    title: 'Slow Lunge Recovery',\n    description: 'Push off your front foot faster to recover',\n    severity: 0.7,\n    joints: [\n      POSE_LANDMARKS.RIGHT_KNEE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n      POSE_LANDMARKS.LEFT_HIP,\n      POSE_LANDMARKS.RIGHT_HIP,\n    ],\n  },\n  INSUFFICIENT_ROTATION: {\n    code: 'INSUFFICIENT_ROTATION',\n    title: 'Insufficient Body Rotation',\n    description: 'Rotate hips before shoulders for more power',\n    severity: 0.5,\n    joints: [\n      POSE_LANDMARKS.LEFT_SHOULDER,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n      POSE_LANDMARKS.LEFT_HIP,\n      POSE_LANDMARKS.RIGHT_HIP,\n    ],\n  },\n  STANCE_TOO_NARROW: {\n    code: 'STANCE_TOO_NARROW',\n    title: 'Stance Too Narrow',\n    description: 'Widen your stance for better stability',\n    severity: 0.4,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n    ],\n  },\n  STANCE_TOO_WIDE: {\n    code: 'STANCE_TOO_WIDE',\n    title: 'Stance Too Wide',\n    description: 'Narrow your stance for quicker movement',\n    severity: 0.4,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n    ],\n  },\n  ELBOW_TOO_BENT: {\n    code: 'ELBOW_TOO_BENT',\n    title: 'Elbow Too Bent at Contact',\n    description: 'Extend your elbow more at contact point',\n    severity: 0.7,\n    joints: [\n      POSE_LANDMARKS.RIGHT_ELBOW,\n      POSE_LANDMARKS.RIGHT_WRIST,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n    ],\n  },\n};\n\n/**\n * Calculate confidence for a mistake based on joint visibility\n */\nfunction calculateMistakeConfidence(\n  landmarks: PoseLandmark[],\n  jointIndices: number[]\n): number {\n  if (!landmarks || jointIndices.length === 0) return 0;\n\n  let totalVisibility = 0;\n  let count = 0;\n\n  for (const idx of jointIndices) {\n    const landmark = landmarks[idx];\n    if (landmark) {\n      totalVisibility += landmark.visibility ?? 0;\n      count++;\n    }\n  }\n\n  return count > 0 ? totalVisibility / count : 0;\n}\n\n/**\n * Detect overhead contact too low\n */\nfunction detectOverheadContactLow(\n  landmarks: PoseLandmark[]\n): { detected: boolean; confidence: number } {\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const head = landmarks[POSE_LANDMARKS.NOSE];\n\n  if (!rightWrist || !rightShoulder || !head) {\n    return { detected: false, confidence: 0 };\n  }\n\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.OVERHEAD_CONTACT_LOW.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  // Check if wrist is raised (overhead position) but not high enough\n  const isOverheadPosition = rightWrist.y < rightShoulder.y;\n  const isTooLow = isOverheadPosition && rightWrist.y > head.y - 0.05;\n\n  return { detected: isOverheadPosition && isTooLow, confidence };\n}\n\n/**\n * Detect late or missing split-step\n * Checks for stance width changes that indicate split-step\n */\nfunction detectLateSplitStep(\n  currentLandmarks: PoseLandmark[],\n  prevLandmarks: PoseLandmark[] | null,\n  prev2Landmarks: PoseLandmark[] | null\n): { detected: boolean; confidence: number } {\n  if (!prevLandmarks || !prev2Landmarks) {\n    return { detected: false, confidence: 0 };\n  }\n\n  const confidence = calculateMistakeConfidence(currentLandmarks, MISTAKE_TYPES.LATE_SPLIT_STEP.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  // Calculate stance widths\n  const currentStance = calculateStanceWidth(currentLandmarks);\n  const prevStance = calculateStanceWidth(prevLandmarks);\n  const prev2Stance = calculateStanceWidth(prev2Landmarks);\n\n  if (currentStance === 0 || prevStance === 0 || prev2Stance === 0) {\n    return { detected: false, confidence };\n  }\n\n  // Detect if there's a significant movement without split-step\n  // Split-step: quick widening then return\n  const stanceChange = Math.abs(currentStance - prevStance);\n  const prevChange = Math.abs(prevStance - prev2Stance);\n\n  // If there's big movement but no stance change, split-step might be missing\n  const movementWithoutSplitStep = stanceChange < 0.1 && prevChange < 0.1;\n\n  // Check if body is moving (hip position change)\n  const currentHip = currentLandmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const prevHip = prevLandmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const prev2Hip = prev2Landmarks[POSE_LANDMARKS.RIGHT_HIP];\n\n  if (!currentHip || !prevHip || !prev2Hip) {\n    return { detected: false, confidence };\n  }\n\n  const hipMovement = Math.sqrt(\n    Math.pow(currentHip.x - prev2Hip.x, 2) + Math.pow(currentHip.y - prev2Hip.y, 2)\n  );\n\n  // Significant movement without split-step\n  const detected = hipMovement > 0.05 && movementWithoutSplitStep;\n\n  return { detected, confidence };\n}\n\n/**\n * Detect poor lunge recovery\n */\nfunction detectPoorLungeRecovery(\n  currentLandmarks: PoseLandmark[],\n  prevLandmarks: PoseLandmark[] | null,\n  isInLunge: boolean,\n  lungeStartFrame: number,\n  currentFrame: number,\n  fps: number\n): { detected: boolean; confidence: number; isInLunge: boolean; lungeStartFrame: number } {\n  const confidence = calculateMistakeConfidence(currentLandmarks, MISTAKE_TYPES.POOR_LUNGE_RECOVERY.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence, isInLunge, lungeStartFrame };\n  }\n\n  const rightHip = currentLandmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const rightKnee = currentLandmarks[POSE_LANDMARKS.RIGHT_KNEE];\n  const rightAnkle = currentLandmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n\n  if (!rightHip || !rightKnee || !rightAnkle) {\n    return { detected: false, confidence, isInLunge, lungeStartFrame };\n  }\n\n  const kneeAngle = calculateAngle(rightHip, rightKnee, rightAnkle);\n\n  // Detect lunge entry (knee angle < 110)\n  if (!isInLunge && kneeAngle < 110) {\n    return { detected: false, confidence, isInLunge: true, lungeStartFrame: currentFrame };\n  }\n\n  // Check recovery (knee angle back > 145)\n  if (isInLunge && kneeAngle > 145) {\n    const recoveryFrames = currentFrame - lungeStartFrame;\n    const recoveryTime = recoveryFrames / fps;\n\n    // Poor recovery if > 0.8 seconds\n    const isPoorRecovery = recoveryTime > 0.8;\n\n    return { detected: isPoorRecovery, confidence, isInLunge: false, lungeStartFrame: 0 };\n  }\n\n  // Still in lunge\n  if (isInLunge) {\n    const lungeTime = (currentFrame - lungeStartFrame) / fps;\n    // Very poor if in lunge > 1.5 seconds\n    return { detected: lungeTime > 1.5, confidence, isInLunge: true, lungeStartFrame };\n  }\n\n  return { detected: false, confidence, isInLunge, lungeStartFrame };\n}\n\n/**\n * Detect insufficient body rotation\n */\nfunction detectInsufficientRotation(\n  landmarks: PoseLandmark[]\n): { detected: boolean; confidence: number } {\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.INSUFFICIENT_ROTATION.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const leftHip = landmarks[POSE_LANDMARKS.LEFT_HIP];\n  const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n\n  if (!leftShoulder || !rightShoulder || !leftHip || !rightHip || !rightWrist) {\n    return { detected: false, confidence };\n  }\n\n  // Only check rotation during overhead shots\n  if (rightWrist.y > rightShoulder.y) {\n    return { detected: false, confidence };\n  }\n\n  // Calculate rotation angle\n  const shoulderAngle = Math.atan2(\n    rightShoulder.y - leftShoulder.y,\n    rightShoulder.x - leftShoulder.x\n  );\n  const hipAngle = Math.atan2(\n    rightHip.y - leftHip.y,\n    rightHip.x - leftHip.x\n  );\n  const rotationDeg = Math.abs(shoulderAngle - hipAngle) * (180 / Math.PI);\n\n  // Insufficient rotation if < 10 degrees during overhead\n  return { detected: rotationDeg < 10, confidence };\n}\n\n/**\n * Detect stance issues\n */\nfunction detectStanceIssues(\n  landmarks: PoseLandmark[]\n): { tooNarrow: boolean; tooWide: boolean; confidence: number } {\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.STANCE_TOO_NARROW.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { tooNarrow: false, tooWide: false, confidence };\n  }\n\n  const stanceWidth = calculateStanceWidth(landmarks);\n  if (stanceWidth === 0) {\n    return { tooNarrow: false, tooWide: false, confidence };\n  }\n\n  return {\n    tooNarrow: stanceWidth < 0.5,\n    tooWide: stanceWidth > 2.0,\n    confidence,\n  };\n}\n\n/**\n * Detect elbow too bent at contact\n */\nfunction detectElbowTooBent(\n  landmarks: PoseLandmark[]\n): { detected: boolean; confidence: number } {\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.ELBOW_TOO_BENT.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const rightElbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n\n  if (!rightShoulder || !rightElbow || !rightWrist) {\n    return { detected: false, confidence };\n  }\n\n  // Only check during overhead\n  if (rightWrist.y > rightShoulder.y) {\n    return { detected: false, confidence };\n  }\n\n  const elbowAngle = calculateAngle(rightShoulder, rightElbow, rightWrist);\n\n  // Elbow too bent if < 130 degrees during overhead contact\n  return { detected: elbowAngle < 130, confidence };\n}\n\n/**\n * Main function: Detect all mistakes from pose data\n */\nexport function detectMistakes(\n  poseData: (PoseLandmark[] | null)[],\n  fps: number = 10\n): MistakeEvent[] {\n  const mistakes: MistakeEvent[] = [];\n  const activeIssues: Map<string, { startFrame: number; frames: number; confidence: number }> = new Map();\n\n  // State for lunge tracking\n  let isInLunge = false;\n  let lungeStartFrame = 0;\n\n  for (let i = 0; i < poseData.length; i++) {\n    const landmarks = poseData[i];\n    if (!landmarks) continue;\n\n    const prevLandmarks = i > 0 ? poseData[i - 1] : null;\n    const prev2Landmarks = i > 1 ? poseData[i - 2] : null;\n\n    // Check each mistake type\n    const detections: { code: string; detected: boolean; confidence: number }[] = [];\n\n    // Overhead contact too low\n    const overhead = detectOverheadContactLow(landmarks);\n    detections.push({ code: 'OVERHEAD_CONTACT_LOW', ...overhead });\n\n    // Late split-step\n    const splitStep = detectLateSplitStep(landmarks, prevLandmarks, prev2Landmarks);\n    detections.push({ code: 'LATE_SPLIT_STEP', ...splitStep });\n\n    // Poor lunge recovery\n    const lungeResult = detectPoorLungeRecovery(\n      landmarks, prevLandmarks, isInLunge, lungeStartFrame, i, fps\n    );\n    isInLunge = lungeResult.isInLunge;\n    lungeStartFrame = lungeResult.lungeStartFrame;\n    detections.push({ code: 'POOR_LUNGE_RECOVERY', detected: lungeResult.detected, confidence: lungeResult.confidence });\n\n    // Insufficient rotation\n    const rotation = detectInsufficientRotation(landmarks);\n    detections.push({ code: 'INSUFFICIENT_ROTATION', ...rotation });\n\n    // Stance issues\n    const stance = detectStanceIssues(landmarks);\n    if (stance.tooNarrow) {\n      detections.push({ code: 'STANCE_TOO_NARROW', detected: true, confidence: stance.confidence });\n    }\n    if (stance.tooWide) {\n      detections.push({ code: 'STANCE_TOO_WIDE', detected: true, confidence: stance.confidence });\n    }\n\n    // Elbow too bent\n    const elbow = detectElbowTooBent(landmarks);\n    detections.push({ code: 'ELBOW_TOO_BENT', ...elbow });\n\n    // Process detections\n    for (const { code, detected, confidence } of detections) {\n      const issue = activeIssues.get(code);\n\n      if (detected) {\n        if (issue) {\n          // Continue existing issue\n          issue.frames++;\n          issue.confidence = Math.max(issue.confidence, confidence);\n        } else {\n          // Start new issue\n          activeIssues.set(code, { startFrame: i, frames: 1, confidence });\n        }\n      } else if (issue) {\n        // Issue ended - check if it persisted long enough\n        if (issue.frames >= MIN_PERSISTENCE_FRAMES) {\n          const mistakeType = MISTAKE_TYPES[code as keyof typeof MISTAKE_TYPES];\n          if (mistakeType) {\n            mistakes.push({\n              id: `${code}-${issue.startFrame}`,\n              type: code,\n              startTimeSec: issue.startFrame / fps,\n              endTimeSec: i / fps,\n              severity: mistakeType.severity,\n              confidence: issue.confidence,\n              joints: mistakeType.joints,\n              summaryTitle: mistakeType.title,\n              description: mistakeType.description,\n            });\n          }\n        }\n        activeIssues.delete(code);\n      }\n    }\n  }\n\n  // Close any remaining active issues\n  for (const [code, issue] of activeIssues) {\n    if (issue.frames >= MIN_PERSISTENCE_FRAMES) {\n      const mistakeType = MISTAKE_TYPES[code as keyof typeof MISTAKE_TYPES];\n      if (mistakeType) {\n        mistakes.push({\n          id: `${code}-${issue.startFrame}`,\n          type: code,\n          startTimeSec: issue.startFrame / fps,\n          endTimeSec: poseData.length / fps,\n          severity: mistakeType.severity,\n          confidence: issue.confidence,\n          joints: mistakeType.joints,\n          summaryTitle: mistakeType.title,\n          description: mistakeType.description,\n        });\n      }\n    }\n  }\n\n  // Sort by time and merge overlapping segments of same type\n  return mergeMistakes(mistakes);\n}\n\n/**\n * Merge overlapping or adjacent mistakes of the same type\n */\nfunction mergeMistakes(mistakes: MistakeEvent[]): MistakeEvent[] {\n  if (mistakes.length === 0) return [];\n\n  // Sort by type then by start time\n  mistakes.sort((a, b) => {\n    if (a.type !== b.type) return a.type.localeCompare(b.type);\n    return a.startTimeSec - b.startTimeSec;\n  });\n\n  const merged: MistakeEvent[] = [];\n  let current = { ...mistakes[0] };\n\n  for (let i = 1; i < mistakes.length; i++) {\n    const next = mistakes[i];\n\n    if (next.type === current.type && next.startTimeSec <= current.endTimeSec + 0.5) {\n      // Merge\n      current.endTimeSec = Math.max(current.endTimeSec, next.endTimeSec);\n      current.confidence = Math.max(current.confidence, next.confidence);\n    } else {\n      merged.push(current);\n      current = { ...next };\n    }\n  }\n\n  merged.push(current);\n\n  // Sort final result by start time\n  merged.sort((a, b) => a.startTimeSec - b.startTimeSec);\n\n  return merged;\n}\n\n/**\n * Convert mistakes to timeline segments for rendering\n */\nexport function mistakesToTimelineSegments(\n  mistakes: MistakeEvent[],\n  totalDuration: number\n): TimelineSegment[] {\n  if (totalDuration <= 0) return [];\n\n  return mistakes.map(event => ({\n    id: event.id,\n    startPercent: (event.startTimeSec / totalDuration) * 100,\n    widthPercent: ((event.endTimeSec - event.startTimeSec) / totalDuration) * 100,\n    color: getSeverityColor(event.severity),\n    event,\n  }));\n}\n\n/**\n * Get color based on severity\n */\nfunction getSeverityColor(severity: number): string {\n  if (severity >= 0.7) return '#ef4444'; // Red\n  if (severity >= 0.4) return '#f97316'; // Orange\n  return '#eab308'; // Yellow\n}\n\n/**\n * Generate fix keyframes for a mistake\n */\nexport function generateFixKeyframes(\n  mistake: MistakeEvent,\n  poseData: (PoseLandmark[] | null)[],\n  fps: number = 10\n): FixKeyframe[] {\n  const startFrame = Math.floor(mistake.startTimeSec * fps);\n  const endFrame = Math.floor(mistake.endTimeSec * fps);\n\n  const keyframes: FixKeyframe[] = [];\n\n  // Setup phase - frame before mistake\n  const setupFrame = Math.max(0, startFrame - Math.floor(fps * 0.3));\n  if (poseData[setupFrame]) {\n    keyframes.push({\n      phase: 'setup',\n      landmarks: poseData[setupFrame]!,\n      label: 'Setup',\n      correction: getSetupCorrection(mistake.type),\n    });\n  }\n\n  // Contact phase - middle of mistake\n  const contactFrame = Math.floor((startFrame + endFrame) / 2);\n  if (poseData[contactFrame]) {\n    keyframes.push({\n      phase: 'contact',\n      landmarks: poseData[contactFrame]!,\n      label: 'Contact',\n      correction: getContactCorrection(mistake.type),\n    });\n  }\n\n  // Recovery phase - frame after mistake\n  const recoveryFrame = Math.min(poseData.length - 1, endFrame + Math.floor(fps * 0.3));\n  if (poseData[recoveryFrame]) {\n    keyframes.push({\n      phase: 'recover',\n      landmarks: poseData[recoveryFrame]!,\n      label: 'Recovery',\n      correction: getRecoveryCorrection(mistake.type),\n    });\n  }\n\n  return keyframes;\n}\n\nfunction getSetupCorrection(mistakeType: string): string {\n  switch (mistakeType) {\n    case 'OVERHEAD_CONTACT_LOW':\n      return 'Position yourself under the shuttle early';\n    case 'LATE_SPLIT_STEP':\n      return 'Watch opponent\\'s racket for timing';\n    case 'POOR_LUNGE_RECOVERY':\n      return 'Prepare to push off front foot';\n    case 'INSUFFICIENT_ROTATION':\n      return 'Turn sideways to the net';\n    default:\n      return 'Ready position';\n  }\n}\n\nfunction getContactCorrection(mistakeType: string): string {\n  switch (mistakeType) {\n    case 'OVERHEAD_CONTACT_LOW':\n      return 'Hit at the highest point above your head';\n    case 'LATE_SPLIT_STEP':\n      return 'Land with both feet as opponent hits';\n    case 'POOR_LUNGE_RECOVERY':\n      return 'Push through heel immediately';\n    case 'INSUFFICIENT_ROTATION':\n      return 'Rotate hips then shoulders';\n    case 'ELBOW_TOO_BENT':\n      return 'Extend elbow fully at contact';\n    default:\n      return 'Contact point';\n  }\n}\n\nfunction getRecoveryCorrection(mistakeType: string): string {\n  switch (mistakeType) {\n    case 'POOR_LUNGE_RECOVERY':\n      return 'Return to center quickly';\n    case 'LATE_SPLIT_STEP':\n      return 'Move explosively after landing';\n    default:\n      return 'Return to ready position';\n  }\n}\n\n// Helper function\nfunction calculateStanceWidth(landmarks: PoseLandmark[]): number {\n  const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n  const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n\n  if (!leftAnkle || !rightAnkle || !leftShoulder || !rightShoulder) return 0;\n  if ((leftAnkle.visibility ?? 0) < 0.5 || (rightAnkle.visibility ?? 0) < 0.5) return 0;\n\n  const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n  const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n\n  return shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n}\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":3882,"cache_read_input_tokens":131538,"cache_creation":{"ephemeral_5m_input_tokens":3882,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCZGiDNL124hY5zFzMD","type":"assistant","uuid":"03355f6e-0483-429a-a40b-d049b3febe54","timestamp":"2026-01-28T05:11:30.906Z"}
{"type":"file-history-snapshot","messageId":"03355f6e-0483-429a-a40b-d049b3febe54","snapshot":{"messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","trackedFileBackups":{"supabase-migration-v3-features.sql":{"backupFileName":null,"version":1,"backupTime":"2026-01-28T05:08:12.613Z"},"rallycoach\\src\\lib\\types.ts":{"backupFileName":"1048a9baa3a842fc@v1","version":1,"backupTime":"2026-01-28T05:08:34.814Z"},"rallycoach\\src\\lib\\skill-scoring.ts":{"backupFileName":"1012db229ac5a83c@v1","version":1,"backupTime":"2026-01-28T05:09:30.561Z"},"rallycoach\\src\\lib\\ghost-overlay.ts":{"backupFileName":"c0850482504218d5@v1","version":1,"backupTime":"2026-01-28T05:10:17.275Z"},"rallycoach\\src\\lib\\mistake-detection.ts":{"backupFileName":"984c328d1d43cc63@v1","version":1,"backupTime":"2026-01-28T05:11:31.523Z"}},"timestamp":"2026-01-28T05:05:21.590Z"},"isSnapshotUpdate":true}
{"parentUuid":"03355f6e-0483-429a-a40b-d049b3febe54","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RLGBrYncD2XASEAhhaDvN4","type":"tool_result","content":"File created successfully at: C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts"}]},"uuid":"82c14cf5-7472-40a2-9a16-84089622f4af","timestamp":"2026-01-28T05:11:31.519Z","toolUseResult":{"type":"create","filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","content":"/**\n * Mistake Detection Module\n *\n * Detects specific mistake types from pose data:\n * 1. Overhead contact too low\n * 2. Late/missing split-step\n * 3. Poor lunge recovery\n * 4. Insufficient body rotation\n * 5. Stance too narrow/wide\n *\n * Each mistake includes:\n * - Time range (startTimeSec, endTimeSec)\n * - Severity (0-1)\n * - Confidence (derived from visibility)\n * - Affected joints\n */\n\nimport type {\n  PoseLandmark,\n  PoseMetrics,\n  MistakeEvent,\n  FixKeyframe,\n  TimelineSegment\n} from './types';\nimport { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n\n// Minimum frames to persist an issue before reporting\nconst MIN_PERSISTENCE_FRAMES = 3;\n// Minimum confidence to report a mistake\nconst MIN_CONFIDENCE_THRESHOLD = 0.4;\n\n/**\n * Mistake type definitions with thresholds and feedback\n */\nconst MISTAKE_TYPES = {\n  OVERHEAD_CONTACT_LOW: {\n    code: 'OVERHEAD_CONTACT_LOW',\n    title: 'Contact Point Too Low',\n    description: 'Raise your contact point for better power and angle',\n    severity: 0.8,\n    joints: [\n      POSE_LANDMARKS.RIGHT_WRIST,\n      POSE_LANDMARKS.RIGHT_ELBOW,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n    ],\n  },\n  LATE_SPLIT_STEP: {\n    code: 'LATE_SPLIT_STEP',\n    title: 'Late or Missing Split-Step',\n    description: 'Time your split-step with opponent\\'s contact',\n    severity: 0.6,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n      POSE_LANDMARKS.LEFT_KNEE,\n      POSE_LANDMARKS.RIGHT_KNEE,\n    ],\n  },\n  POOR_LUNGE_RECOVERY: {\n    code: 'POOR_LUNGE_RECOVERY',\n    title: 'Slow Lunge Recovery',\n    description: 'Push off your front foot faster to recover',\n    severity: 0.7,\n    joints: [\n      POSE_LANDMARKS.RIGHT_KNEE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n      POSE_LANDMARKS.LEFT_HIP,\n      POSE_LANDMARKS.RIGHT_HIP,\n    ],\n  },\n  INSUFFICIENT_ROTATION: {\n    code: 'INSUFFICIENT_ROTATION',\n    title: 'Insufficient Body Rotation',\n    description: 'Rotate hips before shoulders for more power',\n    severity: 0.5,\n    joints: [\n      POSE_LANDMARKS.LEFT_SHOULDER,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n      POSE_LANDMARKS.LEFT_HIP,\n      POSE_LANDMARKS.RIGHT_HIP,\n    ],\n  },\n  STANCE_TOO_NARROW: {\n    code: 'STANCE_TOO_NARROW',\n    title: 'Stance Too Narrow',\n    description: 'Widen your stance for better stability',\n    severity: 0.4,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n    ],\n  },\n  STANCE_TOO_WIDE: {\n    code: 'STANCE_TOO_WIDE',\n    title: 'Stance Too Wide',\n    description: 'Narrow your stance for quicker movement',\n    severity: 0.4,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n    ],\n  },\n  ELBOW_TOO_BENT: {\n    code: 'ELBOW_TOO_BENT',\n    title: 'Elbow Too Bent at Contact',\n    description: 'Extend your elbow more at contact point',\n    severity: 0.7,\n    joints: [\n      POSE_LANDMARKS.RIGHT_ELBOW,\n      POSE_LANDMARKS.RIGHT_WRIST,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n    ],\n  },\n};\n\n/**\n * Calculate confidence for a mistake based on joint visibility\n */\nfunction calculateMistakeConfidence(\n  landmarks: PoseLandmark[],\n  jointIndices: number[]\n): number {\n  if (!landmarks || jointIndices.length === 0) return 0;\n\n  let totalVisibility = 0;\n  let count = 0;\n\n  for (const idx of jointIndices) {\n    const landmark = landmarks[idx];\n    if (landmark) {\n      totalVisibility += landmark.visibility ?? 0;\n      count++;\n    }\n  }\n\n  return count > 0 ? totalVisibility / count : 0;\n}\n\n/**\n * Detect overhead contact too low\n */\nfunction detectOverheadContactLow(\n  landmarks: PoseLandmark[]\n): { detected: boolean; confidence: number } {\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const head = landmarks[POSE_LANDMARKS.NOSE];\n\n  if (!rightWrist || !rightShoulder || !head) {\n    return { detected: false, confidence: 0 };\n  }\n\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.OVERHEAD_CONTACT_LOW.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  // Check if wrist is raised (overhead position) but not high enough\n  const isOverheadPosition = rightWrist.y < rightShoulder.y;\n  const isTooLow = isOverheadPosition && rightWrist.y > head.y - 0.05;\n\n  return { detected: isOverheadPosition && isTooLow, confidence };\n}\n\n/**\n * Detect late or missing split-step\n * Checks for stance width changes that indicate split-step\n */\nfunction detectLateSplitStep(\n  currentLandmarks: PoseLandmark[],\n  prevLandmarks: PoseLandmark[] | null,\n  prev2Landmarks: PoseLandmark[] | null\n): { detected: boolean; confidence: number } {\n  if (!prevLandmarks || !prev2Landmarks) {\n    return { detected: false, confidence: 0 };\n  }\n\n  const confidence = calculateMistakeConfidence(currentLandmarks, MISTAKE_TYPES.LATE_SPLIT_STEP.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  // Calculate stance widths\n  const currentStance = calculateStanceWidth(currentLandmarks);\n  const prevStance = calculateStanceWidth(prevLandmarks);\n  const prev2Stance = calculateStanceWidth(prev2Landmarks);\n\n  if (currentStance === 0 || prevStance === 0 || prev2Stance === 0) {\n    return { detected: false, confidence };\n  }\n\n  // Detect if there's a significant movement without split-step\n  // Split-step: quick widening then return\n  const stanceChange = Math.abs(currentStance - prevStance);\n  const prevChange = Math.abs(prevStance - prev2Stance);\n\n  // If there's big movement but no stance change, split-step might be missing\n  const movementWithoutSplitStep = stanceChange < 0.1 && prevChange < 0.1;\n\n  // Check if body is moving (hip position change)\n  const currentHip = currentLandmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const prevHip = prevLandmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const prev2Hip = prev2Landmarks[POSE_LANDMARKS.RIGHT_HIP];\n\n  if (!currentHip || !prevHip || !prev2Hip) {\n    return { detected: false, confidence };\n  }\n\n  const hipMovement = Math.sqrt(\n    Math.pow(currentHip.x - prev2Hip.x, 2) + Math.pow(currentHip.y - prev2Hip.y, 2)\n  );\n\n  // Significant movement without split-step\n  const detected = hipMovement > 0.05 && movementWithoutSplitStep;\n\n  return { detected, confidence };\n}\n\n/**\n * Detect poor lunge recovery\n */\nfunction detectPoorLungeRecovery(\n  currentLandmarks: PoseLandmark[],\n  prevLandmarks: PoseLandmark[] | null,\n  isInLunge: boolean,\n  lungeStartFrame: number,\n  currentFrame: number,\n  fps: number\n): { detected: boolean; confidence: number; isInLunge: boolean; lungeStartFrame: number } {\n  const confidence = calculateMistakeConfidence(currentLandmarks, MISTAKE_TYPES.POOR_LUNGE_RECOVERY.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence, isInLunge, lungeStartFrame };\n  }\n\n  const rightHip = currentLandmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const rightKnee = currentLandmarks[POSE_LANDMARKS.RIGHT_KNEE];\n  const rightAnkle = currentLandmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n\n  if (!rightHip || !rightKnee || !rightAnkle) {\n    return { detected: false, confidence, isInLunge, lungeStartFrame };\n  }\n\n  const kneeAngle = calculateAngle(rightHip, rightKnee, rightAnkle);\n\n  // Detect lunge entry (knee angle < 110)\n  if (!isInLunge && kneeAngle < 110) {\n    return { detected: false, confidence, isInLunge: true, lungeStartFrame: currentFrame };\n  }\n\n  // Check recovery (knee angle back > 145)\n  if (isInLunge && kneeAngle > 145) {\n    const recoveryFrames = currentFrame - lungeStartFrame;\n    const recoveryTime = recoveryFrames / fps;\n\n    // Poor recovery if > 0.8 seconds\n    const isPoorRecovery = recoveryTime > 0.8;\n\n    return { detected: isPoorRecovery, confidence, isInLunge: false, lungeStartFrame: 0 };\n  }\n\n  // Still in lunge\n  if (isInLunge) {\n    const lungeTime = (currentFrame - lungeStartFrame) / fps;\n    // Very poor if in lunge > 1.5 seconds\n    return { detected: lungeTime > 1.5, confidence, isInLunge: true, lungeStartFrame };\n  }\n\n  return { detected: false, confidence, isInLunge, lungeStartFrame };\n}\n\n/**\n * Detect insufficient body rotation\n */\nfunction detectInsufficientRotation(\n  landmarks: PoseLandmark[]\n): { detected: boolean; confidence: number } {\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.INSUFFICIENT_ROTATION.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const leftHip = landmarks[POSE_LANDMARKS.LEFT_HIP];\n  const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n\n  if (!leftShoulder || !rightShoulder || !leftHip || !rightHip || !rightWrist) {\n    return { detected: false, confidence };\n  }\n\n  // Only check rotation during overhead shots\n  if (rightWrist.y > rightShoulder.y) {\n    return { detected: false, confidence };\n  }\n\n  // Calculate rotation angle\n  const shoulderAngle = Math.atan2(\n    rightShoulder.y - leftShoulder.y,\n    rightShoulder.x - leftShoulder.x\n  );\n  const hipAngle = Math.atan2(\n    rightHip.y - leftHip.y,\n    rightHip.x - leftHip.x\n  );\n  const rotationDeg = Math.abs(shoulderAngle - hipAngle) * (180 / Math.PI);\n\n  // Insufficient rotation if < 10 degrees during overhead\n  return { detected: rotationDeg < 10, confidence };\n}\n\n/**\n * Detect stance issues\n */\nfunction detectStanceIssues(\n  landmarks: PoseLandmark[]\n): { tooNarrow: boolean; tooWide: boolean; confidence: number } {\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.STANCE_TOO_NARROW.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { tooNarrow: false, tooWide: false, confidence };\n  }\n\n  const stanceWidth = calculateStanceWidth(landmarks);\n  if (stanceWidth === 0) {\n    return { tooNarrow: false, tooWide: false, confidence };\n  }\n\n  return {\n    tooNarrow: stanceWidth < 0.5,\n    tooWide: stanceWidth > 2.0,\n    confidence,\n  };\n}\n\n/**\n * Detect elbow too bent at contact\n */\nfunction detectElbowTooBent(\n  landmarks: PoseLandmark[]\n): { detected: boolean; confidence: number } {\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.ELBOW_TOO_BENT.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const rightElbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n\n  if (!rightShoulder || !rightElbow || !rightWrist) {\n    return { detected: false, confidence };\n  }\n\n  // Only check during overhead\n  if (rightWrist.y > rightShoulder.y) {\n    return { detected: false, confidence };\n  }\n\n  const elbowAngle = calculateAngle(rightShoulder, rightElbow, rightWrist);\n\n  // Elbow too bent if < 130 degrees during overhead contact\n  return { detected: elbowAngle < 130, confidence };\n}\n\n/**\n * Main function: Detect all mistakes from pose data\n */\nexport function detectMistakes(\n  poseData: (PoseLandmark[] | null)[],\n  fps: number = 10\n): MistakeEvent[] {\n  const mistakes: MistakeEvent[] = [];\n  const activeIssues: Map<string, { startFrame: number; frames: number; confidence: number }> = new Map();\n\n  // State for lunge tracking\n  let isInLunge = false;\n  let lungeStartFrame = 0;\n\n  for (let i = 0; i < poseData.length; i++) {\n    const landmarks = poseData[i];\n    if (!landmarks) continue;\n\n    const prevLandmarks = i > 0 ? poseData[i - 1] : null;\n    const prev2Landmarks = i > 1 ? poseData[i - 2] : null;\n\n    // Check each mistake type\n    const detections: { code: string; detected: boolean; confidence: number }[] = [];\n\n    // Overhead contact too low\n    const overhead = detectOverheadContactLow(landmarks);\n    detections.push({ code: 'OVERHEAD_CONTACT_LOW', ...overhead });\n\n    // Late split-step\n    const splitStep = detectLateSplitStep(landmarks, prevLandmarks, prev2Landmarks);\n    detections.push({ code: 'LATE_SPLIT_STEP', ...splitStep });\n\n    // Poor lunge recovery\n    const lungeResult = detectPoorLungeRecovery(\n      landmarks, prevLandmarks, isInLunge, lungeStartFrame, i, fps\n    );\n    isInLunge = lungeResult.isInLunge;\n    lungeStartFrame = lungeResult.lungeStartFrame;\n    detections.push({ code: 'POOR_LUNGE_RECOVERY', detected: lungeResult.detected, confidence: lungeResult.confidence });\n\n    // Insufficient rotation\n    const rotation = detectInsufficientRotation(landmarks);\n    detections.push({ code: 'INSUFFICIENT_ROTATION', ...rotation });\n\n    // Stance issues\n    const stance = detectStanceIssues(landmarks);\n    if (stance.tooNarrow) {\n      detections.push({ code: 'STANCE_TOO_NARROW', detected: true, confidence: stance.confidence });\n    }\n    if (stance.tooWide) {\n      detections.push({ code: 'STANCE_TOO_WIDE', detected: true, confidence: stance.confidence });\n    }\n\n    // Elbow too bent\n    const elbow = detectElbowTooBent(landmarks);\n    detections.push({ code: 'ELBOW_TOO_BENT', ...elbow });\n\n    // Process detections\n    for (const { code, detected, confidence } of detections) {\n      const issue = activeIssues.get(code);\n\n      if (detected) {\n        if (issue) {\n          // Continue existing issue\n          issue.frames++;\n          issue.confidence = Math.max(issue.confidence, confidence);\n        } else {\n          // Start new issue\n          activeIssues.set(code, { startFrame: i, frames: 1, confidence });\n        }\n      } else if (issue) {\n        // Issue ended - check if it persisted long enough\n        if (issue.frames >= MIN_PERSISTENCE_FRAMES) {\n          const mistakeType = MISTAKE_TYPES[code as keyof typeof MISTAKE_TYPES];\n          if (mistakeType) {\n            mistakes.push({\n              id: `${code}-${issue.startFrame}`,\n              type: code,\n              startTimeSec: issue.startFrame / fps,\n              endTimeSec: i / fps,\n              severity: mistakeType.severity,\n              confidence: issue.confidence,\n              joints: mistakeType.joints,\n              summaryTitle: mistakeType.title,\n              description: mistakeType.description,\n            });\n          }\n        }\n        activeIssues.delete(code);\n      }\n    }\n  }\n\n  // Close any remaining active issues\n  for (const [code, issue] of activeIssues) {\n    if (issue.frames >= MIN_PERSISTENCE_FRAMES) {\n      const mistakeType = MISTAKE_TYPES[code as keyof typeof MISTAKE_TYPES];\n      if (mistakeType) {\n        mistakes.push({\n          id: `${code}-${issue.startFrame}`,\n          type: code,\n          startTimeSec: issue.startFrame / fps,\n          endTimeSec: poseData.length / fps,\n          severity: mistakeType.severity,\n          confidence: issue.confidence,\n          joints: mistakeType.joints,\n          summaryTitle: mistakeType.title,\n          description: mistakeType.description,\n        });\n      }\n    }\n  }\n\n  // Sort by time and merge overlapping segments of same type\n  return mergeMistakes(mistakes);\n}\n\n/**\n * Merge overlapping or adjacent mistakes of the same type\n */\nfunction mergeMistakes(mistakes: MistakeEvent[]): MistakeEvent[] {\n  if (mistakes.length === 0) return [];\n\n  // Sort by type then by start time\n  mistakes.sort((a, b) => {\n    if (a.type !== b.type) return a.type.localeCompare(b.type);\n    return a.startTimeSec - b.startTimeSec;\n  });\n\n  const merged: MistakeEvent[] = [];\n  let current = { ...mistakes[0] };\n\n  for (let i = 1; i < mistakes.length; i++) {\n    const next = mistakes[i];\n\n    if (next.type === current.type && next.startTimeSec <= current.endTimeSec + 0.5) {\n      // Merge\n      current.endTimeSec = Math.max(current.endTimeSec, next.endTimeSec);\n      current.confidence = Math.max(current.confidence, next.confidence);\n    } else {\n      merged.push(current);\n      current = { ...next };\n    }\n  }\n\n  merged.push(current);\n\n  // Sort final result by start time\n  merged.sort((a, b) => a.startTimeSec - b.startTimeSec);\n\n  return merged;\n}\n\n/**\n * Convert mistakes to timeline segments for rendering\n */\nexport function mistakesToTimelineSegments(\n  mistakes: MistakeEvent[],\n  totalDuration: number\n): TimelineSegment[] {\n  if (totalDuration <= 0) return [];\n\n  return mistakes.map(event => ({\n    id: event.id,\n    startPercent: (event.startTimeSec / totalDuration) * 100,\n    widthPercent: ((event.endTimeSec - event.startTimeSec) / totalDuration) * 100,\n    color: getSeverityColor(event.severity),\n    event,\n  }));\n}\n\n/**\n * Get color based on severity\n */\nfunction getSeverityColor(severity: number): string {\n  if (severity >= 0.7) return '#ef4444'; // Red\n  if (severity >= 0.4) return '#f97316'; // Orange\n  return '#eab308'; // Yellow\n}\n\n/**\n * Generate fix keyframes for a mistake\n */\nexport function generateFixKeyframes(\n  mistake: MistakeEvent,\n  poseData: (PoseLandmark[] | null)[],\n  fps: number = 10\n): FixKeyframe[] {\n  const startFrame = Math.floor(mistake.startTimeSec * fps);\n  const endFrame = Math.floor(mistake.endTimeSec * fps);\n\n  const keyframes: FixKeyframe[] = [];\n\n  // Setup phase - frame before mistake\n  const setupFrame = Math.max(0, startFrame - Math.floor(fps * 0.3));\n  if (poseData[setupFrame]) {\n    keyframes.push({\n      phase: 'setup',\n      landmarks: poseData[setupFrame]!,\n      label: 'Setup',\n      correction: getSetupCorrection(mistake.type),\n    });\n  }\n\n  // Contact phase - middle of mistake\n  const contactFrame = Math.floor((startFrame + endFrame) / 2);\n  if (poseData[contactFrame]) {\n    keyframes.push({\n      phase: 'contact',\n      landmarks: poseData[contactFrame]!,\n      label: 'Contact',\n      correction: getContactCorrection(mistake.type),\n    });\n  }\n\n  // Recovery phase - frame after mistake\n  const recoveryFrame = Math.min(poseData.length - 1, endFrame + Math.floor(fps * 0.3));\n  if (poseData[recoveryFrame]) {\n    keyframes.push({\n      phase: 'recover',\n      landmarks: poseData[recoveryFrame]!,\n      label: 'Recovery',\n      correction: getRecoveryCorrection(mistake.type),\n    });\n  }\n\n  return keyframes;\n}\n\nfunction getSetupCorrection(mistakeType: string): string {\n  switch (mistakeType) {\n    case 'OVERHEAD_CONTACT_LOW':\n      return 'Position yourself under the shuttle early';\n    case 'LATE_SPLIT_STEP':\n      return 'Watch opponent\\'s racket for timing';\n    case 'POOR_LUNGE_RECOVERY':\n      return 'Prepare to push off front foot';\n    case 'INSUFFICIENT_ROTATION':\n      return 'Turn sideways to the net';\n    default:\n      return 'Ready position';\n  }\n}\n\nfunction getContactCorrection(mistakeType: string): string {\n  switch (mistakeType) {\n    case 'OVERHEAD_CONTACT_LOW':\n      return 'Hit at the highest point above your head';\n    case 'LATE_SPLIT_STEP':\n      return 'Land with both feet as opponent hits';\n    case 'POOR_LUNGE_RECOVERY':\n      return 'Push through heel immediately';\n    case 'INSUFFICIENT_ROTATION':\n      return 'Rotate hips then shoulders';\n    case 'ELBOW_TOO_BENT':\n      return 'Extend elbow fully at contact';\n    default:\n      return 'Contact point';\n  }\n}\n\nfunction getRecoveryCorrection(mistakeType: string): string {\n  switch (mistakeType) {\n    case 'POOR_LUNGE_RECOVERY':\n      return 'Return to center quickly';\n    case 'LATE_SPLIT_STEP':\n      return 'Move explosively after landing';\n    default:\n      return 'Return to ready position';\n  }\n}\n\n// Helper function\nfunction calculateStanceWidth(landmarks: PoseLandmark[]): number {\n  const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n  const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n\n  if (!leftAnkle || !rightAnkle || !leftShoulder || !rightShoulder) return 0;\n  if ((leftAnkle.visibility ?? 0) < 0.5 || (rightAnkle.visibility ?? 0) < 0.5) return 0;\n\n  const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n  const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n\n  return shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n}\n","structuredPatch":[],"originalFile":null},"sourceToolAssistantUUID":"03355f6e-0483-429a-a40b-d049b3febe54"}
{"parentUuid":"82c14cf5-7472-40a2-9a16-84089622f4af","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013koQ27iAdENtbyzogGpkuJ","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to create the UI components. Let me create:1. MistakeTimeline.tsx - The horizontal timeline component2. FixItCard.tsx - The animated fix-it card3. SkillMeter.tsx - Skill score badge + confidence meter4. GhostOverlay logic in the existing skeleton render\n\nLet me start with the MistakeTimeline component.","signature":"EuEDCkYICxgCKkCAebe5THWl7YWJ3mXbcTvwhCKgkS5uXkvSAL8rRGBn81BnDTErjw+RMNdG83VP3ExR5NyPoWeguGMV3GxElLIrEgwrtFACBO94SwNPliQaDE2j97TisD/3+d6SmiIw/1Z3POkdNHwB6dLtJW2heDAmqX59/+naJzVXUY1W3btYq2FJDwRCc9cJW2RIfhgtKsgCeuK1J0+02or6lyOorHvnYvquHSbwTOwTemU3lXhJqWGz6xgZWiEBZbfMmlxQhtONYu6OvyFKqEvKyYUI8jYWDkMwFHyWtoORu/DDpl81aMUn7/VXQbQE4CdX5QLmzOtVf6TPWfbPOJWH0OP3eQ37vZyn7hvZHXu+rrdWdsJv008rrx0T1od8Ad/tczh59kJZtOI1Sc/Y7US3oGijbPo1w1brFRST9r6CuuAQ5SCUqq+TYP2xZX+BrUETqB/czVHpyYyejmXxOONznlcVeOr9YMXdEXvB8Nf0yQB0NbLHrZnHE13z7nSwuNsbIVTlH7rM+3xo6OPiECD8vcMQfEzdHfg2NBxC+EvYJa/Vaga4fMoyV7i0+9ISuMVcQ7ADudxhP8TZEXemH/5wUWOCkfLXLy7ytvQK8+JQ+jG+JqZOe8VHeRWZkyiUOBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":6840,"cache_read_input_tokens":135420,"cache_creation":{"ephemeral_5m_input_tokens":6840,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCekKXE8Lor5L85frbp","type":"assistant","uuid":"07aa18d0-8f09-4010-8aa7-8fc7319cf00a","timestamp":"2026-01-28T05:11:36.321Z"}
{"parentUuid":"07aa18d0-8f09-4010-8aa7-8fc7319cf00a","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013koQ27iAdENtbyzogGpkuJ","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me create the UI components. First, the MistakeTimeline component."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":6840,"cache_read_input_tokens":135420,"cache_creation":{"ephemeral_5m_input_tokens":6840,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCekKXE8Lor5L85frbp","type":"assistant","uuid":"968560c1-b70c-4d77-b40f-9a616e9b2eae","timestamp":"2026-01-28T05:11:36.740Z"}
{"parentUuid":"968560c1-b70c-4d77-b40f-9a616e9b2eae","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013koQ27iAdENtbyzogGpkuJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VZie3RhLXLTf5iSSVmCPdP","name":"Write","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\MistakeTimeline.tsx","content":"'use client';\n\nimport { useRef, useCallback, useMemo } from 'react';\nimport type { MistakeEvent, TimelineSegment } from '@/lib/types';\n\ninterface MistakeTimelineProps {\n  mistakes: MistakeEvent[];\n  duration: number;\n  currentTime: number;\n  onSeek: (time: number) => void;\n  onSelectMistake: (mistake: MistakeEvent | null) => void;\n  selectedMistakeId?: string | null;\n}\n\nexport default function MistakeTimeline({\n  mistakes,\n  duration,\n  currentTime,\n  onSeek,\n  onSelectMistake,\n  selectedMistakeId,\n}: MistakeTimelineProps) {\n  const timelineRef = useRef<HTMLDivElement>(null);\n\n  // Convert mistakes to timeline segments\n  const segments = useMemo((): TimelineSegment[] => {\n    if (duration <= 0) return [];\n\n    return mistakes.map(event => ({\n      id: event.id,\n      startPercent: (event.startTimeSec / duration) * 100,\n      widthPercent: Math.max(1, ((event.endTimeSec - event.startTimeSec) / duration) * 100),\n      color: getSeverityColor(event.severity),\n      event,\n    }));\n  }, [mistakes, duration]);\n\n  // Calculate playhead position\n  const playheadPercent = duration > 0 ? (currentTime / duration) * 100 : 0;\n\n  // Handle click on timeline\n  const handleTimelineClick = useCallback((e: React.MouseEvent<HTMLDivElement>) => {\n    if (!timelineRef.current || duration <= 0) return;\n\n    const rect = timelineRef.current.getBoundingClientRect();\n    const clickX = e.clientX - rect.left;\n    const percent = (clickX / rect.width) * 100;\n    const time = (percent / 100) * duration;\n\n    // Seek to clicked time\n    onSeek(Math.max(0, Math.min(duration, time)));\n\n    // Check if clicking on a segment\n    const clickedSegment = segments.find(seg =>\n      percent >= seg.startPercent && percent <= seg.startPercent + seg.widthPercent\n    );\n\n    if (clickedSegment) {\n      onSelectMistake(clickedSegment.event);\n    } else {\n      onSelectMistake(null);\n    }\n  }, [duration, segments, onSeek, onSelectMistake]);\n\n  // Handle segment click\n  const handleSegmentClick = useCallback((e: React.MouseEvent, segment: TimelineSegment) => {\n    e.stopPropagation();\n    onSeek(segment.event.startTimeSec);\n    onSelectMistake(segment.event);\n  }, [onSeek, onSelectMistake]);\n\n  // Format time for display\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Check if current time is within a mistake\n  const currentMistake = useMemo(() => {\n    return mistakes.find(m =>\n      currentTime >= m.startTimeSec && currentTime <= m.endTimeSec\n    );\n  }, [mistakes, currentTime]);\n\n  return (\n    <div className=\"w-full space-y-2\">\n      {/* Timeline label */}\n      <div className=\"flex items-center justify-between text-xs text-gray-500\">\n        <span>Mistake Timeline</span>\n        <span>{formatTime(currentTime)} / {formatTime(duration)}</span>\n      </div>\n\n      {/* Timeline container */}\n      <div\n        ref={timelineRef}\n        onClick={handleTimelineClick}\n        className=\"relative h-8 bg-gray-200 rounded-lg overflow-hidden cursor-pointer hover:bg-gray-300 transition-colors\"\n      >\n        {/* Mistake segments */}\n        {segments.map(segment => (\n          <button\n            key={segment.id}\n            onClick={(e) => handleSegmentClick(e, segment)}\n            className={`absolute top-0 bottom-0 rounded transition-all ${\n              selectedMistakeId === segment.id\n                ? 'ring-2 ring-white ring-offset-1 z-10'\n                : 'hover:opacity-90'\n            }`}\n            style={{\n              left: `${segment.startPercent}%`,\n              width: `${segment.widthPercent}%`,\n              backgroundColor: segment.color,\n              minWidth: '4px',\n            }}\n            title={`${segment.event.summaryTitle} (${formatTime(segment.event.startTimeSec)})`}\n          >\n            {/* Show label if segment is wide enough */}\n            {segment.widthPercent > 8 && (\n              <span className=\"absolute inset-0 flex items-center justify-center text-white text-xs font-medium truncate px-1\">\n                {segment.event.summaryTitle}\n              </span>\n            )}\n          </button>\n        ))}\n\n        {/* Playhead */}\n        <div\n          className=\"absolute top-0 bottom-0 w-0.5 bg-white shadow-lg z-20 pointer-events-none\"\n          style={{ left: `${playheadPercent}%` }}\n        >\n          {/* Playhead triangle */}\n          <div className=\"absolute -top-1 left-1/2 -translate-x-1/2 w-0 h-0 border-l-[4px] border-l-transparent border-r-[4px] border-r-transparent border-t-[6px] border-t-white\"></div>\n        </div>\n\n        {/* Current time indicator */}\n        {currentMistake && (\n          <div className=\"absolute bottom-0 left-0 right-0 h-1 bg-white/30\"></div>\n        )}\n      </div>\n\n      {/* Legend */}\n      <div className=\"flex items-center gap-4 text-xs text-gray-600\">\n        <div className=\"flex items-center gap-1\">\n          <div className=\"w-3 h-3 rounded bg-red-500\"></div>\n          <span>High</span>\n        </div>\n        <div className=\"flex items-center gap-1\">\n          <div className=\"w-3 h-3 rounded bg-orange-500\"></div>\n          <span>Medium</span>\n        </div>\n        <div className=\"flex items-center gap-1\">\n          <div className=\"w-3 h-3 rounded bg-yellow-500\"></div>\n          <span>Low</span>\n        </div>\n        <span className=\"ml-auto text-gray-400\">Click to seek</span>\n      </div>\n\n      {/* Current mistake indicator */}\n      {currentMistake && (\n        <div className=\"flex items-center gap-2 p-2 bg-red-50 border border-red-200 rounded-lg\">\n          <span className=\"w-2 h-2 rounded-full bg-red-500 animate-pulse\"></span>\n          <span className=\"text-sm text-red-800 font-medium\">\n            {currentMistake.summaryTitle}\n          </span>\n          <span className=\"text-xs text-red-600 ml-auto\">\n            {Math.round(currentMistake.confidence * 100)}% confidence\n          </span>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// Helper function for severity colors\nfunction getSeverityColor(severity: number): string {\n  if (severity >= 0.7) return '#ef4444'; // Red\n  if (severity >= 0.4) return '#f97316'; // Orange\n  return '#eab308'; // Yellow\n}\n\n// Mini version for embedding\nexport function MistakeTimelineMini({\n  mistakes,\n  duration,\n  currentTime,\n  onSeek,\n}: {\n  mistakes: MistakeEvent[];\n  duration: number;\n  currentTime: number;\n  onSeek: (time: number) => void;\n}) {\n  const segments = useMemo((): TimelineSegment[] => {\n    if (duration <= 0) return [];\n\n    return mistakes.map(event => ({\n      id: event.id,\n      startPercent: (event.startTimeSec / duration) * 100,\n      widthPercent: Math.max(0.5, ((event.endTimeSec - event.startTimeSec) / duration) * 100),\n      color: getSeverityColor(event.severity),\n      event,\n    }));\n  }, [mistakes, duration]);\n\n  const playheadPercent = duration > 0 ? (currentTime / duration) * 100 : 0;\n\n  const handleClick = (e: React.MouseEvent<HTMLDivElement>) => {\n    const rect = e.currentTarget.getBoundingClientRect();\n    const clickX = e.clientX - rect.left;\n    const percent = clickX / rect.width;\n    onSeek(percent * duration);\n  };\n\n  return (\n    <div\n      onClick={handleClick}\n      className=\"relative h-2 bg-gray-600 rounded-full overflow-hidden cursor-pointer\"\n    >\n      {segments.map(segment => (\n        <div\n          key={segment.id}\n          className=\"absolute top-0 bottom-0\"\n          style={{\n            left: `${segment.startPercent}%`,\n            width: `${segment.widthPercent}%`,\n            backgroundColor: segment.color,\n            minWidth: '2px',\n          }}\n        />\n      ))}\n      <div\n        className=\"absolute top-0 bottom-0 w-1 bg-white rounded-full\"\n        style={{ left: `calc(${playheadPercent}% - 2px)` }}\n      />\n    </div>\n  );\n}\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":6840,"cache_read_input_tokens":135420,"cache_creation":{"ephemeral_5m_input_tokens":6840,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCekKXE8Lor5L85frbp","type":"assistant","uuid":"df21a618-4e37-4975-bcb8-d72eb08968b1","timestamp":"2026-01-28T05:12:01.894Z"}
{"type":"file-history-snapshot","messageId":"df21a618-4e37-4975-bcb8-d72eb08968b1","snapshot":{"messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","trackedFileBackups":{"supabase-migration-v3-features.sql":{"backupFileName":null,"version":1,"backupTime":"2026-01-28T05:08:12.613Z"},"rallycoach\\src\\lib\\types.ts":{"backupFileName":"1048a9baa3a842fc@v1","version":1,"backupTime":"2026-01-28T05:08:34.814Z"},"rallycoach\\src\\lib\\skill-scoring.ts":{"backupFileName":"1012db229ac5a83c@v1","version":1,"backupTime":"2026-01-28T05:09:30.561Z"},"rallycoach\\src\\lib\\ghost-overlay.ts":{"backupFileName":"c0850482504218d5@v1","version":1,"backupTime":"2026-01-28T05:10:17.275Z"},"rallycoach\\src\\lib\\mistake-detection.ts":{"backupFileName":"984c328d1d43cc63@v1","version":1,"backupTime":"2026-01-28T05:11:31.523Z"},"rallycoach\\src\\components\\MistakeTimeline.tsx":{"backupFileName":"1770fa0af8906b46@v1","version":1,"backupTime":"2026-01-28T05:12:02.506Z"}},"timestamp":"2026-01-28T05:05:21.590Z"},"isSnapshotUpdate":true}
{"parentUuid":"df21a618-4e37-4975-bcb8-d72eb08968b1","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VZie3RhLXLTf5iSSVmCPdP","type":"tool_result","content":"File created successfully at: C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\MistakeTimeline.tsx"}]},"uuid":"1c4d104e-1c54-4571-bd3f-72194031b73f","timestamp":"2026-01-28T05:12:02.503Z","toolUseResult":{"type":"create","filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\MistakeTimeline.tsx","content":"'use client';\n\nimport { useRef, useCallback, useMemo } from 'react';\nimport type { MistakeEvent, TimelineSegment } from '@/lib/types';\n\ninterface MistakeTimelineProps {\n  mistakes: MistakeEvent[];\n  duration: number;\n  currentTime: number;\n  onSeek: (time: number) => void;\n  onSelectMistake: (mistake: MistakeEvent | null) => void;\n  selectedMistakeId?: string | null;\n}\n\nexport default function MistakeTimeline({\n  mistakes,\n  duration,\n  currentTime,\n  onSeek,\n  onSelectMistake,\n  selectedMistakeId,\n}: MistakeTimelineProps) {\n  const timelineRef = useRef<HTMLDivElement>(null);\n\n  // Convert mistakes to timeline segments\n  const segments = useMemo((): TimelineSegment[] => {\n    if (duration <= 0) return [];\n\n    return mistakes.map(event => ({\n      id: event.id,\n      startPercent: (event.startTimeSec / duration) * 100,\n      widthPercent: Math.max(1, ((event.endTimeSec - event.startTimeSec) / duration) * 100),\n      color: getSeverityColor(event.severity),\n      event,\n    }));\n  }, [mistakes, duration]);\n\n  // Calculate playhead position\n  const playheadPercent = duration > 0 ? (currentTime / duration) * 100 : 0;\n\n  // Handle click on timeline\n  const handleTimelineClick = useCallback((e: React.MouseEvent<HTMLDivElement>) => {\n    if (!timelineRef.current || duration <= 0) return;\n\n    const rect = timelineRef.current.getBoundingClientRect();\n    const clickX = e.clientX - rect.left;\n    const percent = (clickX / rect.width) * 100;\n    const time = (percent / 100) * duration;\n\n    // Seek to clicked time\n    onSeek(Math.max(0, Math.min(duration, time)));\n\n    // Check if clicking on a segment\n    const clickedSegment = segments.find(seg =>\n      percent >= seg.startPercent && percent <= seg.startPercent + seg.widthPercent\n    );\n\n    if (clickedSegment) {\n      onSelectMistake(clickedSegment.event);\n    } else {\n      onSelectMistake(null);\n    }\n  }, [duration, segments, onSeek, onSelectMistake]);\n\n  // Handle segment click\n  const handleSegmentClick = useCallback((e: React.MouseEvent, segment: TimelineSegment) => {\n    e.stopPropagation();\n    onSeek(segment.event.startTimeSec);\n    onSelectMistake(segment.event);\n  }, [onSeek, onSelectMistake]);\n\n  // Format time for display\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Check if current time is within a mistake\n  const currentMistake = useMemo(() => {\n    return mistakes.find(m =>\n      currentTime >= m.startTimeSec && currentTime <= m.endTimeSec\n    );\n  }, [mistakes, currentTime]);\n\n  return (\n    <div className=\"w-full space-y-2\">\n      {/* Timeline label */}\n      <div className=\"flex items-center justify-between text-xs text-gray-500\">\n        <span>Mistake Timeline</span>\n        <span>{formatTime(currentTime)} / {formatTime(duration)}</span>\n      </div>\n\n      {/* Timeline container */}\n      <div\n        ref={timelineRef}\n        onClick={handleTimelineClick}\n        className=\"relative h-8 bg-gray-200 rounded-lg overflow-hidden cursor-pointer hover:bg-gray-300 transition-colors\"\n      >\n        {/* Mistake segments */}\n        {segments.map(segment => (\n          <button\n            key={segment.id}\n            onClick={(e) => handleSegmentClick(e, segment)}\n            className={`absolute top-0 bottom-0 rounded transition-all ${\n              selectedMistakeId === segment.id\n                ? 'ring-2 ring-white ring-offset-1 z-10'\n                : 'hover:opacity-90'\n            }`}\n            style={{\n              left: `${segment.startPercent}%`,\n              width: `${segment.widthPercent}%`,\n              backgroundColor: segment.color,\n              minWidth: '4px',\n            }}\n            title={`${segment.event.summaryTitle} (${formatTime(segment.event.startTimeSec)})`}\n          >\n            {/* Show label if segment is wide enough */}\n            {segment.widthPercent > 8 && (\n              <span className=\"absolute inset-0 flex items-center justify-center text-white text-xs font-medium truncate px-1\">\n                {segment.event.summaryTitle}\n              </span>\n            )}\n          </button>\n        ))}\n\n        {/* Playhead */}\n        <div\n          className=\"absolute top-0 bottom-0 w-0.5 bg-white shadow-lg z-20 pointer-events-none\"\n          style={{ left: `${playheadPercent}%` }}\n        >\n          {/* Playhead triangle */}\n          <div className=\"absolute -top-1 left-1/2 -translate-x-1/2 w-0 h-0 border-l-[4px] border-l-transparent border-r-[4px] border-r-transparent border-t-[6px] border-t-white\"></div>\n        </div>\n\n        {/* Current time indicator */}\n        {currentMistake && (\n          <div className=\"absolute bottom-0 left-0 right-0 h-1 bg-white/30\"></div>\n        )}\n      </div>\n\n      {/* Legend */}\n      <div className=\"flex items-center gap-4 text-xs text-gray-600\">\n        <div className=\"flex items-center gap-1\">\n          <div className=\"w-3 h-3 rounded bg-red-500\"></div>\n          <span>High</span>\n        </div>\n        <div className=\"flex items-center gap-1\">\n          <div className=\"w-3 h-3 rounded bg-orange-500\"></div>\n          <span>Medium</span>\n        </div>\n        <div className=\"flex items-center gap-1\">\n          <div className=\"w-3 h-3 rounded bg-yellow-500\"></div>\n          <span>Low</span>\n        </div>\n        <span className=\"ml-auto text-gray-400\">Click to seek</span>\n      </div>\n\n      {/* Current mistake indicator */}\n      {currentMistake && (\n        <div className=\"flex items-center gap-2 p-2 bg-red-50 border border-red-200 rounded-lg\">\n          <span className=\"w-2 h-2 rounded-full bg-red-500 animate-pulse\"></span>\n          <span className=\"text-sm text-red-800 font-medium\">\n            {currentMistake.summaryTitle}\n          </span>\n          <span className=\"text-xs text-red-600 ml-auto\">\n            {Math.round(currentMistake.confidence * 100)}% confidence\n          </span>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// Helper function for severity colors\nfunction getSeverityColor(severity: number): string {\n  if (severity >= 0.7) return '#ef4444'; // Red\n  if (severity >= 0.4) return '#f97316'; // Orange\n  return '#eab308'; // Yellow\n}\n\n// Mini version for embedding\nexport function MistakeTimelineMini({\n  mistakes,\n  duration,\n  currentTime,\n  onSeek,\n}: {\n  mistakes: MistakeEvent[];\n  duration: number;\n  currentTime: number;\n  onSeek: (time: number) => void;\n}) {\n  const segments = useMemo((): TimelineSegment[] => {\n    if (duration <= 0) return [];\n\n    return mistakes.map(event => ({\n      id: event.id,\n      startPercent: (event.startTimeSec / duration) * 100,\n      widthPercent: Math.max(0.5, ((event.endTimeSec - event.startTimeSec) / duration) * 100),\n      color: getSeverityColor(event.severity),\n      event,\n    }));\n  }, [mistakes, duration]);\n\n  const playheadPercent = duration > 0 ? (currentTime / duration) * 100 : 0;\n\n  const handleClick = (e: React.MouseEvent<HTMLDivElement>) => {\n    const rect = e.currentTarget.getBoundingClientRect();\n    const clickX = e.clientX - rect.left;\n    const percent = clickX / rect.width;\n    onSeek(percent * duration);\n  };\n\n  return (\n    <div\n      onClick={handleClick}\n      className=\"relative h-2 bg-gray-600 rounded-full overflow-hidden cursor-pointer\"\n    >\n      {segments.map(segment => (\n        <div\n          key={segment.id}\n          className=\"absolute top-0 bottom-0\"\n          style={{\n            left: `${segment.startPercent}%`,\n            width: `${segment.widthPercent}%`,\n            backgroundColor: segment.color,\n            minWidth: '2px',\n          }}\n        />\n      ))}\n      <div\n        className=\"absolute top-0 bottom-0 w-1 bg-white rounded-full\"\n        style={{ left: `calc(${playheadPercent}% - 2px)` }}\n      />\n    </div>\n  );\n}\n","structuredPatch":[],"originalFile":null},"sourceToolAssistantUUID":"df21a618-4e37-4975-bcb8-d72eb08968b1"}
{"parentUuid":"1c4d104e-1c54-4571-bd3f-72194031b73f","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01EfSFpq6Lvkx4zREYhy83Cj","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me create the FixItCard component that shows animated stick figure corrections.","signature":"Ev8BCkYICxgCKkDFG1mhne2Ua1TsYdLKzLybafUWMH0Jnayj3nIDcgpH4MVFAjB86omq3NqJX0HTvGdAm2XNt38l+pWLszXmKuBOEgzDMvsIHFE1kRVZaNwaDKhxaGOGwON19PA2qiIwy6zCjA+fy6kmHl/pfxen9ixPF+RVqalRAOBDv0xJ9OwOvBr8sJxIEG9LYWLBX8VMKmeZQdKAMmV5jPEslFKcM+dkEW3+89dLTT5vh+y8PXhxeQ/ey8KSB3iKR3T/eVoyAQlNCKhhhvOfd2AxlJ1WoFT3svH1fd76tNpBPBsTbSDAu0ji1uY58UpRU2zubKVzJqPEubskHfWcGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":2759,"cache_read_input_tokens":142260,"cache_creation":{"ephemeral_5m_input_tokens":2759,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCh2zS7Mx7amDYmP9Gd","type":"assistant","uuid":"7c3c8b5d-8d22-4035-afe1-12a94726263c","timestamp":"2026-01-28T05:12:06.020Z"}
{"parentUuid":"7c3c8b5d-8d22-4035-afe1-12a94726263c","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01EfSFpq6Lvkx4zREYhy83Cj","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me create the FixItCard component with animated stick figure."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":2759,"cache_read_input_tokens":142260,"cache_creation":{"ephemeral_5m_input_tokens":2759,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCh2zS7Mx7amDYmP9Gd","type":"assistant","uuid":"5579b62e-e20b-45b2-8dfb-9e30edb8c6d6","timestamp":"2026-01-28T05:12:06.334Z"}
{"parentUuid":"5579b62e-e20b-45b2-8dfb-9e30edb8c6d6","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01EfSFpq6Lvkx4zREYhy83Cj","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QQ6m7NQFafGgmzgLQpzCk5","name":"Write","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\FixItCard.tsx","content":"'use client';\n\nimport { useState, useEffect, useRef, useCallback } from 'react';\nimport type { MistakeEvent, FixKeyframe, PoseLandmark } from '@/lib/types';\nimport { POSE_CONNECTIONS } from '@/lib/pose-utils';\n\ninterface FixItCardProps {\n  mistake: MistakeEvent;\n  fixKeyframes?: FixKeyframe[];\n  onClose?: () => void;\n}\n\n// Skeleton connections for drawing\nconst SKELETON_CONNECTIONS = [\n  [11, 12], // shoulders\n  [11, 23], [12, 24], // shoulders to hips\n  [23, 24], // hips\n  [11, 13], [13, 15], // left arm\n  [12, 14], [14, 16], // right arm\n  [23, 25], [25, 27], // left leg\n  [24, 26], [26, 28], // right leg\n];\n\nexport default function FixItCard({\n  mistake,\n  fixKeyframes,\n  onClose,\n}: FixItCardProps) {\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const [activePhase, setActivePhase] = useState(0);\n  const [isAnimating, setIsAnimating] = useState(true);\n  const animationRef = useRef<number | null>(null);\n  const phaseTimeRef = useRef<number>(0);\n\n  const phases = fixKeyframes?.length ? fixKeyframes : getDefaultPhases(mistake.type);\n\n  // Animation loop\n  useEffect(() => {\n    if (!isAnimating || phases.length === 0) return;\n\n    let lastTime = performance.now();\n    const phaseDuration = 1500; // 1.5 seconds per phase\n\n    const animate = (currentTime: number) => {\n      const deltaTime = currentTime - lastTime;\n      lastTime = currentTime;\n\n      phaseTimeRef.current += deltaTime;\n\n      if (phaseTimeRef.current >= phaseDuration) {\n        phaseTimeRef.current = 0;\n        setActivePhase(prev => (prev + 1) % phases.length);\n      }\n\n      animationRef.current = requestAnimationFrame(animate);\n    };\n\n    animationRef.current = requestAnimationFrame(animate);\n\n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current);\n      }\n    };\n  }, [isAnimating, phases.length]);\n\n  // Draw skeleton\n  const drawSkeleton = useCallback((\n    ctx: CanvasRenderingContext2D,\n    landmarks: PoseLandmark[],\n    width: number,\n    height: number,\n    color: string,\n    alpha: number = 1\n  ) => {\n    const padding = 20;\n    const drawWidth = width - padding * 2;\n    const drawHeight = height - padding * 2;\n\n    ctx.globalAlpha = alpha;\n\n    // Draw connections\n    ctx.strokeStyle = color;\n    ctx.lineWidth = 3;\n    ctx.lineCap = 'round';\n\n    for (const [startIdx, endIdx] of SKELETON_CONNECTIONS) {\n      const start = landmarks[startIdx];\n      const end = landmarks[endIdx];\n      if (!start || !end) continue;\n      if ((start.visibility ?? 0) < 0.3 || (end.visibility ?? 0) < 0.3) continue;\n\n      ctx.beginPath();\n      ctx.moveTo(padding + start.x * drawWidth, padding + start.y * drawHeight);\n      ctx.lineTo(padding + end.x * drawWidth, padding + end.y * drawHeight);\n      ctx.stroke();\n    }\n\n    // Draw joints\n    ctx.fillStyle = color;\n    for (let i = 0; i < landmarks.length; i++) {\n      const landmark = landmarks[i];\n      if (!landmark || (landmark.visibility ?? 0) < 0.3) continue;\n\n      const isKeyJoint = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28].includes(i);\n      const isAffected = mistake.joints.includes(i);\n\n      ctx.beginPath();\n      ctx.arc(\n        padding + landmark.x * drawWidth,\n        padding + landmark.y * drawHeight,\n        isAffected ? 6 : isKeyJoint ? 5 : 3,\n        0,\n        Math.PI * 2\n      );\n      ctx.fill();\n\n      // Highlight affected joints\n      if (isAffected) {\n        ctx.strokeStyle = '#ffffff';\n        ctx.lineWidth = 2;\n        ctx.stroke();\n      }\n    }\n\n    ctx.globalAlpha = 1;\n  }, [mistake.joints]);\n\n  // Render canvas\n  useEffect(() => {\n    const canvas = canvasRef.current;\n    if (!canvas || phases.length === 0) return;\n\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    const width = canvas.width;\n    const height = canvas.height;\n\n    // Clear\n    ctx.clearRect(0, 0, width, height);\n\n    // Background gradient\n    const gradient = ctx.createLinearGradient(0, 0, 0, height);\n    gradient.addColorStop(0, '#f8fafc');\n    gradient.addColorStop(1, '#e2e8f0');\n    ctx.fillStyle = gradient;\n    ctx.fillRect(0, 0, width, height);\n\n    // Draw current phase\n    const currentPhase = phases[activePhase];\n    if (currentPhase?.landmarks) {\n      // Draw main skeleton in green (correct form)\n      drawSkeleton(ctx, currentPhase.landmarks, width, height, '#22c55e', 1);\n\n      // Draw arrows for affected joints if correction exists\n      if (currentPhase.correction) {\n        ctx.fillStyle = '#3b82f6';\n        ctx.font = 'bold 10px system-ui';\n        ctx.textAlign = 'center';\n\n        // Draw correction indicator\n        const padding = 20;\n        const drawWidth = width - padding * 2;\n        const drawHeight = height - padding * 2;\n\n        for (const jointIdx of mistake.joints.slice(0, 2)) {\n          const landmark = currentPhase.landmarks[jointIdx];\n          if (landmark && (landmark.visibility ?? 0) > 0.3) {\n            const x = padding + landmark.x * drawWidth;\n            const y = padding + landmark.y * drawHeight;\n\n            // Draw pulsing circle\n            ctx.beginPath();\n            ctx.arc(x, y, 12, 0, Math.PI * 2);\n            ctx.strokeStyle = '#3b82f6';\n            ctx.lineWidth = 2;\n            ctx.setLineDash([3, 3]);\n            ctx.stroke();\n            ctx.setLineDash([]);\n          }\n        }\n      }\n    }\n\n    // Draw phase label\n    ctx.fillStyle = '#334155';\n    ctx.font = 'bold 14px system-ui';\n    ctx.textAlign = 'center';\n    ctx.fillText(currentPhase?.label || `Phase ${activePhase + 1}`, width / 2, height - 10);\n\n  }, [activePhase, phases, drawSkeleton, mistake.joints]);\n\n  return (\n    <div className=\"bg-white rounded-xl shadow-lg overflow-hidden\">\n      {/* Header */}\n      <div className=\"flex items-center justify-between p-4 border-b border-gray-100 bg-gradient-to-r from-red-50 to-orange-50\">\n        <div className=\"flex items-center gap-2\">\n          <div className=\"w-8 h-8 rounded-full bg-red-100 flex items-center justify-center\">\n            <svg className=\"w-4 h-4 text-red-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z\" />\n            </svg>\n          </div>\n          <div>\n            <h3 className=\"font-semibold text-gray-900\">{mistake.summaryTitle}</h3>\n            <p className=\"text-xs text-gray-500\">\n              {Math.round(mistake.confidence * 100)}% confidence\n            </p>\n          </div>\n        </div>\n        {onClose && (\n          <button\n            onClick={onClose}\n            className=\"p-1 hover:bg-gray-100 rounded-full transition\"\n          >\n            <svg className=\"w-5 h-5 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M6 18L18 6M6 6l12 12\" />\n            </svg>\n          </button>\n        )}\n      </div>\n\n      {/* Animation Canvas */}\n      <div className=\"relative\">\n        <canvas\n          ref={canvasRef}\n          width={200}\n          height={240}\n          className=\"w-full\"\n        />\n\n        {/* Play/Pause button */}\n        <button\n          onClick={() => setIsAnimating(!isAnimating)}\n          className=\"absolute bottom-14 right-2 p-2 bg-white/90 rounded-full shadow-md hover:bg-white transition\"\n        >\n          {isAnimating ? (\n            <svg className=\"w-4 h-4 text-gray-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6\" />\n            </svg>\n          ) : (\n            <svg className=\"w-4 h-4 text-gray-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n            </svg>\n          )}\n        </button>\n      </div>\n\n      {/* Phase selector */}\n      <div className=\"flex justify-center gap-2 py-2 bg-gray-50\">\n        {phases.map((phase, idx) => (\n          <button\n            key={idx}\n            onClick={() => {\n              setActivePhase(idx);\n              phaseTimeRef.current = 0;\n            }}\n            className={`px-3 py-1.5 text-xs font-medium rounded-full transition ${\n              activePhase === idx\n                ? 'bg-primary-500 text-white'\n                : 'bg-gray-200 text-gray-600 hover:bg-gray-300'\n            }`}\n          >\n            {phase.label}\n          </button>\n        ))}\n      </div>\n\n      {/* Correction text */}\n      {phases[activePhase]?.correction && (\n        <div className=\"px-4 py-3 bg-blue-50 border-t border-blue-100\">\n          <div className=\"flex items-start gap-2\">\n            <svg className=\"w-4 h-4 text-blue-500 mt-0.5 flex-shrink-0\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n            </svg>\n            <p className=\"text-sm text-blue-800\">\n              {phases[activePhase].correction}\n            </p>\n          </div>\n        </div>\n      )}\n\n      {/* Description */}\n      <div className=\"p-4 border-t border-gray-100\">\n        <p className=\"text-sm text-gray-600\">{mistake.description}</p>\n      </div>\n    </div>\n  );\n}\n\n/**\n * Generate default phases for mistake types when no keyframes provided\n */\nfunction getDefaultPhases(mistakeType: string): FixKeyframe[] {\n  // Default pose landmarks for each phase\n  const defaultPose: PoseLandmark[] = Array(33).fill(null).map((_, i) => ({\n    x: 0.5,\n    y: 0.5,\n    z: 0,\n    visibility: 0,\n  }));\n\n  // Set visible landmarks for a basic stick figure\n  const setLandmark = (pose: PoseLandmark[], idx: number, x: number, y: number) => {\n    pose[idx] = { x, y, z: 0, visibility: 1 };\n  };\n\n  // Setup phase\n  const setupPose = [...defaultPose];\n  setLandmark(setupPose, 0, 0.5, 0.15); // nose\n  setLandmark(setupPose, 11, 0.42, 0.28); // left shoulder\n  setLandmark(setupPose, 12, 0.58, 0.28); // right shoulder\n  setLandmark(setupPose, 13, 0.38, 0.4); // left elbow\n  setLandmark(setupPose, 14, 0.62, 0.4); // right elbow\n  setLandmark(setupPose, 15, 0.35, 0.52); // left wrist\n  setLandmark(setupPose, 16, 0.65, 0.52); // right wrist\n  setLandmark(setupPose, 23, 0.44, 0.55); // left hip\n  setLandmark(setupPose, 24, 0.56, 0.55); // right hip\n  setLandmark(setupPose, 25, 0.42, 0.75); // left knee\n  setLandmark(setupPose, 26, 0.58, 0.75); // right knee\n  setLandmark(setupPose, 27, 0.4, 0.95); // left ankle\n  setLandmark(setupPose, 28, 0.6, 0.95); // right ankle\n\n  // Contact phase (overhead)\n  const contactPose = [...defaultPose];\n  setLandmark(contactPose, 0, 0.5, 0.12); // nose\n  setLandmark(contactPose, 11, 0.4, 0.25); // left shoulder\n  setLandmark(contactPose, 12, 0.6, 0.25); // right shoulder\n  setLandmark(contactPose, 13, 0.35, 0.35); // left elbow\n  setLandmark(contactPose, 14, 0.7, 0.15); // right elbow (raised)\n  setLandmark(contactPose, 15, 0.3, 0.45); // left wrist\n  setLandmark(contactPose, 16, 0.75, 0.08); // right wrist (high)\n  setLandmark(contactPose, 23, 0.42, 0.52); // left hip\n  setLandmark(contactPose, 24, 0.58, 0.52); // right hip\n  setLandmark(contactPose, 25, 0.4, 0.72); // left knee\n  setLandmark(contactPose, 26, 0.6, 0.72); // right knee\n  setLandmark(contactPose, 27, 0.38, 0.92); // left ankle\n  setLandmark(contactPose, 28, 0.62, 0.92); // right ankle\n\n  // Recovery phase\n  const recoveryPose = [...setupPose];\n\n  const corrections = {\n    OVERHEAD_CONTACT_LOW: [\n      { label: 'Setup', correction: 'Position yourself under the shuttle' },\n      { label: 'Contact', correction: 'Hit at highest point above your head' },\n      { label: 'Recovery', correction: 'Return to ready position' },\n    ],\n    LATE_SPLIT_STEP: [\n      { label: 'Watch', correction: 'Watch opponent\\'s racket' },\n      { label: 'Split', correction: 'Land as opponent makes contact' },\n      { label: 'Move', correction: 'Explode to the shuttle' },\n    ],\n    POOR_LUNGE_RECOVERY: [\n      { label: 'Lunge', correction: 'Keep weight on front heel' },\n      { label: 'Push', correction: 'Push off immediately' },\n      { label: 'Return', correction: 'Return to center quickly' },\n    ],\n    INSUFFICIENT_ROTATION: [\n      { label: 'Setup', correction: 'Turn sideways to the net' },\n      { label: 'Rotate', correction: 'Lead with hips, then shoulders' },\n      { label: 'Follow', correction: 'Complete the rotation' },\n    ],\n    ELBOW_TOO_BENT: [\n      { label: 'Prepare', correction: 'Raise elbow high' },\n      { label: 'Extend', correction: 'Fully extend at contact' },\n      { label: 'Follow', correction: 'Follow through smoothly' },\n    ],\n  };\n\n  const mistakeCorrections = corrections[mistakeType as keyof typeof corrections] || [\n    { label: 'Setup', correction: 'Ready position' },\n    { label: 'Action', correction: 'Execute the movement' },\n    { label: 'Finish', correction: 'Return to ready' },\n  ];\n\n  return [\n    { phase: 'setup', landmarks: setupPose, label: mistakeCorrections[0].label, correction: mistakeCorrections[0].correction },\n    { phase: 'contact', landmarks: contactPose, label: mistakeCorrections[1].label, correction: mistakeCorrections[1].correction },\n    { phase: 'recover', landmarks: recoveryPose, label: mistakeCorrections[2].label, correction: mistakeCorrections[2].correction },\n  ];\n}\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":2759,"cache_read_input_tokens":142260,"cache_creation":{"ephemeral_5m_input_tokens":2759,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXZCh2zS7Mx7amDYmP9Gd","type":"assistant","uuid":"118626da-d3bf-4a75-9633-de9579fca715","timestamp":"2026-01-28T05:12:55.855Z"}
{"type":"file-history-snapshot","messageId":"118626da-d3bf-4a75-9633-de9579fca715","snapshot":{"messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","trackedFileBackups":{"supabase-migration-v3-features.sql":{"backupFileName":null,"version":1,"backupTime":"2026-01-28T05:08:12.613Z"},"rallycoach\\src\\lib\\types.ts":{"backupFileName":"1048a9baa3a842fc@v1","version":1,"backupTime":"2026-01-28T05:08:34.814Z"},"rallycoach\\src\\lib\\skill-scoring.ts":{"backupFileName":"1012db229ac5a83c@v1","version":1,"backupTime":"2026-01-28T05:09:30.561Z"},"rallycoach\\src\\lib\\ghost-overlay.ts":{"backupFileName":"c0850482504218d5@v1","version":1,"backupTime":"2026-01-28T05:10:17.275Z"},"rallycoach\\src\\lib\\mistake-detection.ts":{"backupFileName":"984c328d1d43cc63@v1","version":1,"backupTime":"2026-01-28T05:11:31.523Z"},"rallycoach\\src\\components\\MistakeTimeline.tsx":{"backupFileName":"1770fa0af8906b46@v1","version":1,"backupTime":"2026-01-28T05:12:02.506Z"},"rallycoach\\src\\components\\FixItCard.tsx":{"backupFileName":"a41db9eb21739f39@v1","version":1,"backupTime":"2026-01-28T05:12:56.458Z"}},"timestamp":"2026-01-28T05:05:21.590Z"},"isSnapshotUpdate":true}
{"parentUuid":"118626da-d3bf-4a75-9633-de9579fca715","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QQ6m7NQFafGgmzgLQpzCk5","type":"tool_result","content":"File created successfully at: C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\FixItCard.tsx"}]},"uuid":"6faa3e12-95e6-4170-be89-5b18dc2eaaf8","timestamp":"2026-01-28T05:12:56.455Z","toolUseResult":{"type":"create","filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\FixItCard.tsx","content":"'use client';\n\nimport { useState, useEffect, useRef, useCallback } from 'react';\nimport type { MistakeEvent, FixKeyframe, PoseLandmark } from '@/lib/types';\nimport { POSE_CONNECTIONS } from '@/lib/pose-utils';\n\ninterface FixItCardProps {\n  mistake: MistakeEvent;\n  fixKeyframes?: FixKeyframe[];\n  onClose?: () => void;\n}\n\n// Skeleton connections for drawing\nconst SKELETON_CONNECTIONS = [\n  [11, 12], // shoulders\n  [11, 23], [12, 24], // shoulders to hips\n  [23, 24], // hips\n  [11, 13], [13, 15], // left arm\n  [12, 14], [14, 16], // right arm\n  [23, 25], [25, 27], // left leg\n  [24, 26], [26, 28], // right leg\n];\n\nexport default function FixItCard({\n  mistake,\n  fixKeyframes,\n  onClose,\n}: FixItCardProps) {\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const [activePhase, setActivePhase] = useState(0);\n  const [isAnimating, setIsAnimating] = useState(true);\n  const animationRef = useRef<number | null>(null);\n  const phaseTimeRef = useRef<number>(0);\n\n  const phases = fixKeyframes?.length ? fixKeyframes : getDefaultPhases(mistake.type);\n\n  // Animation loop\n  useEffect(() => {\n    if (!isAnimating || phases.length === 0) return;\n\n    let lastTime = performance.now();\n    const phaseDuration = 1500; // 1.5 seconds per phase\n\n    const animate = (currentTime: number) => {\n      const deltaTime = currentTime - lastTime;\n      lastTime = currentTime;\n\n      phaseTimeRef.current += deltaTime;\n\n      if (phaseTimeRef.current >= phaseDuration) {\n        phaseTimeRef.current = 0;\n        setActivePhase(prev => (prev + 1) % phases.length);\n      }\n\n      animationRef.current = requestAnimationFrame(animate);\n    };\n\n    animationRef.current = requestAnimationFrame(animate);\n\n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current);\n      }\n    };\n  }, [isAnimating, phases.length]);\n\n  // Draw skeleton\n  const drawSkeleton = useCallback((\n    ctx: CanvasRenderingContext2D,\n    landmarks: PoseLandmark[],\n    width: number,\n    height: number,\n    color: string,\n    alpha: number = 1\n  ) => {\n    const padding = 20;\n    const drawWidth = width - padding * 2;\n    const drawHeight = height - padding * 2;\n\n    ctx.globalAlpha = alpha;\n\n    // Draw connections\n    ctx.strokeStyle = color;\n    ctx.lineWidth = 3;\n    ctx.lineCap = 'round';\n\n    for (const [startIdx, endIdx] of SKELETON_CONNECTIONS) {\n      const start = landmarks[startIdx];\n      const end = landmarks[endIdx];\n      if (!start || !end) continue;\n      if ((start.visibility ?? 0) < 0.3 || (end.visibility ?? 0) < 0.3) continue;\n\n      ctx.beginPath();\n      ctx.moveTo(padding + start.x * drawWidth, padding + start.y * drawHeight);\n      ctx.lineTo(padding + end.x * drawWidth, padding + end.y * drawHeight);\n      ctx.stroke();\n    }\n\n    // Draw joints\n    ctx.fillStyle = color;\n    for (let i = 0; i < landmarks.length; i++) {\n      const landmark = landmarks[i];\n      if (!landmark || (landmark.visibility ?? 0) < 0.3) continue;\n\n      const isKeyJoint = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28].includes(i);\n      const isAffected = mistake.joints.includes(i);\n\n      ctx.beginPath();\n      ctx.arc(\n        padding + landmark.x * drawWidth,\n        padding + landmark.y * drawHeight,\n        isAffected ? 6 : isKeyJoint ? 5 : 3,\n        0,\n        Math.PI * 2\n      );\n      ctx.fill();\n\n      // Highlight affected joints\n      if (isAffected) {\n        ctx.strokeStyle = '#ffffff';\n        ctx.lineWidth = 2;\n        ctx.stroke();\n      }\n    }\n\n    ctx.globalAlpha = 1;\n  }, [mistake.joints]);\n\n  // Render canvas\n  useEffect(() => {\n    const canvas = canvasRef.current;\n    if (!canvas || phases.length === 0) return;\n\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    const width = canvas.width;\n    const height = canvas.height;\n\n    // Clear\n    ctx.clearRect(0, 0, width, height);\n\n    // Background gradient\n    const gradient = ctx.createLinearGradient(0, 0, 0, height);\n    gradient.addColorStop(0, '#f8fafc');\n    gradient.addColorStop(1, '#e2e8f0');\n    ctx.fillStyle = gradient;\n    ctx.fillRect(0, 0, width, height);\n\n    // Draw current phase\n    const currentPhase = phases[activePhase];\n    if (currentPhase?.landmarks) {\n      // Draw main skeleton in green (correct form)\n      drawSkeleton(ctx, currentPhase.landmarks, width, height, '#22c55e', 1);\n\n      // Draw arrows for affected joints if correction exists\n      if (currentPhase.correction) {\n        ctx.fillStyle = '#3b82f6';\n        ctx.font = 'bold 10px system-ui';\n        ctx.textAlign = 'center';\n\n        // Draw correction indicator\n        const padding = 20;\n        const drawWidth = width - padding * 2;\n        const drawHeight = height - padding * 2;\n\n        for (const jointIdx of mistake.joints.slice(0, 2)) {\n          const landmark = currentPhase.landmarks[jointIdx];\n          if (landmark && (landmark.visibility ?? 0) > 0.3) {\n            const x = padding + landmark.x * drawWidth;\n            const y = padding + landmark.y * drawHeight;\n\n            // Draw pulsing circle\n            ctx.beginPath();\n            ctx.arc(x, y, 12, 0, Math.PI * 2);\n            ctx.strokeStyle = '#3b82f6';\n            ctx.lineWidth = 2;\n            ctx.setLineDash([3, 3]);\n            ctx.stroke();\n            ctx.setLineDash([]);\n          }\n        }\n      }\n    }\n\n    // Draw phase label\n    ctx.fillStyle = '#334155';\n    ctx.font = 'bold 14px system-ui';\n    ctx.textAlign = 'center';\n    ctx.fillText(currentPhase?.label || `Phase ${activePhase + 1}`, width / 2, height - 10);\n\n  }, [activePhase, phases, drawSkeleton, mistake.joints]);\n\n  return (\n    <div className=\"bg-white rounded-xl shadow-lg overflow-hidden\">\n      {/* Header */}\n      <div className=\"flex items-center justify-between p-4 border-b border-gray-100 bg-gradient-to-r from-red-50 to-orange-50\">\n        <div className=\"flex items-center gap-2\">\n          <div className=\"w-8 h-8 rounded-full bg-red-100 flex items-center justify-center\">\n            <svg className=\"w-4 h-4 text-red-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z\" />\n            </svg>\n          </div>\n          <div>\n            <h3 className=\"font-semibold text-gray-900\">{mistake.summaryTitle}</h3>\n            <p className=\"text-xs text-gray-500\">\n              {Math.round(mistake.confidence * 100)}% confidence\n            </p>\n          </div>\n        </div>\n        {onClose && (\n          <button\n            onClick={onClose}\n            className=\"p-1 hover:bg-gray-100 rounded-full transition\"\n          >\n            <svg className=\"w-5 h-5 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M6 18L18 6M6 6l12 12\" />\n            </svg>\n          </button>\n        )}\n      </div>\n\n      {/* Animation Canvas */}\n      <div className=\"relative\">\n        <canvas\n          ref={canvasRef}\n          width={200}\n          height={240}\n          className=\"w-full\"\n        />\n\n        {/* Play/Pause button */}\n        <button\n          onClick={() => setIsAnimating(!isAnimating)}\n          className=\"absolute bottom-14 right-2 p-2 bg-white/90 rounded-full shadow-md hover:bg-white transition\"\n        >\n          {isAnimating ? (\n            <svg className=\"w-4 h-4 text-gray-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6\" />\n            </svg>\n          ) : (\n            <svg className=\"w-4 h-4 text-gray-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n            </svg>\n          )}\n        </button>\n      </div>\n\n      {/* Phase selector */}\n      <div className=\"flex justify-center gap-2 py-2 bg-gray-50\">\n        {phases.map((phase, idx) => (\n          <button\n            key={idx}\n            onClick={() => {\n              setActivePhase(idx);\n              phaseTimeRef.current = 0;\n            }}\n            className={`px-3 py-1.5 text-xs font-medium rounded-full transition ${\n              activePhase === idx\n                ? 'bg-primary-500 text-white'\n                : 'bg-gray-200 text-gray-600 hover:bg-gray-300'\n            }`}\n          >\n            {phase.label}\n          </button>\n        ))}\n      </div>\n\n      {/* Correction text */}\n      {phases[activePhase]?.correction && (\n        <div className=\"px-4 py-3 bg-blue-50 border-t border-blue-100\">\n          <div className=\"flex items-start gap-2\">\n            <svg className=\"w-4 h-4 text-blue-500 mt-0.5 flex-shrink-0\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n            </svg>\n            <p className=\"text-sm text-blue-800\">\n              {phases[activePhase].correction}\n            </p>\n          </div>\n        </div>\n      )}\n\n      {/* Description */}\n      <div className=\"p-4 border-t border-gray-100\">\n        <p className=\"text-sm text-gray-600\">{mistake.description}</p>\n      </div>\n    </div>\n  );\n}\n\n/**\n * Generate default phases for mistake types when no keyframes provided\n */\nfunction getDefaultPhases(mistakeType: string): FixKeyframe[] {\n  // Default pose landmarks for each phase\n  const defaultPose: PoseLandmark[] = Array(33).fill(null).map((_, i) => ({\n    x: 0.5,\n    y: 0.5,\n    z: 0,\n    visibility: 0,\n  }));\n\n  // Set visible landmarks for a basic stick figure\n  const setLandmark = (pose: PoseLandmark[], idx: number, x: number, y: number) => {\n    pose[idx] = { x, y, z: 0, visibility: 1 };\n  };\n\n  // Setup phase\n  const setupPose = [...defaultPose];\n  setLandmark(setupPose, 0, 0.5, 0.15); // nose\n  setLandmark(setupPose, 11, 0.42, 0.28); // left shoulder\n  setLandmark(setupPose, 12, 0.58, 0.28); // right shoulder\n  setLandmark(setupPose, 13, 0.38, 0.4); // left elbow\n  setLandmark(setupPose, 14, 0.62, 0.4); // right elbow\n  setLandmark(setupPose, 15, 0.35, 0.52); // left wrist\n  setLandmark(setupPose, 16, 0.65, 0.52); // right wrist\n  setLandmark(setupPose, 23, 0.44, 0.55); // left hip\n  setLandmark(setupPose, 24, 0.56, 0.55); // right hip\n  setLandmark(setupPose, 25, 0.42, 0.75); // left knee\n  setLandmark(setupPose, 26, 0.58, 0.75); // right knee\n  setLandmark(setupPose, 27, 0.4, 0.95); // left ankle\n  setLandmark(setupPose, 28, 0.6, 0.95); // right ankle\n\n  // Contact phase (overhead)\n  const contactPose = [...defaultPose];\n  setLandmark(contactPose, 0, 0.5, 0.12); // nose\n  setLandmark(contactPose, 11, 0.4, 0.25); // left shoulder\n  setLandmark(contactPose, 12, 0.6, 0.25); // right shoulder\n  setLandmark(contactPose, 13, 0.35, 0.35); // left elbow\n  setLandmark(contactPose, 14, 0.7, 0.15); // right elbow (raised)\n  setLandmark(contactPose, 15, 0.3, 0.45); // left wrist\n  setLandmark(contactPose, 16, 0.75, 0.08); // right wrist (high)\n  setLandmark(contactPose, 23, 0.42, 0.52); // left hip\n  setLandmark(contactPose, 24, 0.58, 0.52); // right hip\n  setLandmark(contactPose, 25, 0.4, 0.72); // left knee\n  setLandmark(contactPose, 26, 0.6, 0.72); // right knee\n  setLandmark(contactPose, 27, 0.38, 0.92); // left ankle\n  setLandmark(contactPose, 28, 0.62, 0.92); // right ankle\n\n  // Recovery phase\n  const recoveryPose = [...setupPose];\n\n  const corrections = {\n    OVERHEAD_CONTACT_LOW: [\n      { label: 'Setup', correction: 'Position yourself under the shuttle' },\n      { label: 'Contact', correction: 'Hit at highest point above your head' },\n      { label: 'Recovery', correction: 'Return to ready position' },\n    ],\n    LATE_SPLIT_STEP: [\n      { label: 'Watch', correction: 'Watch opponent\\'s racket' },\n      { label: 'Split', correction: 'Land as opponent makes contact' },\n      { label: 'Move', correction: 'Explode to the shuttle' },\n    ],\n    POOR_LUNGE_RECOVERY: [\n      { label: 'Lunge', correction: 'Keep weight on front heel' },\n      { label: 'Push', correction: 'Push off immediately' },\n      { label: 'Return', correction: 'Return to center quickly' },\n    ],\n    INSUFFICIENT_ROTATION: [\n      { label: 'Setup', correction: 'Turn sideways to the net' },\n      { label: 'Rotate', correction: 'Lead with hips, then shoulders' },\n      { label: 'Follow', correction: 'Complete the rotation' },\n    ],\n    ELBOW_TOO_BENT: [\n      { label: 'Prepare', correction: 'Raise elbow high' },\n      { label: 'Extend', correction: 'Fully extend at contact' },\n      { label: 'Follow', correction: 'Follow through smoothly' },\n    ],\n  };\n\n  const mistakeCorrections = corrections[mistakeType as keyof typeof corrections] || [\n    { label: 'Setup', correction: 'Ready position' },\n    { label: 'Action', correction: 'Execute the movement' },\n    { label: 'Finish', correction: 'Return to ready' },\n  ];\n\n  return [\n    { phase: 'setup', landmarks: setupPose, label: mistakeCorrections[0].label, correction: mistakeCorrections[0].correction },\n    { phase: 'contact', landmarks: contactPose, label: mistakeCorrections[1].label, correction: mistakeCorrections[1].correction },\n    { phase: 'recover', landmarks: recoveryPose, label: mistakeCorrections[2].label, correction: mistakeCorrections[2].correction },\n  ];\n}\n","structuredPatch":[],"originalFile":null},"sourceToolAssistantUUID":"118626da-d3bf-4a75-9633-de9579fca715"}
{"parentUuid":"6faa3e12-95e6-4170-be89-5b18dc2eaaf8","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01ET6N5jLK23KXc3Z83ZBaFi","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me continue with the SkillMeter component and then update the analytics page to integrate all these features.","signature":"EpoCCkYICxgCKkAngkG7/1QqOy2wbrDE8pfjUaKU7vD8wcqpO4Gd2Y30Isy0c1gBxZN57ZH/znvvdw9InjYcptAqRHgdppbCUt3qEgyY39lcsBsLOrU0+RMaDCvSltbsJ2vs1Oe31CIwuNUwA8S+gdfWErwjKjaS40ImitOZ27W7E9IUtwSLwmpq435b11NFtuxwg6I3erMDKoEBsmPZqCo3fJC7GaJEedjj3pxkZ3B0FfaDt2pT0oXP3xuE3+jiMJO8X/xB1XqN6bmljraDYpgQL1ln7R2Bqf7Mxw0mAGtOULtwlkAAcxYmoUp5QYf+7q0IqwynkjYo0vXxOgoHnJQPDFv9eRjal3JnHwAZXNP087g76saTiFEIKZP+GAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":5140,"cache_read_input_tokens":145019,"cache_creation":{"ephemeral_5m_input_tokens":5140,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCm1o7cC9gy1YPTGqC6","type":"assistant","uuid":"2e411882-4460-47c9-af94-0188cde5efcc","timestamp":"2026-01-28T05:12:59.573Z"}
{"parentUuid":"2e411882-4460-47c9-af94-0188cde5efcc","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01ET6N5jLK23KXc3Z83ZBaFi","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me create the SkillMeter component."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":5140,"cache_read_input_tokens":145019,"cache_creation":{"ephemeral_5m_input_tokens":5140,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCm1o7cC9gy1YPTGqC6","type":"assistant","uuid":"5b3940ce-1f87-4627-9118-f28b05263314","timestamp":"2026-01-28T05:12:59.929Z"}
{"parentUuid":"5b3940ce-1f87-4627-9118-f28b05263314","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01ET6N5jLK23KXc3Z83ZBaFi","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012U3rna6iKMB7Vdg4TYMkXh","name":"Write","input":{"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\SkillMeter.tsx","content":"'use client';\n\nimport { useState } from 'react';\nimport type { ComputedSkillScore } from '@/lib/types';\n\ninterface SkillMeterProps {\n  skillData: ComputedSkillScore;\n  compact?: boolean;\n}\n\nexport default function SkillMeter({ skillData, compact = false }: SkillMeterProps) {\n  const [showDetails, setShowDetails] = useState(false);\n\n  const {\n    skillScore,\n    levelLabel,\n    confidencePercent,\n    confidenceReasons,\n    metrics,\n  } = skillData;\n\n  // Get level color\n  const getLevelColor = (level: string) => {\n    switch (level) {\n      case 'Advanced':\n        return { bg: 'bg-green-100', text: 'text-green-800', ring: 'ring-green-500', bar: 'bg-green-500' };\n      case 'Intermediate':\n        return { bg: 'bg-yellow-100', text: 'text-yellow-800', ring: 'ring-yellow-500', bar: 'bg-yellow-500' };\n      case 'Beginner':\n        return { bg: 'bg-blue-100', text: 'text-blue-800', ring: 'ring-blue-500', bar: 'bg-blue-500' };\n      default:\n        return { bg: 'bg-gray-100', text: 'text-gray-800', ring: 'ring-gray-500', bar: 'bg-gray-500' };\n    }\n  };\n\n  const colors = getLevelColor(levelLabel);\n\n  // Get confidence color\n  const getConfidenceColor = (confidence: number) => {\n    if (confidence >= 70) return 'bg-green-500';\n    if (confidence >= 40) return 'bg-yellow-500';\n    return 'bg-red-500';\n  };\n\n  if (compact) {\n    return (\n      <div className=\"flex items-center gap-3\">\n        {/* Skill Badge */}\n        <div className={`px-3 py-1.5 rounded-full text-sm font-semibold ${colors.bg} ${colors.text}`}>\n          {levelLabel}\n        </div>\n\n        {/* Score */}\n        <div className=\"text-sm text-gray-600\">\n          <span className=\"font-bold text-gray-900\">{skillScore}</span>/100\n        </div>\n\n        {/* Confidence indicator */}\n        <div className=\"flex items-center gap-1.5\">\n          <div className=\"w-16 h-1.5 bg-gray-200 rounded-full overflow-hidden\">\n            <div\n              className={`h-full transition-all ${getConfidenceColor(confidencePercent)}`}\n              style={{ width: `${confidencePercent}%` }}\n            />\n          </div>\n          <span className=\"text-xs text-gray-500\">{confidencePercent}%</span>\n        </div>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"bg-white rounded-xl shadow-sm overflow-hidden\">\n      {/* Header with skill badge */}\n      <div className={`p-4 ${colors.bg} border-b border-gray-100`}>\n        <div className=\"flex items-center justify-between\">\n          <div className=\"flex items-center gap-3\">\n            {/* Skill Level Badge */}\n            <div className={`px-4 py-2 rounded-full font-bold text-lg ${colors.bg} ${colors.text} ring-2 ${colors.ring}`}>\n              {levelLabel}\n            </div>\n\n            {/* Score */}\n            <div>\n              <div className=\"text-3xl font-bold text-gray-900\">{skillScore}</div>\n              <div className=\"text-sm text-gray-600\">Skill Score</div>\n            </div>\n          </div>\n\n          {/* Confidence Meter */}\n          <div className=\"text-right\">\n            <div className=\"text-sm text-gray-600 mb-1\">Detection Confidence</div>\n            <div className=\"flex items-center gap-2\">\n              <div className=\"w-24 h-3 bg-gray-200 rounded-full overflow-hidden\">\n                <div\n                  className={`h-full transition-all ${getConfidenceColor(confidencePercent)}`}\n                  style={{ width: `${confidencePercent}%` }}\n                />\n              </div>\n              <span className=\"font-semibold text-gray-700\">{confidencePercent}%</span>\n            </div>\n          </div>\n        </div>\n\n        {/* Low confidence warning */}\n        {confidencePercent < 60 && confidenceReasons.length > 0 && (\n          <div className=\"mt-3 p-2 bg-yellow-50 border border-yellow-200 rounded-lg\">\n            <div className=\"flex items-start gap-2\">\n              <svg className=\"w-4 h-4 text-yellow-600 mt-0.5 flex-shrink-0\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z\" />\n              </svg>\n              <div className=\"text-xs text-yellow-800\">\n                <span className=\"font-medium\">Lower confidence:</span> {confidenceReasons[0]}\n              </div>\n            </div>\n          </div>\n        )}\n      </div>\n\n      {/* Score breakdown */}\n      <div className=\"p-4\">\n        <button\n          onClick={() => setShowDetails(!showDetails)}\n          className=\"flex items-center justify-between w-full text-sm text-gray-600 hover:text-gray-900 transition\"\n        >\n          <span>Score Breakdown</span>\n          <svg\n            className={`w-4 h-4 transition-transform ${showDetails ? 'rotate-180' : ''}`}\n            fill=\"none\"\n            stroke=\"currentColor\"\n            viewBox=\"0 0 24 24\"\n          >\n            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M19 9l-7 7-7-7\" />\n          </svg>\n        </button>\n\n        {showDetails && (\n          <div className=\"mt-4 space-y-3\">\n            {/* Form Quality */}\n            <MetricBar\n              label=\"Form Quality\"\n              value={metrics.formQuality * 100}\n              description=\"How well your body positions match ideal form\"\n            />\n\n            {/* Consistency */}\n            <MetricBar\n              label=\"Consistency\"\n              value={metrics.consistencyScore * 100}\n              description=\"How stable your form is across frames\"\n            />\n\n            {/* Recovery Speed */}\n            <MetricBar\n              label=\"Recovery Speed\"\n              value={metrics.recoverySpeed * 100}\n              description=\"How quickly you recover after lunges\"\n            />\n\n            {/* Visibility */}\n            <MetricBar\n              label=\"Detection Quality\"\n              value={metrics.visibilityAvg * 100}\n              description=\"Clarity of pose detection in video\"\n            />\n\n            {/* Dropout Rate (inverse) */}\n            <MetricBar\n              label=\"Frame Coverage\"\n              value={(1 - metrics.dropoutRate) * 100}\n              description=\"Percentage of frames with valid pose data\"\n            />\n\n            {/* Confidence reasons */}\n            {confidenceReasons.length > 0 && (\n              <div className=\"mt-4 pt-4 border-t border-gray-100\">\n                <p className=\"text-xs font-medium text-gray-500 mb-2\">Confidence Notes:</p>\n                <ul className=\"space-y-1\">\n                  {confidenceReasons.map((reason, idx) => (\n                    <li key={idx} className=\"text-xs text-gray-600 flex items-start gap-1.5\">\n                      <span className=\"text-yellow-500 mt-0.5\">•</span>\n                      {reason}\n                    </li>\n                  ))}\n                </ul>\n              </div>\n            )}\n          </div>\n        )}\n      </div>\n\n      {/* How score is calculated */}\n      <div className=\"px-4 pb-4\">\n        <p className=\"text-xs text-gray-400 italic\">\n          Score computed from pose metrics. Confidence from landmark visibility.\n        </p>\n      </div>\n    </div>\n  );\n}\n\n// Metric bar sub-component\nfunction MetricBar({\n  label,\n  value,\n  description,\n}: {\n  label: string;\n  value: number;\n  description?: string;\n}) {\n  const getBarColor = (val: number) => {\n    if (val >= 70) return 'bg-green-500';\n    if (val >= 40) return 'bg-yellow-500';\n    return 'bg-red-500';\n  };\n\n  return (\n    <div>\n      <div className=\"flex items-center justify-between text-sm mb-1\">\n        <span className=\"text-gray-700\">{label}</span>\n        <span className=\"font-medium text-gray-900\">{Math.round(value)}%</span>\n      </div>\n      <div className=\"w-full h-2 bg-gray-100 rounded-full overflow-hidden\">\n        <div\n          className={`h-full transition-all ${getBarColor(value)}`}\n          style={{ width: `${Math.max(2, value)}%` }}\n        />\n      </div>\n      {description && (\n        <p className=\"text-xs text-gray-400 mt-0.5\">{description}</p>\n      )}\n    </div>\n  );\n}\n\n// Inline badge version for video overlay\nexport function SkillBadgeInline({ skillData }: { skillData: ComputedSkillScore }) {\n  const { skillScore, levelLabel, confidencePercent } = skillData;\n\n  const getLevelStyles = (level: string) => {\n    switch (level) {\n      case 'Advanced':\n        return 'bg-green-500';\n      case 'Intermediate':\n        return 'bg-yellow-500';\n      case 'Beginner':\n        return 'bg-blue-500';\n      default:\n        return 'bg-gray-500';\n    }\n  };\n\n  return (\n    <div className=\"flex items-center gap-2 bg-black/70 px-3 py-1.5 rounded-full\">\n      <span className={`px-2 py-0.5 rounded text-xs font-bold text-white ${getLevelStyles(levelLabel)}`}>\n        {levelLabel}\n      </span>\n      <span className=\"text-white text-sm font-medium\">{skillScore}</span>\n      <span className=\"text-white/60 text-xs\">({confidencePercent}% conf)</span>\n    </div>\n  );\n}\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":5140,"cache_read_input_tokens":145019,"cache_creation":{"ephemeral_5m_input_tokens":5140,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXZCm1o7cC9gy1YPTGqC6","type":"assistant","uuid":"bb1b6cd9-d72a-4870-a9f0-f7950909d197","timestamp":"2026-01-28T05:13:28.802Z"}
{"type":"file-history-snapshot","messageId":"bb1b6cd9-d72a-4870-a9f0-f7950909d197","snapshot":{"messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","trackedFileBackups":{"supabase-migration-v3-features.sql":{"backupFileName":null,"version":1,"backupTime":"2026-01-28T05:08:12.613Z"},"rallycoach\\src\\lib\\types.ts":{"backupFileName":"1048a9baa3a842fc@v1","version":1,"backupTime":"2026-01-28T05:08:34.814Z"},"rallycoach\\src\\lib\\skill-scoring.ts":{"backupFileName":"1012db229ac5a83c@v1","version":1,"backupTime":"2026-01-28T05:09:30.561Z"},"rallycoach\\src\\lib\\ghost-overlay.ts":{"backupFileName":"c0850482504218d5@v1","version":1,"backupTime":"2026-01-28T05:10:17.275Z"},"rallycoach\\src\\lib\\mistake-detection.ts":{"backupFileName":"984c328d1d43cc63@v1","version":1,"backupTime":"2026-01-28T05:11:31.523Z"},"rallycoach\\src\\components\\MistakeTimeline.tsx":{"backupFileName":"1770fa0af8906b46@v1","version":1,"backupTime":"2026-01-28T05:12:02.506Z"},"rallycoach\\src\\components\\FixItCard.tsx":{"backupFileName":"a41db9eb21739f39@v1","version":1,"backupTime":"2026-01-28T05:12:56.458Z"},"rallycoach\\src\\components\\SkillMeter.tsx":{"backupFileName":"e637290f1c1a76e9@v1","version":1,"backupTime":"2026-01-28T05:13:29.417Z"}},"timestamp":"2026-01-28T05:05:21.590Z"},"isSnapshotUpdate":true}
{"parentUuid":"bb1b6cd9-d72a-4870-a9f0-f7950909d197","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012U3rna6iKMB7Vdg4TYMkXh","type":"tool_result","content":"File created successfully at: C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\SkillMeter.tsx"}]},"uuid":"79ce3e47-5cfb-45c9-8d02-2072351cbd6f","timestamp":"2026-01-28T05:13:29.413Z","toolUseResult":{"type":"create","filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\SkillMeter.tsx","content":"'use client';\n\nimport { useState } from 'react';\nimport type { ComputedSkillScore } from '@/lib/types';\n\ninterface SkillMeterProps {\n  skillData: ComputedSkillScore;\n  compact?: boolean;\n}\n\nexport default function SkillMeter({ skillData, compact = false }: SkillMeterProps) {\n  const [showDetails, setShowDetails] = useState(false);\n\n  const {\n    skillScore,\n    levelLabel,\n    confidencePercent,\n    confidenceReasons,\n    metrics,\n  } = skillData;\n\n  // Get level color\n  const getLevelColor = (level: string) => {\n    switch (level) {\n      case 'Advanced':\n        return { bg: 'bg-green-100', text: 'text-green-800', ring: 'ring-green-500', bar: 'bg-green-500' };\n      case 'Intermediate':\n        return { bg: 'bg-yellow-100', text: 'text-yellow-800', ring: 'ring-yellow-500', bar: 'bg-yellow-500' };\n      case 'Beginner':\n        return { bg: 'bg-blue-100', text: 'text-blue-800', ring: 'ring-blue-500', bar: 'bg-blue-500' };\n      default:\n        return { bg: 'bg-gray-100', text: 'text-gray-800', ring: 'ring-gray-500', bar: 'bg-gray-500' };\n    }\n  };\n\n  const colors = getLevelColor(levelLabel);\n\n  // Get confidence color\n  const getConfidenceColor = (confidence: number) => {\n    if (confidence >= 70) return 'bg-green-500';\n    if (confidence >= 40) return 'bg-yellow-500';\n    return 'bg-red-500';\n  };\n\n  if (compact) {\n    return (\n      <div className=\"flex items-center gap-3\">\n        {/* Skill Badge */}\n        <div className={`px-3 py-1.5 rounded-full text-sm font-semibold ${colors.bg} ${colors.text}`}>\n          {levelLabel}\n        </div>\n\n        {/* Score */}\n        <div className=\"text-sm text-gray-600\">\n          <span className=\"font-bold text-gray-900\">{skillScore}</span>/100\n        </div>\n\n        {/* Confidence indicator */}\n        <div className=\"flex items-center gap-1.5\">\n          <div className=\"w-16 h-1.5 bg-gray-200 rounded-full overflow-hidden\">\n            <div\n              className={`h-full transition-all ${getConfidenceColor(confidencePercent)}`}\n              style={{ width: `${confidencePercent}%` }}\n            />\n          </div>\n          <span className=\"text-xs text-gray-500\">{confidencePercent}%</span>\n        </div>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"bg-white rounded-xl shadow-sm overflow-hidden\">\n      {/* Header with skill badge */}\n      <div className={`p-4 ${colors.bg} border-b border-gray-100`}>\n        <div className=\"flex items-center justify-between\">\n          <div className=\"flex items-center gap-3\">\n            {/* Skill Level Badge */}\n            <div className={`px-4 py-2 rounded-full font-bold text-lg ${colors.bg} ${colors.text} ring-2 ${colors.ring}`}>\n              {levelLabel}\n            </div>\n\n            {/* Score */}\n            <div>\n              <div className=\"text-3xl font-bold text-gray-900\">{skillScore}</div>\n              <div className=\"text-sm text-gray-600\">Skill Score</div>\n            </div>\n          </div>\n\n          {/* Confidence Meter */}\n          <div className=\"text-right\">\n            <div className=\"text-sm text-gray-600 mb-1\">Detection Confidence</div>\n            <div className=\"flex items-center gap-2\">\n              <div className=\"w-24 h-3 bg-gray-200 rounded-full overflow-hidden\">\n                <div\n                  className={`h-full transition-all ${getConfidenceColor(confidencePercent)}`}\n                  style={{ width: `${confidencePercent}%` }}\n                />\n              </div>\n              <span className=\"font-semibold text-gray-700\">{confidencePercent}%</span>\n            </div>\n          </div>\n        </div>\n\n        {/* Low confidence warning */}\n        {confidencePercent < 60 && confidenceReasons.length > 0 && (\n          <div className=\"mt-3 p-2 bg-yellow-50 border border-yellow-200 rounded-lg\">\n            <div className=\"flex items-start gap-2\">\n              <svg className=\"w-4 h-4 text-yellow-600 mt-0.5 flex-shrink-0\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z\" />\n              </svg>\n              <div className=\"text-xs text-yellow-800\">\n                <span className=\"font-medium\">Lower confidence:</span> {confidenceReasons[0]}\n              </div>\n            </div>\n          </div>\n        )}\n      </div>\n\n      {/* Score breakdown */}\n      <div className=\"p-4\">\n        <button\n          onClick={() => setShowDetails(!showDetails)}\n          className=\"flex items-center justify-between w-full text-sm text-gray-600 hover:text-gray-900 transition\"\n        >\n          <span>Score Breakdown</span>\n          <svg\n            className={`w-4 h-4 transition-transform ${showDetails ? 'rotate-180' : ''}`}\n            fill=\"none\"\n            stroke=\"currentColor\"\n            viewBox=\"0 0 24 24\"\n          >\n            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M19 9l-7 7-7-7\" />\n          </svg>\n        </button>\n\n        {showDetails && (\n          <div className=\"mt-4 space-y-3\">\n            {/* Form Quality */}\n            <MetricBar\n              label=\"Form Quality\"\n              value={metrics.formQuality * 100}\n              description=\"How well your body positions match ideal form\"\n            />\n\n            {/* Consistency */}\n            <MetricBar\n              label=\"Consistency\"\n              value={metrics.consistencyScore * 100}\n              description=\"How stable your form is across frames\"\n            />\n\n            {/* Recovery Speed */}\n            <MetricBar\n              label=\"Recovery Speed\"\n              value={metrics.recoverySpeed * 100}\n              description=\"How quickly you recover after lunges\"\n            />\n\n            {/* Visibility */}\n            <MetricBar\n              label=\"Detection Quality\"\n              value={metrics.visibilityAvg * 100}\n              description=\"Clarity of pose detection in video\"\n            />\n\n            {/* Dropout Rate (inverse) */}\n            <MetricBar\n              label=\"Frame Coverage\"\n              value={(1 - metrics.dropoutRate) * 100}\n              description=\"Percentage of frames with valid pose data\"\n            />\n\n            {/* Confidence reasons */}\n            {confidenceReasons.length > 0 && (\n              <div className=\"mt-4 pt-4 border-t border-gray-100\">\n                <p className=\"text-xs font-medium text-gray-500 mb-2\">Confidence Notes:</p>\n                <ul className=\"space-y-1\">\n                  {confidenceReasons.map((reason, idx) => (\n                    <li key={idx} className=\"text-xs text-gray-600 flex items-start gap-1.5\">\n                      <span className=\"text-yellow-500 mt-0.5\">•</span>\n                      {reason}\n                    </li>\n                  ))}\n                </ul>\n              </div>\n            )}\n          </div>\n        )}\n      </div>\n\n      {/* How score is calculated */}\n      <div className=\"px-4 pb-4\">\n        <p className=\"text-xs text-gray-400 italic\">\n          Score computed from pose metrics. Confidence from landmark visibility.\n        </p>\n      </div>\n    </div>\n  );\n}\n\n// Metric bar sub-component\nfunction MetricBar({\n  label,\n  value,\n  description,\n}: {\n  label: string;\n  value: number;\n  description?: string;\n}) {\n  const getBarColor = (val: number) => {\n    if (val >= 70) return 'bg-green-500';\n    if (val >= 40) return 'bg-yellow-500';\n    return 'bg-red-500';\n  };\n\n  return (\n    <div>\n      <div className=\"flex items-center justify-between text-sm mb-1\">\n        <span className=\"text-gray-700\">{label}</span>\n        <span className=\"font-medium text-gray-900\">{Math.round(value)}%</span>\n      </div>\n      <div className=\"w-full h-2 bg-gray-100 rounded-full overflow-hidden\">\n        <div\n          className={`h-full transition-all ${getBarColor(value)}`}\n          style={{ width: `${Math.max(2, value)}%` }}\n        />\n      </div>\n      {description && (\n        <p className=\"text-xs text-gray-400 mt-0.5\">{description}</p>\n      )}\n    </div>\n  );\n}\n\n// Inline badge version for video overlay\nexport function SkillBadgeInline({ skillData }: { skillData: ComputedSkillScore }) {\n  const { skillScore, levelLabel, confidencePercent } = skillData;\n\n  const getLevelStyles = (level: string) => {\n    switch (level) {\n      case 'Advanced':\n        return 'bg-green-500';\n      case 'Intermediate':\n        return 'bg-yellow-500';\n      case 'Beginner':\n        return 'bg-blue-500';\n      default:\n        return 'bg-gray-500';\n    }\n  };\n\n  return (\n    <div className=\"flex items-center gap-2 bg-black/70 px-3 py-1.5 rounded-full\">\n      <span className={`px-2 py-0.5 rounded text-xs font-bold text-white ${getLevelStyles(levelLabel)}`}>\n        {levelLabel}\n      </span>\n      <span className=\"text-white text-sm font-medium\">{skillScore}</span>\n      <span className=\"text-white/60 text-xs\">({confidencePercent}% conf)</span>\n    </div>\n  );\n}\n","structuredPatch":[],"originalFile":null},"sourceToolAssistantUUID":"bb1b6cd9-d72a-4870-a9f0-f7950909d197"}
{"parentUuid":"79ce3e47-5cfb-45c9-8d02-2072351cbd6f","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013bX7L6WfXYVnSc2eEhP76V","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to update the analytics page to integrate all these new features. This is the most important part - I need to:1. Import the new modules and components\n2. Add state for ghost overlay, skill scoring, mistake timeline\n3. Modify the analysis flow to use computed skill score instead of Gemini\n4. Add the MistakeTimeline component\n5. Add ghost overlay toggle and rendering\n6. Add SkillMeter component\n7. Add FixItCard when a mistake is selectedLet me read the page again and then make the necessary edits.","signature":"EqQFCkYICxgCKkAVaj8+TUVeXN9pIrbGtVkbKMyAeJNTViYqWTGEamauZPT/B2AYkvSsx0/yzUIAspKSru0ugk7YVcvmMitSXoZdEgwRc6dJlqY+w57aGd4aDGB9pt38F10NAI1zGSIwR+mAobYO6d4pqZIYRRUn9ln4DCgHCq5DlGNnvd6B/U5NBRpa+K57SIi/reuYHbgFKosErr5msu0IsAg6xNhnA0+j5DLSyDI5mhyvBohC541n3kx0dN6N0NcBH38bS/hRMQR1pkDpRijd6prxA2Yl0Fja1inU1z2u9F89ZVWclRpjVGtQ1rEYyQc9uqNzn2mWhS55JhHtprLZLVNtnpLYe/9MkTRfihZniHo6Xms0uXpXYmJDbgePOw+577jFj8uyL6AhZ90IVvyKVQNn+/eOAlC0jhy9zxmM88j8ftcFZblM/j1yT9N1OWRpAdPKC5QYhyGvU0pVA0YCYDy8Iut7olutcWzUpwNQ2l7Xq/2lFM6iUhsc9g648/8QpRwm1Dw+Jmt540h+goNk+NaUPJsq6+SUo2ZhQ6tJ5P+BY8+RFGdXXN0APGn5QDd440IeyoB7ybbLbWuXO1BK4EdL91zCv7Q28dQBw8niDHL1fkm/TXAnEHYQrE+ZrwLA10TLu15JyCGJOP9Y/n7nKBxhM3wJ2XOrVOnkWYBUuv2VA0PiNF17Zm98u74oO8/kq6w49XDzPe5iMaq9MwsGNukZrmNJE4hXyYmiMU3le9vcVwp7jN01ZrXYAIAKhSJizscYQIEjWDPc42bK950P0S+uJDXhfnGq7zQnwHGpb9pfFKUx0u+0fyt+r+re2FHPNXkX/+CoJ62Q/ZmJzsV5W7B05pijVkxR3uvBMFDpEDDqiH1nJT/CYR0OdJNuBbh6iHsGyBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":3037,"cache_read_input_tokens":150159,"cache_creation":{"ephemeral_5m_input_tokens":3037,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCoSp54RPmD4WqdWuQV","type":"assistant","uuid":"71172c49-6fd8-4910-834b-e4a2d6e4d943","timestamp":"2026-01-28T05:13:34.897Z"}
{"parentUuid":"71172c49-6fd8-4910-834b-e4a2d6e4d943","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013bX7L6WfXYVnSc2eEhP76V","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me update the analytics page to integrate all these features. I'll make targeted edits to add the new functionality."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":3037,"cache_read_input_tokens":150159,"cache_creation":{"ephemeral_5m_input_tokens":3037,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCoSp54RPmD4WqdWuQV","type":"assistant","uuid":"ce94527f-cdfa-4d48-8034-7bfc57650395","timestamp":"2026-01-28T05:13:35.487Z"}
{"parentUuid":"ce94527f-cdfa-4d48-8034-7bfc57650395","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013bX7L6WfXYVnSc2eEhP76V","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CmEcewXm9CdJXvXpx69fr7","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"import {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData } from '@/lib/types';","new_string":"import {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":3037,"cache_read_input_tokens":150159,"cache_creation":{"ephemeral_5m_input_tokens":3037,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCoSp54RPmD4WqdWuQV","type":"assistant","uuid":"b7ee2efa-332a-4a34-9520-ad8afcb3b4a0","timestamp":"2026-01-28T05:13:41.646Z"}
{"type":"file-history-snapshot","messageId":"b7ee2efa-332a-4a34-9520-ad8afcb3b4a0","snapshot":{"messageId":"8f16c2ed-0da0-4368-8812-d887fc0e1dad","trackedFileBackups":{"supabase-migration-v3-features.sql":{"backupFileName":null,"version":1,"backupTime":"2026-01-28T05:08:12.613Z"},"rallycoach\\src\\lib\\types.ts":{"backupFileName":"1048a9baa3a842fc@v1","version":1,"backupTime":"2026-01-28T05:08:34.814Z"},"rallycoach\\src\\lib\\skill-scoring.ts":{"backupFileName":"1012db229ac5a83c@v1","version":1,"backupTime":"2026-01-28T05:09:30.561Z"},"rallycoach\\src\\lib\\ghost-overlay.ts":{"backupFileName":"c0850482504218d5@v1","version":1,"backupTime":"2026-01-28T05:10:17.275Z"},"rallycoach\\src\\lib\\mistake-detection.ts":{"backupFileName":"984c328d1d43cc63@v1","version":1,"backupTime":"2026-01-28T05:11:31.523Z"},"rallycoach\\src\\components\\MistakeTimeline.tsx":{"backupFileName":"1770fa0af8906b46@v1","version":1,"backupTime":"2026-01-28T05:12:02.506Z"},"rallycoach\\src\\components\\FixItCard.tsx":{"backupFileName":"a41db9eb21739f39@v1","version":1,"backupTime":"2026-01-28T05:12:56.458Z"},"rallycoach\\src\\components\\SkillMeter.tsx":{"backupFileName":"e637290f1c1a76e9@v1","version":1,"backupTime":"2026-01-28T05:13:29.417Z"},"rallycoach\\src\\app\\analytics\\page.tsx":{"backupFileName":"fb9c66f040b229b3@v1","version":1,"backupTime":"2026-01-28T05:13:42.246Z"}},"timestamp":"2026-01-28T05:05:21.590Z"},"isSnapshotUpdate":true}
{"parentUuid":"b7ee2efa-332a-4a34-9520-ad8afcb3b4a0","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CmEcewXm9CdJXvXpx69fr7","type":"tool_result","content":"The file C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"0aa2dad9-179e-4550-8372-44bb57248327","timestamp":"2026-01-28T05:13:42.242Z","toolUseResult":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"import {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData } from '@/lib/types';","newString":"import {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // PHASE 3: Auto-detect skill level\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    setAutoLevelResult(levelResult);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n    const avgScore = totalFrames > 0\n      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n      : 0;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":28,"oldLines":7,"newStart":28,"newLines":13,"lines":["   SKILL_LEVEL_DESCRIPTIONS,","   validateSessionPoseData,"," } from '@/lib/scoring-rules';","-import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData } from '@/lib/types';","+import { computeSkillScore } from '@/lib/skill-scoring';","+import { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';","+import { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';","+import MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';","+import FixItCard from '@/components/FixItCard';","+import SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';","+import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';"," "," // MediaPipe Types"," type PoseLandmarker = any;"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"b7ee2efa-332a-4a34-9520-ad8afcb3b4a0"}
{"parentUuid":"0aa2dad9-179e-4550-8372-44bb57248327","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01DuCeXFGrbh24vu1PZPLEFs","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to add the new state variables for ghost, skill scoring, and mistake timeline.","signature":"EoECCkYICxgCKkAbfz8G5ZAwwxH8ARmuNkHMEBQB0Fgs6uOjEAZC8ovTiOnFCpAGHis0RGy/+j/zkvYF4B7sKL6Fok2WERJ75BbyEgyI4yliKymqSphVnFoaDMetLJwEPaOWcbEDfSIwOek9ij6ayEsD7PzcHpjQ2wHVUa5q6lQvGCXmAl5+Vdz8otyTT1I46bZcQRjhB2+uKmmacQ31xu8CCEs1k/HTifBe0QdxFPgYygxEdrijcUFbXdFJBa260vuuYeA7+ZKJYW/qeBuNmSAFqorOO2vt1ntFWMOgJAzNXq58M/DTLgrv+YeCbcK8N0wO6KUGUMkd44ceHS62rqwHjQkYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":705,"cache_read_input_tokens":153196,"cache_creation":{"ephemeral_5m_input_tokens":705,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCpPmHr2YYbnfVjBbnZ","type":"assistant","uuid":"1352ea56-e7ac-4ff3-8aac-37e207decece","timestamp":"2026-01-28T05:13:45.100Z"}
{"parentUuid":"1352ea56-e7ac-4ff3-8aac-37e207decece","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01DuCeXFGrbh24vu1PZPLEFs","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01H2k7kwYTDBfptvdnyyxbnv","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);","new_string":"  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":705,"cache_read_input_tokens":153196,"cache_creation":{"ephemeral_5m_input_tokens":705,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCpPmHr2YYbnfVjBbnZ","type":"assistant","uuid":"7b770dd8-75c2-4767-b8a6-48f9f1abe6db","timestamp":"2026-01-28T05:13:48.651Z"}
{"parentUuid":"7b770dd8-75c2-4767-b8a6-48f9f1abe6db","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01H2k7kwYTDBfptvdnyyxbnv","type":"tool_result","content":"The file C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"43c4b833-9490-468d-963c-ed5b76602301","timestamp":"2026-01-28T05:13:49.277Z","toolUseResult":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);","newString":"  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // PHASE 3: Auto-detect skill level\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    setAutoLevelResult(levelResult);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n    const avgScore = totalFrames > 0\n      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n      : 0;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":106,"oldLines":6,"newStart":106,"newLines":13,"lines":["   const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);","   const [showGuidance, setShowGuidance] = useState(false);"," ","+  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline","+  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);","+  const [showGhost, setShowGhost] = useState(false);","+  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);","+  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);","+  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);","+","   // Video playback state","   const [videoUrl, setVideoUrl] = useState<string | null>(null);","   const [videoFile, setVideoFile] = useState<File | null>(null);"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"7b770dd8-75c2-4767-b8a6-48f9f1abe6db"}
{"parentUuid":"43c4b833-9490-468d-963c-ed5b76602301","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01HAgHoBwarFfy7nYQjpYFzo","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to update the renderFrame function to include ghost overlay rendering. Let me find that function and update it.","signature":"EqMCCkYICxgCKkBOx3SjzlbPSK2oSJDROykH22SlAp2tUTMpDKxbsEAi6y5X9fGtU5qp1GN5qQE7dhvUEvKlo4NgHs0Mi199JhWqEgxWSmjlnL25JhRCJyIaDDmaD2WYwbi/i+457SIwHTsf6CAcOWB4g1zq7lWA4DE6w9grPSgr1dClbxC415OPMg0R94EUX6iqdAupQpOdKooBa+/0CYh8LGR82rbGW9kFpsaUk9di1XzGQjV1WvkO9E/7kKBfbL1/sNHrWj7KNVuhUdqnEKMu7c6Tzrnk8U2sb69C5zoslz+iPcYRpuOTRJtcmz9k6aa9C//Dwuht31QDRez3QT/ZdGKjIemcJ230izDWn7FgBONVQigEswndrUKCgGxZnr6/38OfGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":489,"cache_read_input_tokens":153901,"cache_creation":{"ephemeral_5m_input_tokens":489,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCpuxjWcsu9E6HbS1nE","type":"assistant","uuid":"73baf64a-fd3c-401f-b553-a747a4b7216a","timestamp":"2026-01-28T05:13:52.482Z"}
{"parentUuid":"73baf64a-fd3c-401f-b553-a747a4b7216a","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01HAgHoBwarFfy7nYQjpYFzo","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me update the renderFrame function to include ghost overlay rendering."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":489,"cache_read_input_tokens":153901,"cache_creation":{"ephemeral_5m_input_tokens":489,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCpuxjWcsu9E6HbS1nE","type":"assistant","uuid":"560d387b-198d-4d49-9179-50403abb98e9","timestamp":"2026-01-28T05:13:52.760Z"}
{"parentUuid":"560d387b-198d-4d49-9179-50403abb98e9","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01HAgHoBwarFfy7nYQjpYFzo","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012RmftUGVVRKsAW45UYovk3","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);","new_string":"      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":489,"cache_read_input_tokens":153901,"cache_creation":{"ephemeral_5m_input_tokens":489,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXZCpuxjWcsu9E6HbS1nE","type":"assistant","uuid":"035a0655-ca10-4951-8cf2-a5dfa46d723a","timestamp":"2026-01-28T05:14:01.830Z"}
{"parentUuid":"035a0655-ca10-4951-8cf2-a5dfa46d723a","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012RmftUGVVRKsAW45UYovk3","type":"tool_result","content":"The file C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"d1367610-68e8-464e-ae36-d9bc0d123a67","timestamp":"2026-01-28T05:14:02.442Z","toolUseResult":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);","newString":"      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // PHASE 3: Auto-detect skill level\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    setAutoLevelResult(levelResult);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n    const avgScore = totalFrames > 0\n      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n      : 0;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1392,"oldLines":12,"newStart":1392,"newLines":51,"lines":["           ctx.fill();","         }","       }","+","+      // V4 FEATURE: Draw Ghost Overlay if enabled","+      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {","+        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);","+        if (ghostLandmarks) {","+          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency","+","+          // Draw ghost connections","+          ctx.strokeStyle = ghostColor;","+          ctx.lineWidth = 2;","+","+          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {","+            const start = ghostLandmarks[startIdx];","+            const end = ghostLandmarks[endIdx];","+            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {","+              ctx.beginPath();","+              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);","+              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);","+              ctx.stroke();","+            }","+          }","+","+          // Draw ghost joints","+          ctx.fillStyle = ghostColor;","+          for (const landmark of ghostLandmarks) {","+            if ((landmark.visibility ?? 0) > 0.5) {","+              ctx.beginPath();","+              ctx.arc(","+                offsetX + landmark.x * renderWidth,","+                offsetY + landmark.y * renderHeight,","+                4,","+                0,","+                2 * Math.PI","+              );","+              ctx.fill();","+            }","+          }","+        }","+      }","     }"," ","     if (!video.paused) {","       animationRef.current = requestAnimationFrame(renderFrame);","     }","-  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult]);","+  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);"," ","   // Trigger skeleton render when poseData is loaded","   useEffect(() => {"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"035a0655-ca10-4951-8cf2-a5dfa46d723a"}
{"parentUuid":"d1367610-68e8-464e-ae36-d9bc0d123a67","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01EDamo3dsFYxHvyZmSy5q1J","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to update the analysis flow to compute skill score from pose metrics instead of relying solely on Gemini. Let me find the part where the analysis completes and add the computation.","signature":"EugCCkYICxgCKkCy06AWALpGdfKcjZ5LMkmyom7ar3g0fsPooA196ynPkhi8MvgOhIVStLg+X1Qz9MQASwioF+1wG3aP3TGT5F09EgzmyrOewsjqQTohgK8aDPGoV58lViksaj+FJSIwSRvyHwx2kH2vz0tfk0LuQsdXt0O6KZ7CPlJtShK5jZFK+ay4lM2dJtYOQZB/J+6CKs8BhaEU7vUEc1E2C/rifB4HYTOTm/Pj8H7bc4ofbfOnU4XlwNEKzw1H2HDOn2XyIcgGcGOxUoQ1y5fq7Ooxm+VUqnsu4RI3uRWTMwcLm9xJO6sj27zhpkDcTZXsSjxeYy51OU4B5jtW3R6rvE59tmTQbJhXqJQxwgOERXxE8BlrVruqruTEY+1rlppm8elGkk1phsx1HxR9EpaJ+yvzp7wGanibITcjPAmXVeDfodGycYHIrDDxCJGqna3whXmnsjAIkKNLfT2iAGbW/yieCdRrGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":970,"cache_read_input_tokens":154390,"cache_creation":{"ephemeral_5m_input_tokens":970,"ephemeral_1h_input_tokens":0},"output_tokens":7,"service_tier":"standard"}},"requestId":"req_011CXZCqtHogCsotQix4UfDi","type":"assistant","uuid":"93ec03e1-7eb8-4cd2-b97a-55333f82eaa3","timestamp":"2026-01-28T05:14:06.640Z"}
{"parentUuid":"93ec03e1-7eb8-4cd2-b97a-55333f82eaa3","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01EDamo3dsFYxHvyZmSy5q1J","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me update the `continueAnalysisWithSelection` function to use computed skill score."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":970,"cache_read_input_tokens":154390,"cache_creation":{"ephemeral_5m_input_tokens":970,"ephemeral_1h_input_tokens":0},"output_tokens":7,"service_tier":"standard"}},"requestId":"req_011CXZCqtHogCsotQix4UfDi","type":"assistant","uuid":"abf81e96-c69b-4753-b061-d699ca8e1a24","timestamp":"2026-01-28T05:14:07.124Z"}
{"parentUuid":"abf81e96-c69b-4753-b061-d699ca8e1a24","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01EDamo3dsFYxHvyZmSy5q1J","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012wVXTRFtuX2qYiqSeHeZNB","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // PHASE 3: Auto-detect skill level\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    setAutoLevelResult(levelResult);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n    const avgScore = totalFrames > 0\n      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n      : 0;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };","new_string":"    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":970,"cache_read_input_tokens":154390,"cache_creation":{"ephemeral_5m_input_tokens":970,"ephemeral_1h_input_tokens":0},"output_tokens":7,"service_tier":"standard"}},"requestId":"req_011CXZCqtHogCsotQix4UfDi","type":"assistant","uuid":"f6d89a78-47e1-4bf0-a741-048f1ef45834","timestamp":"2026-01-28T05:14:25.299Z"}
{"parentUuid":"f6d89a78-47e1-4bf0-a741-048f1ef45834","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012wVXTRFtuX2qYiqSeHeZNB","type":"tool_result","content":"The file C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"4a61f50c-d34f-4423-bd49-f147d3eae207","timestamp":"2026-01-28T05:14:25.939Z","toolUseResult":{"filePath":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // PHASE 3: Auto-detect skill level\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    setAutoLevelResult(levelResult);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n    const avgScore = totalFrames > 0\n      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n      : 0;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };","newString":"    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // PHASE 3: Auto-detect skill level\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    setAutoLevelResult(levelResult);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n    const avgScore = totalFrames > 0\n      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n      : 0;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":969,"oldLines":9,"newStart":969,"newLines":28,"lines":["     const detectedIssues = detectIssuesFromAnalyses(analyses);","     setIssues(detectedIssues);"," ","-    // PHASE 3: Auto-detect skill level","+    // V4 FEATURE: Detect mistake events for timeline","+    const mistakes = detectMistakes(poseArray, 10);","+    setMistakeEvents(mistakes);","+","+    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)","+    const metricsHistory = analyses.map(a => a.metrics);","+    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);","+    setComputedSkill(skillResult);","+","+    // V4 FEATURE: Initialize ghost rival data","+    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);","+    setGhostData(ghost);","+","+    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)","     const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);","-    setAutoLevelResult(levelResult);","+    // Override level with computed score","+    const finalLevel = {","+      ...levelResult,","+      level: skillResult.levelLabel,","+      confidence: skillResult.confidencePercent / 100,","+    };","+    setAutoLevelResult(finalLevel);"," ","     // PHASE 4: Generate guidance keyframes","     const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);"]},{"oldStart":979,"oldLines":9,"newStart":998,"newLines":6,"lines":[" ","     const passedFrames = analyses.filter(a => a.evaluation?.passed).length;","     const totalFrames = analyses.filter(a => a.evaluation).length;","-    const avgScore = totalFrames > 0","-      ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames","-      : 0;"," ","     setResult({","       top_issues: detectedIssues.map(issue => ({"]},{"oldStart":999,"oldLines":14,"newStart":1015,"newLines":14,"lines":["         target_metrics: d.targetMetrics,","         instructions: d.steps,","       })),","-      technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,","+      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,","       strategy_summary: passedFrames > totalFrames * 0.7","         ? 'Your form is generally good. Focus on the specific issues identified.'","         : 'Work on maintaining consistent form throughout your movements.',","       training_plan: [],","     });"," ","-    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, avgScore, levelResult);","+    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);","     if (!saveResult.success) {","       setError(saveResult.error || 'Failed to save analysis');","     }"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"f6d89a78-47e1-4bf0-a741-048f1ef45834"}
{"parentUuid":null,"logicalParentUuid":"4a61f50c-d34f-4423-bd49-f147d3eae207","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"system","subtype":"compact_boundary","content":"Conversation compacted","isMeta":false,"timestamp":"2026-01-28T05:15:20.787Z","uuid":"4f00cc6c-4857-4c65-8d89-9f98de928b79","level":"info","compactMetadata":{"trigger":"auto","preTokens":155402}}
{"parentUuid":"4f00cc6c-4857-4c65-8d89-9f98de928b79","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":"This session is being continued from a previous conversation that ran out of context. The summary below covers the earlier portion of the conversation.\n\nAnalysis:\nLet me chronologically analyze the conversation to ensure I capture all technical details:\n\n1. **Initial Request**: The user opened a README.md file and provided extensive instructions for implementing 3 major features in the RallyCoach badminton coaching application:\n   - Feature 1: Ghost Rival Overlay\n   - Feature 2: Mistake Timeline + Click-to-Jump + Animation Cards\n   - Feature 3: Auto Skill Estimation + Confidence Meters\n\n2. **Phase 1 - PLANNER**: I read multiple files to understand the codebase:\n   - Backend files: main.py, analysis.py, pose_estimation.py, gemini_client.py, video_annotator.py\n   - Frontend files: analytics/page.tsx, pose-utils.ts, rules-engine.ts, scoring-rules.ts, types.ts\n   - Components: DrillCard.tsx, GuidanceAnimation.tsx\n   - API routes: auto-level/route.ts\n   - Database: supabase-migration-v2.sql\n\n3. **Phase 2 - BUILDER**: I started implementing:\n   - Created task list for tracking progress\n   - Created database migration file (supabase-migration-v3-features.sql)\n   - Updated types.ts with new interfaces\n   - Created skill-scoring.ts module\n   - Created ghost-overlay.ts module\n   - Created mistake-detection.ts module\n   - Created MistakeTimeline.tsx component\n   - Created FixItCard.tsx component\n   - Created SkillMeter.tsx component\n   - Started updating analytics/page.tsx\n\n4. **Key Technical Requirements**:\n   - Confidence MUST come from actual MediaPipe landmark visibility values\n   - Skill score MUST be computed from pose metrics, NOT Gemini alone\n   - Timeline seeking must use HTMLVideoElement.currentTime\n   - Ghost overlay must show \"My Best Rep\" from same video\n\n5. **Current State**: I was in the middle of updating analytics/page.tsx to integrate all the new features. I made 3 edits:\n   - Added imports for new modules/components\n   - Added state variables for ghost, skill, mistakes\n   - Updated renderFrame to include ghost overlay\n   - Updated continueAnalysisWithSelection to use computed skill score\n\n6. **Pending Work**: \n   - Need to update the other analysis path (analyzeVideo function)\n   - Need to update saveAnalysisToDatabase signature\n   - Need to add UI components to the JSX\n   - Need to update the reset handlers\n   - Need to complete Feature 1 (ghost toggle UI), Feature 2 (timeline in UI), Feature 5 (polish)\n\nSummary:\n1. Primary Request and Intent:\n   The user requested implementation of 3 major features for the RallyCoach badminton coaching application's Video Analytics experience:\n   - **Feature 1: Ghost Rival Overlay** - Show a translucent \"ghost\" skeleton (from \"My Best Rep\") over the user's video, time-synced with toggle\n   - **Feature 2: Mistake Timeline + Click-to-Jump + Animation Cards** - Horizontal timeline showing colored mistake segments by severity, playhead tracking, click-to-seek, and animated Fix-It cards\n   - **Feature 3: Auto Skill Estimation + Confidence Meters** - Remove manual level selection, compute skillScore (0-100) from pose metrics (NOT Gemini), derive confidence from landmark visibility\n\n   Critical constraints:\n   - Confidence MUST come from MediaPipe landmark `visibility` values (0-1)\n   - Skill score MUST be computed from real pose metrics, not invented\n   - Must store results in Supabase\n   - Must show loading animation during analysis\n\n2. Key Technical Concepts:\n   - MediaPipe Tasks-Vision PoseLandmarker with visibility/confidence\n   - HTMLVideoElement.currentTime for seeking\n   - requestAnimationFrame for overlay rendering\n   - Canvas overlay for skeleton rendering\n   - Supabase for data persistence\n   - Next.js 14 App Router (frontend)\n   - FastAPI backend with OpenCV, MediaPipe\n   - Banded scoring system (green/yellow/red)\n\n3. Files and Code Sections:\n\n   - **supabase-migration-v3-features.sql** (CREATED)\n     - Database migration adding skill_score, skill_confidence, best_rep_window, ghost_pose_sequence columns to sessions table\n     - New mistake_events table for timeline segments\n     - Enhanced issues table with start_time_sec, end_time_sec, confidence fields\n\n   - **rallycoach/src/lib/types.ts** (MODIFIED)\n     - Added new interfaces for V4 features\n     ```typescript\n     export interface ComputedSkillScore {\n       skillScore: number; // 0-100\n       levelLabel: 'Beginner' | 'Intermediate' | 'Advanced';\n       confidencePercent: number; // 0-100, derived from landmark visibility\n       confidenceReasons: string[];\n       metrics: { consistencyScore, recoverySpeed, formQuality, visibilityAvg, dropoutRate };\n     }\n     \n     export interface GhostRivalData {\n       source: 'my-best-rep' | 'pro-template';\n       enabled: boolean;\n       poseSequence: GhostPoseFrame[];\n       bestRepWindow?: { startTime, endTime, score, shotType };\n     }\n     \n     export interface MistakeEvent {\n       id: string;\n       type: string;\n       startTimeSec: number;\n       endTimeSec: number;\n       severity: number; // 0-1\n       confidence: number; // 0-1, from visibility\n       joints: number[];\n       summaryTitle: string;\n     }\n     ```\n\n   - **rallycoach/src/lib/skill-scoring.ts** (CREATED)\n     - Computes skill score from REAL pose metrics\n     - Key functions: `computeVisibilityMetrics()`, `computeConsistencyScore()`, `detectSplitStepQuality()`, `computeRecoverySpeed()`, `computeFormQuality()`, `computeSkillScore()`\n     - Confidence derived from MediaPipe visibility values, NOT invented\n\n   - **rallycoach/src/lib/ghost-overlay.ts** (CREATED)\n     - Finds best rep window from same video based on form quality score\n     - Key functions: `findBestRepWindow()`, `extractGhostPoseSequence()`, `getGhostPoseAtTime()`, `initializeGhostRival()`\n     - Downsamples to 15fps for rendering\n\n   - **rallycoach/src/lib/mistake-detection.ts** (CREATED)\n     - Detects specific mistake types: OVERHEAD_CONTACT_LOW, LATE_SPLIT_STEP, POOR_LUNGE_RECOVERY, INSUFFICIENT_ROTATION, STANCE_TOO_NARROW/WIDE, ELBOW_TOO_BENT\n     - Key functions: `detectMistakes()`, `mistakesToTimelineSegments()`, `generateFixKeyframes()`\n     - Each mistake includes confidence from joint visibility\n\n   - **rallycoach/src/components/MistakeTimeline.tsx** (CREATED)\n     - Horizontal timeline with colored severity segments\n     - Playhead synced with video currentTime\n     - Click-to-seek functionality\n     - Legend and current mistake indicator\n\n   - **rallycoach/src/components/FixItCard.tsx** (CREATED)\n     - Animated stick-figure correction card\n     - 3 phases: setup, contact, recover\n     - Canvas-based skeleton rendering with phase interpolation\n\n   - **rallycoach/src/components/SkillMeter.tsx** (CREATED)\n     - Skill badge with level label\n     - Confidence meter bar\n     - Score breakdown (form quality, consistency, recovery speed)\n     - Low confidence warnings with reasons\n\n   - **rallycoach/src/app/analytics/page.tsx** (MODIFIED - 3 edits)\n     - Added imports for new modules/components\n     - Added state: `ghostData`, `showGhost`, `computedSkill`, `mistakeEvents`, `selectedMistake`\n     - Updated renderFrame to draw ghost overlay when enabled\n     - Updated continueAnalysisWithSelection to use computed skill score\n\n4. Errors and fixes:\n   - No explicit errors encountered yet, implementation in progress\n\n5. Problem Solving:\n   - Solved the architecture for computing skill score from real metrics instead of Gemini\n   - Solved ghost overlay sync by using absolute timestamps and looping within best rep window\n   - Solved confidence calculation from MediaPipe visibility values\n\n6. All user messages:\n   - Initial comprehensive request with detailed specifications for 3 features (Ghost Rival, Mistake Timeline, Auto Skill Estimation)\n   - Included project context, tech constraints, phase-by-phase implementation plan, and acceptance criteria\n\n7. Pending Tasks:\n   - Complete analytics/page.tsx updates (second analysis path, saveAnalysisToDatabase signature, UI components in JSX)\n   - Add ghost toggle UI and source selector\n   - Add MistakeTimeline component to page\n   - Add SkillMeter component to page\n   - Add FixItCard when mistake is selected\n   - Update reset handlers to clear new state\n   - Phase 3 - REFINER: Polish and performance optimization\n   - Phase 4 - SUPERVISOR: Verification and test checklist\n   - Update README with new features\n\n8. Current Work:\n   I was updating `rallycoach/src/app/analytics/page.tsx` to integrate all three features. Made 3 edits:\n   1. Added imports for new modules\n   2. Added state variables for ghost, skill, mistakes\n   3. Updated renderFrame to include ghost overlay drawing\n   4. Updated continueAnalysisWithSelection to compute skill score from pose metrics\n\n   The last edit updated the analysis flow:\n   ```typescript\n   // V4 FEATURE: Detect mistake events for timeline\n   const mistakes = detectMistakes(poseArray, 10);\n   setMistakeEvents(mistakes);\n\n   // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n   const metricsHistory = analyses.map(a => a.metrics);\n   const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n   setComputedSkill(skillResult);\n\n   // V4 FEATURE: Initialize ghost rival data\n   const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n   setGhostData(ghost);\n   ```\n\n9. Optional Next Step:\n   Continue updating analytics/page.tsx:\n   1. Update the saveAnalysisToDatabase function signature to accept new parameters (mistakes, bestRepWindow)\n   2. Update the main analyzeVideo function with the same V4 feature integration\n   3. Add the UI components to the JSX (MistakeTimeline, SkillMeter, ghost toggle, FixItCard)\n   4. Update reset handlers to clear new state\n\n   The user's request stated: \"NOW START: 1) PLANNER: read files and produce a file-level plan 2) BUILDER: implement 3) REFINER: polish 4) SUPERVISOR: verify + checklist\"\n   \n   I am currently in PHASE 2 - BUILDER, implementing the features by modifying analytics/page.tsx.\n\nIf you need specific details from before compaction (like exact code snippets, error messages, or content you generated), read the full transcript at: C:\\Users\\ASUS\\.claude\\projects\\C--Users-ASUS-Desktop-Gemini-3-hack\\d33a5d5e-2558-4393-affc-97df18cc3930.jsonl\nPlease continue the conversation from where we left it off without asking the user any further questions. Continue with the last task that you were asked to work on."},"isVisibleInTranscriptOnly":true,"isCompactSummary":true,"uuid":"c19ad35b-8267-4cde-88c2-3ff6470e44cb","timestamp":"2026-01-28T05:15:20.788Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-01-28T05:15:21.016Z","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","content":"/rate-limit-options"}
{"parentUuid":"c19ad35b-8267-4cde-88c2-3ff6470e44cb","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"assistant","uuid":"ab701aa4-0f9e-430a-8588-6808c3afa022","timestamp":"2026-01-28T05:15:21.004Z","message":{"id":"e4e17649-d72a-4a99-80e2-6ccbdc89f9f9","container":null,"model":"<synthetic>","role":"assistant","stop_reason":"stop_sequence","stop_sequence":"","type":"message","usage":{"input_tokens":0,"output_tokens":0,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":null,"cache_creation":{"ephemeral_1h_input_tokens":0,"ephemeral_5m_input_tokens":0}},"content":[{"type":"text","text":"You've hit your limit · resets 1am (America/Los_Angeles)"}],"context_management":null},"error":"rate_limit","isApiErrorMessage":true}
{"type":"queue-operation","operation":"dequeue","timestamp":"2026-01-28T05:15:21.075Z","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930"}
{"parentUuid":"ab701aa4-0f9e-430a-8588-6808c3afa022","isSidechain":false,"userType":"external","cwd":"C:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.19","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"system","subtype":"turn_duration","durationMs":574547,"timestamp":"2026-01-28T05:15:21.057Z","uuid":"68e1f232-76df-48ad-a27d-49adc06c4c39","isMeta":false}
{"type":"queue-operation","operation":"dequeue","timestamp":"2026-01-28T23:23:50.356Z","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930"}
{"type":"file-history-snapshot","messageId":"fe658491-c683-4132-8e78-4cc3f12bf5ba","snapshot":{"messageId":"fe658491-c683-4132-8e78-4cc3f12bf5ba","trackedFileBackups":{},"timestamp":"2026-01-28T23:23:50.394Z"},"isSnapshotUpdate":false}
{"parentUuid":"68e1f232-76df-48ad-a27d-49adc06c4c39","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"type":"text","text":"<ide_opened_file>The user opened the file mcpServer.mcp.config.usrlocal.pencil in the IDE. This may or may not be related to the current task.</ide_opened_file>"},{"type":"text","text":"keep working"}]},"uuid":"fe658491-c683-4132-8e78-4cc3f12bf5ba","timestamp":"2026-01-28T23:23:50.392Z","permissionMode":"default"}
{"parentUuid":"fe658491-c683-4132-8e78-4cc3f12bf5ba","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_017j9CQWnpiBnJUHqszzwxgo","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user wants me to continue implementing the V4 features for the RallyCoach badminton coaching application. Based on the summary, I was in the middle of updating `analytics/page.tsx` to integrate all three features (Ghost Rival Overlay, Mistake Timeline, and Auto Skill Estimation).\n\nLet me continue with the pending tasks:\n1. Update the saveAnalysisToDatabase function signature to accept new parameters\n2. Update the main analyzeVideo function with V4 feature integration\n3. Add the UI components to the JSX (MistakeTimeline, SkillMeter, ghost toggle, FixItCard)\n4. Update reset handlers to clear new state\n\nLet me first read the current state of the analytics/page.tsx file to see what has already been implemented and what still needs to be done.","signature":"EpUHCkYICxgCKkAsLykQXW4MUK9c8bO5n1JXZ1mflN8L2frY+mzj/ytrEKZ6eUxUXqP6olPqpf8dOGFXWCEiLOCrl0jLcg0+Z0oDEgzQ0H6m16xIOWqDJ8gaDOcx93rmIVU6HRrYCCIw8aVfNe0mjyy4bDspc53AcThbnBaZCYDDPeIQXaIVWOkEzVuxRUu/GYpSeqtagcojKvwF7Pt6X+b9CD8WnfkYCQfEzWp2w5hoIoR9B4mFLNbOuQGfMRGj+HZqAh6cUZRbWFxypPzhGbxWuOreLVF2VlhTHWFoUBaejEDdXYAZXZYH8/3/HixnXiT1lm1a1WtV5ExoK0XPepYYoRHIf9LjvQLCg7HZsDxiNDzPdpag4vqL3WHWu2zPZzu8nuxC7s3vvyzZm3zHUzrVrvpgAdQiohA0KfkVbtlhPydmHRr/Id73eedEluIF0qcUcIJ5dKCQXfVAEjMZSnPcPD8+z46sZYDBrxWXcrcvhRZczY7OViMxmpSM09Ms1E4j1a80STRCGNXjjRx9Bvg/fsodWhKpQ3MhhOVCYToogbn05cOgl3s0lYC9PR6BTvXOOD9ID1airh913MwGiqVvg2l1s73SMgmnpyKgyuf8t7wA4zqi0PTjpwARJqFoMMjBwdrdo8TZPZy7/GfLa2RtWCyRi8kvakmi5pir+rxKSvLdaoZMed98Sz3VtwqxdUmgHv4s/TsSMBCt29jV5B+TSB5EzIZghiYJziJlLLhN1yTKiw0rLfvpAQtWZd0ojAY/T/Jh5wlSHS1OFXIHxVh1Rcl40GRPtLbBMIK9h0cfO9o/EicAUQupEIZTbl6TaZKzmUWFWXB+NcQws2sssO51Cjv+RkSSRVKTITsKTJcuQ5tlc8PWDWlkD+Eosdjbl2DCanrfLx3eDghDjzorQIDNutF3iEvsEok19d36pPtvosldJO0VuMjzMrgC+d+5SplKazN/HQEtHX0t3II+XFWPpISYeAcO2KOLG2P51ihuBjAoOI64x20AW7HkYiIEftreyIMzZJ63bnQ/nD5cek/8UfDhZcesN7ZglL/OU7gPM3AJ2yiNC9jC5S1Ro880AZG0vKwjmrrOS0nQyADVq78C3LI/do6gG4ytP3iD27wtlT5Cs9NfGNFF7hS2Ywkq4CYxIaytoFh656NrzetlKcX+f2YyU3v/X1iYygXb1gXnD4bVwbmSUgUNZSQ8LnE+FZ5yGwCbNmwYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":17478,"cache_read_input_tokens":13809,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":17478},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXadwo8pu5kqpmMFgneKk","type":"assistant","uuid":"8f5308be-f716-4432-9c8d-a56b1ae56840","timestamp":"2026-01-28T23:23:54.674Z"}
{"parentUuid":"8f5308be-f716-4432-9c8d-a56b1ae56840","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_017j9CQWnpiBnJUHqszzwxgo","type":"message","role":"assistant","content":[{"type":"text","text":"Continuing with the implementation. Let me first read the current state of the analytics page to see what has been done and what remains."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":17478,"cache_read_input_tokens":13809,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":17478},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXadwo8pu5kqpmMFgneKk","type":"assistant","uuid":"f89fabab-c1fb-45c8-be55-d024bb5af1dc","timestamp":"2026-01-28T23:23:55.352Z"}
{"parentUuid":"f89fabab-c1fb-45c8-be55-d024bb5af1dc","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_017j9CQWnpiBnJUHqszzwxgo","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012jkzasGEneBHUMS4AjecgX","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":17478,"cache_read_input_tokens":13809,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":17478},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXadwo8pu5kqpmMFgneKk","type":"assistant","uuid":"af64ffc8-905b-486a-af67-e4184a702b99","timestamp":"2026-01-28T23:23:56.003Z"}
{"parentUuid":"af64ffc8-905b-486a-af67-e4184a702b99","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012jkzasGEneBHUMS4AjecgX","type":"tool_result","content":"     1→'use client';\n     2→\n     3→import { useState, useEffect, useRef, useCallback, Suspense } from 'react';\n     4→import { useSearchParams } from 'next/navigation';\n     5→import Link from 'next/link';\n     6→import DashboardNav from '@/components/DashboardNav';\n     7→import DrillCard from '@/components/DrillCard';\n     8→import { TabbedDrillAnimation } from '@/components/Skeleton3D';\n     9→import PlayerSelectionModal from '@/components/PlayerSelectionModal';\n    10→import GuidanceAnimation from '@/components/GuidanceAnimation';\n    11→import { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\n    12→import {\n    13→  drawSkeleton,\n    14→  extractMetrics,\n    15→  POSE_CONNECTIONS,\n    16→  POSE_LANDMARKS\n    17→} from '@/lib/pose-utils';\n    18→import {\n    19→  DRILLS,\n    20→  FORM_RULES,\n    21→  evaluateForm,\n    22→  findViolationTimestamps,\n    23→  type EvaluationResult\n    24→} from '@/lib/rules-engine';\n    25→import {\n    26→  evaluateWithBands,\n    27→  SCORING_LEGEND,\n    28→  SKILL_LEVEL_DESCRIPTIONS,\n    29→  validateSessionPoseData,\n    30→} from '@/lib/scoring-rules';\n    31→import { computeSkillScore } from '@/lib/skill-scoring';\n    32→import { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\n    33→import { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\n    34→import MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\n    35→import FixItCard from '@/components/FixItCard';\n    36→import SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\n    37→import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n    38→\n    39→// MediaPipe Types\n    40→type PoseLandmarker = any;\n    41→\n    42→interface FrameAnalysis {\n    43→  timestamp: number;\n    44→  landmarks: PoseLandmark[] | null;\n    45→  evaluation: EvaluationResult | null;\n    46→  metrics: PoseMetrics | null;\n    47→}\n    48→\n    49→interface DetectedIssue {\n    50→  code: string;\n    51→  title: string;\n    52→  severity: 'low' | 'medium' | 'high';\n    53→  description?: string;\n    54→  timestamps: number[];\n    55→  drill?: any;\n    56→}\n    57→\n    58→// PHASE 5: Analysis state machine\n    59→type AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n    60→\n    61→// PHASE 3: Auto-level detection result from Gemini\n    62→interface AutoLevelResult {\n    63→  level: 'Beginner' | 'Intermediate' | 'Advanced';\n    64→  confidence: number;\n    65→  rationaleBullets: string[];\n    66→  guidanceKeyframes?: GuidanceKeyframe[];\n    67→}\n    68→\n    69→// PHASE 4: Guidance keyframe for animation\n    70→interface GuidanceKeyframe {\n    71→  name: string;\n    72→  description: string;\n    73→  landmarks: PoseLandmark[] | null;\n    74→  targetLandmarks?: PoseLandmark[] | null;\n    75→  correction?: string;\n    76→}\n    77→\n    78→function AnalyticsContent() {\n    79→  const searchParams = useSearchParams();\n    80→  const sessionId = searchParams.get('session');\n    81→\n    82→  // State\n    83→  const [uploading, setUploading] = useState(false);\n    84→  const [analyzing, setAnalyzing] = useState(false);\n    85→  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n    86→  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n    87→  const [analysisId, setAnalysisId] = useState<string | null>(null);\n    88→  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n    89→  const [error, setError] = useState<string | null>(null);\n    90→  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n    91→  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n    92→\n    93→  // Multi-pose and player selection state\n    94→  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n    95→  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n    96→  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n    97→  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n    98→  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n    99→  const [eventType, setEventType] = useState<string>('');\n   100→\n   101→  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n   102→  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n   103→  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n   104→\n   105→  // PHASE 4: Guidance animation state\n   106→  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n   107→  const [showGuidance, setShowGuidance] = useState(false);\n   108→\n   109→  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n   110→  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n   111→  const [showGhost, setShowGhost] = useState(false);\n   112→  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n   113→  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n   114→  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n   115→\n   116→  // Video playback state\n   117→  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n   118→  const [videoFile, setVideoFile] = useState<File | null>(null);\n   119→  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n   120→  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n   121→  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n   122→  const [currentTime, setCurrentTime] = useState(0);\n   123→  const [duration, setDuration] = useState(0);\n   124→  const [isPlaying, setIsPlaying] = useState(false);\n   125→  const [showSkeleton, setShowSkeleton] = useState(true);\n   126→  const [fps, setFps] = useState(30);\n   127→\n   128→  // PHASE 2: Canvas overlay alignment state\n   129→  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n   130→\n   131→  // Pose detection\n   132→  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n   133→  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n   134→\n   135→  // PHASE 1: Timestamp tracking for monotonic enforcement\n   136→  const lastTimestampMsRef = useRef<number>(-1);\n   137→  const timestampBaseOffsetRef = useRef<number>(0);\n   138→  const isProcessingRef = useRef<boolean>(false);\n   139→\n   140→  // Refs\n   141→  const fileInputRef = useRef<HTMLInputElement>(null);\n   142→  const videoRef = useRef<HTMLVideoElement>(null);\n   143→  const canvasRef = useRef<HTMLCanvasElement>(null);\n   144→  const videoContainerRef = useRef<HTMLDivElement>(null);\n   145→  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n   146→  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n   147→  const animationRef = useRef<number | null>(null);\n   148→\n   149→  // Initialize MediaPipe Pose Landmarker\n   150→  useEffect(() => {\n   151→    initializePoseLandmarker();\n   152→    return () => {\n   153→      cleanup();\n   154→    };\n   155→  }, []);\n   156→\n   157→  // Load session if ID provided\n   158→  useEffect(() => {\n   159→    if (sessionId) {\n   160→      loadSession(sessionId);\n   161→    }\n   162→  }, [sessionId]);\n   163→\n   164→  // PHASE 2: Update canvas size on video resize\n   165→  useEffect(() => {\n   166→    const updateVideoRect = () => {\n   167→      if (videoRef.current && videoContainerRef.current) {\n   168→        const video = videoRef.current;\n   169→        const container = videoContainerRef.current;\n   170→\n   171→        // Calculate the actual rendered video rectangle (accounting for object-contain)\n   172→        const containerRect = container.getBoundingClientRect();\n   173→        const videoAspect = video.videoWidth / video.videoHeight;\n   174→        const containerAspect = containerRect.width / containerRect.height;\n   175→\n   176→        let renderWidth, renderHeight, offsetX, offsetY;\n   177→\n   178→        if (videoAspect > containerAspect) {\n   179→          // Video is wider - letterbox top/bottom\n   180→          renderWidth = containerRect.width;\n   181→          renderHeight = containerRect.width / videoAspect;\n   182→          offsetX = 0;\n   183→          offsetY = (containerRect.height - renderHeight) / 2;\n   184→        } else {\n   185→          // Video is taller - letterbox left/right\n   186→          renderHeight = containerRect.height;\n   187→          renderWidth = containerRect.height * videoAspect;\n   188→          offsetX = (containerRect.width - renderWidth) / 2;\n   189→          offsetY = 0;\n   190→        }\n   191→\n   192→        setVideoRect({\n   193→          x: offsetX,\n   194→          y: offsetY,\n   195→          width: renderWidth,\n   196→          height: renderHeight,\n   197→          top: offsetY,\n   198→          left: offsetX,\n   199→          right: offsetX + renderWidth,\n   200→          bottom: offsetY + renderHeight,\n   201→          toJSON: () => ({})\n   202→        } as DOMRect);\n   203→      }\n   204→    };\n   205→\n   206→    updateVideoRect();\n   207→    window.addEventListener('resize', updateVideoRect);\n   208→\n   209→    return () => window.removeEventListener('resize', updateVideoRect);\n   210→  }, [videoUrl]);\n   211→\n   212→  const initializePoseLandmarker = async () => {\n   213→    try {\n   214→      const vision = await import('@mediapipe/tasks-vision');\n   215→      const { PoseLandmarker, FilesetResolver } = vision;\n   216→\n   217→      const filesetResolver = await FilesetResolver.forVisionTasks(\n   218→        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n   219→      );\n   220→\n   221→      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n   222→        baseOptions: {\n   223→          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n   224→          delegate: 'GPU',\n   225→        },\n   226→        runningMode: 'VIDEO',\n   227→        numPoses: 4, // Support up to 4 players for doubles\n   228→        minPoseDetectionConfidence: 0.5,\n   229→        minPosePresenceConfidence: 0.5,\n   230→        minTrackingConfidence: 0.5,\n   231→      });\n   232→\n   233→      setPoseLandmarkerReady(true);\n   234→    } catch (error) {\n   235→      console.error('Failed to load MediaPipe Pose:', error);\n   236→      // Continue without pose detection - will use fallback\n   237→    }\n   238→  };\n   239→\n   240→  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n   241→  const recreatePoseLandmarker = async () => {\n   242→    if (poseLandmarkerRef.current) {\n   243→      poseLandmarkerRef.current.close();\n   244→    }\n   245→    lastTimestampMsRef.current = -1;\n   246→    timestampBaseOffsetRef.current = 0;\n   247→    await initializePoseLandmarker();\n   248→  };\n   249→\n   250→  const cleanup = () => {\n   251→    if (pollIntervalRef.current) {\n   252→      clearInterval(pollIntervalRef.current);\n   253→    }\n   254→    if (animationRef.current) {\n   255→      cancelAnimationFrame(animationRef.current);\n   256→    }\n   257→    if (poseLandmarkerRef.current) {\n   258→      poseLandmarkerRef.current.close();\n   259→    }\n   260→  };\n   261→\n   262→  const loadSession = async (id: string) => {\n   263→    try {\n   264→      setAnalyzing(true);\n   265→      setAnalysisState('EXTRACTING_POSE');\n   266→\n   267→      // Try new sessions table first\n   268→      const { data: sessionData, error: sessionError } = await supabase\n   269→        .from('sessions')\n   270→        .select('*')\n   271→        .eq('id', id)\n   272→        .single();\n   273→\n   274→      if (sessionError) {\n   275→        // Try legacy table\n   276→        const { data: legacyData, error: legacyError } = await supabase\n   277→          .from('analysis_results')\n   278→          .select('*')\n   279→          .eq('id', id)\n   280→          .single();\n   281→\n   282→        if (legacyError) throw legacyError;\n   283→        if (legacyData?.result_json) {\n   284→          setResult(legacyData.result_json);\n   285→          if (legacyData.result_json.video_url) {\n   286→            setVideoUrl(legacyData.result_json.video_url);\n   287→          }\n   288→        }\n   289→      } else if (sessionData) {\n   290→        // New session format\n   291→        setVideoUrl(sessionData.video_url);\n   292→\n   293→        if (sessionData.pose_data) {\n   294→          setPoseData(sessionData.pose_data);\n   295→        }\n   296→\n   297→        // Fetch issues\n   298→        const { data: issuesData } = await supabase\n   299→          .from('issues')\n   300→          .select('*')\n   301→          .eq('session_id', id);\n   302→\n   303→        if (issuesData && issuesData.length > 0) {\n   304→          setIssues(issuesData.map((issue: any) => ({\n   305→            code: issue.code,\n   306→            title: issue.title,\n   307→            severity: issue.severity,\n   308→            description: issue.description,\n   309→            timestamps: issue.timestamps || [],\n   310→            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n   311→          })));\n   312→        }\n   313→\n   314→        // Build result from session summary\n   315→        const summary = sessionData.summary || {};\n   316→        setResult({\n   317→          top_issues: issuesData?.map((i: any) => ({\n   318→            id: i.id,\n   319→            title: i.title,\n   320→            severity: i.severity,\n   321→            description: i.description,\n   322→            affected_metrics: [],\n   323→          })) || [],\n   324→          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n   325→            id: d.id,\n   326→            name: d.name,\n   327→            description: d.description,\n   328→            duration_minutes: d.durationMinutes,\n   329→            target_metrics: d.targetMetrics,\n   330→            instructions: d.steps,\n   331→          })) || [],\n   332→          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n   333→          strategy_summary: summary.feedback?.strategy_summary || '',\n   334→          training_plan: [],\n   335→        });\n   336→      }\n   337→      setAnalysisState('DONE');\n   338→    } catch (err) {\n   339→      console.error('Error loading session:', err);\n   340→      setError('Failed to load session');\n   341→      setAnalysisState('ERROR');\n   342→    } finally {\n   343→      setAnalyzing(false);\n   344→    }\n   345→  };\n   346→\n   347→  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n   348→  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n   349→  const processVideoWithPose = async (\n   350→    videoElement: HTMLVideoElement,\n   351→    selectedTracks: number[] = [0]\n   352→  ): Promise<FrameAnalysis[]> => {\n   353→    if (!poseLandmarkerRef.current) {\n   354→      console.warn('Pose landmarker not ready');\n   355→      return [];\n   356→    }\n   357→\n   358→    // Prevent concurrent processing\n   359→    if (isProcessingRef.current) {\n   360→      console.warn('Already processing video, skipping');\n   361→      return [];\n   362→    }\n   363→    isProcessingRef.current = true;\n   364→\n   365→    const analyses: FrameAnalysis[] = [];\n   366→    const videoDuration = videoElement.duration;\n   367→    const sampleRate = 10; // Process 10 frames per second\n   368→    const totalFrames = Math.floor(videoDuration * sampleRate);\n   369→\n   370→    // PHASE 1: Reset timestamp tracking for fresh processing\n   371→    // Use base offset approach so timestamps always increase even if we restart\n   372→    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n   373→    let localLastTimestamp = timestampBaseOffsetRef.current;\n   374→\n   375→    let validPoseFrames = 0;\n   376→    let lowConfidenceFrames = 0;\n   377→    let noPoseFrames = 0;\n   378→\n   379→    setAnalyzeProgress(10); // Start at 10% after track detection\n   380→\n   381→    for (let i = 0; i <= totalFrames; i++) {\n   382→      const timestamp = i / sampleRate;\n   383→      videoElement.currentTime = timestamp;\n   384→\n   385→      // Wait for video to seek\n   386→      await new Promise<void>((resolve) => {\n   387→        const onSeeked = () => {\n   388→          videoElement.removeEventListener('seeked', onSeeked);\n   389→          resolve();\n   390→        };\n   391→        videoElement.addEventListener('seeked', onSeeked);\n   392→      });\n   393→\n   394→      // Give the video a moment to render the frame\n   395→      await new Promise(resolve => setTimeout(resolve, 50));\n   396→\n   397→      try {\n   398→        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n   399→        // Use base offset + local timestamp to guarantee monotonic increase\n   400→        const rawTimestampMs = Math.floor(timestamp * 1000);\n   401→        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n   402→\n   403→        // Double-check monotonicity\n   404→        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n   405→        localLastTimestamp = safeTimestampMs;\n   406→        lastTimestampMsRef.current = safeTimestampMs;\n   407→\n   408→        const results = poseLandmarkerRef.current.detectForVideo(\n   409→          videoElement,\n   410→          safeTimestampMs\n   411→        );\n   412→\n   413→        let landmarks: PoseLandmark[] | null = null;\n   414→        let evaluation: EvaluationResult | null = null;\n   415→        let metrics: PoseMetrics | null = null;\n   416→\n   417→        if (results.landmarks && results.landmarks.length > 0) {\n   418→          // Only use the selected player's landmarks\n   419→          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n   420→            ? selectedTracks[0]\n   421→            : 0;\n   422→\n   423→          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n   424→            x: lm.x,\n   425→            y: lm.y,\n   426→            z: lm.z,\n   427→            visibility: lm.visibility ?? 1.0,\n   428→          }));\n   429→\n   430→          if (landmarks && landmarks.length > 0) {\n   431→            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n   432→\n   433→            if (avgVisibility < 0.5) {\n   434→              lowConfidenceFrames++;\n   435→            } else {\n   436→              validPoseFrames++;\n   437→            }\n   438→            metrics = extractMetrics(landmarks);\n   439→\n   440→            // Use intermediate level for initial processing (auto-level will adjust later)\n   441→            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n   442→            evaluation = {\n   443→              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n   444→              score: bandedResult.overall_score,\n   445→              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n   446→                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n   447→                value: 0,\n   448→                feedback: f,\n   449→              })) : [],\n   450→              passedRules: [],\n   451→              highlightJoints: bandedResult.highlight_joints,\n   452→              recommendedDrills: [],\n   453→            };\n   454→          }\n   455→        } else {\n   456→          noPoseFrames++;\n   457→        }\n   458→\n   459→        analyses.push({\n   460→          timestamp,\n   461→          landmarks,\n   462→          evaluation,\n   463→          metrics,\n   464→        });\n   465→      } catch (err) {\n   466→        const errorMsg = err instanceof Error ? err.message : String(err);\n   467→        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n   468→          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n   469→          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n   470→          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n   471→          localLastTimestamp = timestampBaseOffsetRef.current;\n   472→        } else {\n   473→          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n   474→        }\n   475→        analyses.push({\n   476→          timestamp,\n   477→          landmarks: null,\n   478→          evaluation: null,\n   479→          metrics: null,\n   480→        });\n   481→      }\n   482→\n   483→      // Update progress (10-70%)\n   484→      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n   485→    }\n   486→\n   487→    // PHASE 1: Log pose detection statistics\n   488→    const totalProcessed = totalFrames + 1;\n   489→    const validRatio = validPoseFrames / totalProcessed;\n   490→    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n   491→\n   492→    if (validRatio < 0.3) {\n   493→      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n   494→    }\n   495→\n   496→    isProcessingRef.current = false;\n   497→    return analyses;\n   498→  };\n   499→\n   500→  // Detect issues from frame analyses\n   501→  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n   502→    const issueMap: Map<string, {\n   503→      rule: any;\n   504→      timestamps: number[];\n   505→      count: number;\n   506→    }> = new Map();\n   507→\n   508→    for (const frame of analyses) {\n   509→      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n   510→        for (const failed of frame.evaluation.failedRules) {\n   511→          const code = failed.rule.code;\n   512→          if (!issueMap.has(code)) {\n   513→            issueMap.set(code, {\n   514→              rule: failed.rule,\n   515→              timestamps: [],\n   516→              count: 0,\n   517→            });\n   518→          }\n   519→          const issue = issueMap.get(code)!;\n   520→          issue.timestamps.push(frame.timestamp);\n   521→          issue.count++;\n   522→        }\n   523→      }\n   524→    }\n   525→\n   526→    // Convert to array and sort by count\n   527→    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n   528→      .map(([code, data]) => ({\n   529→        code,\n   530→        title: data.rule.name,\n   531→        severity: data.rule.severity,\n   532→        description: data.rule.description,\n   533→        timestamps: data.timestamps,\n   534→        drill: DRILLS[data.rule.drillId],\n   535→      }))\n   536→      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n   537→      .slice(0, 5); // Top 5 issues\n   538→\n   539→    return issues;\n   540→  };\n   541→\n   542→  // PHASE 3: Auto-detect skill level using Gemini\n   543→  const detectSkillLevelWithGemini = async (\n   544→    analyses: FrameAnalysis[],\n   545→    detectedIssues: DetectedIssue[]\n   546→  ): Promise<AutoLevelResult> => {\n   547→    setAnalysisState('GEMINI_SCORING');\n   548→    setAnalyzeProgress(75);\n   549→\n   550→    try {\n   551→      // Extract features for Gemini analysis\n   552→      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n   553→\n   554→      if (validAnalyses.length < 5) {\n   555→        // Fallback if not enough data\n   556→        return {\n   557→          level: 'Intermediate',\n   558→          confidence: 0.5,\n   559→          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n   560→        };\n   561→      }\n   562→\n   563→      // Calculate aggregate metrics\n   564→      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n   565→      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n   566→      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n   567→      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n   568→\n   569→      // Calculate consistency (standard deviation proxy)\n   570→      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n   571→      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n   572→\n   573→      // Calculate movement intensity (velocity proxy from position changes)\n   574→      let totalMovement = 0;\n   575→      for (let i = 1; i < validAnalyses.length; i++) {\n   576→        const prev = validAnalyses[i - 1].landmarks;\n   577→        const curr = validAnalyses[i].landmarks;\n   578→        if (prev && curr) {\n   579→          const hipMovement = Math.sqrt(\n   580→            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n   581→            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n   582→          );\n   583→          totalMovement += hipMovement;\n   584→        }\n   585→      }\n   586→      const avgMovement = totalMovement / (validAnalyses.length - 1);\n   587→\n   588→      // Issue frequency\n   589→      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n   590→\n   591→      // Call Gemini API for skill level detection\n   592→      const response = await fetch('/api/analysis/auto-level', {\n   593→        method: 'POST',\n   594→        headers: { 'Content-Type': 'application/json' },\n   595→        body: JSON.stringify({\n   596→          metrics: {\n   597→            avgElbowAngle,\n   598→            avgKneeAngle,\n   599→            avgStanceWidth,\n   600→            avgRotation,\n   601→            elbowConsistency: Math.sqrt(elbowVariance),\n   602→            kneeConsistency: Math.sqrt(kneeVariance),\n   603→            movementIntensity: avgMovement,\n   604→            issueFrequency,\n   605→            totalFrames: validAnalyses.length,\n   606→            issueCount: detectedIssues.length,\n   607→          },\n   608→          issues: detectedIssues.map(i => ({\n   609→            code: i.code,\n   610→            title: i.title,\n   611→            frequency: i.timestamps.length / validAnalyses.length,\n   612→          })),\n   613→        }),\n   614→      });\n   615→\n   616→      if (response.ok) {\n   617→        const result = await response.json();\n   618→        setAnalyzeProgress(90);\n   619→        return {\n   620→          level: result.level || 'Intermediate',\n   621→          confidence: result.confidence || 0.7,\n   622→          rationaleBullets: result.rationaleBullets || [],\n   623→          guidanceKeyframes: result.guidanceKeyframes,\n   624→        };\n   625→      }\n   626→    } catch (err) {\n   627→      console.error('Gemini auto-level detection failed:', err);\n   628→    }\n   629→\n   630→    // Fallback rule-based detection\n   631→    setAnalyzeProgress(90);\n   632→    return fallbackSkillLevelDetection(analyses, detectedIssues);\n   633→  };\n   634→\n   635→  // Fallback rule-based skill level detection\n   636→  const fallbackSkillLevelDetection = (\n   637→    analyses: FrameAnalysis[],\n   638→    detectedIssues: DetectedIssue[]\n   639→  ): AutoLevelResult => {\n   640→    const validAnalyses = analyses.filter(a => a.evaluation);\n   641→    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n   642→    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n   643→    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n   644→\n   645→    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n   646→      return {\n   647→        level: 'Advanced',\n   648→        confidence: 0.75,\n   649→        rationaleBullets: [\n   650→          'Consistent form across frames',\n   651→          'No major technique issues detected',\n   652→          'Good body mechanics observed',\n   653→        ],\n   654→      };\n   655→    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n   656→      return {\n   657→        level: 'Intermediate',\n   658→        confidence: 0.7,\n   659→        rationaleBullets: [\n   660→          'Moderate consistency in technique',\n   661→          `${highSeverityIssues} area(s) need focused improvement`,\n   662→          'Foundations are solid with room to refine',\n   663→        ],\n   664→      };\n   665→    } else {\n   666→      return {\n   667→        level: 'Beginner',\n   668→        confidence: 0.8,\n   669→        rationaleBullets: [\n   670→          'Multiple technique areas need development',\n   671→          'Focus on fundamentals before advancing',\n   672→          'Regular practice will show rapid improvement',\n   673→        ],\n   674→      };\n   675→    }\n   676→  };\n   677→\n   678→  // PHASE 4: Generate guidance keyframes from analysis\n   679→  const generateGuidanceKeyframes = (\n   680→    analyses: FrameAnalysis[],\n   681→    detectedIssues: DetectedIssue[]\n   682→  ): GuidanceKeyframe[] => {\n   683→    const keyframes: GuidanceKeyframe[] = [];\n   684→    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n   685→\n   686→    if (validAnalyses.length < 3) return keyframes;\n   687→\n   688→    // Find key moments: Setup, Contact/Action, Recovery\n   689→    // Setup: Early stable frame\n   690→    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n   691→    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n   692→    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n   693→\n   694→    const setupFrame = validAnalyses[setupIdx];\n   695→    const contactFrame = validAnalyses[contactIdx];\n   696→    const recoveryFrame = validAnalyses[recoveryIdx];\n   697→\n   698→    // Determine primary issue for corrections\n   699→    const primaryIssue = detectedIssues[0];\n   700→    let correction = '';\n   701→    if (primaryIssue) {\n   702→      if (primaryIssue.code.includes('ELBOW')) {\n   703→        correction = 'Extend elbow more at contact';\n   704→      } else if (primaryIssue.code.includes('KNEE')) {\n   705→        correction = 'Maintain athletic knee bend';\n   706→      } else if (primaryIssue.code.includes('STANCE')) {\n   707→        correction = 'Widen stance for stability';\n   708→      } else if (primaryIssue.code.includes('ROTATION')) {\n   709→        correction = 'Rotate hips before shoulders';\n   710→      }\n   711→    }\n   712→\n   713→    keyframes.push({\n   714→      name: 'Setup',\n   715→      description: 'Preparation phase',\n   716→      landmarks: setupFrame?.landmarks || null,\n   717→      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n   718→    });\n   719→\n   720→    keyframes.push({\n   721→      name: 'Contact',\n   722→      description: 'Point of contact',\n   723→      landmarks: contactFrame?.landmarks || null,\n   724→      correction: correction || undefined,\n   725→    });\n   726→\n   727→    keyframes.push({\n   728→      name: 'Recovery',\n   729→      description: 'Return to ready',\n   730→      landmarks: recoveryFrame?.landmarks || null,\n   731→      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n   732→    });\n   733→\n   734→    return keyframes;\n   735→  };\n   736→\n   737→  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n   738→    const file = e.target.files?.[0];\n   739→    if (!file) return;\n   740→\n   741→    if (!file.type.startsWith('video/')) {\n   742→      setError('Please select a video file');\n   743→      return;\n   744→    }\n   745→\n   746→    if (file.size > 100 * 1024 * 1024) {\n   747→      setError('File size must be less than 100MB. Please compress your video before uploading.');\n   748→      return;\n   749→    }\n   750→\n   751→    setError(null);\n   752→    setVideoFile(file);\n   753→    setResult(null);\n   754→    setIssues([]);\n   755→    setPoseData([]);\n   756→    setFrameAnalyses([]);\n   757→    setAutoLevelResult(null);\n   758→    setGuidanceKeyframes([]);\n   759→\n   760→    // Create object URL for video preview\n   761→    const objectUrl = URL.createObjectURL(file);\n   762→    setVideoUrl(objectUrl);\n   763→\n   764→    // Start analysis\n   765→    await analyzeVideo(file, objectUrl);\n   766→  };\n   767→\n   768→  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n   769→  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n   770→    if (!poseLandmarkerRef.current) return [];\n   771→\n   772→    const tracks: Map<number, PlayerTrackData> = new Map();\n   773→    const sampleFrames = 5;\n   774→    const duration = videoElement.duration;\n   775→\n   776→    // Use separate timestamp tracking for track detection\n   777→    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n   778→\n   779→    for (let i = 0; i < sampleFrames; i++) {\n   780→      const timestamp = (i / sampleFrames) * duration;\n   781→      videoElement.currentTime = timestamp;\n   782→\n   783→      await new Promise<void>((resolve) => {\n   784→        const onSeeked = () => {\n   785→          videoElement.removeEventListener('seeked', onSeeked);\n   786→          resolve();\n   787→        };\n   788→        videoElement.addEventListener('seeked', onSeeked);\n   789→      });\n   790→\n   791→      await new Promise(resolve => setTimeout(resolve, 50));\n   792→\n   793→      try {\n   794→        // PHASE 1 FIX: Ensure monotonic timestamp\n   795→        trackDetectionTimestamp += 100; // 100ms between samples\n   796→        const safeTimestamp = trackDetectionTimestamp;\n   797→        lastTimestampMsRef.current = safeTimestamp;\n   798→\n   799→        const results = poseLandmarkerRef.current.detectForVideo(\n   800→          videoElement,\n   801→          safeTimestamp\n   802→        );\n   803→\n   804→        if (results.landmarks && results.landmarks.length > 0) {\n   805→          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n   806→            const landmarks = results.landmarks[poseIdx];\n   807→            const bbox = calculateBoundingBox(landmarks);\n   808→\n   809→            if (!tracks.has(poseIdx)) {\n   810→              tracks.set(poseIdx, {\n   811→                track_id: poseIdx,\n   812→                bbox_samples: [],\n   813→                is_selected: false,\n   814→                confidence_avg: 0,\n   815→                frame_count: 0,\n   816→                side: bbox.y < 0.5 ? 'far' : 'near',\n   817→              });\n   818→            }\n   819→\n   820→            const track = tracks.get(poseIdx)!;\n   821→            track.bbox_samples.push({\n   822→              frame: i,\n   823→              x: bbox.x,\n   824→              y: bbox.y,\n   825→              w: bbox.w,\n   826→              h: bbox.h,\n   827→              confidence: landmarks[0].visibility || 0.5,\n   828→            });\n   829→            track.frame_count++;\n   830→            track.confidence_avg =\n   831→              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n   832→              track.frame_count;\n   833→          }\n   834→        }\n   835→      } catch (err) {\n   836→        console.warn('Error detecting poses in frame:', err);\n   837→      }\n   838→    }\n   839→\n   840→    // Generate thumbnails\n   841→    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n   842→\n   843→    if (tracksArray.length > 0) {\n   844→      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n   845→      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n   846→      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n   847→\n   848→      await new Promise<void>((resolve) => {\n   849→        const onSeeked = () => {\n   850→          videoElement.removeEventListener('seeked', onSeeked);\n   851→          resolve();\n   852→        };\n   853→        videoElement.addEventListener('seeked', onSeeked);\n   854→      });\n   855→      await new Promise(resolve => setTimeout(resolve, 100));\n   856→\n   857→      for (const track of tracksArray) {\n   858→        if (track.bbox_samples.length > 0) {\n   859→          const bestBbox = track.bbox_samples.reduce((best, current) =>\n   860→            (current.confidence || 0) > (best.confidence || 0) ? current : best\n   861→          );\n   862→\n   863→          const thumbnail = generateThumbnail(videoElement, {\n   864→            x: bestBbox.x,\n   865→            y: bestBbox.y,\n   866→            w: bestBbox.w,\n   867→            h: bestBbox.h,\n   868→          });\n   869→\n   870→          if (thumbnail) {\n   871→            track.thumbnail_url = thumbnail;\n   872→          }\n   873→        }\n   874→      }\n   875→    }\n   876→\n   877→    return tracksArray;\n   878→  };\n   879→\n   880→  // Calculate bounding box from landmarks\n   881→  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n   882→    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n   883→    for (const lm of landmarks) {\n   884→      if (lm.visibility > 0.5) {\n   885→        minX = Math.min(minX, lm.x);\n   886→        minY = Math.min(minY, lm.y);\n   887→        maxX = Math.max(maxX, lm.x);\n   888→        maxY = Math.max(maxY, lm.y);\n   889→      }\n   890→    }\n   891→    return {\n   892→      x: minX,\n   893→      y: minY,\n   894→      w: maxX - minX,\n   895→      h: maxY - minY,\n   896→    };\n   897→  };\n   898→\n   899→  // Generate thumbnail from video at specific bounding box\n   900→  const generateThumbnail = (\n   901→    video: HTMLVideoElement,\n   902→    bbox: { x: number; y: number; w: number; h: number },\n   903→    padding: number = 0.1\n   904→  ): string | null => {\n   905→    try {\n   906→      const canvas = document.createElement('canvas');\n   907→      const ctx = canvas.getContext('2d');\n   908→      if (!ctx) return null;\n   909→\n   910→      const vw = video.videoWidth;\n   911→      const vh = video.videoHeight;\n   912→\n   913→      const padX = bbox.w * padding;\n   914→      const padY = bbox.h * padding;\n   915→\n   916→      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n   917→      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n   918→      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n   919→      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n   920→\n   921→      if (cropW <= 0 || cropH <= 0) return null;\n   922→\n   923→      const maxSize = 150;\n   924→      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n   925→      canvas.width = Math.floor(cropW * scale);\n   926→      canvas.height = Math.floor(cropH * scale);\n   927→\n   928→      ctx.drawImage(\n   929→        video,\n   930→        cropX, cropY, cropW, cropH,\n   931→        0, 0, canvas.width, canvas.height\n   932→      );\n   933→\n   934→      return canvas.toDataURL('image/jpeg', 0.8);\n   935→    } catch (err) {\n   936→      console.warn('Error generating thumbnail:', err);\n   937→      return null;\n   938→    }\n   939→  };\n   940→\n   941→  // Handle player selection confirmation\n   942→  const handlePlayerSelectionConfirm = (\n   943→    selectedTracks: number[],\n   944→    format: 'singles' | 'doubles',\n   945→    event: string\n   946→  ) => {\n   947→    setSelectedTrackIds(selectedTracks);\n   948→    setMatchFormat(format);\n   949→    setEventType(event);\n   950→    setShowPlayerSelection(false);\n   951→\n   952→    if (processVideoRef.current && videoFile) {\n   953→      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n   954→    }\n   955→  };\n   956→\n   957→  // Continue analysis after player selection\n   958→  const continueAnalysisWithSelection = async (\n   959→    processVideo: HTMLVideoElement,\n   960→    selectedTracks: number[]\n   961→  ) => {\n   962→    setAnalysisState('EXTRACTING_POSE');\n   963→    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n   964→    setFrameAnalyses(analyses);\n   965→\n   966→    const poseArray = analyses.map(a => a.landmarks);\n   967→    setPoseData(poseArray);\n   968→\n   969→    const detectedIssues = detectIssuesFromAnalyses(analyses);\n   970→    setIssues(detectedIssues);\n   971→\n   972→    // V4 FEATURE: Detect mistake events for timeline\n   973→    const mistakes = detectMistakes(poseArray, 10);\n   974→    setMistakeEvents(mistakes);\n   975→\n   976→    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n   977→    const metricsHistory = analyses.map(a => a.metrics);\n   978→    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n   979→    setComputedSkill(skillResult);\n   980→\n   981→    // V4 FEATURE: Initialize ghost rival data\n   982→    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n   983→    setGhostData(ghost);\n   984→\n   985→    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n   986→    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n   987→    // Override level with computed score\n   988→    const finalLevel = {\n   989→      ...levelResult,\n   990→      level: skillResult.levelLabel,\n   991→      confidence: skillResult.confidencePercent / 100,\n   992→    };\n   993→    setAutoLevelResult(finalLevel);\n   994→\n   995→    // PHASE 4: Generate guidance keyframes\n   996→    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n   997→    setGuidanceKeyframes(guidance);\n   998→\n   999→    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n  1000→    const totalFrames = analyses.filter(a => a.evaluation).length;\n  1001→\n  1002→    setResult({\n  1003→      top_issues: detectedIssues.map(issue => ({\n  1004→        id: issue.code,\n  1005→        title: issue.title,\n  1006→        severity: issue.severity,\n  1007→        description: issue.description || '',\n  1008→        affected_metrics: [],\n  1009→      })),\n  1010→      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n  1011→        id: d.id,\n  1012→        name: d.name,\n  1013→        description: d.description,\n  1014→        duration_minutes: d.durationMinutes,\n  1015→        target_metrics: d.targetMetrics,\n  1016→        instructions: d.steps,\n  1017→      })),\n  1018→      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n  1019→      strategy_summary: passedFrames > totalFrames * 0.7\n  1020→        ? 'Your form is generally good. Focus on the specific issues identified.'\n  1021→        : 'Work on maintaining consistent form throughout your movements.',\n  1022→      training_plan: [],\n  1023→    });\n  1024→\n  1025→    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n  1026→    if (!saveResult.success) {\n  1027→      setError(saveResult.error || 'Failed to save analysis');\n  1028→    }\n  1029→    setAnalyzing(false);\n  1030→    setAnalysisState('DONE');\n  1031→    setAnalyzeProgress(100);\n  1032→  };\n  1033→\n  1034→  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n  1035→    setAnalyzing(true);\n  1036→    setAnalyzeProgress(0);\n  1037→    setAnalysisState('DETECTING_PLAYERS');\n  1038→\n  1039→    try {\n  1040→      const processVideo = document.createElement('video');\n  1041→      processVideo.src = videoObjectUrl;\n  1042→      processVideo.muted = true;\n  1043→      processVideo.playsInline = true;\n  1044→      processVideoRef.current = processVideo;\n  1045→\n  1046→      await new Promise<void>((resolve, reject) => {\n  1047→        processVideo.onloadedmetadata = () => {\n  1048→          setDuration(processVideo.duration);\n  1049→          setFps(30);\n  1050→          resolve();\n  1051→        };\n  1052→        processVideo.onerror = () => reject(new Error('Failed to load video'));\n  1053→      });\n  1054→\n  1055→      await new Promise<void>((resolve) => {\n  1056→        if (processVideo.readyState >= 2) {\n  1057→          resolve();\n  1058→        } else {\n  1059→          processVideo.oncanplay = () => resolve();\n  1060→        }\n  1061→      });\n  1062→\n  1063→      // Detect player tracks first\n  1064→      setAnalyzeProgress(5);\n  1065→      const tracks = await detectPlayerTracks(processVideo);\n  1066→      setDetectedTracks(tracks);\n  1067→\n  1068→      const uniquePlayers = tracks.length;\n  1069→      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n  1070→      setDetectedMatchFormat(detectedFormat);\n  1071→\n  1072→      if (tracks.length > 1) {\n  1073→        setShowPlayerSelection(true);\n  1074→        return;\n  1075→      }\n  1076→\n  1077→      if (tracks.length === 1) {\n  1078→        setSelectedTrackIds([tracks[0].track_id]);\n  1079→      }\n  1080→\n  1081→      // Process video with pose detection\n  1082→      let analyses: FrameAnalysis[] = [];\n  1083→\n  1084→      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n  1085→        setAnalysisState('EXTRACTING_POSE');\n  1086→        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n  1087→        setFrameAnalyses(analyses);\n  1088→\n  1089→        const poseArray = analyses.map(a => a.landmarks);\n  1090→        setPoseData(poseArray);\n  1091→\n  1092→        const detectedIssues = detectIssuesFromAnalyses(analyses);\n  1093→        setIssues(detectedIssues);\n  1094→\n  1095→        // PHASE 3: Auto-detect skill level\n  1096→        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n  1097→        setAutoLevelResult(levelResult);\n  1098→\n  1099→        // PHASE 4: Generate guidance keyframes\n  1100→        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n  1101→        setGuidanceKeyframes(guidance);\n  1102→\n  1103→        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n  1104→        const totalFrames = analyses.filter(a => a.evaluation).length;\n  1105→        const avgScore = totalFrames > 0\n  1106→          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n  1107→          : 0;\n  1108→\n  1109→        setResult({\n  1110→          top_issues: detectedIssues.map(issue => ({\n  1111→            id: issue.code,\n  1112→            title: issue.title,\n  1113→            severity: issue.severity,\n  1114→            description: issue.description || '',\n  1115→            affected_metrics: [],\n  1116→          })),\n  1117→          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n  1118→            id: d.id,\n  1119→            name: d.name,\n  1120→            description: d.description,\n  1121→            duration_minutes: d.durationMinutes,\n  1122→            target_metrics: d.targetMetrics,\n  1123→            instructions: d.steps,\n  1124→          })),\n  1125→          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n  1126→          strategy_summary: passedFrames > totalFrames * 0.7\n  1127→            ? 'Your form is generally good. Focus on the specific issues identified.'\n  1128→            : 'Work on maintaining consistent form throughout your movements.',\n  1129→          training_plan: [],\n  1130→        });\n  1131→\n  1132→        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n  1133→        if (!saveResult.success) {\n  1134→          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n  1135→        }\n  1136→        setAnalysisState('DONE');\n  1137→      } else {\n  1138→        setError('Pose detection not available. Using demo mode.');\n  1139→        setAnalysisState('ERROR');\n  1140→\n  1141→        const demoIssues: DetectedIssue[] = [\n  1142→          {\n  1143→            code: 'ELBOW_ANGLE_OVERHEAD',\n  1144→            title: 'Elbow Extension (Overhead)',\n  1145→            severity: 'high',\n  1146→            description: 'Elbow should be nearly straight at contact point',\n  1147→            timestamps: [1.2, 3.5, 7.8],\n  1148→            drill: DRILLS['elbow-extension'],\n  1149→          },\n  1150→          {\n  1151→            code: 'KNEE_BEND',\n  1152→            title: 'Knee Bend',\n  1153→            severity: 'medium',\n  1154→            description: 'Bend knees more for power',\n  1155→            timestamps: [2.1, 5.3],\n  1156→            drill: DRILLS['lunge-practice'],\n  1157→          },\n  1158→        ];\n  1159→        setIssues(demoIssues);\n  1160→        setAutoLevelResult({\n  1161→          level: 'Intermediate',\n  1162→          confidence: 0.5,\n  1163→          rationaleBullets: ['Demo mode - upload video for real analysis'],\n  1164→        });\n  1165→        setResult({\n  1166→          top_issues: demoIssues.map(i => ({\n  1167→            id: i.code,\n  1168→            title: i.title,\n  1169→            severity: i.severity,\n  1170→            description: i.description || '',\n  1171→            affected_metrics: [],\n  1172→          })),\n  1173→          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n  1174→            id: d!.id,\n  1175→            name: d!.name,\n  1176→            description: d!.description,\n  1177→            duration_minutes: d!.durationMinutes,\n  1178→            target_metrics: d!.targetMetrics,\n  1179→            instructions: d!.steps,\n  1180→          })),\n  1181→          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n  1182→          strategy_summary: '',\n  1183→          training_plan: [],\n  1184→        });\n  1185→      }\n  1186→\n  1187→    } catch (err) {\n  1188→      console.error('Analysis error:', err);\n  1189→      setError('Failed to analyze video. Please try again.');\n  1190→      setAnalysisState('ERROR');\n  1191→    } finally {\n  1192→      setAnalyzing(false);\n  1193→      setAnalyzeProgress(100);\n  1194→    }\n  1195→  };\n  1196→\n  1197→  const saveAnalysisToDatabase = async (\n  1198→    file: File,\n  1199→    analyses: FrameAnalysis[],\n  1200→    detectedIssues: DetectedIssue[],\n  1201→    avgScore: number,\n  1202→    levelResult?: AutoLevelResult\n  1203→  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n  1204→    try {\n  1205→      const { data: { user } } = await supabase.auth.getUser();\n  1206→      if (!user) {\n  1207→        return { success: false, error: 'Not authenticated' };\n  1208→      }\n  1209→\n  1210→      let videoPath: string | null = null;\n  1211→      let publicVideoUrl = '';\n  1212→\n  1213→      try {\n  1214→        videoPath = await uploadVideo(file, user.id, (progress) => {\n  1215→          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n  1216→        });\n  1217→\n  1218→        if (!videoPath) {\n  1219→          throw new Error('Upload returned empty path');\n  1220→        }\n  1221→\n  1222→        publicVideoUrl = getVideoUrl(videoPath);\n  1223→        console.log('Video uploaded successfully:', videoPath);\n  1224→\n  1225→      } catch (uploadError) {\n  1226→        console.error('Video upload failed:', uploadError);\n  1227→        const errorMessage = uploadError instanceof Error\n  1228→          ? uploadError.message\n  1229→          : 'Failed to upload video. Please try again.';\n  1230→        setError(errorMessage);\n  1231→        return { success: false, error: errorMessage };\n  1232→      }\n  1233→\n  1234→      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n  1235→      const totalFrames = analyses.filter(a => a.evaluation).length;\n  1236→\n  1237→      const { data: session, error: sessionError } = await supabase\n  1238→        .from('sessions')\n  1239→        .insert({\n  1240→          user_id: user.id,\n  1241→          type: 'analytics',\n  1242→          video_path: videoPath,\n  1243→          video_url: publicVideoUrl,\n  1244→          filename: file.name,\n  1245→          frame_count: analyses.length,\n  1246→          overall_score: Math.round(avgScore),\n  1247→          pose_data: analyses.map(a => a.landmarks),\n  1248→          status: 'ready',\n  1249→          match_format: matchFormat,\n  1250→          event_type: eventType || null,\n  1251→          selected_tracks: selectedTrackIds,\n  1252→          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n  1253→          rules_version: 'v1',\n  1254→          summary: {\n  1255→            total_frames: totalFrames,\n  1256→            green_frames: passedFrames,\n  1257→            red_frames: totalFrames - passedFrames,\n  1258→            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n  1259→            average_score: avgScore,\n  1260→            duration_seconds: duration,\n  1261→            auto_level: levelResult,\n  1262→          },\n  1263→        })\n  1264→        .select()\n  1265→        .single();\n  1266→\n  1267→      if (sessionError) {\n  1268→        console.error('Session save error:', sessionError);\n  1269→        return { success: false, error: 'Failed to save session data' };\n  1270→      }\n  1271→\n  1272→      if (session && detectedIssues.length > 0) {\n  1273→        const issueInserts = detectedIssues.map(issue => ({\n  1274→          session_id: session.id,\n  1275→          code: issue.code,\n  1276→          title: issue.title,\n  1277→          severity: issue.severity,\n  1278→          description: issue.description,\n  1279→          timestamps: issue.timestamps,\n  1280→          drill: issue.drill,\n  1281→        }));\n  1282→\n  1283→        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n  1284→        if (issuesError) {\n  1285→          console.warn('Issues save warning:', issuesError);\n  1286→        }\n  1287→      }\n  1288→\n  1289→      setAnalyzeProgress(100);\n  1290→      return { success: true, sessionId: session.id };\n  1291→\n  1292→    } catch (err) {\n  1293→      console.error('Error saving to database:', err);\n  1294→      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n  1295→      return { success: false, error: errorMessage };\n  1296→    }\n  1297→  };\n  1298→\n  1299→  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  1300→  const renderFrame = useCallback(() => {\n  1301→    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n  1302→\n  1303→    const video = videoRef.current;\n  1304→    const canvas = canvasRef.current;\n  1305→    const ctx = canvas.getContext('2d');\n  1306→    if (!ctx) return;\n  1307→\n  1308→    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n  1309→    const container = videoContainerRef.current;\n  1310→    const containerRect = container.getBoundingClientRect();\n  1311→\n  1312→    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n  1313→\n  1314→    const videoAspect = video.videoWidth / video.videoHeight;\n  1315→    const containerAspect = containerRect.width / containerRect.height;\n  1316→\n  1317→    let renderWidth, renderHeight, offsetX, offsetY;\n  1318→\n  1319→    if (videoAspect > containerAspect) {\n  1320→      // Video is wider - letterbox top/bottom\n  1321→      renderWidth = containerRect.width;\n  1322→      renderHeight = containerRect.width / videoAspect;\n  1323→      offsetX = 0;\n  1324→      offsetY = (containerRect.height - renderHeight) / 2;\n  1325→    } else {\n  1326→      // Video is taller - letterbox left/right\n  1327→      renderHeight = containerRect.height;\n  1328→      renderWidth = containerRect.height * videoAspect;\n  1329→      offsetX = (containerRect.width - renderWidth) / 2;\n  1330→      offsetY = 0;\n  1331→    }\n  1332→\n  1333→    // Set canvas to match container size\n  1334→    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n  1335→      canvas.width = containerRect.width;\n  1336→      canvas.height = containerRect.height;\n  1337→    }\n  1338→\n  1339→    // Clear canvas\n  1340→    ctx.clearRect(0, 0, canvas.width, canvas.height);\n  1341→\n  1342→    if (!showSkeleton) return;\n  1343→\n  1344→    // Find the closest frame analysis\n  1345→    let closestFrame: FrameAnalysis | null = null;\n  1346→    let minDiff = Infinity;\n  1347→\n  1348→    for (const frame of frameAnalyses) {\n  1349→      const diff = Math.abs(frame.timestamp - video.currentTime);\n  1350→      if (diff < minDiff) {\n  1351→        minDiff = diff;\n  1352→        closestFrame = frame;\n  1353→      }\n  1354→    }\n  1355→\n  1356→    // Also check raw poseData array (for loaded sessions)\n  1357→    if (!closestFrame && poseData.length > 0) {\n  1358→      const frameIndex = Math.floor(video.currentTime * 10);\n  1359→      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n  1360→      if (landmarks) {\n  1361→        closestFrame = {\n  1362→          timestamp: video.currentTime,\n  1363→          landmarks,\n  1364→          evaluation: evaluateForm(landmarks, 'general'),\n  1365→          metrics: extractMetrics(landmarks),\n  1366→        };\n  1367→      }\n  1368→    }\n  1369→\n  1370→    if (closestFrame?.landmarks) {\n  1371→      // Get skill level from auto-detection or default to intermediate\n  1372→      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n  1373→      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n  1374→      setCurrentBandedScore(bandedResult);\n  1375→\n  1376→      const isGreen = bandedResult.overall_band === 'green';\n  1377→      const isYellow = bandedResult.overall_band === 'yellow';\n  1378→      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n  1379→\n  1380→      ctx.strokeStyle = color;\n  1381→      ctx.lineWidth = 3;\n  1382→      ctx.fillStyle = color;\n  1383→\n  1384→      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n  1385→      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n  1386→        const start = closestFrame.landmarks[startIdx];\n  1387→        const end = closestFrame.landmarks[endIdx];\n  1388→        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n  1389→          ctx.beginPath();\n  1390→          // Apply offset and scale to match actual video render position\n  1391→          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n  1392→          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n  1393→          ctx.stroke();\n  1394→        }\n  1395→      }\n  1396→\n  1397→      // Draw joints\n  1398→      for (const landmark of closestFrame.landmarks) {\n  1399→        if (landmark.visibility > 0.5) {\n  1400→          ctx.beginPath();\n  1401→          ctx.arc(\n  1402→            offsetX + landmark.x * renderWidth,\n  1403→            offsetY + landmark.y * renderHeight,\n  1404→            5,\n  1405→            0,\n  1406→            2 * Math.PI\n  1407→          );\n  1408→          ctx.fill();\n  1409→        }\n  1410→      }\n  1411→\n  1412→      // V4 FEATURE: Draw Ghost Overlay if enabled\n  1413→      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n  1414→        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n  1415→        if (ghostLandmarks) {\n  1416→          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n  1417→\n  1418→          // Draw ghost connections\n  1419→          ctx.strokeStyle = ghostColor;\n  1420→          ctx.lineWidth = 2;\n  1421→\n  1422→          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n  1423→            const start = ghostLandmarks[startIdx];\n  1424→            const end = ghostLandmarks[endIdx];\n  1425→            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n  1426→              ctx.beginPath();\n  1427→              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n  1428→              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n  1429→              ctx.stroke();\n  1430→            }\n  1431→          }\n  1432→\n  1433→          // Draw ghost joints\n  1434→          ctx.fillStyle = ghostColor;\n  1435→          for (const landmark of ghostLandmarks) {\n  1436→            if ((landmark.visibility ?? 0) > 0.5) {\n  1437→              ctx.beginPath();\n  1438→              ctx.arc(\n  1439→                offsetX + landmark.x * renderWidth,\n  1440→                offsetY + landmark.y * renderHeight,\n  1441→                4,\n  1442→                0,\n  1443→                2 * Math.PI\n  1444→              );\n  1445→              ctx.fill();\n  1446→            }\n  1447→          }\n  1448→        }\n  1449→      }\n  1450→    }\n  1451→\n  1452→    if (!video.paused) {\n  1453→      animationRef.current = requestAnimationFrame(renderFrame);\n  1454→    }\n  1455→  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n  1456→\n  1457→  // Trigger skeleton render when poseData is loaded\n  1458→  useEffect(() => {\n  1459→    if (poseData.length > 0 && videoRef.current) {\n  1460→      const tryRender = () => {\n  1461→        if (videoRef.current && videoRef.current.readyState >= 2) {\n  1462→          renderFrame();\n  1463→        } else {\n  1464→          setTimeout(tryRender, 100);\n  1465→        }\n  1466→      };\n  1467→      tryRender();\n  1468→    }\n  1469→  }, [poseData, renderFrame]);\n  1470→\n  1471→  // Handle video time updates\n  1472→  const handleTimeUpdate = useCallback(() => {\n  1473→    if (videoRef.current) {\n  1474→      setCurrentTime(videoRef.current.currentTime);\n  1475→      renderFrame();\n  1476→    }\n  1477→  }, [renderFrame]);\n  1478→\n  1479→  // Handle video play/pause\n  1480→  const togglePlayPause = useCallback(() => {\n  1481→    if (videoRef.current) {\n  1482→      if (videoRef.current.paused) {\n  1483→        videoRef.current.play();\n  1484→        setIsPlaying(true);\n  1485→        animationRef.current = requestAnimationFrame(renderFrame);\n  1486→      } else {\n  1487→        videoRef.current.pause();\n  1488→        setIsPlaying(false);\n  1489→        if (animationRef.current) {\n  1490→          cancelAnimationFrame(animationRef.current);\n  1491→        }\n  1492→      }\n  1493→    }\n  1494→  }, [renderFrame]);\n  1495→\n  1496→  // Jump to timestamp\n  1497→  const jumpToTimestamp = useCallback((timestamp: number) => {\n  1498→    if (videoRef.current) {\n  1499→      videoRef.current.currentTime = timestamp;\n  1500→      videoRef.current.pause();\n  1501→      setIsPlaying(false);\n  1502→      setCurrentTime(timestamp);\n  1503→      setTimeout(renderFrame, 50);\n  1504→    }\n  1505→  }, [renderFrame]);\n  1506→\n  1507→  // Find next mistake\n  1508→  const goToNextMistake = useCallback(() => {\n  1509→    const allTimestamps = issues\n  1510→      .flatMap((i) => i.timestamps || [])\n  1511→      .sort((a, b) => a - b);\n  1512→\n  1513→    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n  1514→    if (nextTimestamp !== undefined) {\n  1515→      jumpToTimestamp(nextTimestamp);\n  1516→    } else if (allTimestamps.length > 0) {\n  1517→      jumpToTimestamp(allTimestamps[0]);\n  1518→    }\n  1519→  }, [issues, currentTime, jumpToTimestamp]);\n  1520→\n  1521→  // Handle video metadata loaded\n  1522→  const handleLoadedMetadata = useCallback(() => {\n  1523→    if (videoRef.current) {\n  1524→      setDuration(videoRef.current.duration);\n  1525→      setTimeout(renderFrame, 100);\n  1526→    }\n  1527→  }, [renderFrame]);\n  1528→\n  1529→  const getSeverityColor = (severity: string) => {\n  1530→    switch (severity) {\n  1531→      case 'high':\n  1532→        return 'bg-red-50 border-red-200 text-red-800';\n  1533→      case 'medium':\n  1534→        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n  1535→      case 'low':\n  1536→        return 'bg-green-50 border-green-200 text-green-800';\n  1537→      default:\n  1538→        return 'bg-gray-50 border-gray-200 text-gray-800';\n  1539→    }\n  1540→  };\n  1541→\n  1542→  const formatTime = (seconds: number) => {\n  1543→    const mins = Math.floor(seconds / 60);\n  1544→    const secs = Math.floor(seconds % 60);\n  1545→    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  1546→  };\n  1547→\n  1548→  // Get current frame info for display\n  1549→  const getCurrentFrameInfo = () => {\n  1550→    if (frameAnalyses.length === 0) return null;\n  1551→\n  1552→    let closestFrame: FrameAnalysis | null = null;\n  1553→    let minDiff = Infinity;\n  1554→\n  1555→    for (const frame of frameAnalyses) {\n  1556→      const diff = Math.abs(frame.timestamp - currentTime);\n  1557→      if (diff < minDiff) {\n  1558→        minDiff = diff;\n  1559→        closestFrame = frame;\n  1560→      }\n  1561→    }\n  1562→\n  1563→    return closestFrame;\n  1564→  };\n  1565→\n  1566→  const currentFrameInfo = getCurrentFrameInfo();\n  1567→\n  1568→  // PHASE 5: Get analysis state message\n  1569→  const getAnalysisStateMessage = () => {\n  1570→    switch (analysisState) {\n  1571→      case 'DETECTING_PLAYERS':\n  1572→        return 'Detecting players in video...';\n  1573→      case 'EXTRACTING_POSE':\n  1574→        return 'Extracting pose data from frames...';\n  1575→      case 'GEMINI_SCORING':\n  1576→        return 'AI analyzing skill level...';\n  1577→      case 'DONE':\n  1578→        return 'Analysis complete!';\n  1579→      case 'ERROR':\n  1580→        return 'Analysis failed';\n  1581→      default:\n  1582→        return 'Ready to analyze';\n  1583→    }\n  1584→  };\n  1585→\n  1586→  return (\n  1587→    <div className=\"min-h-screen bg-gray-50\">\n  1588→      <DashboardNav />\n  1589→\n  1590→      <main className=\"ml-64 p-8\">\n  1591→        <div className=\"max-w-7xl mx-auto\">\n  1592→          {/* Header */}\n  1593→          <div className=\"mb-8\">\n  1594→            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n  1595→            <p className=\"text-gray-600 mt-1\">\n  1596→              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n  1597→            </p>\n  1598→          </div>\n  1599→\n  1600→          {/* Upload Section */}\n  1601→          {!result && !videoUrl && (\n  1602→            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n  1603→              <div\n  1604→                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n  1605→                  uploading || analyzing\n  1606→                    ? 'border-primary-300 bg-primary-50'\n  1607→                    : 'border-gray-300 hover:border-primary-400'\n  1608→                }`}\n  1609→              >\n  1610→                {uploading ? (\n  1611→                  <div className=\"space-y-4\">\n  1612→                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n  1613→                    <p className=\"text-gray-600\">Uploading video...</p>\n  1614→                  </div>\n  1615→                ) : analyzing ? (\n  1616→                  // PHASE 5: Enhanced loading state with state machine\n  1617→                  <div className=\"space-y-4\">\n  1618→                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n  1619→                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1620→                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n  1621→                      </svg>\n  1622→                      {/* Spinning ring */}\n  1623→                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n  1624→                    </div>\n  1625→                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n  1626→\n  1627→                    {/* Progress steps */}\n  1628→                    <div className=\"flex justify-center gap-2 mt-4\">\n  1629→                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n  1630→                        <div\n  1631→                          key={state}\n  1632→                          className={`w-3 h-3 rounded-full transition-colors ${\n  1633→                            analysisState === state\n  1634→                              ? 'bg-primary-500 animate-pulse'\n  1635→                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n  1636→                              ? 'bg-green-500'\n  1637→                              : 'bg-gray-300'\n  1638→                          }`}\n  1639→                        />\n  1640→                      ))}\n  1641→                    </div>\n  1642→                    <p className=\"text-gray-500 text-sm\">\n  1643→                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n  1644→                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n  1645→                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n  1646→                    </p>\n  1647→\n  1648→                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n  1649→                      <div\n  1650→                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n  1651→                        style={{ width: `${analyzeProgress}%` }}\n  1652→                      ></div>\n  1653→                    </div>\n  1654→                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n  1655→                  </div>\n  1656→                ) : (\n  1657→                  <>\n  1658→                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n  1659→                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1660→                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n  1661→                      </svg>\n  1662→                    </div>\n  1663→                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n  1664→                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n  1665→                    {poseLandmarkerReady && (\n  1666→                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n  1667→                    )}\n  1668→                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n  1669→                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n  1670→                      Select Video\n  1671→                    </button>\n  1672→                  </>\n  1673→                )}\n  1674→              </div>\n  1675→\n  1676→              {error && (\n  1677→                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n  1678→              )}\n  1679→            </div>\n  1680→          )}\n  1681→\n  1682→          {/* Video Player with Overlay */}\n  1683→          {videoUrl && (\n  1684→            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n  1685→              <div className=\"lg:col-span-2\">\n  1686→                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n  1687→                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n  1688→                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n  1689→                    <video\n  1690→                      ref={videoRef}\n  1691→                      src={videoUrl}\n  1692→                      className=\"absolute inset-0 w-full h-full object-contain\"\n  1693→                      onTimeUpdate={handleTimeUpdate}\n  1694→                      onLoadedMetadata={handleLoadedMetadata}\n  1695→                      onEnded={() => setIsPlaying(false)}\n  1696→                      playsInline\n  1697→                    />\n  1698→                    <canvas\n  1699→                      ref={canvasRef}\n  1700→                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n  1701→                        showSkeleton ? '' : 'hidden'\n  1702→                      }`}\n  1703→                    />\n  1704→\n  1705→                    {/* Status indicator with auto-detected level */}\n  1706→                    {currentBandedScore && (\n  1707→                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n  1708→                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n  1709→                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n  1710→                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n  1711→                        'bg-gray-500 text-white'\n  1712→                      }`}>\n  1713→                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n  1714→                        <span className=\"ml-2 opacity-75\">\n  1715→                          {Math.round(currentBandedScore.overall_score)}%\n  1716→                        </span>\n  1717→                      </div>\n  1718→                    )}\n  1719→\n  1720→                    {/* Time display */}\n  1721→                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n  1722→                      {formatTime(currentTime)} / {formatTime(duration)}\n  1723→                    </div>\n  1724→\n  1725→                    {/* Current metrics display */}\n  1726→                    {currentFrameInfo?.metrics && (\n  1727→                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n  1728→                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n  1729→                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n  1730→                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n  1731→                      </div>\n  1732→                    )}\n  1733→                  </div>\n  1734→\n  1735→                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n  1736→                  <div className=\"p-4 flex items-center justify-between\">\n  1737→                    <div className=\"flex items-center gap-2\">\n  1738→                      <button\n  1739→                        onClick={togglePlayPause}\n  1740→                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n  1741→                      >\n  1742→                        {isPlaying ? (\n  1743→                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1744→                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n  1745→                          </svg>\n  1746→                        ) : (\n  1747→                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n  1748→                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n  1749→                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n  1750→                          </svg>\n  1751→                        )}\n  1752→                      </button>\n  1753→\n  1754→                      <button\n  1755→                        onClick={goToNextMistake}\n  1756→                        disabled={issues.length === 0 || analyzing}\n  1757→                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n  1758→                      >\n  1759→                        Next Mistake\n  1760→                      </button>\n  1761→                    </div>\n  1762→\n  1763→                    <div className=\"flex items-center gap-4\">\n  1764→                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n  1765→                      {autoLevelResult && (\n  1766→                        <div className=\"flex items-center gap-2 text-white text-sm\">\n  1767→                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n  1768→                            {autoLevelResult.level}\n  1769→                          </span>\n  1770→                          <span className=\"text-gray-400 text-xs\">\n  1771→                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n  1772→                          </span>\n  1773→                        </div>\n  1774→                      )}\n  1775→\n  1776→                      <label className=\"flex items-center gap-2 text-white text-sm\">\n  1777→                        <input\n  1778→                          type=\"checkbox\"\n  1779→                          checked={showSkeleton}\n  1780→                          onChange={(e) => {\n  1781→                            setShowSkeleton(e.target.checked);\n  1782→                            if (e.target.checked) {\n  1783→                              setTimeout(renderFrame, 50);\n  1784→                            }\n  1785→                          }}\n  1786→                          className=\"rounded\"\n  1787→                        />\n  1788→                        Show Skeleton\n  1789→                      </label>\n  1790→                    </div>\n  1791→                  </div>\n  1792→\n  1793→                  {/* Timeline scrubber */}\n  1794→                  <div className=\"px-4 pb-4\">\n  1795→                    <input\n  1796→                      type=\"range\"\n  1797→                      min={0}\n  1798→                      max={duration || 100}\n  1799→                      step={0.1}\n  1800→                      value={currentTime}\n  1801→                      onChange={(e) => {\n  1802→                        const time = parseFloat(e.target.value);\n  1803→                        if (videoRef.current) {\n  1804→                          videoRef.current.currentTime = time;\n  1805→                          setCurrentTime(time);\n  1806→                          setTimeout(renderFrame, 50);\n  1807→                        }\n  1808→                      }}\n  1809→                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n  1810→                    />\n  1811→                  </div>\n  1812→                </div>\n  1813→\n  1814→                {/* PHASE 3: Auto-level detection result panel */}\n  1815→                {autoLevelResult && (\n  1816→                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n  1817→                    <div className=\"flex items-center justify-between mb-4\">\n  1818→                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n  1819→                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n  1820→                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n  1821→                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n  1822→                        'bg-blue-100 text-blue-800'\n  1823→                      }`}>\n  1824→                        {autoLevelResult.level}\n  1825→                      </span>\n  1826→                    </div>\n  1827→                    <div className=\"space-y-2\">\n  1828→                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n  1829→                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n  1830→                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n  1831→                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n  1832→                          </svg>\n  1833→                          <span>{bullet}</span>\n  1834→                        </div>\n  1835→                      ))}\n  1836→                    </div>\n  1837→                  </div>\n  1838→                )}\n  1839→\n  1840→                {/* PHASE 4: Guidance Animation */}\n  1841→                {guidanceKeyframes.length > 0 && (\n  1842→                  <div className=\"mt-6\">\n  1843→                    <div className=\"flex items-center justify-between mb-4\">\n  1844→                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n  1845→                      <button\n  1846→                        onClick={() => setShowGuidance(!showGuidance)}\n  1847→                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n  1848→                      >\n  1849→                        {showGuidance ? 'Hide' : 'Show'} Animation\n  1850→                      </button>\n  1851→                    </div>\n  1852→                    {showGuidance && (\n  1853→                      <GuidanceAnimation\n  1854→                        keyframes={guidanceKeyframes}\n  1855→                        primaryIssue={issues[0]}\n  1856→                      />\n  1857→                    )}\n  1858→                  </div>\n  1859→                )}\n  1860→\n  1861→                {/* Analysis Summary */}\n  1862→                {result && (\n  1863→                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n  1864→                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n  1865→                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n  1866→                    {result.strategy_summary && (\n  1867→                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n  1868→                    )}\n  1869→                  </div>\n  1870→                )}\n  1871→              </div>\n  1872→\n  1873→              {/* Issues Panel */}\n  1874→              <div className=\"space-y-4\">\n  1875→                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n  1876→                {analyzing ? (\n  1877→                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1878→                    {/* Shimmer loading animation */}\n  1879→                    <div className=\"animate-pulse space-y-4\">\n  1880→                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n  1881→                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n  1882→                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n  1883→                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n  1884→                    </div>\n  1885→                  </div>\n  1886→                ) : issues.length > 0 ? (\n  1887→                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n  1888→                    {issues.map((issue, index) => (\n  1889→                      <DrillCard\n  1890→                        key={index}\n  1891→                        issue={issue}\n  1892→                        onTimestampClick={jumpToTimestamp}\n  1893→                        currentTime={currentTime}\n  1894→                      />\n  1895→                    ))}\n  1896→                  </div>\n  1897→                ) : (\n  1898→                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n  1899→                    <p className=\"font-medium\">Great form!</p>\n  1900→                    <p className=\"text-sm\">No major issues detected in this video.</p>\n  1901→                  </div>\n  1902→                )}\n  1903→\n  1904→                {/* Reset button */}\n  1905→                {videoUrl && !analyzing && (\n  1906→                  <button\n  1907→                    onClick={() => {\n  1908→                      setResult(null);\n  1909→                      setVideoUrl(null);\n  1910→                      setVideoFile(null);\n  1911→                      setIssues([]);\n  1912→                      setPoseData([]);\n  1913→                      setFrameAnalyses([]);\n  1914→                      setCurrentTime(0);\n  1915→                      setDuration(0);\n  1916→                      setAutoLevelResult(null);\n  1917→                      setGuidanceKeyframes([]);\n  1918→                      setAnalysisState('IDLE');\n  1919→                    }}\n  1920→                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n  1921→                  >\n  1922→                    Analyze Another Video\n  1923→                  </button>\n  1924→                )}\n  1925→              </div>\n  1926→            </div>\n  1927→          )}\n  1928→\n  1929→          {/* Results Section (legacy format without video) */}\n  1930→          {result && !videoUrl && (\n  1931→            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n  1932→              {/* Left Column - Issues */}\n  1933→              <div className=\"space-y-6\">\n  1934→                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1935→                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n  1936→                  <div className=\"space-y-3\">\n  1937→                    {result.top_issues.map((issue) => (\n  1938→                      <button\n  1939→                        key={issue.id}\n  1940→                        onClick={() => setSelectedIssue(issue)}\n  1941→                        className={`w-full text-left p-4 rounded-lg border transition ${\n  1942→                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n  1943→                        } ${getSeverityColor(issue.severity)}`}\n  1944→                      >\n  1945→                        <div className=\"flex items-center justify-between mb-1\">\n  1946→                          <span className=\"font-medium\">{issue.title}</span>\n  1947→                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n  1948→                        </div>\n  1949→                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n  1950→                      </button>\n  1951→                    ))}\n  1952→                  </div>\n  1953→                </div>\n  1954→\n  1955→                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1956→                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n  1957→                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n  1958→                </div>\n  1959→              </div>\n  1960→\n  1961→              {/* Right Column - Drills */}\n  1962→              <div className=\"space-y-6\">\n  1963→                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n  1964→                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n  1965→                  <div className=\"space-y-3\">\n  1966→                    {result.drills.map((drill) => (\n  1967→                      <button\n  1968→                        key={drill.id}\n  1969→                        onClick={() => setSelectedDrill(drill)}\n  1970→                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n  1971→                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n  1972→                        }`}\n  1973→                      >\n  1974→                        <div className=\"flex items-center justify-between mb-1\">\n  1975→                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n  1976→                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n  1977→                        </div>\n  1978→                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n  1979→                      </button>\n  1980→                    ))}\n  1981→                  </div>\n  1982→                </div>\n  1983→\n  1984→                {selectedDrill && (\n  1985→                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n  1986→                    <div className=\"flex items-center justify-between mb-4\">\n  1987→                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n  1988→                      <Link\n  1989→                        href={`/practice?drill=${selectedDrill.id}`}\n  1990→                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n  1991→                      >\n  1992→                        Let&apos;s Practice\n  1993→                      </Link>\n  1994→                    </div>\n  1995→                    <div className=\"space-y-3\">\n  1996→                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n  1997→                      <div>\n  1998→                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n  1999→                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n  2000→                          {selectedDrill.instructions.map((instruction, i) => (\n  2001→                            <li key={i}>{instruction}</li>\n  2002→                          ))}\n  2003→                        </ol>\n  2004→                      </div>\n  2005→                    </div>\n  2006→                  </div>\n  2007→                )}\n  2008→\n  2009→                <button\n  2010→                  onClick={() => {\n  2011→                    setResult(null);\n  2012→                    setSelectedIssue(null);\n  2013→                    setSelectedDrill(null);\n  2014→                    setVideoUrl(null);\n  2015→                    setPoseData([]);\n  2016→                    setIssues([]);\n  2017→                    setAutoLevelResult(null);\n  2018→                    setGuidanceKeyframes([]);\n  2019→                    setAnalysisState('IDLE');\n  2020→                  }}\n  2021→                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n  2022→                >\n  2023→                  Analyze Another Video\n  2024→                </button>\n  2025→              </div>\n  2026→            </div>\n  2027→          )}\n  2028→        </div>\n  2029→      </main>\n  2030→\n  2031→      {/* Player Selection Modal */}\n  2032→      <PlayerSelectionModal\n  2033→        isOpen={showPlayerSelection}\n  2034→        onClose={() => {\n  2035→          setShowPlayerSelection(false);\n  2036→          setAnalyzing(false);\n  2037→          setVideoUrl(null);\n  2038→          setVideoFile(null);\n  2039→          setAnalysisState('IDLE');\n  2040→        }}\n  2041→        onConfirm={handlePlayerSelectionConfirm}\n  2042→        tracks={detectedTracks}\n  2043→        detectedFormat={detectedMatchFormat}\n  2044→      />\n  2045→    </div>\n  2046→  );\n  2047→}\n  2048→\n  2049→function AnalyticsLoading() {\n  2050→  return (\n  2051→    <div className=\"min-h-screen bg-gray-50\">\n  2052→      <DashboardNav />\n  2053→      <main className=\"ml-64 p-8\">\n  2054→        <div className=\"max-w-7xl mx-auto\">\n  2055→          <div className=\"animate-pulse\">\n  2056→            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n  2057→            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n  2058→            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n  2059→          </div>\n  2060→        </div>\n  2061→      </main>\n  2062→    </div>\n  2063→  );\n  2064→}\n  2065→\n  2066→export default function AnalyticsPage() {\n  2067→  return (\n  2068→    <Suspense fallback={<AnalyticsLoading />}>\n  2069→      <AnalyticsContent />\n  2070→    </Suspense>\n  2071→  );\n  2072→}\n  2073→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"b4d7bca8-444c-429f-a618-54b501cadf71","timestamp":"2026-01-28T23:23:57.317Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","content":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","numLines":2073,"startLine":1,"totalLines":2073}},"sourceToolAssistantUUID":"af64ffc8-905b-486a-af67-e4184a702b99"}
{"parentUuid":"b4d7bca8-444c-429f-a618-54b501cadf71","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012DmEdYXp7NRmmgQ494mc71","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The file has been partially updated with V4 features. I can see:\n\n1. ✅ Imports for new modules are added (lines 31-36)\n2. ✅ State variables for ghost, skill, mistakes are added (lines 109-114)\n3. ✅ renderFrame includes ghost overlay drawing (lines 1412-1449)\n4. ✅ continueAnalysisWithSelection computes skill score and initializes ghost (lines 972-984)\n\nNow I need to:\n1. Update the saveAnalysisToDatabase function signature to accept new parameters (mistakes, bestRepWindow)\n2. Update the main analyzeVideo function to use V4 features too (since it bypasses player selection for single player videos)\n3. Add the V4 UI components to the JSX (MistakeTimeline, SkillMeter, ghost toggle, FixItCard)\n4. Update reset handlers to clear new state\n\nLet me update the analytics page:\n\n1. First, update saveAnalysisToDatabase to accept additional parameters\n2. Add V4 features to the main analyzeVideo path\n3. Add UI components\n4. Update reset handlers\n\nLet's start!","signature":"EuIICkYICxgCKkDnOyHpnwl6JQJqjZ4OPDzM530E1lbOD7O5E6zsuui0lSmxNWlo48rdOllouyjyyiClIHSboUwN+JCYuXPteepcEgxySLg3KTnGci0Ks+AaDLgPMRlbnr2C4FphXyIweeWjCAOwDqWLR9Wo+LQmulcdj1J3hoifKfqkBL9e1fSv1J3yXPSCKAHIffx1diKPKskH47LwNLWqH6EgWKakpBwLZNbQqPPcIIYzIp2q8+WB9Z8qAqhnI/U7bDKBqlkHJGrTxmfmhfhGjk1DlWqsBtGv7y0mKEFZBX1faNlM8pLOxFsfeuCZwkGzKXPcFWnynXfy8xkzfrCcBaol/RtW5cXbqm70VW5jVX2KSDoKhK8HF3BylyX0JhO9wNtQvyNtbq7jbjP7/uRJov/1C8sANvPWpX6IwBhV11xdlgfn9XGiJI/cOc/lHdJ0dQbJlusryC0oxaySJadCC680rtSLixscIUeCMS98p3MhxJTdPGwH93n3+rYE+/Zwp896rgN7gIegJ+qTURw1TximbFAsEbQapBMgybET9ClzjXr9DmnrS3bP6z66h84Oro9NA+z345M/KQlM9PAv3Da7aZrMKGcUdBjBwDhu00iiXl61px4a+Ms3PF96L/3SzEET5DsOk2JchYAvm+qreuCLWKE5I18Vm3wb77A1boO+sPMR/9c9Cfg0nbhxGnhLnsnJvW6O0kAQHgX3A7qXGr6U8MLNMrwA2s5dFofociLtaSMlSFRfjK08qkdowkM4vhebLP941gMu6GNLJiCtnA49kv9b7zf9lQdD+Hv1K7xin+V1ot2JQKjGabtnWyPwTlWfD0auO076VvnShe0ZFEiye8uc1i8bb4L+lt0MTSvBts2TgUrmuZ6HaV/CR0tn9BJqR9aX2dhJUrT3pm3pMlXWFZ6oJmWQM6KkhES3s/05/aqcsbGwQXeOJL7n44865opA/WTwfYDnwZ8kDrlvp3g+3jinvs1skvi52JobT7CPm9CQF+sVXK9EPpI661kU0I9c+BTtjemrXe+V0+TFyiHvbdPK7EnNFmQN8Z/ZX31t0p9MLCsrRhRwV4lfj6WkTjBlo/pAgWgtuZczYxBImBxHuLJP54UsLY8k7uvCrPEyh6S9HF2uhnFFnzgrJV1QNBvsUSLLYJfZtkCdVqJl4vshGC3nKOK6rK32WshkwBPH4CC33CvzE1nHdrXs3lFI9vQagin3znUjpKKw0/p+MLfgDn3fy/Kn2R8l8nixcAxxP5Ci5PJxXb4IWiCReVVai/7WVIBXaUc0KzkeFZJEh5l3d5cFcTW1e1I0e66RS2iudgXy6plHpujmNldTW5rH06LNCBeBoz0mbjehwvRP+iEUaaZ8MRHSW2PpiFLqSW9p1evjeO99WKw3sRwIHUeVh5fQbCvcJBU7lGsKKGGKOPc+s+J9yuvQ8VBt948NQVFAol0z9yUmctwWafzbLWBX/8Aa1D2vZKwyafUIJRcc9lovGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":31029,"cache_read_input_tokens":31287,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":31029},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXadxJsVecnX5ZRuTD8ig","type":"assistant","uuid":"600f497b-dcc0-4c9c-8834-e67639a943a4","timestamp":"2026-01-28T23:24:06.466Z"}
{"parentUuid":"600f497b-dcc0-4c9c-8834-e67639a943a4","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012DmEdYXp7NRmmgQ494mc71","type":"message","role":"assistant","content":[{"type":"text","text":"I can see the analytics page has been partially updated. Now I need to:\n1. Update the `saveAnalysisToDatabase` function signature to accept V4 parameters\n2. Update the main `analyzeVideo` function with V4 feature integration  \n3. Add UI components to the JSX (MistakeTimeline, SkillMeter, ghost toggle, FixItCard)\n4. Update reset handlers to clear new state\n\nLet me update the `saveAnalysisToDatabase` function signature first."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":31029,"cache_read_input_tokens":31287,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":31029},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXadxJsVecnX5ZRuTD8ig","type":"assistant","uuid":"ec565e3e-99bb-4016-9bc7-85d08d62bc03","timestamp":"2026-01-28T23:24:08.053Z"}
{"parentUuid":"ec565e3e-99bb-4016-9bc7-85d08d62bc03","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012DmEdYXp7NRmmgQ494mc71","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015CJy38AGWDKtq6pi8HFRou","name":"TodoWrite","input":{"todos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"in_progress","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"pending","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"pending","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"pending","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":31029,"cache_read_input_tokens":31287,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":31029},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXadxJsVecnX5ZRuTD8ig","type":"assistant","uuid":"03001fff-9d77-43b1-835c-c4b230360232","timestamp":"2026-01-28T23:24:10.547Z"}
{"parentUuid":"03001fff-9d77-43b1-835c-c4b230360232","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015CJy38AGWDKtq6pi8HFRou","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"6ae3e406-e577-4958-9b6f-c9a0b485bc30","timestamp":"2026-01-28T23:24:10.590Z","toolUseResult":{"oldTodos":[],"newTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"in_progress","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"pending","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"pending","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"pending","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}]},"sourceToolAssistantUUID":"03001fff-9d77-43b1-835c-c4b230360232"}
{"parentUuid":"6ae3e406-e577-4958-9b6f-c9a0b485bc30","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01FiAPCXyW1Fx58eqiSBxGSP","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the saveAnalysisToDatabase function signature and implementation to accept the V4 parameters.","signature":"EpcCCkYICxgCKkAO9M8LPJefh4mUxoL8fJwlgb7ChU6W4wsqGzoWu1AX+50CN331No/BYxs4CsGJehkbIDcr04Pi/XFDAA4pVzzKEgx6W7HcdwP++DueAeYaDBiRf0D6aN23ScP8UiIw/0ijco3PkQhVUCau0xxfdSlQ9dAWu5Us3sDXKF/suHAZCnebILwFj2bX2Brg+TgwKn934OTDWjXUyjXbpZZFKHkh4VhfImt8vmxTBvf4GiADTaRtVvMxaEBm+evBcKiaKvdUEFOhvefihkXjuRVvIaRbX6TaNveymVv7j64JBMqZvuuiFBbTyrfMdgkFzH8k5Qb1MKc7cLdnJu5RwZ44iw6fIANftJbukCklRMSPOjLrGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":699,"cache_read_input_tokens":62316,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":699},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXadyHb8PjLbzTPtEbc3m","type":"assistant","uuid":"11f048de-5bb0-46cf-b27c-34b36924b633","timestamp":"2026-01-28T23:24:12.834Z"}
{"parentUuid":"11f048de-5bb0-46cf-b27c-34b36924b633","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01FiAPCXyW1Fx58eqiSBxGSP","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01F5Gxbe3HTtj9vj8bqvdahJ","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {","new_string":"  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":699,"cache_read_input_tokens":62316,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":699},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXadyHb8PjLbzTPtEbc3m","type":"assistant","uuid":"a3595ae9-36b8-4c2c-bc74-415d09078774","timestamp":"2026-01-28T23:24:16.578Z"}
{"type":"file-history-snapshot","messageId":"a3595ae9-36b8-4c2c-bc74-415d09078774","snapshot":{"messageId":"fe658491-c683-4132-8e78-4cc3f12bf5ba","trackedFileBackups":{"rallycoach\\src\\app\\analytics\\page.tsx":{"backupFileName":"3f45345577d2b22e@v1","version":1,"backupTime":"2026-01-28T23:24:20.053Z"}},"timestamp":"2026-01-28T23:23:50.394Z"},"isSnapshotUpdate":true}
{"parentUuid":"a3595ae9-36b8-4c2c-bc74-415d09078774","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01F5Gxbe3HTtj9vj8bqvdahJ","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"cb9c08c4-d15d-431d-9e59-086d52314d04","timestamp":"2026-01-28T23:24:20.066Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {","newString":"  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1199,"oldLines":7,"newStart":1199,"newLines":9,"lines":["     analyses: FrameAnalysis[],","     detectedIssues: DetectedIssue[],","     avgScore: number,","-    levelResult?: AutoLevelResult","+    levelResult?: AutoLevelResult,","+    mistakeEventsData?: MistakeEvent[],","+    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }","   ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {","     try {","       const { data: { user } } = await supabase.auth.getUser();"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"a3595ae9-36b8-4c2c-bc74-415d09078774"}
{"parentUuid":"cb9c08c4-d15d-431d-9e59-086d52314d04","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Bo5G118oCtaA69pU4WL2sY","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to update the database insert to include the new V4 columns (skill_score, skill_confidence, best_rep_window, ghost_pose_sequence). Let me find the insert statement.","signature":"EtgCCkYICxgCKkDONpkF/tm8aDVMwRPaJ+GJH3d4rm4igKvv1b4TYngNNQQRRTyFCeF4dK0YD0xv8Xd5z0pE0JO0WFoRB8ctcadGEgzhkInBp219anwE7aAaDKa+LVcDkL2Vqpuv9yIwZjIw4eRd9xsH25N/Btn3JDNmQLs1Yw7zVru80Y1fMRhW6+Xr9oDIM0k6ruAxJacuKr8BWrwY51pwK7BcJDLVaU26DSD9kFsEscvOq0z2G4XDEnPVi8ee4h+FI4kECytIzX/8qwB2fWeHm4BVDB/wU6lTlwF9uApyvHvzTB5VvevdiR+qTeTc3LQBmEsxFevkCuzuOSvlO0iEU90hGH3Nw5OApVzwKBO2D7Rj3R1lmtWjA80pl8IlDNmOC3tTWlkJz45LOFPzmJp9j+tfxG+FpW55kTLrSfbm+z0rI+zilY7QLWIl+nFJYic0loDOWEi5JtwYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":433,"cache_read_input_tokens":63015,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":433},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXadz4fn8QCX7nGKZz9aB","type":"assistant","uuid":"92a5d765-5fac-4ee2-a482-b4ddc20df339","timestamp":"2026-01-28T23:24:23.957Z"}
{"parentUuid":"92a5d765-5fac-4ee2-a482-b4ddc20df339","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Bo5G118oCtaA69pU4WL2sY","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me update the database insert statement to include V4 fields."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":433,"cache_read_input_tokens":63015,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":433},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXadz4fn8QCX7nGKZz9aB","type":"assistant","uuid":"604ec633-37d1-4de8-9b1d-e4532af627c1","timestamp":"2026-01-28T23:24:24.333Z"}
{"parentUuid":"604ec633-37d1-4de8-9b1d-e4532af627c1","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Bo5G118oCtaA69pU4WL2sY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UE5ddBUFxU6esJnKcRGZgn","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();","new_string":"      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":433,"cache_read_input_tokens":63015,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":433},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXadz4fn8QCX7nGKZz9aB","type":"assistant","uuid":"fc5fc87b-c0e1-4181-839f-f6171647a169","timestamp":"2026-01-28T23:24:32.059Z"}
{"parentUuid":"fc5fc87b-c0e1-4181-839f-f6171647a169","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UE5ddBUFxU6esJnKcRGZgn","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"6e0b2693-242a-4291-80c4-ce6401c1e6f0","timestamp":"2026-01-28T23:24:32.644Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();","newString":"      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1253,"oldLines":6,"newStart":1253,"newLines":10,"lines":["           selected_tracks: selectedTrackIds,","           skill_level: levelResult?.level.toLowerCase() || 'intermediate',","           rules_version: 'v1',","+          // V4 FEATURES: Store computed skill metrics","+          skill_score: avgScore,","+          skill_confidence: levelResult?.confidence || 0.5,","+          best_rep_window: bestRepWindowData || null,","           summary: {","             total_frames: totalFrames,","             green_frames: passedFrames,"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"fc5fc87b-c0e1-4181-839f-f6171647a169"}
{"parentUuid":"6e0b2693-242a-4291-80c4-ce6401c1e6f0","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_014oF6HaueJ8qzZ1A8KoxLp5","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to add the mistake events insert after the issues insert. Let me find that section and add it.","signature":"EpECCkYICxgCKkBWj0YGH4BtCZ+zFhbVV9KcGcEXqBvQJadKx6wEkOSAOUQNF8hz60R/miQpukbxKzf4fM9cfOSpNX6abSNoIYRjEgyoW8ITV5lRmZFTiR8aDIVVkd00IOgypK5TliIwR+lfKGJFsaQ+adI9H3LlfFwQ2iMPrUPqfPx91ESxW6PVPI6ULgpxb2qXTPzSwUEiKnmhA2CNLDx+eyJouMshG54QE8M+bMSXX/O917qLjDCl4YAneDAHEHV5Fk2OyNmFFTLh03og2p46FswgC/d+Wt2jTKZsXN4BxyWtyVxC3KefeSXIqaFrsonbWrbpgo9/uTRFwzBNgPyYnlTc3GEdTXDgY8RrEBckB2tKGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":897,"cache_read_input_tokens":63448,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":897},"output_tokens":7,"service_tier":"standard"}},"requestId":"req_011CXadzzR59cAVqb1hBsZTW","type":"assistant","uuid":"cf85e46a-de7a-41b6-85c3-8e862baf5239","timestamp":"2026-01-28T23:24:35.783Z"}
{"parentUuid":"cf85e46a-de7a-41b6-85c3-8e862baf5239","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_014oF6HaueJ8qzZ1A8KoxLp5","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me add the mistake events insert after the issues insert."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":897,"cache_read_input_tokens":63448,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":897},"output_tokens":7,"service_tier":"standard"}},"requestId":"req_011CXadzzR59cAVqb1hBsZTW","type":"assistant","uuid":"404f51fd-1a87-4dd4-974e-e9a0ac549807","timestamp":"2026-01-28T23:24:36.092Z"}
{"parentUuid":"404f51fd-1a87-4dd4-974e-e9a0ac549807","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_014oF6HaueJ8qzZ1A8KoxLp5","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MxrU7MhrUpTuPuX3d2cBsf","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }","new_string":"      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":897,"cache_read_input_tokens":63448,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":897},"output_tokens":7,"service_tier":"standard"}},"requestId":"req_011CXadzzR59cAVqb1hBsZTW","type":"assistant","uuid":"6cdcf0ea-c03c-4dc0-b6d6-a563723e83b9","timestamp":"2026-01-28T23:24:41.469Z"}
{"parentUuid":"6cdcf0ea-c03c-4dc0-b6d6-a563723e83b9","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MxrU7MhrUpTuPuX3d2cBsf","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"68c092e2-fc52-49ef-a147-e0e4d540708a","timestamp":"2026-01-28T23:24:42.060Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }","newString":"      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1292,"oldLines":6,"newStart":1292,"newLines":25,"lines":["         }","       }"," ","+      // V4 FEATURE: Save mistake events for timeline","+      if (session && mistakeEventsData && mistakeEventsData.length > 0) {","+        const mistakeInserts = mistakeEventsData.map(mistake => ({","+          session_id: session.id,","+          type: mistake.type,","+          start_time_sec: mistake.startTimeSec,","+          end_time_sec: mistake.endTimeSec,","+          severity: mistake.severity,","+          confidence: mistake.confidence,","+          joints: mistake.joints,","+          summary_title: mistake.summaryTitle,","+        }));","+","+        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);","+        if (mistakeError) {","+          console.warn('Mistake events save warning:', mistakeError);","+        }","+      }","+","       setAnalyzeProgress(100);","       return { success: true, sessionId: session.id };"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"6cdcf0ea-c03c-4dc0-b6d6-a563723e83b9"}
{"parentUuid":"68c092e2-fc52-49ef-a147-e0e4d540708a","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013FCXyvRUwP32JLY7amwGgT","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the todo and proceed to update the main analyzeVideo function to also include V4 features. Looking at the code, when there's only one player (or no player selection needed), it goes directly to processVideoWithPose and doesn't use the V4 features. I need to add V4 features there too.","signature":"EtcDCkYICxgCKkCYytjz2YM4HmsaQ/JwXZC03WWcEraHShY8FFbx1gEe4ULdsyZ4czYdPfiksSvhhYFzgWSNTtljF08y0AgtPOVhEgzA/XJsfz13I+zRmogaDGgkkQy64EA6PDl3xiIwSwWG8wJJ1ACQhh6WS34n6HS6nS8VYFsd592lqhc55pL02zT7oyXncSsRm/tkBoD3Kr4Cx5GRIMpDEVqq4DHMKpkkoiMDLI2uSPrTrV1504lhEVlFoW+g3FCEmHFwxGLCSGdaqer+ZPaVgJN8bYduacRTbqTocb2KgBuX+naEKwFsqk/zZ7lS8sBKnFUQH+GI2ivSID/+BWR8laVFJtIFNEHKt13OQ3vUA0HF8JXhgUgCpyDr7KcR0aQBt1i97UvRU3sbx2D0QN+jUS6sqs+OWcdpfhuOLAwAfn3jppu4j4o+3BFJ7tJC1uNNuDHcerJaXWDW68IhiRE9HHU6rSDzTSpW6pFqf+ND78VCbUa4+jTLxQ0Pd8PeQ/9yVL2PMtpYG9KmmcDU/0XJ17i+mjbaxrC9bXTyHmbxNdomPBf13gxe+rUDnPT7EjXMBNTitgUmo9O+FF6zyizczrDJUb15JR5nmVL0ovB33Ky5ggovdGfcGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":754,"cache_read_input_tokens":64345,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":754},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXae1ggkL2JQ3A211WPuq","type":"assistant","uuid":"cb8d6aa1-9c0d-42c8-9837-8f8f3eb775e8","timestamp":"2026-01-28T23:24:46.437Z"}
{"parentUuid":"cb8d6aa1-9c0d-42c8-9837-8f8f3eb775e8","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013FCXyvRUwP32JLY7amwGgT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NiJZpXM5Az9etsLiutt42v","name":"TodoWrite","input":{"todos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"in_progress","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"pending","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"pending","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":754,"cache_read_input_tokens":64345,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":754},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXae1ggkL2JQ3A211WPuq","type":"assistant","uuid":"6653ce9e-1ce0-40eb-be0f-0faf4da1d732","timestamp":"2026-01-28T23:24:48.138Z"}
{"parentUuid":"6653ce9e-1ce0-40eb-be0f-0faf4da1d732","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NiJZpXM5Az9etsLiutt42v","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"2dd9ea21-d764-423d-a2e7-55dc68e9569c","timestamp":"2026-01-28T23:24:48.179Z","toolUseResult":{"oldTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"in_progress","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"pending","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"pending","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"pending","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}],"newTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"in_progress","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"pending","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"pending","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}]},"sourceToolAssistantUUID":"6653ce9e-1ce0-40eb-be0f-0faf4da1d732"}
{"parentUuid":"2dd9ea21-d764-423d-a2e7-55dc68e9569c","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Tmw1MXm7VHw8nfvtCHGR64","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the analyzeVideo function to include V4 features when there's only one player (single player path).","signature":"Ep4CCkYICxgCKkCFgnDQvQt4WJ/+aI+H3+7hYkHQjShf9CTALIcmKNQDNE3754VHbZPqbQtVE9OxErafq25JZ4l2lkrQ1AwtM4zOEgzHc8Lspfa/K2aaOkMaDArkyKEmt2ix1Gzw4yIwRSsun9IH2MtfFSGsvy+0rDcLAt0IavD7EX6hktFW2PKM8fpcfm+rOGjVUDxu128nKoUBeHuoaXYEdZvGQsakixvrMIOsbL3gcy8EawNMrtk9i58UOxSNjUJTNbecEGiTVsGPvvNriBBK43rH2NE1BEJjBBBh0D+GGiXrAsFBxYkz4+2K+eGfVSEdtRQgliFaIvjhxeZlUiznqajaRdRXDYZZZFxg7yy/SW2V01dzNiYgwgz7HpYxIhgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":391,"cache_read_input_tokens":65099,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":391},"output_tokens":8,"service_tier":"standard"}},"requestId":"req_011CXae24SCNCFAZd5VhuxzC","type":"assistant","uuid":"bd53642f-1ebb-4ae4-8098-654ac3df15b5","timestamp":"2026-01-28T23:24:50.194Z"}
{"parentUuid":"bd53642f-1ebb-4ae4-8098-654ac3df15b5","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Tmw1MXm7VHw8nfvtCHGR64","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me update the main `analyzeVideo` function to include V4 features."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":391,"cache_read_input_tokens":65099,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":391},"output_tokens":8,"service_tier":"standard"}},"requestId":"req_011CXae24SCNCFAZd5VhuxzC","type":"assistant","uuid":"3fa73895-1467-49a9-95da-f07a6dae0ab6","timestamp":"2026-01-28T23:24:50.551Z"}
{"parentUuid":"3fa73895-1467-49a9-95da-f07a6dae0ab6","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Tmw1MXm7VHw8nfvtCHGR64","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JLujR5QPbg7Ty5qBFQv8Tp","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      }","new_string":"      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      }"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":391,"cache_read_input_tokens":65099,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":391},"output_tokens":8,"service_tier":"standard"}},"requestId":"req_011CXae24SCNCFAZd5VhuxzC","type":"assistant","uuid":"44106dc2-c5fa-4a8b-9914-dfbaec853bd9","timestamp":"2026-01-28T23:25:10.598Z"}
{"parentUuid":"44106dc2-c5fa-4a8b-9914-dfbaec853bd9","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JLujR5QPbg7Ty5qBFQv8Tp","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"fa96bea1-cb8d-4e6e-a0d5-2d1d015d8f31","timestamp":"2026-01-28T23:25:11.202Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      }","newString":"      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      }","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // PHASE 3: Auto-detect skill level\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        setAutoLevelResult(levelResult);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n        const avgScore = totalFrames > 0\n          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames\n          : 0;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1092,"oldLines":9,"newStart":1092,"newLines":28,"lines":["         const detectedIssues = detectIssuesFromAnalyses(analyses);","         setIssues(detectedIssues);"," ","-        // PHASE 3: Auto-detect skill level","+        // V4 FEATURE: Detect mistake events for timeline","+        const mistakes = detectMistakes(poseArray, 10);","+        setMistakeEvents(mistakes);","+","+        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)","+        const metricsHistory = analyses.map(a => a.metrics);","+        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);","+        setComputedSkill(skillResult);","+","+        // V4 FEATURE: Initialize ghost rival data","+        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);","+        setGhostData(ghost);","+","+        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)","         const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);","-        setAutoLevelResult(levelResult);","+        // Override level with computed score","+        const finalLevel = {","+          ...levelResult,","+          level: skillResult.levelLabel,","+          confidence: skillResult.confidencePercent / 100,","+        };","+        setAutoLevelResult(finalLevel);"," ","         // PHASE 4: Generate guidance keyframes","         const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);"]},{"oldStart":1102,"oldLines":9,"newStart":1121,"newLines":6,"lines":[" ","         const passedFrames = analyses.filter(a => a.evaluation?.passed).length;","         const totalFrames = analyses.filter(a => a.evaluation).length;","-        const avgScore = totalFrames > 0","-          ? analyses.reduce((sum, a) => sum + (a.evaluation?.score || 0), 0) / totalFrames","-          : 0;"," ","         setResult({","           top_issues: detectedIssues.map(issue => ({"]},{"oldStart":1122,"oldLines":14,"newStart":1138,"newLines":14,"lines":["             target_metrics: d.targetMetrics,","             instructions: d.steps,","           })),","-          technique_summary: `Analysis complete. Detected skill level: ${levelResult.level} (${Math.round(levelResult.confidence * 100)}% confidence). Found ${detectedIssues.length} areas to improve.`,","+          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,","           strategy_summary: passedFrames > totalFrames * 0.7","             ? 'Your form is generally good. Focus on the specific issues identified.'","             : 'Work on maintaining consistent form throughout your movements.',","           training_plan: [],","         });"," ","-        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, avgScore, levelResult);","+        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);","         if (!saveResult.success) {","           setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');","         }"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"44106dc2-c5fa-4a8b-9914-dfbaec853bd9"}
{"parentUuid":"fa96bea1-cb8d-4e6e-a0d5-2d1d015d8f31","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01HTUmRM6GrNED8PGV3oE4R3","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to add the UI components. Let me update the todo and add the MistakeTimeline, SkillMeter, Ghost toggle, and FixItCard to the JSX.","signature":"ErUCCkYICxgCKkBSppjNF4i3MRoymmqxzEOCSdSYgqd8asLbQCB9FkPtEuFvtQh/Bw+8NIqxgCKWv/fCYzbgfIkIVOGAShdGPtSAEgyyJa5+zwlKj8GpImAaDD31u0CL10pXc0LgkCIwqsLUG0o5m2Lqwwgep9H8gSNkvNGx49U8DAVDR5sATG58m7ykpYqhaFOD4vLtOwWaKpwBw0KtMOj1w1VHQ/IbeSPaCvX0JQ1MGe0SGalztIkOW/hTQonO1z6SmJ73/4gmsgzBCAKaBHSc3YvfkXSS6aDFmOzh1dmq8GE/EcBANZINVBPaUdKfjqt2PwtCqAms7lO/Sn8625VDTnQtUV/HRCc6mzEDffsHgce1QoEo2ldR6zE+43x4YApDAl/I058cQxi8EB78yT/zahasXgSCGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":1810,"cache_read_input_tokens":65490,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1810},"output_tokens":7,"service_tier":"standard"}},"requestId":"req_011CXae3qHUsJQcH7GopLLyx","type":"assistant","uuid":"ca64ea3e-0e26-422e-a482-ae47795cf066","timestamp":"2026-01-28T23:25:14.917Z"}
{"parentUuid":"ca64ea3e-0e26-422e-a482-ae47795cf066","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01HTUmRM6GrNED8PGV3oE4R3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01KBnPXqKWG9unjFbPgZSVFS","name":"TodoWrite","input":{"todos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"in_progress","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"pending","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":1810,"cache_read_input_tokens":65490,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1810},"output_tokens":7,"service_tier":"standard"}},"requestId":"req_011CXae3qHUsJQcH7GopLLyx","type":"assistant","uuid":"2b7808e1-8efc-469b-a0d9-6ec50977311c","timestamp":"2026-01-28T23:25:16.713Z"}
{"parentUuid":"2b7808e1-8efc-469b-a0d9-6ec50977311c","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01KBnPXqKWG9unjFbPgZSVFS","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"e63afbdd-a5fd-49ea-8f4a-89ae3a230823","timestamp":"2026-01-28T23:25:16.802Z","toolUseResult":{"oldTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"in_progress","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"pending","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"pending","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}],"newTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"in_progress","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"pending","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}]},"sourceToolAssistantUUID":"2b7808e1-8efc-469b-a0d9-6ec50977311c"}
{"parentUuid":"e63afbdd-a5fd-49ea-8f4a-89ae3a230823","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01KyfLvedDAKXScoAPVYdZxr","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me add the UI components. I need to:\n1. Add the MistakeTimeline below the video timeline scrubber\n2. Add the ghost toggle checkbox in the controls\n3. Add SkillMeter component in the results area\n4. Add FixItCard when a mistake is selected\n\nLet me first add the ghost toggle checkbox to the video controls.","signature":"EtwDCkYICxgCKkCBFfKH9LjSnwq+Z0fFETYZCd2UbIoQjE2+fo00phWIfkNnJho5AyLjcALlGSS4CzSMhXC5cFwjBym/qjZN90V3EgyYm98TPz0I3/bppo0aDHHYvlAaN54ZrKFavyIw0ALs+W2YMRB/XpRk0ZXI+woxS/NIkcWPof5hASzwOt5hw6kZNLq20UgshlkntuRBKsMCMqeHBQvxzwLpzKWA9bMgttpNGbjm+2MF1W7/VojXCKYujLyQfnfuUl456qHRl4u9CTEc8wnWHPbD1/kndTw5M6OPty7H93ujV0PQQBjBCMgPunBZM4/cn9dY6FNBdr/KdnKHBWNfjd0tGPOPalMqHiKUsejRgJVmx8S9n8MJBeDy7+auZE8m4BUhcQhpf2wli+PntY2F1rQWkR7emMMmlVLmTWoLy1j0Zxgtpo7BG9+DXv6emv4QOa58Flp/DP/9eC6lPJSeFt0fF6Yep6I2dpRZLEwwjGFqG4JPK1aT+lhaH9K+uYH6X++3tATKQlHFiqs2kBsybAv7Bux17xKF3N2HH9Pc0Mw9ctqPumCcgKI9grEIyTDKKz1SbOa0JmoxOtWgDDPl3o925gBV8RYe5pFSp8JOCgzJICxf5q3je135S/wYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":361,"cache_read_input_tokens":67300,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":361},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXae4BYdkFff3AMpm5ALa","type":"assistant","uuid":"82c4dc66-b835-4a06-b1f1-1f34c95cc4c0","timestamp":"2026-01-28T23:25:20.159Z"}
{"parentUuid":"82c4dc66-b835-4a06-b1f1-1f34c95cc4c0","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01KyfLvedDAKXScoAPVYdZxr","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me add the ghost toggle to the video controls."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":361,"cache_read_input_tokens":67300,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":361},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXae4BYdkFff3AMpm5ALa","type":"assistant","uuid":"f0c3de33-de85-487c-ab23-553d10e5cecd","timestamp":"2026-01-28T23:25:20.389Z"}
{"parentUuid":"f0c3de33-de85-487c-ab23-553d10e5cecd","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01KyfLvedDAKXScoAPVYdZxr","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EdNQgYUV6gZSHVhH5xsXNL","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>","new_string":"                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":361,"cache_read_input_tokens":67300,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":361},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXae4BYdkFff3AMpm5ALa","type":"assistant","uuid":"7738d82a-2c67-44be-b3a2-c84f41522c03","timestamp":"2026-01-28T23:25:25.791Z"}
{"parentUuid":"7738d82a-2c67-44be-b3a2-c84f41522c03","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EdNQgYUV6gZSHVhH5xsXNL","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"a99ebe33-c03c-4917-8628-831f65f6cc75","timestamp":"2026-01-28T23:25:26.446Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>","newString":"                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1828,"oldLines":6,"newStart":1828,"newLines":24,"lines":["                         />","                         Show Skeleton","                       </label>","+","+                      {/* V4 FEATURE: Ghost overlay toggle */}","+                      {ghostData && ghostData.poseSequence.length > 0 && (","+                        <label className=\"flex items-center gap-2 text-white text-sm\">","+                          <input","+                            type=\"checkbox\"","+                            checked={showGhost}","+                            onChange={(e) => {","+                              setShowGhost(e.target.checked);","+                              if (e.target.checked) {","+                                setTimeout(renderFrame, 50);","+                              }","+                            }}","+                            className=\"rounded accent-cyan-400\"","+                          />","+                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>","+                        </label>","+                      )}","                     </div>","                   </div>"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"7738d82a-2c67-44be-b3a2-c84f41522c03"}
{"parentUuid":"a99ebe33-c03c-4917-8628-831f65f6cc75","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BEHNXxgPdXH5xTAL6hdctS","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me add the MistakeTimeline component below the timeline scrubber.","signature":"EvEBCkYICxgCKkCQUNJvRlrQeodqJmZzfJB3WPh3iqToE8ihgFC/qoKV81qzTcUer+vbMebG+97a94qcL67HyhN78dFIUAFOZXwXEgyEhViyCZFpaJCWB8AaDAHXHhJYrLfSnp3kGiIw4jHMhaXqLZHV4JaH3To5LTa0yKT6E+yuiosx35iB21DLAdVGlry8bdIKdUikih6gKlnkTiqXZkzBZ4Ci1+hqZRlJQ5tQCOUpTfQQQbgWEXwIUYnQNt85dNn8ZHjsIF5YsSz0L050WYFBLCk6vqZ/oaCjWaDDENMKoFkY+toFREzoS2lu69wxhhyg0xgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":727,"cache_read_input_tokens":67661,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":727},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXae4xa4SfNCiqg1HebN7","type":"assistant","uuid":"cef80ae3-0809-4cf6-ad5f-9975d68bec06","timestamp":"2026-01-28T23:25:29.605Z"}
{"parentUuid":"cef80ae3-0809-4cf6-ad5f-9975d68bec06","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BEHNXxgPdXH5xTAL6hdctS","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me add the MistakeTimeline component below the timeline scrubber."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":727,"cache_read_input_tokens":67661,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":727},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXae4xa4SfNCiqg1HebN7","type":"assistant","uuid":"4f306988-d6b7-42cf-b53c-b778ee0c0cfa","timestamp":"2026-01-28T23:25:29.914Z"}
{"parentUuid":"4f306988-d6b7-42cf-b53c-b778ee0c0cfa","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BEHNXxgPdXH5xTAL6hdctS","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NDnXtK61m1pXNgSMS4ZMZa","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>","new_string":"                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        segments={mistakesToTimelineSegments(mistakeEvents, duration)}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistake={selectedMistake}\n                      />\n                    </div>\n                  )}\n                </div>"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":727,"cache_read_input_tokens":67661,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":727},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CXae4xa4SfNCiqg1HebN7","type":"assistant","uuid":"adbca8a2-56d0-44f4-9524-2bbcd8a6e4cd","timestamp":"2026-01-28T23:25:36.818Z"}
{"parentUuid":"adbca8a2-56d0-44f4-9524-2bbcd8a6e4cd","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NDnXtK61m1pXNgSMS4ZMZa","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"e3d604c6-0269-4b7e-840d-cc83b76de6c4","timestamp":"2026-01-28T23:25:37.824Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>","newString":"                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        segments={mistakesToTimelineSegments(mistakeEvents, duration)}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistake={selectedMistake}\n                      />\n                    </div>\n                  )}\n                </div>","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1868,"oldLines":6,"newStart":1868,"newLines":33,"lines":["                       className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"","                     />","                   </div>","+","+                  {/* V4 FEATURE: Mistake Timeline */}","+                  {mistakeEvents.length > 0 && duration > 0 && (","+                    <div className=\"px-4 pb-4\">","+                      <MistakeTimeline","+                        segments={mistakesToTimelineSegments(mistakeEvents, duration)}","+                        duration={duration}","+                        currentTime={currentTime}","+                        onSeek={(time) => {","+                          if (videoRef.current) {","+                            videoRef.current.currentTime = time;","+                            setCurrentTime(time);","+                            setTimeout(renderFrame, 50);","+                          }","+                        }}","+                        onSelectMistake={(mistake) => {","+                          setSelectedMistake(mistake);","+                          if (videoRef.current) {","+                            videoRef.current.currentTime = mistake.startTimeSec;","+                            setCurrentTime(mistake.startTimeSec);","+                            setTimeout(renderFrame, 50);","+                          }","+                        }}","+                        selectedMistake={selectedMistake}","+                      />","+                    </div>","+                  )}","                 </div>"," ","                 {/* PHASE 3: Auto-level detection result panel */}"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"adbca8a2-56d0-44f4-9524-2bbcd8a6e4cd"}
{"parentUuid":"e3d604c6-0269-4b7e-840d-cc83b76de6c4","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Mxi3GMj8BgZEcsVyCxXZ6e","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I see there are type errors. Let me check the MistakeTimeline component to see what props it expects.","signature":"Eo0CCkYICxgCKkBAXjlKF2D9LUiSU9+suIM5JLa4tT8JlaGwPN/Zsuujjt/rO4aqoH2bjVKEXRHJZH58Yb41S1LSFe3uRBIiCxkcEgwXdeH/CmpXxGA+ckMaDAXc6V2hrhravyjJuCIwDuJrz3qnCiHH7xiU7gWNT0c+u83fMHh7wU9pngu1kdn668ZhdwTxiQ3/N4jQzjADKnXSZVCm742wrWq8IUDgV32dPUXR4W7k7K4m4y3N9MKzpIibvWER+RPFtKYGsJKaxdIS/Dd7D+mSJ8rhqS855J97e+bbeCiG9eswzfCUfGPR6m40NA9x2zJnmhOahpbO/o/uC/3GKlm64WVYNaq50POiiBWuLyoYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":1424,"cache_read_input_tokens":68388,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1424},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae5o74rb19GaXMQUPJk","type":"assistant","uuid":"76b423c7-cc40-4c0f-8d4c-36d18b42be32","timestamp":"2026-01-28T23:25:41.083Z"}
{"parentUuid":"76b423c7-cc40-4c0f-8d4c-36d18b42be32","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Mxi3GMj8BgZEcsVyCxXZ6e","type":"message","role":"assistant","content":[{"type":"text","text":"Let me check the MistakeTimeline component to see the correct props interface."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":1424,"cache_read_input_tokens":68388,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1424},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae5o74rb19GaXMQUPJk","type":"assistant","uuid":"0201d4d8-6b41-4e31-99e0-938f99d297a3","timestamp":"2026-01-28T23:25:41.610Z"}
{"parentUuid":"0201d4d8-6b41-4e31-99e0-938f99d297a3","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Mxi3GMj8BgZEcsVyCxXZ6e","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0128hGUeKQLE7ciYz6i8VhGU","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\MistakeTimeline.tsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":1424,"cache_read_input_tokens":68388,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1424},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae5o74rb19GaXMQUPJk","type":"assistant","uuid":"28effc11-54bc-4e3b-a29d-1ff05ffb1b80","timestamp":"2026-01-28T23:25:42.076Z"}
{"parentUuid":"28effc11-54bc-4e3b-a29d-1ff05ffb1b80","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0128hGUeKQLE7ciYz6i8VhGU","type":"tool_result","content":"     1→'use client';\n     2→\n     3→import { useRef, useCallback, useMemo } from 'react';\n     4→import type { MistakeEvent, TimelineSegment } from '@/lib/types';\n     5→\n     6→interface MistakeTimelineProps {\n     7→  mistakes: MistakeEvent[];\n     8→  duration: number;\n     9→  currentTime: number;\n    10→  onSeek: (time: number) => void;\n    11→  onSelectMistake: (mistake: MistakeEvent | null) => void;\n    12→  selectedMistakeId?: string | null;\n    13→}\n    14→\n    15→export default function MistakeTimeline({\n    16→  mistakes,\n    17→  duration,\n    18→  currentTime,\n    19→  onSeek,\n    20→  onSelectMistake,\n    21→  selectedMistakeId,\n    22→}: MistakeTimelineProps) {\n    23→  const timelineRef = useRef<HTMLDivElement>(null);\n    24→\n    25→  // Convert mistakes to timeline segments\n    26→  const segments = useMemo((): TimelineSegment[] => {\n    27→    if (duration <= 0) return [];\n    28→\n    29→    return mistakes.map(event => ({\n    30→      id: event.id,\n    31→      startPercent: (event.startTimeSec / duration) * 100,\n    32→      widthPercent: Math.max(1, ((event.endTimeSec - event.startTimeSec) / duration) * 100),\n    33→      color: getSeverityColor(event.severity),\n    34→      event,\n    35→    }));\n    36→  }, [mistakes, duration]);\n    37→\n    38→  // Calculate playhead position\n    39→  const playheadPercent = duration > 0 ? (currentTime / duration) * 100 : 0;\n    40→\n    41→  // Handle click on timeline\n    42→  const handleTimelineClick = useCallback((e: React.MouseEvent<HTMLDivElement>) => {\n    43→    if (!timelineRef.current || duration <= 0) return;\n    44→\n    45→    const rect = timelineRef.current.getBoundingClientRect();\n    46→    const clickX = e.clientX - rect.left;\n    47→    const percent = (clickX / rect.width) * 100;\n    48→    const time = (percent / 100) * duration;\n    49→\n    50→    // Seek to clicked time\n    51→    onSeek(Math.max(0, Math.min(duration, time)));\n    52→\n    53→    // Check if clicking on a segment\n    54→    const clickedSegment = segments.find(seg =>\n    55→      percent >= seg.startPercent && percent <= seg.startPercent + seg.widthPercent\n    56→    );\n    57→\n    58→    if (clickedSegment) {\n    59→      onSelectMistake(clickedSegment.event);\n    60→    } else {\n    61→      onSelectMistake(null);\n    62→    }\n    63→  }, [duration, segments, onSeek, onSelectMistake]);\n    64→\n    65→  // Handle segment click\n    66→  const handleSegmentClick = useCallback((e: React.MouseEvent, segment: TimelineSegment) => {\n    67→    e.stopPropagation();\n    68→    onSeek(segment.event.startTimeSec);\n    69→    onSelectMistake(segment.event);\n    70→  }, [onSeek, onSelectMistake]);\n    71→\n    72→  // Format time for display\n    73→  const formatTime = (seconds: number) => {\n    74→    const mins = Math.floor(seconds / 60);\n    75→    const secs = Math.floor(seconds % 60);\n    76→    return `${mins}:${secs.toString().padStart(2, '0')}`;\n    77→  };\n    78→\n    79→  // Check if current time is within a mistake\n    80→  const currentMistake = useMemo(() => {\n    81→    return mistakes.find(m =>\n    82→      currentTime >= m.startTimeSec && currentTime <= m.endTimeSec\n    83→    );\n    84→  }, [mistakes, currentTime]);\n    85→\n    86→  return (\n    87→    <div className=\"w-full space-y-2\">\n    88→      {/* Timeline label */}\n    89→      <div className=\"flex items-center justify-between text-xs text-gray-500\">\n    90→        <span>Mistake Timeline</span>\n    91→        <span>{formatTime(currentTime)} / {formatTime(duration)}</span>\n    92→      </div>\n    93→\n    94→      {/* Timeline container */}\n    95→      <div\n    96→        ref={timelineRef}\n    97→        onClick={handleTimelineClick}\n    98→        className=\"relative h-8 bg-gray-200 rounded-lg overflow-hidden cursor-pointer hover:bg-gray-300 transition-colors\"\n    99→      >\n   100→        {/* Mistake segments */}\n   101→        {segments.map(segment => (\n   102→          <button\n   103→            key={segment.id}\n   104→            onClick={(e) => handleSegmentClick(e, segment)}\n   105→            className={`absolute top-0 bottom-0 rounded transition-all ${\n   106→              selectedMistakeId === segment.id\n   107→                ? 'ring-2 ring-white ring-offset-1 z-10'\n   108→                : 'hover:opacity-90'\n   109→            }`}\n   110→            style={{\n   111→              left: `${segment.startPercent}%`,\n   112→              width: `${segment.widthPercent}%`,\n   113→              backgroundColor: segment.color,\n   114→              minWidth: '4px',\n   115→            }}\n   116→            title={`${segment.event.summaryTitle} (${formatTime(segment.event.startTimeSec)})`}\n   117→          >\n   118→            {/* Show label if segment is wide enough */}\n   119→            {segment.widthPercent > 8 && (\n   120→              <span className=\"absolute inset-0 flex items-center justify-center text-white text-xs font-medium truncate px-1\">\n   121→                {segment.event.summaryTitle}\n   122→              </span>\n   123→            )}\n   124→          </button>\n   125→        ))}\n   126→\n   127→        {/* Playhead */}\n   128→        <div\n   129→          className=\"absolute top-0 bottom-0 w-0.5 bg-white shadow-lg z-20 pointer-events-none\"\n   130→          style={{ left: `${playheadPercent}%` }}\n   131→        >\n   132→          {/* Playhead triangle */}\n   133→          <div className=\"absolute -top-1 left-1/2 -translate-x-1/2 w-0 h-0 border-l-[4px] border-l-transparent border-r-[4px] border-r-transparent border-t-[6px] border-t-white\"></div>\n   134→        </div>\n   135→\n   136→        {/* Current time indicator */}\n   137→        {currentMistake && (\n   138→          <div className=\"absolute bottom-0 left-0 right-0 h-1 bg-white/30\"></div>\n   139→        )}\n   140→      </div>\n   141→\n   142→      {/* Legend */}\n   143→      <div className=\"flex items-center gap-4 text-xs text-gray-600\">\n   144→        <div className=\"flex items-center gap-1\">\n   145→          <div className=\"w-3 h-3 rounded bg-red-500\"></div>\n   146→          <span>High</span>\n   147→        </div>\n   148→        <div className=\"flex items-center gap-1\">\n   149→          <div className=\"w-3 h-3 rounded bg-orange-500\"></div>\n   150→          <span>Medium</span>\n   151→        </div>\n   152→        <div className=\"flex items-center gap-1\">\n   153→          <div className=\"w-3 h-3 rounded bg-yellow-500\"></div>\n   154→          <span>Low</span>\n   155→        </div>\n   156→        <span className=\"ml-auto text-gray-400\">Click to seek</span>\n   157→      </div>\n   158→\n   159→      {/* Current mistake indicator */}\n   160→      {currentMistake && (\n   161→        <div className=\"flex items-center gap-2 p-2 bg-red-50 border border-red-200 rounded-lg\">\n   162→          <span className=\"w-2 h-2 rounded-full bg-red-500 animate-pulse\"></span>\n   163→          <span className=\"text-sm text-red-800 font-medium\">\n   164→            {currentMistake.summaryTitle}\n   165→          </span>\n   166→          <span className=\"text-xs text-red-600 ml-auto\">\n   167→            {Math.round(currentMistake.confidence * 100)}% confidence\n   168→          </span>\n   169→        </div>\n   170→      )}\n   171→    </div>\n   172→  );\n   173→}\n   174→\n   175→// Helper function for severity colors\n   176→function getSeverityColor(severity: number): string {\n   177→  if (severity >= 0.7) return '#ef4444'; // Red\n   178→  if (severity >= 0.4) return '#f97316'; // Orange\n   179→  return '#eab308'; // Yellow\n   180→}\n   181→\n   182→// Mini version for embedding\n   183→export function MistakeTimelineMini({\n   184→  mistakes,\n   185→  duration,\n   186→  currentTime,\n   187→  onSeek,\n   188→}: {\n   189→  mistakes: MistakeEvent[];\n   190→  duration: number;\n   191→  currentTime: number;\n   192→  onSeek: (time: number) => void;\n   193→}) {\n   194→  const segments = useMemo((): TimelineSegment[] => {\n   195→    if (duration <= 0) return [];\n   196→\n   197→    return mistakes.map(event => ({\n   198→      id: event.id,\n   199→      startPercent: (event.startTimeSec / duration) * 100,\n   200→      widthPercent: Math.max(0.5, ((event.endTimeSec - event.startTimeSec) / duration) * 100),\n   201→      color: getSeverityColor(event.severity),\n   202→      event,\n   203→    }));\n   204→  }, [mistakes, duration]);\n   205→\n   206→  const playheadPercent = duration > 0 ? (currentTime / duration) * 100 : 0;\n   207→\n   208→  const handleClick = (e: React.MouseEvent<HTMLDivElement>) => {\n   209→    const rect = e.currentTarget.getBoundingClientRect();\n   210→    const clickX = e.clientX - rect.left;\n   211→    const percent = clickX / rect.width;\n   212→    onSeek(percent * duration);\n   213→  };\n   214→\n   215→  return (\n   216→    <div\n   217→      onClick={handleClick}\n   218→      className=\"relative h-2 bg-gray-600 rounded-full overflow-hidden cursor-pointer\"\n   219→    >\n   220→      {segments.map(segment => (\n   221→        <div\n   222→          key={segment.id}\n   223→          className=\"absolute top-0 bottom-0\"\n   224→          style={{\n   225→            left: `${segment.startPercent}%`,\n   226→            width: `${segment.widthPercent}%`,\n   227→            backgroundColor: segment.color,\n   228→            minWidth: '2px',\n   229→          }}\n   230→        />\n   231→      ))}\n   232→      <div\n   233→        className=\"absolute top-0 bottom-0 w-1 bg-white rounded-full\"\n   234→        style={{ left: `calc(${playheadPercent}% - 2px)` }}\n   235→      />\n   236→    </div>\n   237→  );\n   238→}\n   239→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"e4db46b1-f37d-4b20-91b7-180efec6374f","timestamp":"2026-01-28T23:25:42.761Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\MistakeTimeline.tsx","content":"'use client';\n\nimport { useRef, useCallback, useMemo } from 'react';\nimport type { MistakeEvent, TimelineSegment } from '@/lib/types';\n\ninterface MistakeTimelineProps {\n  mistakes: MistakeEvent[];\n  duration: number;\n  currentTime: number;\n  onSeek: (time: number) => void;\n  onSelectMistake: (mistake: MistakeEvent | null) => void;\n  selectedMistakeId?: string | null;\n}\n\nexport default function MistakeTimeline({\n  mistakes,\n  duration,\n  currentTime,\n  onSeek,\n  onSelectMistake,\n  selectedMistakeId,\n}: MistakeTimelineProps) {\n  const timelineRef = useRef<HTMLDivElement>(null);\n\n  // Convert mistakes to timeline segments\n  const segments = useMemo((): TimelineSegment[] => {\n    if (duration <= 0) return [];\n\n    return mistakes.map(event => ({\n      id: event.id,\n      startPercent: (event.startTimeSec / duration) * 100,\n      widthPercent: Math.max(1, ((event.endTimeSec - event.startTimeSec) / duration) * 100),\n      color: getSeverityColor(event.severity),\n      event,\n    }));\n  }, [mistakes, duration]);\n\n  // Calculate playhead position\n  const playheadPercent = duration > 0 ? (currentTime / duration) * 100 : 0;\n\n  // Handle click on timeline\n  const handleTimelineClick = useCallback((e: React.MouseEvent<HTMLDivElement>) => {\n    if (!timelineRef.current || duration <= 0) return;\n\n    const rect = timelineRef.current.getBoundingClientRect();\n    const clickX = e.clientX - rect.left;\n    const percent = (clickX / rect.width) * 100;\n    const time = (percent / 100) * duration;\n\n    // Seek to clicked time\n    onSeek(Math.max(0, Math.min(duration, time)));\n\n    // Check if clicking on a segment\n    const clickedSegment = segments.find(seg =>\n      percent >= seg.startPercent && percent <= seg.startPercent + seg.widthPercent\n    );\n\n    if (clickedSegment) {\n      onSelectMistake(clickedSegment.event);\n    } else {\n      onSelectMistake(null);\n    }\n  }, [duration, segments, onSeek, onSelectMistake]);\n\n  // Handle segment click\n  const handleSegmentClick = useCallback((e: React.MouseEvent, segment: TimelineSegment) => {\n    e.stopPropagation();\n    onSeek(segment.event.startTimeSec);\n    onSelectMistake(segment.event);\n  }, [onSeek, onSelectMistake]);\n\n  // Format time for display\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Check if current time is within a mistake\n  const currentMistake = useMemo(() => {\n    return mistakes.find(m =>\n      currentTime >= m.startTimeSec && currentTime <= m.endTimeSec\n    );\n  }, [mistakes, currentTime]);\n\n  return (\n    <div className=\"w-full space-y-2\">\n      {/* Timeline label */}\n      <div className=\"flex items-center justify-between text-xs text-gray-500\">\n        <span>Mistake Timeline</span>\n        <span>{formatTime(currentTime)} / {formatTime(duration)}</span>\n      </div>\n\n      {/* Timeline container */}\n      <div\n        ref={timelineRef}\n        onClick={handleTimelineClick}\n        className=\"relative h-8 bg-gray-200 rounded-lg overflow-hidden cursor-pointer hover:bg-gray-300 transition-colors\"\n      >\n        {/* Mistake segments */}\n        {segments.map(segment => (\n          <button\n            key={segment.id}\n            onClick={(e) => handleSegmentClick(e, segment)}\n            className={`absolute top-0 bottom-0 rounded transition-all ${\n              selectedMistakeId === segment.id\n                ? 'ring-2 ring-white ring-offset-1 z-10'\n                : 'hover:opacity-90'\n            }`}\n            style={{\n              left: `${segment.startPercent}%`,\n              width: `${segment.widthPercent}%`,\n              backgroundColor: segment.color,\n              minWidth: '4px',\n            }}\n            title={`${segment.event.summaryTitle} (${formatTime(segment.event.startTimeSec)})`}\n          >\n            {/* Show label if segment is wide enough */}\n            {segment.widthPercent > 8 && (\n              <span className=\"absolute inset-0 flex items-center justify-center text-white text-xs font-medium truncate px-1\">\n                {segment.event.summaryTitle}\n              </span>\n            )}\n          </button>\n        ))}\n\n        {/* Playhead */}\n        <div\n          className=\"absolute top-0 bottom-0 w-0.5 bg-white shadow-lg z-20 pointer-events-none\"\n          style={{ left: `${playheadPercent}%` }}\n        >\n          {/* Playhead triangle */}\n          <div className=\"absolute -top-1 left-1/2 -translate-x-1/2 w-0 h-0 border-l-[4px] border-l-transparent border-r-[4px] border-r-transparent border-t-[6px] border-t-white\"></div>\n        </div>\n\n        {/* Current time indicator */}\n        {currentMistake && (\n          <div className=\"absolute bottom-0 left-0 right-0 h-1 bg-white/30\"></div>\n        )}\n      </div>\n\n      {/* Legend */}\n      <div className=\"flex items-center gap-4 text-xs text-gray-600\">\n        <div className=\"flex items-center gap-1\">\n          <div className=\"w-3 h-3 rounded bg-red-500\"></div>\n          <span>High</span>\n        </div>\n        <div className=\"flex items-center gap-1\">\n          <div className=\"w-3 h-3 rounded bg-orange-500\"></div>\n          <span>Medium</span>\n        </div>\n        <div className=\"flex items-center gap-1\">\n          <div className=\"w-3 h-3 rounded bg-yellow-500\"></div>\n          <span>Low</span>\n        </div>\n        <span className=\"ml-auto text-gray-400\">Click to seek</span>\n      </div>\n\n      {/* Current mistake indicator */}\n      {currentMistake && (\n        <div className=\"flex items-center gap-2 p-2 bg-red-50 border border-red-200 rounded-lg\">\n          <span className=\"w-2 h-2 rounded-full bg-red-500 animate-pulse\"></span>\n          <span className=\"text-sm text-red-800 font-medium\">\n            {currentMistake.summaryTitle}\n          </span>\n          <span className=\"text-xs text-red-600 ml-auto\">\n            {Math.round(currentMistake.confidence * 100)}% confidence\n          </span>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// Helper function for severity colors\nfunction getSeverityColor(severity: number): string {\n  if (severity >= 0.7) return '#ef4444'; // Red\n  if (severity >= 0.4) return '#f97316'; // Orange\n  return '#eab308'; // Yellow\n}\n\n// Mini version for embedding\nexport function MistakeTimelineMini({\n  mistakes,\n  duration,\n  currentTime,\n  onSeek,\n}: {\n  mistakes: MistakeEvent[];\n  duration: number;\n  currentTime: number;\n  onSeek: (time: number) => void;\n}) {\n  const segments = useMemo((): TimelineSegment[] => {\n    if (duration <= 0) return [];\n\n    return mistakes.map(event => ({\n      id: event.id,\n      startPercent: (event.startTimeSec / duration) * 100,\n      widthPercent: Math.max(0.5, ((event.endTimeSec - event.startTimeSec) / duration) * 100),\n      color: getSeverityColor(event.severity),\n      event,\n    }));\n  }, [mistakes, duration]);\n\n  const playheadPercent = duration > 0 ? (currentTime / duration) * 100 : 0;\n\n  const handleClick = (e: React.MouseEvent<HTMLDivElement>) => {\n    const rect = e.currentTarget.getBoundingClientRect();\n    const clickX = e.clientX - rect.left;\n    const percent = clickX / rect.width;\n    onSeek(percent * duration);\n  };\n\n  return (\n    <div\n      onClick={handleClick}\n      className=\"relative h-2 bg-gray-600 rounded-full overflow-hidden cursor-pointer\"\n    >\n      {segments.map(segment => (\n        <div\n          key={segment.id}\n          className=\"absolute top-0 bottom-0\"\n          style={{\n            left: `${segment.startPercent}%`,\n            width: `${segment.widthPercent}%`,\n            backgroundColor: segment.color,\n            minWidth: '2px',\n          }}\n        />\n      ))}\n      <div\n        className=\"absolute top-0 bottom-0 w-1 bg-white rounded-full\"\n        style={{ left: `calc(${playheadPercent}% - 2px)` }}\n      />\n    </div>\n  );\n}\n","numLines":239,"startLine":1,"totalLines":239}},"sourceToolAssistantUUID":"28effc11-54bc-4e3b-a29d-1ff05ffb1b80"}
{"parentUuid":"e4db46b1-f37d-4b20-91b7-180efec6374f","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01DmbFQqAaetTpzQdYyCBCQU","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I see. The MistakeTimeline component expects `mistakes` prop instead of `segments`, and `selectedMistakeId` instead of `selectedMistake`. Let me fix the usage in analytics/page.tsx.","signature":"Et4CCkYICxgCKkBinDV8pr8bPJKSJQFdmkHPoK2d9RQ93kccnRaSt73J+3R74esa4XDzuxdMbGesv2rEZrkyHZLl81W40d5fW/ZgEgw2bEPY62ecoHizcF8aDK+NJ1zL3UC+V2YyFSIwdFUuDWLtafjEQN7REATK3VQyzXPtC3CaD0UE4lbek/EBwRVkCT2R7Y6Ul2ZUa3f/KsUB+GpYpjfRXtNxB/e4iDoSi94ZnA26tf5r8QNSymRx955J5C0mGEXuq5iR23/S9LasrU1EyeyXl091zBld01kY+jgu/gxweOhj8Mfn7YQamTPYCqZCJ4OTuxfc0HMi7VS8h6DANlo71+Yp8eYuIDP/8IcB3abc2+XJi5mj2XZm5T9nBrS3stfSPlnSvP38VPkOiNG2HFXiPQQ/VFXacw+Z3C+XBrUM3bMcN7zYQ+w4iaD4lCJuNb+cukQDP1I03/WXLssDS0oYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":3467,"cache_read_input_tokens":69812,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3467},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae65qtXqz6wyytE1387","type":"assistant","uuid":"63fffbf8-485c-4a51-a066-b73272ef2ae5","timestamp":"2026-01-28T23:25:45.493Z"}
{"parentUuid":"63fffbf8-485c-4a51-a066-b73272ef2ae5","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01DmbFQqAaetTpzQdYyCBCQU","type":"message","role":"assistant","content":[{"type":"text","text":"I see the issue. The component expects `mistakes` and `selectedMistakeId`, not `segments` and `selectedMistake`. Let me fix the usage."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":3467,"cache_read_input_tokens":69812,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3467},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae65qtXqz6wyytE1387","type":"assistant","uuid":"6e528448-c856-4ddd-8fed-ef2de8c93c45","timestamp":"2026-01-28T23:25:46.125Z"}
{"parentUuid":"6e528448-c856-4ddd-8fed-ef2de8c93c45","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01DmbFQqAaetTpzQdYyCBCQU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011XKhDPC1RmZk42tuxMTCBb","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        segments={mistakesToTimelineSegments(mistakeEvents, duration)}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistake={selectedMistake}\n                      />\n                    </div>\n                  )}","new_string":"                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":3467,"cache_read_input_tokens":69812,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3467},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae65qtXqz6wyytE1387","type":"assistant","uuid":"63b3dc0a-624e-4ae0-a199-4e2d23bd999c","timestamp":"2026-01-28T23:25:51.998Z"}
{"parentUuid":"63b3dc0a-624e-4ae0-a199-4e2d23bd999c","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011XKhDPC1RmZk42tuxMTCBb","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"9b6c33b4-9167-44db-9f27-e6ef1bc70647","timestamp":"2026-01-28T23:25:52.579Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        segments={mistakesToTimelineSegments(mistakeEvents, duration)}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistake={selectedMistake}\n                      />\n                    </div>\n                  )}","newString":"                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        segments={mistakesToTimelineSegments(mistakeEvents, duration)}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistake={selectedMistake}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1873,"oldLines":7,"newStart":1873,"newLines":7,"lines":["                   {mistakeEvents.length > 0 && duration > 0 && (","                     <div className=\"px-4 pb-4\">","                       <MistakeTimeline","-                        segments={mistakesToTimelineSegments(mistakeEvents, duration)}","+                        mistakes={mistakeEvents}","                         duration={duration}","                         currentTime={currentTime}","                         onSeek={(time) => {"]},{"oldStart":1885,"oldLines":13,"newStart":1885,"newLines":13,"lines":["                         }}","                         onSelectMistake={(mistake) => {","                           setSelectedMistake(mistake);","-                          if (videoRef.current) {","+                          if (mistake && videoRef.current) {","                             videoRef.current.currentTime = mistake.startTimeSec;","                             setCurrentTime(mistake.startTimeSec);","                             setTimeout(renderFrame, 50);","                           }","                         }}","-                        selectedMistake={selectedMistake}","+                        selectedMistakeId={selectedMistake?.id}","                       />","                     </div>","                   )}"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"63b3dc0a-624e-4ae0-a199-4e2d23bd999c"}
{"parentUuid":"9b6c33b4-9167-44db-9f27-e6ef1bc70647","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_015mEGEZqdZMV7V8epFbdBoE","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Good, the main errors are fixed. Now I have an unused import. Let me remove it from the imports and also add the SkillMeter component to the UI. Let me continue updating the page.","signature":"EtwCCkYICxgCKkBbs4+IADsCLyEw011VvDdDrRmiG3Q8IJ5itJLSt5lbjQbofN03zx5iboIql3rJETUx0PFdST9rPnjrVBD+k8L+EgzDD2BFxSx6NyyWSXcaDGeAtBHOcHpavbjsDyIwWn3oiAYKAC/VAl1IM+mLxSsoJJB7hBVLqi0MSL2eelvd6f12DUHwlyJAFylO3MN/KsMBFQFo/BgupfAbeC13uWUCWSgZCpTxN0EydHylKpCtEskF4xe53eLOZj3nJbeRlK7yyaHpZMf3X2pRgZT1DwO98wC9CFd3SSwyO6vZ/mRM9CsTX6XQM20Jt8Nzp1pZu4boBjklcK2eRmLX8zSFrD5UspObFLFO6dU2BDxn94XzIxFoQCTFMPaaUJ9hMyeeJ5a9n07ivixA7U3D+2wEzXhjXQfcgtsDh1QmArXtob1VxmjlaZoCGstPI2OBUKXKP0KToNr+GAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":968,"cache_read_input_tokens":73279,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":968},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae6t9TKJfGQCGsmuaab","type":"assistant","uuid":"5bca396b-b6de-4316-bd6d-407eeab52cd4","timestamp":"2026-01-28T23:25:57.093Z"}
{"parentUuid":"5bca396b-b6de-4316-bd6d-407eeab52cd4","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_015mEGEZqdZMV7V8epFbdBoE","type":"message","role":"assistant","content":[{"type":"text","text":"Good, the main errors are fixed. Let me remove the unused import and continue adding UI components."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":968,"cache_read_input_tokens":73279,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":968},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae6t9TKJfGQCGsmuaab","type":"assistant","uuid":"2021d026-86e1-4209-8520-62a960897234","timestamp":"2026-01-28T23:25:57.513Z"}
{"parentUuid":"2021d026-86e1-4209-8520-62a960897234","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_015mEGEZqdZMV7V8epFbdBoE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NMvCQ2g7v8D8jYRx77bPFr","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"import { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';","new_string":"import { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":968,"cache_read_input_tokens":73279,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":968},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae6t9TKJfGQCGsmuaab","type":"assistant","uuid":"73570167-a54a-439e-8bbe-3c13a694abca","timestamp":"2026-01-28T23:25:59.175Z"}
{"parentUuid":"73570167-a54a-439e-8bbe-3c13a694abca","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NMvCQ2g7v8D8jYRx77bPFr","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"d06e1457-f732-49cc-a0d1-492762cd2c69","timestamp":"2026-01-28T23:25:59.763Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"import { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';","newString":"import { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":30,"oldLines":7,"newStart":30,"newLines":7,"lines":[" } from '@/lib/scoring-rules';"," import { computeSkillScore } from '@/lib/skill-scoring';"," import { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';","-import { detectMistakes, mistakesToTimelineSegments, generateFixKeyframes } from '@/lib/mistake-detection';","+import { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';"," import MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';"," import FixItCard from '@/components/FixItCard';"," import SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"73570167-a54a-439e-8bbe-3c13a694abca"}
{"parentUuid":"d06e1457-f732-49cc-a0d1-492762cd2c69","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01ECp7xSfxdsPnEw4g5udeCQ","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I have another unused import. Let me keep it for now as we'll use it with the FixItCard component. Let me update the todo and add the SkillMeter component to the UI.","signature":"Es4CCkYICxgCKkCVd5zRzO454li0v4b3hfekUt3u16ex2DtUWXMJFqnMZTvN+VwLHqxQ0ecTtZM7gMz2VDdw0Giq+lLVTF56mVffEgxRAL1M+RSn2NQp4QEaDGpKtZsQTWL1pCjydCIwoHAZsGotwR9JubywOSN/EmDgZnRat+Wjz7gRIjb4/Dl3yEpp9VRmLoBy/jh1GDxbKrUBLxefTj1ql6ddzEcfJImeAKUa0ZkHRrOLXuXO36Po+swhr2u7IKdZ1OqlVma5hO2Mb3MSxE9iHUJt9bmDtWYa+TWa+JiltGJNTTslg/GYnH463fQzWO6dPCnFkVGl1udonYnWgu44ouK+GEMZHr2kht/xi89YQuWl7pLQTxzlQ5ONX1dCtG/wsY/fwBSu0jFE1M5AQWwyX63A7KHosjZ40baoNLO0WFjTafc0pPQw4h8nk3kneBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":673,"cache_read_input_tokens":74247,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":673},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae7QsQhReXweQzLYXUo","type":"assistant","uuid":"b8acbfe4-2bdd-45b7-b3cd-f58ea4f486e3","timestamp":"2026-01-28T23:26:03.826Z"}
{"parentUuid":"b8acbfe4-2bdd-45b7-b3cd-f58ea4f486e3","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01ECp7xSfxdsPnEw4g5udeCQ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01AKFxDEJREQya6mx8fa9Hek","name":"TodoWrite","input":{"todos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"in_progress","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":673,"cache_read_input_tokens":74247,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":673},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae7QsQhReXweQzLYXUo","type":"assistant","uuid":"e29cab54-ed01-496d-b992-e01f160f81c9","timestamp":"2026-01-28T23:26:05.966Z"}
{"parentUuid":"e29cab54-ed01-496d-b992-e01f160f81c9","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01AKFxDEJREQya6mx8fa9Hek","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"0abe1da5-3a4a-4382-bd98-a4a56ebafa99","timestamp":"2026-01-28T23:26:06.009Z","toolUseResult":{"oldTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"in_progress","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"pending","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}],"newTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"in_progress","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}]},"sourceToolAssistantUUID":"e29cab54-ed01-496d-b992-e01f160f81c9"}
{"parentUuid":"0abe1da5-3a4a-4382-bd98-a4a56ebafa99","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01XAwyoqSvmnCXUpYFqmNuKE","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me add the SkillMeter component to the UI. I'll add it after the autoLevelResult panel. Let me find that section and add the SkillMeter.","signature":"ErkCCkYICxgCKkAwpup1SzMCYCY+P71R1vkX0nzCz6xFi7o4QY2ijxkxG/uD4Ly5NtMFoManSqbTcv9V6V6mnbN87zqwXzWcxKyeEgxBxK1a371s7sSRPCYaDJns97fNNo6yyxeqyiIwqiDxKhkPB/HHZJdOyvY1CgHY02gSM2PAxsvw3+LvzAHZ7XOdkL9V0jRJbE5WlHHNKqABwUuleNVeshOJSytsXxLnY749DxPIMEcSCE84FdVO0BpT7phYPzAwWDEBe947jigSuaZRxv0LmfmW0baQlGpBmVQcIpU7GgAB8l7PrmUvOkaSVy+zgFa81hymdcio3OCbgv/haLm8yL8YfPyIbVm+I+6A85qPpE42mwq5/g7Ou6ZJR7UOy4AyeLf70Pxhhp5zd+jnUgiahZ9OauYyeRPjlBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":364,"cache_read_input_tokens":74920,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":364},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae7oFJZj5mwKd5WEaLD","type":"assistant","uuid":"785c4caa-b130-437c-89ea-098f3a6aa1d5","timestamp":"2026-01-28T23:26:08.608Z"}
{"parentUuid":"785c4caa-b130-437c-89ea-098f3a6aa1d5","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01XAwyoqSvmnCXUpYFqmNuKE","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me add the SkillMeter component below the auto-level result panel."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":364,"cache_read_input_tokens":74920,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":364},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae7oFJZj5mwKd5WEaLD","type":"assistant","uuid":"86986432-ae4d-4df5-98ab-85762ae88bf0","timestamp":"2026-01-28T23:26:08.987Z"}
{"parentUuid":"86986432-ae4d-4df5-98ab-85762ae88bf0","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01XAwyoqSvmnCXUpYFqmNuKE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EQEB4Wfe4soWRd6ijs46rt","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}","new_string":"                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skill={computedSkill} />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":364,"cache_read_input_tokens":74920,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":364},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae7oFJZj5mwKd5WEaLD","type":"assistant","uuid":"1243c9e7-2f62-4338-b689-dfd012073c11","timestamp":"2026-01-28T23:26:19.229Z"}
{"parentUuid":"1243c9e7-2f62-4338-b689-dfd012073c11","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EQEB4Wfe4soWRd6ijs46rt","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"d6e6df2b-e4e4-4459-9370-081dfbfb6aad","timestamp":"2026-01-28T23:26:19.842Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}","newString":"                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skill={computedSkill} />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* PHASE 3: Auto-level detection result panel */}\n                {autoLevelResult && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1897,"oldLines":11,"newStart":1897,"newLines":18,"lines":["                   )}","                 </div>"," ","-                {/* PHASE 3: Auto-level detection result panel */}","-                {autoLevelResult && (","+                {/* V4 FEATURE: SkillMeter with computed metrics */}","+                {computedSkill && (","+                  <div className=\"mt-6\">","+                    <SkillMeter skill={computedSkill} />","+                  </div>","+                )}","+","+                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}","+                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (","                   <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">","                     <div className=\"flex items-center justify-between mb-4\">","-                      <h3 className=\"font-semibold text-gray-900\">AI Skill Assessment</h3>","+                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>","                       <span className={`px-3 py-1 rounded-full text-sm font-medium ${","                         autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :","                         autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"1243c9e7-2f62-4338-b689-dfd012073c11"}
{"parentUuid":"d6e6df2b-e4e4-4459-9370-081dfbfb6aad","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01X6HmFkYura9kQ1uSauwKB1","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I need to check the SkillMeter component to see the correct props interface.","signature":"EvQBCkYICxgCKkBI8OriCOcYUBJl+vTuaWQGVdmjYICh5SsyERQs1yzE1mcGrixAzbfA7vPS3Lvh67/ljwxMdHRogMlwJEWdil/0EgxiYU8ZacC8DXCpjRgaDCW/OtIqmXemMjQ+lyIw6q1QvHYPrqHqHtWUJvTFioKWRCNIBwWrFHlPYobJ8XJKc7yXfuwO/SW+Jl7PoaOzKlxqVkAGvRnhJlNp3SV/f+zdWAmY9HbGMCxTnunXx9fWbwYX+hffmmHuWPMDjiAdqGtV20ykvdM1VjZ85JiPS06IlNV998/MEC/SEQJATDMQw6ZY/jRtYOjsq5yN8xgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":1659,"cache_read_input_tokens":75284,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1659},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXae8tiF2AppCRqueyRQB","type":"assistant","uuid":"df6ffd32-f10a-4442-bbd2-0bc42b2024f9","timestamp":"2026-01-28T23:26:23.216Z"}
{"parentUuid":"df6ffd32-f10a-4442-bbd2-0bc42b2024f9","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01X6HmFkYura9kQ1uSauwKB1","type":"message","role":"assistant","content":[{"type":"text","text":"Let me check the SkillMeter component props."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":1659,"cache_read_input_tokens":75284,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1659},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXae8tiF2AppCRqueyRQB","type":"assistant","uuid":"a3f56eb7-6718-4f9b-a193-20d6839ec794","timestamp":"2026-01-28T23:26:23.598Z"}
{"parentUuid":"a3f56eb7-6718-4f9b-a193-20d6839ec794","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01X6HmFkYura9kQ1uSauwKB1","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0162LBffX5338Uoc1GiesRzH","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\SkillMeter.tsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":1659,"cache_read_input_tokens":75284,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1659},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXae8tiF2AppCRqueyRQB","type":"assistant","uuid":"31673462-1314-4ecc-be9b-837d2e4c6f90","timestamp":"2026-01-28T23:26:24.084Z"}
{"parentUuid":"31673462-1314-4ecc-be9b-837d2e4c6f90","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0162LBffX5338Uoc1GiesRzH","type":"tool_result","content":"     1→'use client';\n     2→\n     3→import { useState } from 'react';\n     4→import type { ComputedSkillScore } from '@/lib/types';\n     5→\n     6→interface SkillMeterProps {\n     7→  skillData: ComputedSkillScore;\n     8→  compact?: boolean;\n     9→}\n    10→\n    11→export default function SkillMeter({ skillData, compact = false }: SkillMeterProps) {\n    12→  const [showDetails, setShowDetails] = useState(false);\n    13→\n    14→  const {\n    15→    skillScore,\n    16→    levelLabel,\n    17→    confidencePercent,\n    18→    confidenceReasons,\n    19→    metrics,\n    20→  } = skillData;\n    21→\n    22→  // Get level color\n    23→  const getLevelColor = (level: string) => {\n    24→    switch (level) {\n    25→      case 'Advanced':\n    26→        return { bg: 'bg-green-100', text: 'text-green-800', ring: 'ring-green-500', bar: 'bg-green-500' };\n    27→      case 'Intermediate':\n    28→        return { bg: 'bg-yellow-100', text: 'text-yellow-800', ring: 'ring-yellow-500', bar: 'bg-yellow-500' };\n    29→      case 'Beginner':\n    30→        return { bg: 'bg-blue-100', text: 'text-blue-800', ring: 'ring-blue-500', bar: 'bg-blue-500' };\n    31→      default:\n    32→        return { bg: 'bg-gray-100', text: 'text-gray-800', ring: 'ring-gray-500', bar: 'bg-gray-500' };\n    33→    }\n    34→  };\n    35→\n    36→  const colors = getLevelColor(levelLabel);\n    37→\n    38→  // Get confidence color\n    39→  const getConfidenceColor = (confidence: number) => {\n    40→    if (confidence >= 70) return 'bg-green-500';\n    41→    if (confidence >= 40) return 'bg-yellow-500';\n    42→    return 'bg-red-500';\n    43→  };\n    44→\n    45→  if (compact) {\n    46→    return (\n    47→      <div className=\"flex items-center gap-3\">\n    48→        {/* Skill Badge */}\n    49→        <div className={`px-3 py-1.5 rounded-full text-sm font-semibold ${colors.bg} ${colors.text}`}>\n    50→          {levelLabel}\n    51→        </div>\n    52→\n    53→        {/* Score */}\n    54→        <div className=\"text-sm text-gray-600\">\n    55→          <span className=\"font-bold text-gray-900\">{skillScore}</span>/100\n    56→        </div>\n    57→\n    58→        {/* Confidence indicator */}\n    59→        <div className=\"flex items-center gap-1.5\">\n    60→          <div className=\"w-16 h-1.5 bg-gray-200 rounded-full overflow-hidden\">\n    61→            <div\n    62→              className={`h-full transition-all ${getConfidenceColor(confidencePercent)}`}\n    63→              style={{ width: `${confidencePercent}%` }}\n    64→            />\n    65→          </div>\n    66→          <span className=\"text-xs text-gray-500\">{confidencePercent}%</span>\n    67→        </div>\n    68→      </div>\n    69→    );\n    70→  }\n    71→\n    72→  return (\n    73→    <div className=\"bg-white rounded-xl shadow-sm overflow-hidden\">\n    74→      {/* Header with skill badge */}\n    75→      <div className={`p-4 ${colors.bg} border-b border-gray-100`}>\n    76→        <div className=\"flex items-center justify-between\">\n    77→          <div className=\"flex items-center gap-3\">\n    78→            {/* Skill Level Badge */}\n    79→            <div className={`px-4 py-2 rounded-full font-bold text-lg ${colors.bg} ${colors.text} ring-2 ${colors.ring}`}>\n    80→              {levelLabel}\n    81→            </div>\n    82→\n    83→            {/* Score */}\n    84→            <div>\n    85→              <div className=\"text-3xl font-bold text-gray-900\">{skillScore}</div>\n    86→              <div className=\"text-sm text-gray-600\">Skill Score</div>\n    87→            </div>\n    88→          </div>\n    89→\n    90→          {/* Confidence Meter */}\n    91→          <div className=\"text-right\">\n    92→            <div className=\"text-sm text-gray-600 mb-1\">Detection Confidence</div>\n    93→            <div className=\"flex items-center gap-2\">\n    94→              <div className=\"w-24 h-3 bg-gray-200 rounded-full overflow-hidden\">\n    95→                <div\n    96→                  className={`h-full transition-all ${getConfidenceColor(confidencePercent)}`}\n    97→                  style={{ width: `${confidencePercent}%` }}\n    98→                />\n    99→              </div>\n   100→              <span className=\"font-semibold text-gray-700\">{confidencePercent}%</span>\n   101→            </div>\n   102→          </div>\n   103→        </div>\n   104→\n   105→        {/* Low confidence warning */}\n   106→        {confidencePercent < 60 && confidenceReasons.length > 0 && (\n   107→          <div className=\"mt-3 p-2 bg-yellow-50 border border-yellow-200 rounded-lg\">\n   108→            <div className=\"flex items-start gap-2\">\n   109→              <svg className=\"w-4 h-4 text-yellow-600 mt-0.5 flex-shrink-0\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n   110→                <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z\" />\n   111→              </svg>\n   112→              <div className=\"text-xs text-yellow-800\">\n   113→                <span className=\"font-medium\">Lower confidence:</span> {confidenceReasons[0]}\n   114→              </div>\n   115→            </div>\n   116→          </div>\n   117→        )}\n   118→      </div>\n   119→\n   120→      {/* Score breakdown */}\n   121→      <div className=\"p-4\">\n   122→        <button\n   123→          onClick={() => setShowDetails(!showDetails)}\n   124→          className=\"flex items-center justify-between w-full text-sm text-gray-600 hover:text-gray-900 transition\"\n   125→        >\n   126→          <span>Score Breakdown</span>\n   127→          <svg\n   128→            className={`w-4 h-4 transition-transform ${showDetails ? 'rotate-180' : ''}`}\n   129→            fill=\"none\"\n   130→            stroke=\"currentColor\"\n   131→            viewBox=\"0 0 24 24\"\n   132→          >\n   133→            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M19 9l-7 7-7-7\" />\n   134→          </svg>\n   135→        </button>\n   136→\n   137→        {showDetails && (\n   138→          <div className=\"mt-4 space-y-3\">\n   139→            {/* Form Quality */}\n   140→            <MetricBar\n   141→              label=\"Form Quality\"\n   142→              value={metrics.formQuality * 100}\n   143→              description=\"How well your body positions match ideal form\"\n   144→            />\n   145→\n   146→            {/* Consistency */}\n   147→            <MetricBar\n   148→              label=\"Consistency\"\n   149→              value={metrics.consistencyScore * 100}\n   150→              description=\"How stable your form is across frames\"\n   151→            />\n   152→\n   153→            {/* Recovery Speed */}\n   154→            <MetricBar\n   155→              label=\"Recovery Speed\"\n   156→              value={metrics.recoverySpeed * 100}\n   157→              description=\"How quickly you recover after lunges\"\n   158→            />\n   159→\n   160→            {/* Visibility */}\n   161→            <MetricBar\n   162→              label=\"Detection Quality\"\n   163→              value={metrics.visibilityAvg * 100}\n   164→              description=\"Clarity of pose detection in video\"\n   165→            />\n   166→\n   167→            {/* Dropout Rate (inverse) */}\n   168→            <MetricBar\n   169→              label=\"Frame Coverage\"\n   170→              value={(1 - metrics.dropoutRate) * 100}\n   171→              description=\"Percentage of frames with valid pose data\"\n   172→            />\n   173→\n   174→            {/* Confidence reasons */}\n   175→            {confidenceReasons.length > 0 && (\n   176→              <div className=\"mt-4 pt-4 border-t border-gray-100\">\n   177→                <p className=\"text-xs font-medium text-gray-500 mb-2\">Confidence Notes:</p>\n   178→                <ul className=\"space-y-1\">\n   179→                  {confidenceReasons.map((reason, idx) => (\n   180→                    <li key={idx} className=\"text-xs text-gray-600 flex items-start gap-1.5\">\n   181→                      <span className=\"text-yellow-500 mt-0.5\">•</span>\n   182→                      {reason}\n   183→                    </li>\n   184→                  ))}\n   185→                </ul>\n   186→              </div>\n   187→            )}\n   188→          </div>\n   189→        )}\n   190→      </div>\n   191→\n   192→      {/* How score is calculated */}\n   193→      <div className=\"px-4 pb-4\">\n   194→        <p className=\"text-xs text-gray-400 italic\">\n   195→          Score computed from pose metrics. Confidence from landmark visibility.\n   196→        </p>\n   197→      </div>\n   198→    </div>\n   199→  );\n   200→}\n   201→\n   202→// Metric bar sub-component\n   203→function MetricBar({\n   204→  label,\n   205→  value,\n   206→  description,\n   207→}: {\n   208→  label: string;\n   209→  value: number;\n   210→  description?: string;\n   211→}) {\n   212→  const getBarColor = (val: number) => {\n   213→    if (val >= 70) return 'bg-green-500';\n   214→    if (val >= 40) return 'bg-yellow-500';\n   215→    return 'bg-red-500';\n   216→  };\n   217→\n   218→  return (\n   219→    <div>\n   220→      <div className=\"flex items-center justify-between text-sm mb-1\">\n   221→        <span className=\"text-gray-700\">{label}</span>\n   222→        <span className=\"font-medium text-gray-900\">{Math.round(value)}%</span>\n   223→      </div>\n   224→      <div className=\"w-full h-2 bg-gray-100 rounded-full overflow-hidden\">\n   225→        <div\n   226→          className={`h-full transition-all ${getBarColor(value)}`}\n   227→          style={{ width: `${Math.max(2, value)}%` }}\n   228→        />\n   229→      </div>\n   230→      {description && (\n   231→        <p className=\"text-xs text-gray-400 mt-0.5\">{description}</p>\n   232→      )}\n   233→    </div>\n   234→  );\n   235→}\n   236→\n   237→// Inline badge version for video overlay\n   238→export function SkillBadgeInline({ skillData }: { skillData: ComputedSkillScore }) {\n   239→  const { skillScore, levelLabel, confidencePercent } = skillData;\n   240→\n   241→  const getLevelStyles = (level: string) => {\n   242→    switch (level) {\n   243→      case 'Advanced':\n   244→        return 'bg-green-500';\n   245→      case 'Intermediate':\n   246→        return 'bg-yellow-500';\n   247→      case 'Beginner':\n   248→        return 'bg-blue-500';\n   249→      default:\n   250→        return 'bg-gray-500';\n   251→    }\n   252→  };\n   253→\n   254→  return (\n   255→    <div className=\"flex items-center gap-2 bg-black/70 px-3 py-1.5 rounded-full\">\n   256→      <span className={`px-2 py-0.5 rounded text-xs font-bold text-white ${getLevelStyles(levelLabel)}`}>\n   257→        {levelLabel}\n   258→      </span>\n   259→      <span className=\"text-white text-sm font-medium\">{skillScore}</span>\n   260→      <span className=\"text-white/60 text-xs\">({confidencePercent}% conf)</span>\n   261→    </div>\n   262→  );\n   263→}\n   264→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"df87d1c2-bd54-47d9-8ddd-3db32596260f","timestamp":"2026-01-28T23:26:24.753Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\SkillMeter.tsx","content":"'use client';\n\nimport { useState } from 'react';\nimport type { ComputedSkillScore } from '@/lib/types';\n\ninterface SkillMeterProps {\n  skillData: ComputedSkillScore;\n  compact?: boolean;\n}\n\nexport default function SkillMeter({ skillData, compact = false }: SkillMeterProps) {\n  const [showDetails, setShowDetails] = useState(false);\n\n  const {\n    skillScore,\n    levelLabel,\n    confidencePercent,\n    confidenceReasons,\n    metrics,\n  } = skillData;\n\n  // Get level color\n  const getLevelColor = (level: string) => {\n    switch (level) {\n      case 'Advanced':\n        return { bg: 'bg-green-100', text: 'text-green-800', ring: 'ring-green-500', bar: 'bg-green-500' };\n      case 'Intermediate':\n        return { bg: 'bg-yellow-100', text: 'text-yellow-800', ring: 'ring-yellow-500', bar: 'bg-yellow-500' };\n      case 'Beginner':\n        return { bg: 'bg-blue-100', text: 'text-blue-800', ring: 'ring-blue-500', bar: 'bg-blue-500' };\n      default:\n        return { bg: 'bg-gray-100', text: 'text-gray-800', ring: 'ring-gray-500', bar: 'bg-gray-500' };\n    }\n  };\n\n  const colors = getLevelColor(levelLabel);\n\n  // Get confidence color\n  const getConfidenceColor = (confidence: number) => {\n    if (confidence >= 70) return 'bg-green-500';\n    if (confidence >= 40) return 'bg-yellow-500';\n    return 'bg-red-500';\n  };\n\n  if (compact) {\n    return (\n      <div className=\"flex items-center gap-3\">\n        {/* Skill Badge */}\n        <div className={`px-3 py-1.5 rounded-full text-sm font-semibold ${colors.bg} ${colors.text}`}>\n          {levelLabel}\n        </div>\n\n        {/* Score */}\n        <div className=\"text-sm text-gray-600\">\n          <span className=\"font-bold text-gray-900\">{skillScore}</span>/100\n        </div>\n\n        {/* Confidence indicator */}\n        <div className=\"flex items-center gap-1.5\">\n          <div className=\"w-16 h-1.5 bg-gray-200 rounded-full overflow-hidden\">\n            <div\n              className={`h-full transition-all ${getConfidenceColor(confidencePercent)}`}\n              style={{ width: `${confidencePercent}%` }}\n            />\n          </div>\n          <span className=\"text-xs text-gray-500\">{confidencePercent}%</span>\n        </div>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"bg-white rounded-xl shadow-sm overflow-hidden\">\n      {/* Header with skill badge */}\n      <div className={`p-4 ${colors.bg} border-b border-gray-100`}>\n        <div className=\"flex items-center justify-between\">\n          <div className=\"flex items-center gap-3\">\n            {/* Skill Level Badge */}\n            <div className={`px-4 py-2 rounded-full font-bold text-lg ${colors.bg} ${colors.text} ring-2 ${colors.ring}`}>\n              {levelLabel}\n            </div>\n\n            {/* Score */}\n            <div>\n              <div className=\"text-3xl font-bold text-gray-900\">{skillScore}</div>\n              <div className=\"text-sm text-gray-600\">Skill Score</div>\n            </div>\n          </div>\n\n          {/* Confidence Meter */}\n          <div className=\"text-right\">\n            <div className=\"text-sm text-gray-600 mb-1\">Detection Confidence</div>\n            <div className=\"flex items-center gap-2\">\n              <div className=\"w-24 h-3 bg-gray-200 rounded-full overflow-hidden\">\n                <div\n                  className={`h-full transition-all ${getConfidenceColor(confidencePercent)}`}\n                  style={{ width: `${confidencePercent}%` }}\n                />\n              </div>\n              <span className=\"font-semibold text-gray-700\">{confidencePercent}%</span>\n            </div>\n          </div>\n        </div>\n\n        {/* Low confidence warning */}\n        {confidencePercent < 60 && confidenceReasons.length > 0 && (\n          <div className=\"mt-3 p-2 bg-yellow-50 border border-yellow-200 rounded-lg\">\n            <div className=\"flex items-start gap-2\">\n              <svg className=\"w-4 h-4 text-yellow-600 mt-0.5 flex-shrink-0\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z\" />\n              </svg>\n              <div className=\"text-xs text-yellow-800\">\n                <span className=\"font-medium\">Lower confidence:</span> {confidenceReasons[0]}\n              </div>\n            </div>\n          </div>\n        )}\n      </div>\n\n      {/* Score breakdown */}\n      <div className=\"p-4\">\n        <button\n          onClick={() => setShowDetails(!showDetails)}\n          className=\"flex items-center justify-between w-full text-sm text-gray-600 hover:text-gray-900 transition\"\n        >\n          <span>Score Breakdown</span>\n          <svg\n            className={`w-4 h-4 transition-transform ${showDetails ? 'rotate-180' : ''}`}\n            fill=\"none\"\n            stroke=\"currentColor\"\n            viewBox=\"0 0 24 24\"\n          >\n            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M19 9l-7 7-7-7\" />\n          </svg>\n        </button>\n\n        {showDetails && (\n          <div className=\"mt-4 space-y-3\">\n            {/* Form Quality */}\n            <MetricBar\n              label=\"Form Quality\"\n              value={metrics.formQuality * 100}\n              description=\"How well your body positions match ideal form\"\n            />\n\n            {/* Consistency */}\n            <MetricBar\n              label=\"Consistency\"\n              value={metrics.consistencyScore * 100}\n              description=\"How stable your form is across frames\"\n            />\n\n            {/* Recovery Speed */}\n            <MetricBar\n              label=\"Recovery Speed\"\n              value={metrics.recoverySpeed * 100}\n              description=\"How quickly you recover after lunges\"\n            />\n\n            {/* Visibility */}\n            <MetricBar\n              label=\"Detection Quality\"\n              value={metrics.visibilityAvg * 100}\n              description=\"Clarity of pose detection in video\"\n            />\n\n            {/* Dropout Rate (inverse) */}\n            <MetricBar\n              label=\"Frame Coverage\"\n              value={(1 - metrics.dropoutRate) * 100}\n              description=\"Percentage of frames with valid pose data\"\n            />\n\n            {/* Confidence reasons */}\n            {confidenceReasons.length > 0 && (\n              <div className=\"mt-4 pt-4 border-t border-gray-100\">\n                <p className=\"text-xs font-medium text-gray-500 mb-2\">Confidence Notes:</p>\n                <ul className=\"space-y-1\">\n                  {confidenceReasons.map((reason, idx) => (\n                    <li key={idx} className=\"text-xs text-gray-600 flex items-start gap-1.5\">\n                      <span className=\"text-yellow-500 mt-0.5\">•</span>\n                      {reason}\n                    </li>\n                  ))}\n                </ul>\n              </div>\n            )}\n          </div>\n        )}\n      </div>\n\n      {/* How score is calculated */}\n      <div className=\"px-4 pb-4\">\n        <p className=\"text-xs text-gray-400 italic\">\n          Score computed from pose metrics. Confidence from landmark visibility.\n        </p>\n      </div>\n    </div>\n  );\n}\n\n// Metric bar sub-component\nfunction MetricBar({\n  label,\n  value,\n  description,\n}: {\n  label: string;\n  value: number;\n  description?: string;\n}) {\n  const getBarColor = (val: number) => {\n    if (val >= 70) return 'bg-green-500';\n    if (val >= 40) return 'bg-yellow-500';\n    return 'bg-red-500';\n  };\n\n  return (\n    <div>\n      <div className=\"flex items-center justify-between text-sm mb-1\">\n        <span className=\"text-gray-700\">{label}</span>\n        <span className=\"font-medium text-gray-900\">{Math.round(value)}%</span>\n      </div>\n      <div className=\"w-full h-2 bg-gray-100 rounded-full overflow-hidden\">\n        <div\n          className={`h-full transition-all ${getBarColor(value)}`}\n          style={{ width: `${Math.max(2, value)}%` }}\n        />\n      </div>\n      {description && (\n        <p className=\"text-xs text-gray-400 mt-0.5\">{description}</p>\n      )}\n    </div>\n  );\n}\n\n// Inline badge version for video overlay\nexport function SkillBadgeInline({ skillData }: { skillData: ComputedSkillScore }) {\n  const { skillScore, levelLabel, confidencePercent } = skillData;\n\n  const getLevelStyles = (level: string) => {\n    switch (level) {\n      case 'Advanced':\n        return 'bg-green-500';\n      case 'Intermediate':\n        return 'bg-yellow-500';\n      case 'Beginner':\n        return 'bg-blue-500';\n      default:\n        return 'bg-gray-500';\n    }\n  };\n\n  return (\n    <div className=\"flex items-center gap-2 bg-black/70 px-3 py-1.5 rounded-full\">\n      <span className={`px-2 py-0.5 rounded text-xs font-bold text-white ${getLevelStyles(levelLabel)}`}>\n        {levelLabel}\n      </span>\n      <span className=\"text-white text-sm font-medium\">{skillScore}</span>\n      <span className=\"text-white/60 text-xs\">({confidencePercent}% conf)</span>\n    </div>\n  );\n}\n","numLines":264,"startLine":1,"totalLines":264}},"sourceToolAssistantUUID":"31673462-1314-4ecc-be9b-837d2e4c6f90"}
{"parentUuid":"df87d1c2-bd54-47d9-8ddd-3db32596260f","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019edkKzGZ1EKKS41HqNdrbt","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I see - the prop is `skillData`, not `skill`. Let me fix that.","signature":"EuYBCkYICxgCKkBaYOaXEo7HQr7ZuhOb3brerg1ZddDa5CF/oqEScJHzxpiyFznaKOq1BkxtAjYHJjovTCcD/rQBI03T+JintTOlEgzg65CJIjdu4kw47YUaDONboXfVOrKkOU6EZSIw9HBsmDYkYLYsFb4H12T9O689R1ah+8fsRsS59yIJQFORoB9A4U3vuWv7Z2ZTMuzjKk48D65j2Fxk3M9kzohbuFG4sFPaxX9e2QXg4ySk2Jwboa8TniVOfSHr3TsjBMc43MID3js8yV87S9gaaGAjG+p6+tiKCbmFccuJ5rbPWl0YAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":3878,"cache_read_input_tokens":76943,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3878},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae9BMMtU3iP8gmcF7Hg","type":"assistant","uuid":"e49ee21c-ba93-4b45-832c-3cd988ec6f0c","timestamp":"2026-01-28T23:26:27.204Z"}
{"parentUuid":"e49ee21c-ba93-4b45-832c-3cd988ec6f0c","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019edkKzGZ1EKKS41HqNdrbt","type":"message","role":"assistant","content":[{"type":"text","text":"The prop is `skillData`, not `skill`. Let me fix that."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":3878,"cache_read_input_tokens":76943,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3878},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae9BMMtU3iP8gmcF7Hg","type":"assistant","uuid":"cd253e68-ed7d-4069-b1b5-c849b9bdfd5e","timestamp":"2026-01-28T23:26:27.591Z"}
{"parentUuid":"cd253e68-ed7d-4069-b1b5-c849b9bdfd5e","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019edkKzGZ1EKKS41HqNdrbt","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HDH7sZh6bXXFjoTGn7omDX","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skill={computedSkill} />\n                  </div>\n                )}","new_string":"                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":3878,"cache_read_input_tokens":76943,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3878},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXae9BMMtU3iP8gmcF7Hg","type":"assistant","uuid":"a28ff3a3-6873-4252-8505-9839266dea8a","timestamp":"2026-01-28T23:26:30.265Z"}
{"parentUuid":"a28ff3a3-6873-4252-8505-9839266dea8a","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HDH7sZh6bXXFjoTGn7omDX","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"2b338caa-78c0-47b8-8fed-511a4cdda781","timestamp":"2026-01-28T23:26:30.835Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skill={computedSkill} />\n                  </div>\n                )}","newString":"                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skill={computedSkill} />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1900,"oldLines":7,"newStart":1900,"newLines":7,"lines":["                 {/* V4 FEATURE: SkillMeter with computed metrics */}","                 {computedSkill && (","                   <div className=\"mt-6\">","-                    <SkillMeter skill={computedSkill} />","+                    <SkillMeter skillData={computedSkill} />","                   </div>","                 )}"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"a28ff3a3-6873-4252-8505-9839266dea8a"}
{"parentUuid":"2b338caa-78c0-47b8-8fed-511a4cdda781","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01W5tmpnyfVqG37scFmfBo3P","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me add the FixItCard component when a mistake is selected. I should add it near the analysis summary section.","signature":"Ep4CCkYICxgCKkBSDi87d0Mx3TuCmqzFlEKOBfYfoQHuUVRgpWA8t12qfoC4Mg0s9F5+9q/aT6g51rT8Q4SM7C6/38/Nd2QMuYG2EgzYjnl/B1ZfBS7vZSUaDBgvmpx8HTiSBXwbJyIwNcls6bDmlibAKY7s9fSX2xISiR+cWAEZSRECh31rNRznNkIVx+e2fCCKHOxcJDovKoUBHQW5RTRqkjnrYJbhgtQu1gxqz3Abo/C7zE5g8QYRlcjOQlxEOY/Cye86anirGD2iJuKztyBEaFrR6ug1y7OyiptmOUTqzEDtp7zwiEVzDCIuedR7PcCF9+3LqoOs8vjpfA0j2sKQ89shD8HclT4GM739J7gbQ8yBpLQI2SacRlEWZ0Mc7xgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":371,"cache_read_input_tokens":80821,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":371},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXae9hjieUH95A3yc6o6g","type":"assistant","uuid":"e6c2d5b9-a3fc-4d9f-8aae-99e51f516408","timestamp":"2026-01-28T23:26:34.607Z"}
{"parentUuid":"e6c2d5b9-a3fc-4d9f-8aae-99e51f516408","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01W5tmpnyfVqG37scFmfBo3P","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NQUAPKk6WtAGeG6136H9rz","name":"TodoWrite","input":{"todos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"in_progress","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":371,"cache_read_input_tokens":80821,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":371},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXae9hjieUH95A3yc6o6g","type":"assistant","uuid":"7023b8a7-463b-4829-a9d8-f45a056b8a2f","timestamp":"2026-01-28T23:26:38.010Z"}
{"parentUuid":"7023b8a7-463b-4829-a9d8-f45a056b8a2f","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NQUAPKk6WtAGeG6136H9rz","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"f9ce56ea-b210-426d-82f0-46ac48971a93","timestamp":"2026-01-28T23:26:38.060Z","toolUseResult":{"oldTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"in_progress","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"pending","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}],"newTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"in_progress","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}]},"sourceToolAssistantUUID":"7023b8a7-463b-4829-a9d8-f45a056b8a2f"}
{"parentUuid":"f9ce56ea-b210-426d-82f0-46ac48971a93","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_017xwEY3PkjnJ1fBCPGB6Aeb","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The ghost toggle is already added. Now let me add the FixItCard component when a mistake is selected. I'll add it after the SkillMeter but before the AI Assessment section.","signature":"EtUCCkYICxgCKkAaL7wbSCQSjxz8e2oTy3IAgdRRW7MzzLH2FtL32lk4TFLxjPfbeJhkav4lPr9B4zdQiHgV48TC5+h7Eu+umFoVEgzjQRxNlSYMxwywj+oaDO5pkaqyS19t3/SgiiIwLStWnrAgPb3+EjeaV7ZWKdX/ByQozXBxZOyEeSgvqSIAoAwfYCPCZ6msvoExT1CqKrwBy9Mj2g2HmUnoCMCBtnn+Wlz4/tHdgLtNJAD9Di8i7ZrRIDB7RDSw0+mU7Z8BVGxxseqNmUQPhhw5NzMiaFWAfNpsF+q0bOAsGqxlbaLt2zAagn7vFBz19pYQPbUvD+s7sHMBeD4vkTTJO5ZgwuZXXFB3OV6mPXOXf0k+VvTNaD95dg2jLzwhFE1Hs1HEc5PSnPIvx9AKtCDLeXRwwBXvF+xxBdFF1eOfdbPDYAGMJXAhxg5HVVCbB16oPYIYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":345,"cache_read_input_tokens":81192,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":345},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeAAPM3nkfP5sFsxZVN","type":"assistant","uuid":"32944306-f316-4f19-914f-5df147bde8b3","timestamp":"2026-01-28T23:26:40.761Z"}
{"parentUuid":"32944306-f316-4f19-914f-5df147bde8b3","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_017xwEY3PkjnJ1fBCPGB6Aeb","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me add the FixItCard component when a mistake is selected."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":345,"cache_read_input_tokens":81192,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":345},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeAAPM3nkfP5sFsxZVN","type":"assistant","uuid":"f32e7466-f49d-4b13-90e8-ac3af0e8c0cb","timestamp":"2026-01-28T23:26:41.124Z"}
{"parentUuid":"f32e7466-f49d-4b13-90e8-ac3af0e8c0cb","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_017xwEY3PkjnJ1fBCPGB6Aeb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PZAUqgLsTQZEhqv6nfMqd3","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}","new_string":"                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      keyframes={generateFixKeyframes(selectedMistake)}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":345,"cache_read_input_tokens":81192,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":345},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeAAPM3nkfP5sFsxZVN","type":"assistant","uuid":"e8ad3de0-f523-4513-a225-cafae5b06116","timestamp":"2026-01-28T23:26:45.727Z"}
{"parentUuid":"e8ad3de0-f523-4513-a225-cafae5b06116","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PZAUqgLsTQZEhqv6nfMqd3","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"d79acba4-0656-47cf-8889-87ab2fe8d387","timestamp":"2026-01-28T23:26:46.336Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}","newString":"                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      keyframes={generateFixKeyframes(selectedMistake)}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1904,"oldLines":6,"newStart":1904,"newLines":26,"lines":["                   </div>","                 )}"," ","+                {/* V4 FEATURE: FixItCard for selected mistake */}","+                {selectedMistake && (","+                  <div className=\"mt-6\">","+                    <div className=\"flex items-center justify-between mb-3\">","+                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>","+                      <button","+                        onClick={() => setSelectedMistake(null)}","+                        className=\"text-sm text-gray-500 hover:text-gray-700\"","+                      >","+                        Close","+                      </button>","+                    </div>","+                    <FixItCard","+                      mistake={selectedMistake}","+                      keyframes={generateFixKeyframes(selectedMistake)}","+                      onClose={() => setSelectedMistake(null)}","+                    />","+                  </div>","+                )}","+","                 {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}","                 {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (","                   <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"e8ad3de0-f523-4513-a225-cafae5b06116"}
{"parentUuid":"d79acba4-0656-47cf-8889-87ab2fe8d387","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01KjfiSFRrVF4PMTp4vGXy3U","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I need to check the FixItCard component to see the correct props and the generateFixKeyframes function signature.","signature":"EpoCCkYICxgCKkCs/oyY2rEyf+YB5w/zKx834vn7y0xrYX9Ki87DinOnUBho5FxuS9x+tBLqyoyXw85R1pdyjmKtkNc6zV+2dOtdEgxBsp6cS9/eO+yWliEaDABA6+cJ23I0tsKksCIwqBk8t1/c4zFbRYlMFS77YE7afH1hjcKdlgighMFAvD6EmqQKMZ7F7Vvg1oisxurUKoEBynY4UYadSsWpkQhONABZIONe03X4XxGam5N/NUqPp0EwBop1forioleZfDl4h42QEXO9iXKor2O/Q5sGVY5czFJ8yP4uMYoth1rSYUOR7TFQ6Alh4FpZ/xHxQ3LjPnqIutI79Mh1hOmzhaidqaYBH55tuRtr/IGQxbEadNYZ6EQ0GAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":959,"cache_read_input_tokens":81537,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":959},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeAr82U93cXZPxzRYWX","type":"assistant","uuid":"8cc75546-c675-4040-972a-c9fa87ab883c","timestamp":"2026-01-28T23:26:49.780Z"}
{"parentUuid":"8cc75546-c675-4040-972a-c9fa87ab883c","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01KjfiSFRrVF4PMTp4vGXy3U","type":"message","role":"assistant","content":[{"type":"text","text":"Let me check the FixItCard component props."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":959,"cache_read_input_tokens":81537,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":959},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeAr82U93cXZPxzRYWX","type":"assistant","uuid":"d33fe504-9eb3-4836-8c20-432199a46ba5","timestamp":"2026-01-28T23:26:50.167Z"}
{"parentUuid":"d33fe504-9eb3-4836-8c20-432199a46ba5","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01KjfiSFRrVF4PMTp4vGXy3U","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01H3PdaNyYMPdJu4ekaLj9L5","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\FixItCard.tsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":959,"cache_read_input_tokens":81537,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":959},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeAr82U93cXZPxzRYWX","type":"assistant","uuid":"5ef30d71-6c55-48b1-8a5f-30d1cb8a15a8","timestamp":"2026-01-28T23:26:50.610Z"}
{"parentUuid":"5ef30d71-6c55-48b1-8a5f-30d1cb8a15a8","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01H3PdaNyYMPdJu4ekaLj9L5","type":"tool_result","content":"     1→'use client';\n     2→\n     3→import { useState, useEffect, useRef, useCallback } from 'react';\n     4→import type { MistakeEvent, FixKeyframe, PoseLandmark } from '@/lib/types';\n     5→import { POSE_CONNECTIONS } from '@/lib/pose-utils';\n     6→\n     7→interface FixItCardProps {\n     8→  mistake: MistakeEvent;\n     9→  fixKeyframes?: FixKeyframe[];\n    10→  onClose?: () => void;\n    11→}\n    12→\n    13→// Skeleton connections for drawing\n    14→const SKELETON_CONNECTIONS = [\n    15→  [11, 12], // shoulders\n    16→  [11, 23], [12, 24], // shoulders to hips\n    17→  [23, 24], // hips\n    18→  [11, 13], [13, 15], // left arm\n    19→  [12, 14], [14, 16], // right arm\n    20→  [23, 25], [25, 27], // left leg\n    21→  [24, 26], [26, 28], // right leg\n    22→];\n    23→\n    24→export default function FixItCard({\n    25→  mistake,\n    26→  fixKeyframes,\n    27→  onClose,\n    28→}: FixItCardProps) {\n    29→  const canvasRef = useRef<HTMLCanvasElement>(null);\n    30→  const [activePhase, setActivePhase] = useState(0);\n    31→  const [isAnimating, setIsAnimating] = useState(true);\n    32→  const animationRef = useRef<number | null>(null);\n    33→  const phaseTimeRef = useRef<number>(0);\n    34→\n    35→  const phases = fixKeyframes?.length ? fixKeyframes : getDefaultPhases(mistake.type);\n    36→\n    37→  // Animation loop\n    38→  useEffect(() => {\n    39→    if (!isAnimating || phases.length === 0) return;\n    40→\n    41→    let lastTime = performance.now();\n    42→    const phaseDuration = 1500; // 1.5 seconds per phase\n    43→\n    44→    const animate = (currentTime: number) => {\n    45→      const deltaTime = currentTime - lastTime;\n    46→      lastTime = currentTime;\n    47→\n    48→      phaseTimeRef.current += deltaTime;\n    49→\n    50→      if (phaseTimeRef.current >= phaseDuration) {\n    51→        phaseTimeRef.current = 0;\n    52→        setActivePhase(prev => (prev + 1) % phases.length);\n    53→      }\n    54→\n    55→      animationRef.current = requestAnimationFrame(animate);\n    56→    };\n    57→\n    58→    animationRef.current = requestAnimationFrame(animate);\n    59→\n    60→    return () => {\n    61→      if (animationRef.current) {\n    62→        cancelAnimationFrame(animationRef.current);\n    63→      }\n    64→    };\n    65→  }, [isAnimating, phases.length]);\n    66→\n    67→  // Draw skeleton\n    68→  const drawSkeleton = useCallback((\n    69→    ctx: CanvasRenderingContext2D,\n    70→    landmarks: PoseLandmark[],\n    71→    width: number,\n    72→    height: number,\n    73→    color: string,\n    74→    alpha: number = 1\n    75→  ) => {\n    76→    const padding = 20;\n    77→    const drawWidth = width - padding * 2;\n    78→    const drawHeight = height - padding * 2;\n    79→\n    80→    ctx.globalAlpha = alpha;\n    81→\n    82→    // Draw connections\n    83→    ctx.strokeStyle = color;\n    84→    ctx.lineWidth = 3;\n    85→    ctx.lineCap = 'round';\n    86→\n    87→    for (const [startIdx, endIdx] of SKELETON_CONNECTIONS) {\n    88→      const start = landmarks[startIdx];\n    89→      const end = landmarks[endIdx];\n    90→      if (!start || !end) continue;\n    91→      if ((start.visibility ?? 0) < 0.3 || (end.visibility ?? 0) < 0.3) continue;\n    92→\n    93→      ctx.beginPath();\n    94→      ctx.moveTo(padding + start.x * drawWidth, padding + start.y * drawHeight);\n    95→      ctx.lineTo(padding + end.x * drawWidth, padding + end.y * drawHeight);\n    96→      ctx.stroke();\n    97→    }\n    98→\n    99→    // Draw joints\n   100→    ctx.fillStyle = color;\n   101→    for (let i = 0; i < landmarks.length; i++) {\n   102→      const landmark = landmarks[i];\n   103→      if (!landmark || (landmark.visibility ?? 0) < 0.3) continue;\n   104→\n   105→      const isKeyJoint = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28].includes(i);\n   106→      const isAffected = mistake.joints.includes(i);\n   107→\n   108→      ctx.beginPath();\n   109→      ctx.arc(\n   110→        padding + landmark.x * drawWidth,\n   111→        padding + landmark.y * drawHeight,\n   112→        isAffected ? 6 : isKeyJoint ? 5 : 3,\n   113→        0,\n   114→        Math.PI * 2\n   115→      );\n   116→      ctx.fill();\n   117→\n   118→      // Highlight affected joints\n   119→      if (isAffected) {\n   120→        ctx.strokeStyle = '#ffffff';\n   121→        ctx.lineWidth = 2;\n   122→        ctx.stroke();\n   123→      }\n   124→    }\n   125→\n   126→    ctx.globalAlpha = 1;\n   127→  }, [mistake.joints]);\n   128→\n   129→  // Render canvas\n   130→  useEffect(() => {\n   131→    const canvas = canvasRef.current;\n   132→    if (!canvas || phases.length === 0) return;\n   133→\n   134→    const ctx = canvas.getContext('2d');\n   135→    if (!ctx) return;\n   136→\n   137→    const width = canvas.width;\n   138→    const height = canvas.height;\n   139→\n   140→    // Clear\n   141→    ctx.clearRect(0, 0, width, height);\n   142→\n   143→    // Background gradient\n   144→    const gradient = ctx.createLinearGradient(0, 0, 0, height);\n   145→    gradient.addColorStop(0, '#f8fafc');\n   146→    gradient.addColorStop(1, '#e2e8f0');\n   147→    ctx.fillStyle = gradient;\n   148→    ctx.fillRect(0, 0, width, height);\n   149→\n   150→    // Draw current phase\n   151→    const currentPhase = phases[activePhase];\n   152→    if (currentPhase?.landmarks) {\n   153→      // Draw main skeleton in green (correct form)\n   154→      drawSkeleton(ctx, currentPhase.landmarks, width, height, '#22c55e', 1);\n   155→\n   156→      // Draw arrows for affected joints if correction exists\n   157→      if (currentPhase.correction) {\n   158→        ctx.fillStyle = '#3b82f6';\n   159→        ctx.font = 'bold 10px system-ui';\n   160→        ctx.textAlign = 'center';\n   161→\n   162→        // Draw correction indicator\n   163→        const padding = 20;\n   164→        const drawWidth = width - padding * 2;\n   165→        const drawHeight = height - padding * 2;\n   166→\n   167→        for (const jointIdx of mistake.joints.slice(0, 2)) {\n   168→          const landmark = currentPhase.landmarks[jointIdx];\n   169→          if (landmark && (landmark.visibility ?? 0) > 0.3) {\n   170→            const x = padding + landmark.x * drawWidth;\n   171→            const y = padding + landmark.y * drawHeight;\n   172→\n   173→            // Draw pulsing circle\n   174→            ctx.beginPath();\n   175→            ctx.arc(x, y, 12, 0, Math.PI * 2);\n   176→            ctx.strokeStyle = '#3b82f6';\n   177→            ctx.lineWidth = 2;\n   178→            ctx.setLineDash([3, 3]);\n   179→            ctx.stroke();\n   180→            ctx.setLineDash([]);\n   181→          }\n   182→        }\n   183→      }\n   184→    }\n   185→\n   186→    // Draw phase label\n   187→    ctx.fillStyle = '#334155';\n   188→    ctx.font = 'bold 14px system-ui';\n   189→    ctx.textAlign = 'center';\n   190→    ctx.fillText(currentPhase?.label || `Phase ${activePhase + 1}`, width / 2, height - 10);\n   191→\n   192→  }, [activePhase, phases, drawSkeleton, mistake.joints]);\n   193→\n   194→  return (\n   195→    <div className=\"bg-white rounded-xl shadow-lg overflow-hidden\">\n   196→      {/* Header */}\n   197→      <div className=\"flex items-center justify-between p-4 border-b border-gray-100 bg-gradient-to-r from-red-50 to-orange-50\">\n   198→        <div className=\"flex items-center gap-2\">\n   199→          <div className=\"w-8 h-8 rounded-full bg-red-100 flex items-center justify-center\">\n   200→            <svg className=\"w-4 h-4 text-red-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n   201→              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z\" />\n   202→            </svg>\n   203→          </div>\n   204→          <div>\n   205→            <h3 className=\"font-semibold text-gray-900\">{mistake.summaryTitle}</h3>\n   206→            <p className=\"text-xs text-gray-500\">\n   207→              {Math.round(mistake.confidence * 100)}% confidence\n   208→            </p>\n   209→          </div>\n   210→        </div>\n   211→        {onClose && (\n   212→          <button\n   213→            onClick={onClose}\n   214→            className=\"p-1 hover:bg-gray-100 rounded-full transition\"\n   215→          >\n   216→            <svg className=\"w-5 h-5 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n   217→              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M6 18L18 6M6 6l12 12\" />\n   218→            </svg>\n   219→          </button>\n   220→        )}\n   221→      </div>\n   222→\n   223→      {/* Animation Canvas */}\n   224→      <div className=\"relative\">\n   225→        <canvas\n   226→          ref={canvasRef}\n   227→          width={200}\n   228→          height={240}\n   229→          className=\"w-full\"\n   230→        />\n   231→\n   232→        {/* Play/Pause button */}\n   233→        <button\n   234→          onClick={() => setIsAnimating(!isAnimating)}\n   235→          className=\"absolute bottom-14 right-2 p-2 bg-white/90 rounded-full shadow-md hover:bg-white transition\"\n   236→        >\n   237→          {isAnimating ? (\n   238→            <svg className=\"w-4 h-4 text-gray-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n   239→              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6\" />\n   240→            </svg>\n   241→          ) : (\n   242→            <svg className=\"w-4 h-4 text-gray-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n   243→              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n   244→            </svg>\n   245→          )}\n   246→        </button>\n   247→      </div>\n   248→\n   249→      {/* Phase selector */}\n   250→      <div className=\"flex justify-center gap-2 py-2 bg-gray-50\">\n   251→        {phases.map((phase, idx) => (\n   252→          <button\n   253→            key={idx}\n   254→            onClick={() => {\n   255→              setActivePhase(idx);\n   256→              phaseTimeRef.current = 0;\n   257→            }}\n   258→            className={`px-3 py-1.5 text-xs font-medium rounded-full transition ${\n   259→              activePhase === idx\n   260→                ? 'bg-primary-500 text-white'\n   261→                : 'bg-gray-200 text-gray-600 hover:bg-gray-300'\n   262→            }`}\n   263→          >\n   264→            {phase.label}\n   265→          </button>\n   266→        ))}\n   267→      </div>\n   268→\n   269→      {/* Correction text */}\n   270→      {phases[activePhase]?.correction && (\n   271→        <div className=\"px-4 py-3 bg-blue-50 border-t border-blue-100\">\n   272→          <div className=\"flex items-start gap-2\">\n   273→            <svg className=\"w-4 h-4 text-blue-500 mt-0.5 flex-shrink-0\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n   274→              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n   275→            </svg>\n   276→            <p className=\"text-sm text-blue-800\">\n   277→              {phases[activePhase].correction}\n   278→            </p>\n   279→          </div>\n   280→        </div>\n   281→      )}\n   282→\n   283→      {/* Description */}\n   284→      <div className=\"p-4 border-t border-gray-100\">\n   285→        <p className=\"text-sm text-gray-600\">{mistake.description}</p>\n   286→      </div>\n   287→    </div>\n   288→  );\n   289→}\n   290→\n   291→/**\n   292→ * Generate default phases for mistake types when no keyframes provided\n   293→ */\n   294→function getDefaultPhases(mistakeType: string): FixKeyframe[] {\n   295→  // Default pose landmarks for each phase\n   296→  const defaultPose: PoseLandmark[] = Array(33).fill(null).map((_, i) => ({\n   297→    x: 0.5,\n   298→    y: 0.5,\n   299→    z: 0,\n   300→    visibility: 0,\n   301→  }));\n   302→\n   303→  // Set visible landmarks for a basic stick figure\n   304→  const setLandmark = (pose: PoseLandmark[], idx: number, x: number, y: number) => {\n   305→    pose[idx] = { x, y, z: 0, visibility: 1 };\n   306→  };\n   307→\n   308→  // Setup phase\n   309→  const setupPose = [...defaultPose];\n   310→  setLandmark(setupPose, 0, 0.5, 0.15); // nose\n   311→  setLandmark(setupPose, 11, 0.42, 0.28); // left shoulder\n   312→  setLandmark(setupPose, 12, 0.58, 0.28); // right shoulder\n   313→  setLandmark(setupPose, 13, 0.38, 0.4); // left elbow\n   314→  setLandmark(setupPose, 14, 0.62, 0.4); // right elbow\n   315→  setLandmark(setupPose, 15, 0.35, 0.52); // left wrist\n   316→  setLandmark(setupPose, 16, 0.65, 0.52); // right wrist\n   317→  setLandmark(setupPose, 23, 0.44, 0.55); // left hip\n   318→  setLandmark(setupPose, 24, 0.56, 0.55); // right hip\n   319→  setLandmark(setupPose, 25, 0.42, 0.75); // left knee\n   320→  setLandmark(setupPose, 26, 0.58, 0.75); // right knee\n   321→  setLandmark(setupPose, 27, 0.4, 0.95); // left ankle\n   322→  setLandmark(setupPose, 28, 0.6, 0.95); // right ankle\n   323→\n   324→  // Contact phase (overhead)\n   325→  const contactPose = [...defaultPose];\n   326→  setLandmark(contactPose, 0, 0.5, 0.12); // nose\n   327→  setLandmark(contactPose, 11, 0.4, 0.25); // left shoulder\n   328→  setLandmark(contactPose, 12, 0.6, 0.25); // right shoulder\n   329→  setLandmark(contactPose, 13, 0.35, 0.35); // left elbow\n   330→  setLandmark(contactPose, 14, 0.7, 0.15); // right elbow (raised)\n   331→  setLandmark(contactPose, 15, 0.3, 0.45); // left wrist\n   332→  setLandmark(contactPose, 16, 0.75, 0.08); // right wrist (high)\n   333→  setLandmark(contactPose, 23, 0.42, 0.52); // left hip\n   334→  setLandmark(contactPose, 24, 0.58, 0.52); // right hip\n   335→  setLandmark(contactPose, 25, 0.4, 0.72); // left knee\n   336→  setLandmark(contactPose, 26, 0.6, 0.72); // right knee\n   337→  setLandmark(contactPose, 27, 0.38, 0.92); // left ankle\n   338→  setLandmark(contactPose, 28, 0.62, 0.92); // right ankle\n   339→\n   340→  // Recovery phase\n   341→  const recoveryPose = [...setupPose];\n   342→\n   343→  const corrections = {\n   344→    OVERHEAD_CONTACT_LOW: [\n   345→      { label: 'Setup', correction: 'Position yourself under the shuttle' },\n   346→      { label: 'Contact', correction: 'Hit at highest point above your head' },\n   347→      { label: 'Recovery', correction: 'Return to ready position' },\n   348→    ],\n   349→    LATE_SPLIT_STEP: [\n   350→      { label: 'Watch', correction: 'Watch opponent\\'s racket' },\n   351→      { label: 'Split', correction: 'Land as opponent makes contact' },\n   352→      { label: 'Move', correction: 'Explode to the shuttle' },\n   353→    ],\n   354→    POOR_LUNGE_RECOVERY: [\n   355→      { label: 'Lunge', correction: 'Keep weight on front heel' },\n   356→      { label: 'Push', correction: 'Push off immediately' },\n   357→      { label: 'Return', correction: 'Return to center quickly' },\n   358→    ],\n   359→    INSUFFICIENT_ROTATION: [\n   360→      { label: 'Setup', correction: 'Turn sideways to the net' },\n   361→      { label: 'Rotate', correction: 'Lead with hips, then shoulders' },\n   362→      { label: 'Follow', correction: 'Complete the rotation' },\n   363→    ],\n   364→    ELBOW_TOO_BENT: [\n   365→      { label: 'Prepare', correction: 'Raise elbow high' },\n   366→      { label: 'Extend', correction: 'Fully extend at contact' },\n   367→      { label: 'Follow', correction: 'Follow through smoothly' },\n   368→    ],\n   369→  };\n   370→\n   371→  const mistakeCorrections = corrections[mistakeType as keyof typeof corrections] || [\n   372→    { label: 'Setup', correction: 'Ready position' },\n   373→    { label: 'Action', correction: 'Execute the movement' },\n   374→    { label: 'Finish', correction: 'Return to ready' },\n   375→  ];\n   376→\n   377→  return [\n   378→    { phase: 'setup', landmarks: setupPose, label: mistakeCorrections[0].label, correction: mistakeCorrections[0].correction },\n   379→    { phase: 'contact', landmarks: contactPose, label: mistakeCorrections[1].label, correction: mistakeCorrections[1].correction },\n   380→    { phase: 'recover', landmarks: recoveryPose, label: mistakeCorrections[2].label, correction: mistakeCorrections[2].correction },\n   381→  ];\n   382→}\n   383→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"260408a3-f301-46c9-afc7-15eeda2e0af3","timestamp":"2026-01-28T23:26:51.277Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\components\\FixItCard.tsx","content":"'use client';\n\nimport { useState, useEffect, useRef, useCallback } from 'react';\nimport type { MistakeEvent, FixKeyframe, PoseLandmark } from '@/lib/types';\nimport { POSE_CONNECTIONS } from '@/lib/pose-utils';\n\ninterface FixItCardProps {\n  mistake: MistakeEvent;\n  fixKeyframes?: FixKeyframe[];\n  onClose?: () => void;\n}\n\n// Skeleton connections for drawing\nconst SKELETON_CONNECTIONS = [\n  [11, 12], // shoulders\n  [11, 23], [12, 24], // shoulders to hips\n  [23, 24], // hips\n  [11, 13], [13, 15], // left arm\n  [12, 14], [14, 16], // right arm\n  [23, 25], [25, 27], // left leg\n  [24, 26], [26, 28], // right leg\n];\n\nexport default function FixItCard({\n  mistake,\n  fixKeyframes,\n  onClose,\n}: FixItCardProps) {\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const [activePhase, setActivePhase] = useState(0);\n  const [isAnimating, setIsAnimating] = useState(true);\n  const animationRef = useRef<number | null>(null);\n  const phaseTimeRef = useRef<number>(0);\n\n  const phases = fixKeyframes?.length ? fixKeyframes : getDefaultPhases(mistake.type);\n\n  // Animation loop\n  useEffect(() => {\n    if (!isAnimating || phases.length === 0) return;\n\n    let lastTime = performance.now();\n    const phaseDuration = 1500; // 1.5 seconds per phase\n\n    const animate = (currentTime: number) => {\n      const deltaTime = currentTime - lastTime;\n      lastTime = currentTime;\n\n      phaseTimeRef.current += deltaTime;\n\n      if (phaseTimeRef.current >= phaseDuration) {\n        phaseTimeRef.current = 0;\n        setActivePhase(prev => (prev + 1) % phases.length);\n      }\n\n      animationRef.current = requestAnimationFrame(animate);\n    };\n\n    animationRef.current = requestAnimationFrame(animate);\n\n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current);\n      }\n    };\n  }, [isAnimating, phases.length]);\n\n  // Draw skeleton\n  const drawSkeleton = useCallback((\n    ctx: CanvasRenderingContext2D,\n    landmarks: PoseLandmark[],\n    width: number,\n    height: number,\n    color: string,\n    alpha: number = 1\n  ) => {\n    const padding = 20;\n    const drawWidth = width - padding * 2;\n    const drawHeight = height - padding * 2;\n\n    ctx.globalAlpha = alpha;\n\n    // Draw connections\n    ctx.strokeStyle = color;\n    ctx.lineWidth = 3;\n    ctx.lineCap = 'round';\n\n    for (const [startIdx, endIdx] of SKELETON_CONNECTIONS) {\n      const start = landmarks[startIdx];\n      const end = landmarks[endIdx];\n      if (!start || !end) continue;\n      if ((start.visibility ?? 0) < 0.3 || (end.visibility ?? 0) < 0.3) continue;\n\n      ctx.beginPath();\n      ctx.moveTo(padding + start.x * drawWidth, padding + start.y * drawHeight);\n      ctx.lineTo(padding + end.x * drawWidth, padding + end.y * drawHeight);\n      ctx.stroke();\n    }\n\n    // Draw joints\n    ctx.fillStyle = color;\n    for (let i = 0; i < landmarks.length; i++) {\n      const landmark = landmarks[i];\n      if (!landmark || (landmark.visibility ?? 0) < 0.3) continue;\n\n      const isKeyJoint = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28].includes(i);\n      const isAffected = mistake.joints.includes(i);\n\n      ctx.beginPath();\n      ctx.arc(\n        padding + landmark.x * drawWidth,\n        padding + landmark.y * drawHeight,\n        isAffected ? 6 : isKeyJoint ? 5 : 3,\n        0,\n        Math.PI * 2\n      );\n      ctx.fill();\n\n      // Highlight affected joints\n      if (isAffected) {\n        ctx.strokeStyle = '#ffffff';\n        ctx.lineWidth = 2;\n        ctx.stroke();\n      }\n    }\n\n    ctx.globalAlpha = 1;\n  }, [mistake.joints]);\n\n  // Render canvas\n  useEffect(() => {\n    const canvas = canvasRef.current;\n    if (!canvas || phases.length === 0) return;\n\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    const width = canvas.width;\n    const height = canvas.height;\n\n    // Clear\n    ctx.clearRect(0, 0, width, height);\n\n    // Background gradient\n    const gradient = ctx.createLinearGradient(0, 0, 0, height);\n    gradient.addColorStop(0, '#f8fafc');\n    gradient.addColorStop(1, '#e2e8f0');\n    ctx.fillStyle = gradient;\n    ctx.fillRect(0, 0, width, height);\n\n    // Draw current phase\n    const currentPhase = phases[activePhase];\n    if (currentPhase?.landmarks) {\n      // Draw main skeleton in green (correct form)\n      drawSkeleton(ctx, currentPhase.landmarks, width, height, '#22c55e', 1);\n\n      // Draw arrows for affected joints if correction exists\n      if (currentPhase.correction) {\n        ctx.fillStyle = '#3b82f6';\n        ctx.font = 'bold 10px system-ui';\n        ctx.textAlign = 'center';\n\n        // Draw correction indicator\n        const padding = 20;\n        const drawWidth = width - padding * 2;\n        const drawHeight = height - padding * 2;\n\n        for (const jointIdx of mistake.joints.slice(0, 2)) {\n          const landmark = currentPhase.landmarks[jointIdx];\n          if (landmark && (landmark.visibility ?? 0) > 0.3) {\n            const x = padding + landmark.x * drawWidth;\n            const y = padding + landmark.y * drawHeight;\n\n            // Draw pulsing circle\n            ctx.beginPath();\n            ctx.arc(x, y, 12, 0, Math.PI * 2);\n            ctx.strokeStyle = '#3b82f6';\n            ctx.lineWidth = 2;\n            ctx.setLineDash([3, 3]);\n            ctx.stroke();\n            ctx.setLineDash([]);\n          }\n        }\n      }\n    }\n\n    // Draw phase label\n    ctx.fillStyle = '#334155';\n    ctx.font = 'bold 14px system-ui';\n    ctx.textAlign = 'center';\n    ctx.fillText(currentPhase?.label || `Phase ${activePhase + 1}`, width / 2, height - 10);\n\n  }, [activePhase, phases, drawSkeleton, mistake.joints]);\n\n  return (\n    <div className=\"bg-white rounded-xl shadow-lg overflow-hidden\">\n      {/* Header */}\n      <div className=\"flex items-center justify-between p-4 border-b border-gray-100 bg-gradient-to-r from-red-50 to-orange-50\">\n        <div className=\"flex items-center gap-2\">\n          <div className=\"w-8 h-8 rounded-full bg-red-100 flex items-center justify-center\">\n            <svg className=\"w-4 h-4 text-red-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z\" />\n            </svg>\n          </div>\n          <div>\n            <h3 className=\"font-semibold text-gray-900\">{mistake.summaryTitle}</h3>\n            <p className=\"text-xs text-gray-500\">\n              {Math.round(mistake.confidence * 100)}% confidence\n            </p>\n          </div>\n        </div>\n        {onClose && (\n          <button\n            onClick={onClose}\n            className=\"p-1 hover:bg-gray-100 rounded-full transition\"\n          >\n            <svg className=\"w-5 h-5 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M6 18L18 6M6 6l12 12\" />\n            </svg>\n          </button>\n        )}\n      </div>\n\n      {/* Animation Canvas */}\n      <div className=\"relative\">\n        <canvas\n          ref={canvasRef}\n          width={200}\n          height={240}\n          className=\"w-full\"\n        />\n\n        {/* Play/Pause button */}\n        <button\n          onClick={() => setIsAnimating(!isAnimating)}\n          className=\"absolute bottom-14 right-2 p-2 bg-white/90 rounded-full shadow-md hover:bg-white transition\"\n        >\n          {isAnimating ? (\n            <svg className=\"w-4 h-4 text-gray-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6\" />\n            </svg>\n          ) : (\n            <svg className=\"w-4 h-4 text-gray-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n            </svg>\n          )}\n        </button>\n      </div>\n\n      {/* Phase selector */}\n      <div className=\"flex justify-center gap-2 py-2 bg-gray-50\">\n        {phases.map((phase, idx) => (\n          <button\n            key={idx}\n            onClick={() => {\n              setActivePhase(idx);\n              phaseTimeRef.current = 0;\n            }}\n            className={`px-3 py-1.5 text-xs font-medium rounded-full transition ${\n              activePhase === idx\n                ? 'bg-primary-500 text-white'\n                : 'bg-gray-200 text-gray-600 hover:bg-gray-300'\n            }`}\n          >\n            {phase.label}\n          </button>\n        ))}\n      </div>\n\n      {/* Correction text */}\n      {phases[activePhase]?.correction && (\n        <div className=\"px-4 py-3 bg-blue-50 border-t border-blue-100\">\n          <div className=\"flex items-start gap-2\">\n            <svg className=\"w-4 h-4 text-blue-500 mt-0.5 flex-shrink-0\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n            </svg>\n            <p className=\"text-sm text-blue-800\">\n              {phases[activePhase].correction}\n            </p>\n          </div>\n        </div>\n      )}\n\n      {/* Description */}\n      <div className=\"p-4 border-t border-gray-100\">\n        <p className=\"text-sm text-gray-600\">{mistake.description}</p>\n      </div>\n    </div>\n  );\n}\n\n/**\n * Generate default phases for mistake types when no keyframes provided\n */\nfunction getDefaultPhases(mistakeType: string): FixKeyframe[] {\n  // Default pose landmarks for each phase\n  const defaultPose: PoseLandmark[] = Array(33).fill(null).map((_, i) => ({\n    x: 0.5,\n    y: 0.5,\n    z: 0,\n    visibility: 0,\n  }));\n\n  // Set visible landmarks for a basic stick figure\n  const setLandmark = (pose: PoseLandmark[], idx: number, x: number, y: number) => {\n    pose[idx] = { x, y, z: 0, visibility: 1 };\n  };\n\n  // Setup phase\n  const setupPose = [...defaultPose];\n  setLandmark(setupPose, 0, 0.5, 0.15); // nose\n  setLandmark(setupPose, 11, 0.42, 0.28); // left shoulder\n  setLandmark(setupPose, 12, 0.58, 0.28); // right shoulder\n  setLandmark(setupPose, 13, 0.38, 0.4); // left elbow\n  setLandmark(setupPose, 14, 0.62, 0.4); // right elbow\n  setLandmark(setupPose, 15, 0.35, 0.52); // left wrist\n  setLandmark(setupPose, 16, 0.65, 0.52); // right wrist\n  setLandmark(setupPose, 23, 0.44, 0.55); // left hip\n  setLandmark(setupPose, 24, 0.56, 0.55); // right hip\n  setLandmark(setupPose, 25, 0.42, 0.75); // left knee\n  setLandmark(setupPose, 26, 0.58, 0.75); // right knee\n  setLandmark(setupPose, 27, 0.4, 0.95); // left ankle\n  setLandmark(setupPose, 28, 0.6, 0.95); // right ankle\n\n  // Contact phase (overhead)\n  const contactPose = [...defaultPose];\n  setLandmark(contactPose, 0, 0.5, 0.12); // nose\n  setLandmark(contactPose, 11, 0.4, 0.25); // left shoulder\n  setLandmark(contactPose, 12, 0.6, 0.25); // right shoulder\n  setLandmark(contactPose, 13, 0.35, 0.35); // left elbow\n  setLandmark(contactPose, 14, 0.7, 0.15); // right elbow (raised)\n  setLandmark(contactPose, 15, 0.3, 0.45); // left wrist\n  setLandmark(contactPose, 16, 0.75, 0.08); // right wrist (high)\n  setLandmark(contactPose, 23, 0.42, 0.52); // left hip\n  setLandmark(contactPose, 24, 0.58, 0.52); // right hip\n  setLandmark(contactPose, 25, 0.4, 0.72); // left knee\n  setLandmark(contactPose, 26, 0.6, 0.72); // right knee\n  setLandmark(contactPose, 27, 0.38, 0.92); // left ankle\n  setLandmark(contactPose, 28, 0.62, 0.92); // right ankle\n\n  // Recovery phase\n  const recoveryPose = [...setupPose];\n\n  const corrections = {\n    OVERHEAD_CONTACT_LOW: [\n      { label: 'Setup', correction: 'Position yourself under the shuttle' },\n      { label: 'Contact', correction: 'Hit at highest point above your head' },\n      { label: 'Recovery', correction: 'Return to ready position' },\n    ],\n    LATE_SPLIT_STEP: [\n      { label: 'Watch', correction: 'Watch opponent\\'s racket' },\n      { label: 'Split', correction: 'Land as opponent makes contact' },\n      { label: 'Move', correction: 'Explode to the shuttle' },\n    ],\n    POOR_LUNGE_RECOVERY: [\n      { label: 'Lunge', correction: 'Keep weight on front heel' },\n      { label: 'Push', correction: 'Push off immediately' },\n      { label: 'Return', correction: 'Return to center quickly' },\n    ],\n    INSUFFICIENT_ROTATION: [\n      { label: 'Setup', correction: 'Turn sideways to the net' },\n      { label: 'Rotate', correction: 'Lead with hips, then shoulders' },\n      { label: 'Follow', correction: 'Complete the rotation' },\n    ],\n    ELBOW_TOO_BENT: [\n      { label: 'Prepare', correction: 'Raise elbow high' },\n      { label: 'Extend', correction: 'Fully extend at contact' },\n      { label: 'Follow', correction: 'Follow through smoothly' },\n    ],\n  };\n\n  const mistakeCorrections = corrections[mistakeType as keyof typeof corrections] || [\n    { label: 'Setup', correction: 'Ready position' },\n    { label: 'Action', correction: 'Execute the movement' },\n    { label: 'Finish', correction: 'Return to ready' },\n  ];\n\n  return [\n    { phase: 'setup', landmarks: setupPose, label: mistakeCorrections[0].label, correction: mistakeCorrections[0].correction },\n    { phase: 'contact', landmarks: contactPose, label: mistakeCorrections[1].label, correction: mistakeCorrections[1].correction },\n    { phase: 'recover', landmarks: recoveryPose, label: mistakeCorrections[2].label, correction: mistakeCorrections[2].correction },\n  ];\n}\n","numLines":383,"startLine":1,"totalLines":383}},"sourceToolAssistantUUID":"5ef30d71-6c55-48b1-8a5f-30d1cb8a15a8"}
{"parentUuid":"260408a3-f301-46c9-afc7-15eeda2e0af3","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Qz8ARFtyRdaDD7ei38KMmh","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I see. The FixItCard takes `fixKeyframes` as an optional prop (not `keyframes`). Let me also check the `generateFixKeyframes` function to see its signature.","signature":"EsUCCkYICxgCKkABCkQM+ZWMRqWxDDJDeG1v8G2DTV758rjevyGlIg+avZx+GOu6vCrR9Ku1U8GB0AX/BsgDqprQcgjmALyfBKnmEgyCjPYv6dXjumkg8GMaDGVm/1oaoyfJRlxXriIwxrYJQe852yiLtdLw9wzLFyktbRQj5Q+fywgE8ZKa1EQBBf2lckeTkZIycBeDUygwKqwB7T2RbmC945yueTAYFQZSyFae9fbUlnbbKS0kIB6bGWLbqVWNdEKaH8DiyQI9DGohLxFVBga9vxmQeEZkHcgALooKMOnbt6vGOeUGTCTGY1latLDzQT15tJvpzLZzlz/Yzi/7Cs4bFLuATCEx7dPF1S0WW5IDs/2oYXjCA2Q+Ev4ywWM4+RNN4f7q7BXIt05wcNugxd88FHH4yEHzXthCfMztwUTLVFNgAPKrjBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":6172,"cache_read_input_tokens":82496,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6172},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeB8rc5ZmB6keNkih9b","type":"assistant","uuid":"3c422f3c-ca55-4999-9152-85f55e352629","timestamp":"2026-01-28T23:26:54.640Z"}
{"parentUuid":"3c422f3c-ca55-4999-9152-85f55e352629","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Qz8ARFtyRdaDD7ei38KMmh","type":"message","role":"assistant","content":[{"type":"text","text":"Let me check the `generateFixKeyframes` function signature."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":6172,"cache_read_input_tokens":82496,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6172},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeB8rc5ZmB6keNkih9b","type":"assistant","uuid":"8d4c8046-12f3-49c3-9a0e-c3ac150b08fe","timestamp":"2026-01-28T23:26:55.019Z"}
{"parentUuid":"8d4c8046-12f3-49c3-9a0e-c3ac150b08fe","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Qz8ARFtyRdaDD7ei38KMmh","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01W6miAFagWHmxg45m1P7KQH","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","offset":1,"limit":100}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":6172,"cache_read_input_tokens":82496,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6172},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeB8rc5ZmB6keNkih9b","type":"assistant","uuid":"22ddb8de-99f4-4101-8f58-0d1b32ab8a52","timestamp":"2026-01-28T23:26:56.576Z"}
{"parentUuid":"22ddb8de-99f4-4101-8f58-0d1b32ab8a52","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01W6miAFagWHmxg45m1P7KQH","type":"tool_result","content":"     1→/**\n     2→ * Mistake Detection Module\n     3→ *\n     4→ * Detects specific mistake types from pose data:\n     5→ * 1. Overhead contact too low\n     6→ * 2. Late/missing split-step\n     7→ * 3. Poor lunge recovery\n     8→ * 4. Insufficient body rotation\n     9→ * 5. Stance too narrow/wide\n    10→ *\n    11→ * Each mistake includes:\n    12→ * - Time range (startTimeSec, endTimeSec)\n    13→ * - Severity (0-1)\n    14→ * - Confidence (derived from visibility)\n    15→ * - Affected joints\n    16→ */\n    17→\n    18→import type {\n    19→  PoseLandmark,\n    20→  PoseMetrics,\n    21→  MistakeEvent,\n    22→  FixKeyframe,\n    23→  TimelineSegment\n    24→} from './types';\n    25→import { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n    26→\n    27→// Minimum frames to persist an issue before reporting\n    28→const MIN_PERSISTENCE_FRAMES = 3;\n    29→// Minimum confidence to report a mistake\n    30→const MIN_CONFIDENCE_THRESHOLD = 0.4;\n    31→\n    32→/**\n    33→ * Mistake type definitions with thresholds and feedback\n    34→ */\n    35→const MISTAKE_TYPES = {\n    36→  OVERHEAD_CONTACT_LOW: {\n    37→    code: 'OVERHEAD_CONTACT_LOW',\n    38→    title: 'Contact Point Too Low',\n    39→    description: 'Raise your contact point for better power and angle',\n    40→    severity: 0.8,\n    41→    joints: [\n    42→      POSE_LANDMARKS.RIGHT_WRIST,\n    43→      POSE_LANDMARKS.RIGHT_ELBOW,\n    44→      POSE_LANDMARKS.RIGHT_SHOULDER,\n    45→    ],\n    46→  },\n    47→  LATE_SPLIT_STEP: {\n    48→    code: 'LATE_SPLIT_STEP',\n    49→    title: 'Late or Missing Split-Step',\n    50→    description: 'Time your split-step with opponent\\'s contact',\n    51→    severity: 0.6,\n    52→    joints: [\n    53→      POSE_LANDMARKS.LEFT_ANKLE,\n    54→      POSE_LANDMARKS.RIGHT_ANKLE,\n    55→      POSE_LANDMARKS.LEFT_KNEE,\n    56→      POSE_LANDMARKS.RIGHT_KNEE,\n    57→    ],\n    58→  },\n    59→  POOR_LUNGE_RECOVERY: {\n    60→    code: 'POOR_LUNGE_RECOVERY',\n    61→    title: 'Slow Lunge Recovery',\n    62→    description: 'Push off your front foot faster to recover',\n    63→    severity: 0.7,\n    64→    joints: [\n    65→      POSE_LANDMARKS.RIGHT_KNEE,\n    66→      POSE_LANDMARKS.RIGHT_ANKLE,\n    67→      POSE_LANDMARKS.LEFT_HIP,\n    68→      POSE_LANDMARKS.RIGHT_HIP,\n    69→    ],\n    70→  },\n    71→  INSUFFICIENT_ROTATION: {\n    72→    code: 'INSUFFICIENT_ROTATION',\n    73→    title: 'Insufficient Body Rotation',\n    74→    description: 'Rotate hips before shoulders for more power',\n    75→    severity: 0.5,\n    76→    joints: [\n    77→      POSE_LANDMARKS.LEFT_SHOULDER,\n    78→      POSE_LANDMARKS.RIGHT_SHOULDER,\n    79→      POSE_LANDMARKS.LEFT_HIP,\n    80→      POSE_LANDMARKS.RIGHT_HIP,\n    81→    ],\n    82→  },\n    83→  STANCE_TOO_NARROW: {\n    84→    code: 'STANCE_TOO_NARROW',\n    85→    title: 'Stance Too Narrow',\n    86→    description: 'Widen your stance for better stability',\n    87→    severity: 0.4,\n    88→    joints: [\n    89→      POSE_LANDMARKS.LEFT_ANKLE,\n    90→      POSE_LANDMARKS.RIGHT_ANKLE,\n    91→    ],\n    92→  },\n    93→  STANCE_TOO_WIDE: {\n    94→    code: 'STANCE_TOO_WIDE',\n    95→    title: 'Stance Too Wide',\n    96→    description: 'Narrow your stance for quicker movement',\n    97→    severity: 0.4,\n    98→    joints: [\n    99→      POSE_LANDMARKS.LEFT_ANKLE,\n   100→      POSE_LANDMARKS.RIGHT_ANKLE,\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"5c1f48b8-eeff-4c18-8332-259e565fa630","timestamp":"2026-01-28T23:26:57.248Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","content":"/**\n * Mistake Detection Module\n *\n * Detects specific mistake types from pose data:\n * 1. Overhead contact too low\n * 2. Late/missing split-step\n * 3. Poor lunge recovery\n * 4. Insufficient body rotation\n * 5. Stance too narrow/wide\n *\n * Each mistake includes:\n * - Time range (startTimeSec, endTimeSec)\n * - Severity (0-1)\n * - Confidence (derived from visibility)\n * - Affected joints\n */\n\nimport type {\n  PoseLandmark,\n  PoseMetrics,\n  MistakeEvent,\n  FixKeyframe,\n  TimelineSegment\n} from './types';\nimport { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n\n// Minimum frames to persist an issue before reporting\nconst MIN_PERSISTENCE_FRAMES = 3;\n// Minimum confidence to report a mistake\nconst MIN_CONFIDENCE_THRESHOLD = 0.4;\n\n/**\n * Mistake type definitions with thresholds and feedback\n */\nconst MISTAKE_TYPES = {\n  OVERHEAD_CONTACT_LOW: {\n    code: 'OVERHEAD_CONTACT_LOW',\n    title: 'Contact Point Too Low',\n    description: 'Raise your contact point for better power and angle',\n    severity: 0.8,\n    joints: [\n      POSE_LANDMARKS.RIGHT_WRIST,\n      POSE_LANDMARKS.RIGHT_ELBOW,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n    ],\n  },\n  LATE_SPLIT_STEP: {\n    code: 'LATE_SPLIT_STEP',\n    title: 'Late or Missing Split-Step',\n    description: 'Time your split-step with opponent\\'s contact',\n    severity: 0.6,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n      POSE_LANDMARKS.LEFT_KNEE,\n      POSE_LANDMARKS.RIGHT_KNEE,\n    ],\n  },\n  POOR_LUNGE_RECOVERY: {\n    code: 'POOR_LUNGE_RECOVERY',\n    title: 'Slow Lunge Recovery',\n    description: 'Push off your front foot faster to recover',\n    severity: 0.7,\n    joints: [\n      POSE_LANDMARKS.RIGHT_KNEE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n      POSE_LANDMARKS.LEFT_HIP,\n      POSE_LANDMARKS.RIGHT_HIP,\n    ],\n  },\n  INSUFFICIENT_ROTATION: {\n    code: 'INSUFFICIENT_ROTATION',\n    title: 'Insufficient Body Rotation',\n    description: 'Rotate hips before shoulders for more power',\n    severity: 0.5,\n    joints: [\n      POSE_LANDMARKS.LEFT_SHOULDER,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n      POSE_LANDMARKS.LEFT_HIP,\n      POSE_LANDMARKS.RIGHT_HIP,\n    ],\n  },\n  STANCE_TOO_NARROW: {\n    code: 'STANCE_TOO_NARROW',\n    title: 'Stance Too Narrow',\n    description: 'Widen your stance for better stability',\n    severity: 0.4,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n    ],\n  },\n  STANCE_TOO_WIDE: {\n    code: 'STANCE_TOO_WIDE',\n    title: 'Stance Too Wide',\n    description: 'Narrow your stance for quicker movement',\n    severity: 0.4,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,","numLines":100,"startLine":1,"totalLines":652}},"sourceToolAssistantUUID":"22ddb8de-99f4-4101-8f58-0d1b32ab8a52"}
{"parentUuid":"5c1f48b8-eeff-4c18-8332-259e565fa630","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019Hp3KgYb9PA5tM9gHYSUio","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me find the generateFixKeyframes function.","signature":"EtYBCkYICxgCKkAacQ0Tw9HusiKQYYd1nJQplSsSzg17iFPbmZCWpBSjYgTztI/vnCD+Tzmm5wIXbeCpWWnpUV3yAHlBwNhvbwxOEgzizmheegO8sDyV7fIaDO8vDnZFzG7qRBXCzSIw0eWSchea8ZhDlp1wxmU4qvY81KbgVLLBqfHNu6ecPgnlWLRnENx9BpxMLTuWoBy5Kj6lDQzy5cCJRemBoVKJSHGMPTV1R6BOhre0yXfDaz9XYSpFOAwaR/jp5787KT5RYbHqXtPjIPSo9lmUVaIDvxgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":1550,"cache_read_input_tokens":88668,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1550},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeBaMGqxGZRfaCcREx4","type":"assistant","uuid":"065b4478-5d25-464c-8a0b-67e6c715d45b","timestamp":"2026-01-28T23:26:59.915Z"}
{"parentUuid":"065b4478-5d25-464c-8a0b-67e6c715d45b","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019Hp3KgYb9PA5tM9gHYSUio","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PFmy1UQfS63oTfP7deQBNM","name":"Grep","input":{"pattern":"export function generateFixKeyframes","path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","output_mode":"content"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":1550,"cache_read_input_tokens":88668,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1550},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeBaMGqxGZRfaCcREx4","type":"assistant","uuid":"81c15232-7f50-4121-9ab0-73ca9e1bd9a4","timestamp":"2026-01-28T23:27:00.832Z"}
{"parentUuid":"81c15232-7f50-4121-9ab0-73ca9e1bd9a4","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PFmy1UQfS63oTfP7deQBNM","type":"tool_result","content":"548:export function generateFixKeyframes("}]},"uuid":"410eae2d-038a-4c08-9b5a-40db2553ccf5","timestamp":"2026-01-28T23:27:02.727Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"548:export function generateFixKeyframes(","numLines":1},"sourceToolAssistantUUID":"81c15232-7f50-4121-9ab0-73ca9e1bd9a4"}
{"parentUuid":"410eae2d-038a-4c08-9b5a-40db2553ccf5","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_011pZDKdKtNn9f5efvb6bgFs","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me read the generateFixKeyframes function.","signature":"EtYBCkYICxgCKkARAXJk2jUbaSfuTzUhHQZOHUwQOWVOLATvTls8zqvPD1+JzRsbRpU78NMQIBTdN1YFEMFTOsgQQGEqfFYOzoiiEgwrsbMqPpAv54oM8/MaDNfVClFF7SDd++uKRCIww+9QZ8fSiOq10q8u+slTWruoojXAtobJejkCDe6KEzt3APLtb22ODXO+XEpqmPHSKj5+nepbatwWoAwrx+ScBjAV6GxGzm8K7Jr1bDHtWO11Y9hykCu+X0cNX4Zv+U1fMxSjUYmqk4bFyK1eROwKXhgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":170,"cache_read_input_tokens":90218,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":170},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeByw6tC3FAP47z2eBs","type":"assistant","uuid":"5dd88a26-62ef-4629-a0b8-0a83b3b72206","timestamp":"2026-01-28T23:27:04.963Z"}
{"parentUuid":"5dd88a26-62ef-4629-a0b8-0a83b3b72206","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_011pZDKdKtNn9f5efvb6bgFs","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01X1A6cUn2i77aq4CSRwUxLb","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","offset":548,"limit":50}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":170,"cache_read_input_tokens":90218,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":170},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeByw6tC3FAP47z2eBs","type":"assistant","uuid":"d8069bbf-4f8d-43b9-90ca-6638a73eef33","timestamp":"2026-01-28T23:27:05.590Z"}
{"parentUuid":"d8069bbf-4f8d-43b9-90ca-6638a73eef33","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01X1A6cUn2i77aq4CSRwUxLb","type":"tool_result","content":"   548→export function generateFixKeyframes(\n   549→  mistake: MistakeEvent,\n   550→  poseData: (PoseLandmark[] | null)[],\n   551→  fps: number = 10\n   552→): FixKeyframe[] {\n   553→  const startFrame = Math.floor(mistake.startTimeSec * fps);\n   554→  const endFrame = Math.floor(mistake.endTimeSec * fps);\n   555→\n   556→  const keyframes: FixKeyframe[] = [];\n   557→\n   558→  // Setup phase - frame before mistake\n   559→  const setupFrame = Math.max(0, startFrame - Math.floor(fps * 0.3));\n   560→  if (poseData[setupFrame]) {\n   561→    keyframes.push({\n   562→      phase: 'setup',\n   563→      landmarks: poseData[setupFrame]!,\n   564→      label: 'Setup',\n   565→      correction: getSetupCorrection(mistake.type),\n   566→    });\n   567→  }\n   568→\n   569→  // Contact phase - middle of mistake\n   570→  const contactFrame = Math.floor((startFrame + endFrame) / 2);\n   571→  if (poseData[contactFrame]) {\n   572→    keyframes.push({\n   573→      phase: 'contact',\n   574→      landmarks: poseData[contactFrame]!,\n   575→      label: 'Contact',\n   576→      correction: getContactCorrection(mistake.type),\n   577→    });\n   578→  }\n   579→\n   580→  // Recovery phase - frame after mistake\n   581→  const recoveryFrame = Math.min(poseData.length - 1, endFrame + Math.floor(fps * 0.3));\n   582→  if (poseData[recoveryFrame]) {\n   583→    keyframes.push({\n   584→      phase: 'recover',\n   585→      landmarks: poseData[recoveryFrame]!,\n   586→      label: 'Recovery',\n   587→      correction: getRecoveryCorrection(mistake.type),\n   588→    });\n   589→  }\n   590→\n   591→  return keyframes;\n   592→}\n   593→\n   594→function getSetupCorrection(mistakeType: string): string {\n   595→  switch (mistakeType) {\n   596→    case 'OVERHEAD_CONTACT_LOW':\n   597→      return 'Position yourself under the shuttle early';\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"bb892bc8-461e-4aca-b6ea-b6ef33734eaf","timestamp":"2026-01-28T23:27:06.296Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","content":"export function generateFixKeyframes(\n  mistake: MistakeEvent,\n  poseData: (PoseLandmark[] | null)[],\n  fps: number = 10\n): FixKeyframe[] {\n  const startFrame = Math.floor(mistake.startTimeSec * fps);\n  const endFrame = Math.floor(mistake.endTimeSec * fps);\n\n  const keyframes: FixKeyframe[] = [];\n\n  // Setup phase - frame before mistake\n  const setupFrame = Math.max(0, startFrame - Math.floor(fps * 0.3));\n  if (poseData[setupFrame]) {\n    keyframes.push({\n      phase: 'setup',\n      landmarks: poseData[setupFrame]!,\n      label: 'Setup',\n      correction: getSetupCorrection(mistake.type),\n    });\n  }\n\n  // Contact phase - middle of mistake\n  const contactFrame = Math.floor((startFrame + endFrame) / 2);\n  if (poseData[contactFrame]) {\n    keyframes.push({\n      phase: 'contact',\n      landmarks: poseData[contactFrame]!,\n      label: 'Contact',\n      correction: getContactCorrection(mistake.type),\n    });\n  }\n\n  // Recovery phase - frame after mistake\n  const recoveryFrame = Math.min(poseData.length - 1, endFrame + Math.floor(fps * 0.3));\n  if (poseData[recoveryFrame]) {\n    keyframes.push({\n      phase: 'recover',\n      landmarks: poseData[recoveryFrame]!,\n      label: 'Recovery',\n      correction: getRecoveryCorrection(mistake.type),\n    });\n  }\n\n  return keyframes;\n}\n\nfunction getSetupCorrection(mistakeType: string): string {\n  switch (mistakeType) {\n    case 'OVERHEAD_CONTACT_LOW':\n      return 'Position yourself under the shuttle early';","numLines":50,"startLine":548,"totalLines":652}},"sourceToolAssistantUUID":"d8069bbf-4f8d-43b9-90ca-6638a73eef33"}
{"parentUuid":"bb892bc8-461e-4aca-b6ea-b6ef33734eaf","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019KtcbYVJnME5gc6j6cJkrD","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Ah, I see. The `generateFixKeyframes` function requires 2-3 arguments: `mistake`, `poseData`, and optionally `fps`. The FixItCard component has a default fallback when no keyframes are provided, so I can either:\n\n1. Pass the pose data to generate keyframes, or\n2. Just use the default keyframes in FixItCard\n\nSince we have pose data available, let me update the component to pass keyframes with the pose data. But for simplicity, let me just pass the mistake to FixItCard without keyframes (it has default fallback), or I'll need to pass poseData as well.\n\nLet me simplify and just let FixItCard use its default phases.","signature":"EpIGCkYICxgCKkA8uwmCIubC2FckvCv86ntyrsC+R8lUHv3xDy7w4eKJ5rAfkRm1iQFDjQDM4nfCsgsSOa4Hh4lcsX5SJS4yLW8BEgzMJUD9DbWVZuVpYaEaDAyQTup5ssZGQPofiiIwL2KipOxbeM6hpPeCifFT6IvKr+10SKZb/HBiUYOeADgbDDo4b7HiDEDFuvdx13vWKvkECThdyxidbIYZVtWb89XyqzrUqOtJF0lKg7FmFUoPMZMR1JBrunX408HrxvIBUNUkzqe+Y8x49p/99SiR5Ysj8lo54RbuerAQyEC5QiWf7KTaCrdWLd1p411yqYE14UpodHb1FWbVVphcsfORAW9CaG14YG4BwNMKaY4fmx3TlzOwrP2X6evjMBUlQB4glI9YUSyImsF+YT9n8N/HBMTg2mx9C9qV8Efd2zgdr5UnaIZVowg/T3Jco6QLOryl13OjFyzxOzGtSW/cBff8/tQnNcXOGongKSWkNOSQDxrX/oOQ3dCjbp26P/tahMhQTZpORhld8ET/ERxwd2V6eC3xu0O+m03o8CX8HUwbRhPD0GA3QH/fQ4SAsvlHLePc62XpEpsnOL5zaBFFT45ssXvBmM65JVTXX0dNmfEjsgIQ6nLTbCHgWKfYmA6z99mK1+fX0Q/1JtobnbRoG/IiXKHFx84pcYtfPbKj9dIe5hnQ/hjTwkprjW8INNeG+m9AkRkDC0tYxHtNDmK65NwpWOf8XYixb7qxN0GO3b3HgxRybeLXsaGW7iNre4IlZ0poezI89vm1viVXmAPeQ6rzdRKgWnL7cys2OJHeNBBvXsL48wEpGW/AiprnfDxz8t1PKG2cMBmyodenh9Lfymb+dcvymUKSrqbmIHNCXgnMyPNuLZzPfsefb4v//bVjMPVVA2Us09GfN156ddUQWnYdONivNlspkN732o/uSZLUadi7sXlGWzfp5ByCMTzvDR7Bo/W45R8zi5WrY/QpgDPy0nBAzYxk2B1brNADtmiTZ58NW3/ESyGwh77keq0xkh+AoFb1El2f5iyyVphHGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":862,"cache_read_input_tokens":90388,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":862},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeCF3CpzR4eNDuac3jE","type":"assistant","uuid":"bd7e0616-303a-4278-8f48-03f88787ec5c","timestamp":"2026-01-28T23:27:11.493Z"}
{"parentUuid":"bd7e0616-303a-4278-8f48-03f88787ec5c","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019KtcbYVJnME5gc6j6cJkrD","type":"message","role":"assistant","content":[{"type":"text","text":"I see - `generateFixKeyframes` requires 2-3 arguments. Since FixItCard has default fallback phases, let me simplify and just pass the mistake (the component handles it automatically)."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":862,"cache_read_input_tokens":90388,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":862},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeCF3CpzR4eNDuac3jE","type":"assistant","uuid":"c6d6e3d3-c9b9-47de-a50c-f212b25ae026","timestamp":"2026-01-28T23:27:12.495Z"}
{"parentUuid":"c6d6e3d3-c9b9-47de-a50c-f212b25ae026","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019KtcbYVJnME5gc6j6cJkrD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SyajuZ4SaEmFTEAGuXxDze","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      keyframes={generateFixKeyframes(selectedMistake)}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}","new_string":"                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":862,"cache_read_input_tokens":90388,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":862},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeCF3CpzR4eNDuac3jE","type":"assistant","uuid":"3dc08a1e-9fd7-4455-93a2-7fd264169259","timestamp":"2026-01-28T23:27:17.691Z"}
{"parentUuid":"3dc08a1e-9fd7-4455-93a2-7fd264169259","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SyajuZ4SaEmFTEAGuXxDze","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"6a66fcc2-e7e2-433f-bd26-5b42ccf11dc3","timestamp":"2026-01-28T23:27:18.296Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      keyframes={generateFixKeyframes(selectedMistake)}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}","newString":"                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      keyframes={generateFixKeyframes(selectedMistake)}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":1918,"oldLines":7,"newStart":1918,"newLines":7,"lines":["                     </div>","                     <FixItCard","                       mistake={selectedMistake}","-                      keyframes={generateFixKeyframes(selectedMistake)}","+                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}","                       onClose={() => setSelectedMistake(null)}","                     />","                   </div>"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"3dc08a1e-9fd7-4455-93a2-7fd264169259"}
{"parentUuid":"6a66fcc2-e7e2-433f-bd26-5b42ccf11dc3","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_017hGFZZLnVjESMvbqhQMuJ5","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"There's an error: `GhostRivalData` is not exported from `@/lib/ghost-overlay`. Let me check that file and export the type.","signature":"EqMCCkYICxgCKkD7/QV3kS0ZbTa6nAsnHV9/lHuYTJKB5Nk2qVfevNIXb7T42D2EKLdZP/JUz9OorBEUCjz4mVjvQeDEeJkJ5UzUEgxQb0+xNkmvTLIwi+8aDJGHjeM33pmroSV/mSIwjwVAAbRctCkATUw0elKdIH//oXzjeGuROoiuLiX8nenFNUKl4HFUeW/wx0aT0yufKooBOp8QD0cISqxvhzK45rTAi26R5GC5wTUkZwlzoKtSrIDuvyO2tL0LgciT4dJAv4WjV9pKSevVsU6M7LvOWwHSX3YY0vs9f27Jd6F3TO1GFNh+/jhwYrORroyvpuojE83TcmhFIgDwtUsH7o6wLoCwJl7q4vQM8o7KnwrhoSe4LxGoTuKqzJiceReAGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":2926,"cache_read_input_tokens":91250,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2926},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeDCgqg3Zma6oSZsjBU","type":"assistant","uuid":"72b79fdc-f8f5-41e7-a3df-e633f6df1534","timestamp":"2026-01-28T23:27:22.140Z"}
{"parentUuid":"72b79fdc-f8f5-41e7-a3df-e633f6df1534","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_017hGFZZLnVjESMvbqhQMuJ5","type":"message","role":"assistant","content":[{"type":"text","text":"There's an export issue with `GhostRivalData`. Let me check the ghost-overlay module."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":2926,"cache_read_input_tokens":91250,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2926},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeDCgqg3Zma6oSZsjBU","type":"assistant","uuid":"a8eba049-ab30-47b3-8413-2ce0498af54c","timestamp":"2026-01-28T23:27:22.601Z"}
{"parentUuid":"a8eba049-ab30-47b3-8413-2ce0498af54c","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_017hGFZZLnVjESMvbqhQMuJ5","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DtVrjJhDM5Vk8qUKr9tah1","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\ghost-overlay.ts","limit":60}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":2926,"cache_read_input_tokens":91250,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2926},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeDCgqg3Zma6oSZsjBU","type":"assistant","uuid":"d58dbd42-0fd4-40fc-b7a0-abe57f57cccf","timestamp":"2026-01-28T23:27:23.182Z"}
{"parentUuid":"d58dbd42-0fd4-40fc-b7a0-abe57f57cccf","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DtVrjJhDM5Vk8qUKr9tah1","type":"tool_result","content":"     1→/**\n     2→ * Ghost Rival Overlay Module\n     3→ *\n     4→ * Provides \"My Best Rep\" ghost skeleton overlay functionality:\n     5→ * 1. Finds the highest-quality segment from the same video\n     6→ * 2. Extracts pose frames for ghost rendering\n     7→ * 3. Syncs ghost playback with user video time\n     8→ */\n     9→\n    10→import type {\n    11→  PoseLandmark,\n    12→  PoseMetrics,\n    13→  GhostRivalData,\n    14→  GhostPoseFrame,\n    15→  MistakeEvent\n    16→} from './types';\n    17→import { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n    18→\n    19→// Minimum window size for a valid \"rep\"\n    20→const MIN_REP_DURATION_SEC = 0.8;\n    21→const MAX_REP_DURATION_SEC = 3.0;\n    22→const GHOST_FPS = 15; // Downsample to 15fps for rendering\n    23→\n    24→/**\n    25→ * Shot event detected in video\n    26→ */\n    27→interface ShotEvent {\n    28→  frameIndex: number;\n    29→  timestamp: number;\n    30→  shotType: 'overhead' | 'drive' | 'netshot' | 'footwork' | 'unknown';\n    31→  confidence: number;\n    32→}\n    33→\n    34→/**\n    35→ * Calculate form quality score for a segment of pose frames\n    36→ * Higher score = better form\n    37→ */\n    38→export function calculateSegmentFormScore(\n    39→  poseFrames: (PoseLandmark[] | null)[],\n    40→  metricsHistory: (PoseMetrics | null)[]\n    41→): number {\n    42→  let totalScore = 0;\n    43→  let validFrames = 0;\n    44→\n    45→  for (let i = 0; i < poseFrames.length; i++) {\n    46→    const landmarks = poseFrames[i];\n    47→    const metrics = metricsHistory[i];\n    48→\n    49→    if (!landmarks || !metrics) continue;\n    50→\n    51→    // Calculate average visibility\n    52→    const avgVisibility = landmarks.reduce((sum, lm) => sum + (lm.visibility ?? 0), 0) / landmarks.length;\n    53→    if (avgVisibility < 0.5) continue;\n    54→\n    55→    let frameScore = avgVisibility * 20; // Base score from visibility\n    56→\n    57→    // Elbow angle scoring (ideal: 90-130 for most shots)\n    58→    const elbowScore = scoreInRange(metrics.elbow_angle, 80, 140, 60, 160);\n    59→    frameScore += elbowScore * 25;\n    60→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"1276e0c4-c44b-435d-8b65-0cb30a16cf60","timestamp":"2026-01-28T23:27:23.849Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\ghost-overlay.ts","content":"/**\n * Ghost Rival Overlay Module\n *\n * Provides \"My Best Rep\" ghost skeleton overlay functionality:\n * 1. Finds the highest-quality segment from the same video\n * 2. Extracts pose frames for ghost rendering\n * 3. Syncs ghost playback with user video time\n */\n\nimport type {\n  PoseLandmark,\n  PoseMetrics,\n  GhostRivalData,\n  GhostPoseFrame,\n  MistakeEvent\n} from './types';\nimport { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n\n// Minimum window size for a valid \"rep\"\nconst MIN_REP_DURATION_SEC = 0.8;\nconst MAX_REP_DURATION_SEC = 3.0;\nconst GHOST_FPS = 15; // Downsample to 15fps for rendering\n\n/**\n * Shot event detected in video\n */\ninterface ShotEvent {\n  frameIndex: number;\n  timestamp: number;\n  shotType: 'overhead' | 'drive' | 'netshot' | 'footwork' | 'unknown';\n  confidence: number;\n}\n\n/**\n * Calculate form quality score for a segment of pose frames\n * Higher score = better form\n */\nexport function calculateSegmentFormScore(\n  poseFrames: (PoseLandmark[] | null)[],\n  metricsHistory: (PoseMetrics | null)[]\n): number {\n  let totalScore = 0;\n  let validFrames = 0;\n\n  for (let i = 0; i < poseFrames.length; i++) {\n    const landmarks = poseFrames[i];\n    const metrics = metricsHistory[i];\n\n    if (!landmarks || !metrics) continue;\n\n    // Calculate average visibility\n    const avgVisibility = landmarks.reduce((sum, lm) => sum + (lm.visibility ?? 0), 0) / landmarks.length;\n    if (avgVisibility < 0.5) continue;\n\n    let frameScore = avgVisibility * 20; // Base score from visibility\n\n    // Elbow angle scoring (ideal: 90-130 for most shots)\n    const elbowScore = scoreInRange(metrics.elbow_angle, 80, 140, 60, 160);\n    frameScore += elbowScore * 25;\n","numLines":60,"startLine":1,"totalLines":372}},"sourceToolAssistantUUID":"d58dbd42-0fd4-40fc-b7a0-abe57f57cccf"}
{"parentUuid":"1276e0c4-c44b-435d-8b65-0cb30a16cf60","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012Lb2qrqJPUut9vwUtuHgfC","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"I see - `GhostRivalData` is imported from `./types` but used internally. The issue is that we're also trying to import `GhostRivalData` from `ghost-overlay.ts` in the analytics page. The type should be exported from types.ts and we should import it from there.\n\nLet me check if GhostRivalData is exported from types.ts.","signature":"EuYDCkYICxgCKkBqS1W89Wq7gsUIujw9hFW2/roC4qdF7caMWTl9HTD+ZuuTgk7Un6w1VM6NEqaMpTRu8REQ0wiH/NnmRm1c0FWGEgx1bmSL4erp/inOKMkaDLhuXZ2qnNJRDF1jMCIwKXLvfWrtfOD28hFmt7jNCQ3XVfI7iaVQavKduGf8u046VPOugGLBk5TEoLb2fCvaKs0CXBX5WaHDJ+yIZYs/Y4U7o1MquLCKMU0qu5xzik7TTBcOYTlfOlNXVPcaTH0n56RsUyxbL8N0n0gqQevYo5drah8vtKgJq9li/i6rW/TlajpRBnwhXlc5iiAjYzzumY92ir26H2DTf0IJ/M+B4L4NuFmg3GYJ8BbU0O/AXvj0g/7qaK95G8gtMILrHkICjxUosNPZZfeqPF351glDCuyiJvlFn/+SJOzGL+DhJ7X6qDCVjKd/zp1OEQLNiwmpKmlSGO13akMPbld/B66rJ1pvHwZrtFCycbp9aYQtC1oT4WJWTbC44jzXdYBz/CMfwD2GviFiVyYDYhYS5wnW8yCb2aWOgWN8HY4hrEOeTpAo+5+AYZcbHlO1NQUOWK2VI4hiXOIOWlE1x0UbpTGlZnP+CIZZTVzUXM8cwgZHv8rHLDnkTgawCRDtglvJp7BZGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":1036,"cache_read_input_tokens":94176,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1036},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeDY4R6Fbyg7q84wdKV","type":"assistant","uuid":"4f20cc00-ae25-479a-bf14-6bc3f1885426","timestamp":"2026-01-28T23:27:27.591Z"}
{"parentUuid":"4f20cc00-ae25-479a-bf14-6bc3f1885426","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012Lb2qrqJPUut9vwUtuHgfC","type":"message","role":"assistant","content":[{"type":"text","text":"The type is imported from `./types`. Let me check if it's exported correctly from types.ts and update the import in analytics page."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":1036,"cache_read_input_tokens":94176,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1036},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeDY4R6Fbyg7q84wdKV","type":"assistant","uuid":"9bd64de0-e9e6-4d44-8a49-3975b24c6bbf","timestamp":"2026-01-28T23:27:28.324Z"}
{"parentUuid":"9bd64de0-e9e6-4d44-8a49-3975b24c6bbf","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012Lb2qrqJPUut9vwUtuHgfC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0112EkXUabnAwRyXSz5n6fVT","name":"Grep","input":{"pattern":"export.*GhostRivalData","path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\types.ts","output_mode":"content"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":1036,"cache_read_input_tokens":94176,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1036},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeDY4R6Fbyg7q84wdKV","type":"assistant","uuid":"87da9264-048b-4821-8c30-b1fd66b78002","timestamp":"2026-01-28T23:27:29.261Z"}
{"parentUuid":"87da9264-048b-4821-8c30-b1fd66b78002","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0112EkXUabnAwRyXSz5n6fVT","type":"tool_result","content":"333:export interface GhostRivalData {"}]},"uuid":"0e0a8e39-15c8-4189-9696-299d0174e182","timestamp":"2026-01-28T23:27:31.001Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"333:export interface GhostRivalData {","numLines":1},"sourceToolAssistantUUID":"87da9264-048b-4821-8c30-b1fd66b78002"}
{"parentUuid":"0e0a8e39-15c8-4189-9696-299d0174e182","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Hz4D1fyWju5vYEauosBjix","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Good, `GhostRivalData` is exported from types.ts. The issue is that analytics/page.tsx is importing it from `@/lib/ghost-overlay` instead of `@/lib/types`. Let me fix the import.","signature":"EtsCCkYICxgCKkCxs9BLL3j+bdnpalUpk5LbDfHAteRyYhJpNlt+5HyNFQggRxwbDQJyjDhW2/Zhhc6HeKYPobD+AhK8ikSJhDcdEgxBEO4195ESnvs7nfIaDHxd0OlMvuv8v5xRKiIwNlWTPijL+vjKwe0zexMAnor88AscoZGWzVWIsoQo+ialpzCWh71u7NmyQa77Hz7uKsIB0yTnH9vMi7/TLNok9K8jc229NiAy0OCjvytxG4CnepO0wA5IHm4IZZ5+S4cgzNk8hB/ST3tvga1fCC6B/cmlNURcbPhr8ztE7XshpFxLFyC8T0QL9ljjdkvC1bVAwKXBgtl4+GmyeIVCkiNiCaalhkUDgE/IIlqIQh6wyn1IGLGoWzBijyn5CrVjnBTTe0ke0xOCkklihP71ivJX2SfIpn8TUqp2PmTiUUXlq89ah/noellPzMCESKgQSPJ0Idu9XnUYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":279,"cache_read_input_tokens":95212,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":279},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeE4itr2N5BfuKWLFUr","type":"assistant","uuid":"bb89dc78-c4ab-4088-be95-4e80a6622453","timestamp":"2026-01-28T23:27:34.254Z"}
{"parentUuid":"bb89dc78-c4ab-4088-be95-4e80a6622453","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Hz4D1fyWju5vYEauosBjix","type":"message","role":"assistant","content":[{"type":"text","text":"The type is in types.ts. Let me fix the import in analytics/page.tsx to import `GhostRivalData` from types instead of ghost-overlay."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":279,"cache_read_input_tokens":95212,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":279},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeE4itr2N5BfuKWLFUr","type":"assistant","uuid":"fc72aa76-7ea0-40a7-aa31-7f93418f8ba1","timestamp":"2026-01-28T23:27:34.888Z"}
{"parentUuid":"fc72aa76-7ea0-40a7-aa31-7f93418f8ba1","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Hz4D1fyWju5vYEauosBjix","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EUa9SgybTUWKyPisiyRTs3","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"import { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';","new_string":"import { initializeGhostRival, getGhostPoseAtTime } from '@/lib/ghost-overlay';"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":279,"cache_read_input_tokens":95212,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":279},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeE4itr2N5BfuKWLFUr","type":"assistant","uuid":"112dc558-1cb4-4f68-8a92-d1185153a33f","timestamp":"2026-01-28T23:27:36.643Z"}
{"parentUuid":"112dc558-1cb4-4f68-8a92-d1185153a33f","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EUa9SgybTUWKyPisiyRTs3","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"3dd1c775-251b-437e-886d-8335595a434c","timestamp":"2026-01-28T23:27:37.280Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"import { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';","newString":"import { initializeGhostRival, getGhostPoseAtTime } from '@/lib/ghost-overlay';","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":29,"oldLines":7,"newStart":29,"newLines":7,"lines":["   validateSessionPoseData,"," } from '@/lib/scoring-rules';"," import { computeSkillScore } from '@/lib/skill-scoring';","-import { initializeGhostRival, getGhostPoseAtTime, type GhostRivalData } from '@/lib/ghost-overlay';","+import { initializeGhostRival, getGhostPoseAtTime } from '@/lib/ghost-overlay';"," import { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';"," import MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';"," import FixItCard from '@/components/FixItCard';"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"112dc558-1cb4-4f68-8a92-d1185153a33f"}
{"parentUuid":"3dd1c775-251b-437e-886d-8335595a434c","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01UAG6Brja9gdHK4VwxcXitY","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to add GhostRivalData to the types import.","signature":"Et0BCkYICxgCKkCQ7ivR9rVrB0XTZsQMBV8itskdze2sumGBb/Okc2Z6I/KLTxtptHNZQu6az1Vf/GgbkcD/BUqK02N/Fx6cFsE5Egz21phFXHy8i/HJIuIaDIMzMFAJIpfPyg4dZCIwn+9y5E5+PHclXKnvIi8J2xgHfHnzsNDNf0/0pRqd2ZvRAPkQVWN1Ul5WGYHuWYecKkVPAIPMm6CjHaTqC5lPvV/8XE0dOWu8+6LffsOFWXmq8Nd+mqGePvTx1iyZuqxlpcEToEcn25yrfmR951SgqZdWsXU+/tAYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":497,"cache_read_input_tokens":95491,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":497},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeEc9krhXhtqV3vBqpX","type":"assistant","uuid":"193fd98a-d6ca-4e26-bd6d-4a8604da6e24","timestamp":"2026-01-28T23:27:40.761Z"}
{"parentUuid":"193fd98a-d6ca-4e26-bd6d-4a8604da6e24","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01UAG6Brja9gdHK4VwxcXitY","type":"message","role":"assistant","content":[{"type":"text","text":"Let me add `GhostRivalData` to the types import."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":497,"cache_read_input_tokens":95491,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":497},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeEc9krhXhtqV3vBqpX","type":"assistant","uuid":"43806bcc-45ea-45c2-bf7f-b179f8c04124","timestamp":"2026-01-28T23:27:41.025Z"}
{"parentUuid":"43806bcc-45ea-45c2-bf7f-b179f8c04124","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01UAG6Brja9gdHK4VwxcXitY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019rYnsvXSAhg9TpRzNde2wk","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';","new_string":"import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame, GhostRivalData } from '@/lib/types';"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":497,"cache_read_input_tokens":95491,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":497},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeEc9krhXhtqV3vBqpX","type":"assistant","uuid":"960a7e0b-1584-4a36-89e6-5bf8d86564d5","timestamp":"2026-01-28T23:27:43.563Z"}
{"parentUuid":"960a7e0b-1584-4a36-89e6-5bf8d86564d5","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019rYnsvXSAhg9TpRzNde2wk","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"5afa3a27-b63b-4f2c-b816-ede210333a3d","timestamp":"2026-01-28T23:27:44.294Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';","newString":"import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame, GhostRivalData } from '@/lib/types';","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":34,"oldLines":7,"newStart":34,"newLines":7,"lines":[" import MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';"," import FixItCard from '@/components/FixItCard';"," import SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';","-import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame } from '@/lib/types';","+import type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame, GhostRivalData } from '@/lib/types';"," "," // MediaPipe Types"," type PoseLandmarker = any;"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"960a7e0b-1584-4a36-89e6-5bf8d86564d5"}
{"parentUuid":"5afa3a27-b63b-4f2c-b816-ede210333a3d","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019KQxtnrgZXHVnJoQJbtAQQ","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the todos and continue to update the reset handlers.","signature":"Eu4BCkYICxgCKkBjmWGEVYSf42b1KN13Fy621oOl6fJhzP8fDLamjtESMd34pOpP9pkFusCVPx/3WZPwXWTyDv2WEkY0jWsWO/tpEgxE/4gMESVUyM2ppkcaDHZrRHAA97DX28PunSIweAni0dsG/fIcOVCFbRa5XTLJ2MHmZH39HsFggOMDxQDxvNqF4uldb3xM0MBrSQ0iKlbdjKqFq6KXty04qAUWfdlXUBZ171qGevIwB7PvPqXWRA1J6HyaXKW0nbzPWgRqP7yLcaWBWGstR7irx1Q2rA4mlUgxIZjb2HsJoJANV+frEaPpZ8H4BxgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":364,"cache_read_input_tokens":95988,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":364},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeF7rwGDnczyNUkCS8W","type":"assistant","uuid":"ecd01263-1cb1-483e-9f23-2395c5a00c3b","timestamp":"2026-01-28T23:27:48.304Z"}
{"parentUuid":"ecd01263-1cb1-483e-9f23-2395c5a00c3b","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019KQxtnrgZXHVnJoQJbtAQQ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SiTnRPAcAqNk84vT8QwPAb","name":"TodoWrite","input":{"todos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"completed","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"in_progress","activeForm":"Updating reset handlers"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":364,"cache_read_input_tokens":95988,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":364},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeF7rwGDnczyNUkCS8W","type":"assistant","uuid":"0f8ee27f-da3b-48b6-a64b-b6c44a23468d","timestamp":"2026-01-28T23:27:51.381Z"}
{"parentUuid":"0f8ee27f-da3b-48b6-a64b-b6c44a23468d","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SiTnRPAcAqNk84vT8QwPAb","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"9e44bf55-de74-435d-9a25-bf9889b2fc71","timestamp":"2026-01-28T23:27:51.420Z","toolUseResult":{"oldTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"in_progress","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"pending","activeForm":"Updating reset handlers"}],"newTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"completed","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"in_progress","activeForm":"Updating reset handlers"}]},"sourceToolAssistantUUID":"0f8ee27f-da3b-48b6-a64b-b6c44a23468d"}
{"parentUuid":"9e44bf55-de74-435d-9a25-bf9889b2fc71","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019VM7VCuGZwA1eZv2vdEySM","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me find and update the reset handlers in the analytics page to clear V4 state.","signature":"Ev4BCkYICxgCKkBo8hy/gnwHrHaYfXdfL/N0q78GkIINQPeXEalcGPQg15eK/yy0pPHtVzoh4tLOfJ+P7Zbakc2Vc1JLrFYe3g1KEgwVulJJsgTjlDEYKggaDCikz4eUb8SiByBgqyIwW0bx/+3/xNQMQ6yUddhR5yxHZ6E13vr3USDwj3dZ6hJFcVHVbNaSh4YBUZEdj1+sKmbrhOV4qXhOrYIxm+sh9ZnIqWhD3351AaNVvzppfvyvOWitmmq/88vRB5k4LGsWAvi6XJxOZq9U+09RLKFmpnxY7Af0JdDVUaFQjmIehncfJv8UzJqvmMwWq01iSevrNT/GoJpVTxYYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":333,"cache_read_input_tokens":96352,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":333},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeFZzZTQUVdX7nfRcDJ","type":"assistant","uuid":"155942b0-3e85-4378-a964-c83b306cd23a","timestamp":"2026-01-28T23:27:53.805Z"}
{"parentUuid":"155942b0-3e85-4378-a964-c83b306cd23a","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019VM7VCuGZwA1eZv2vdEySM","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me update the reset handlers to clear V4 state. Let me find the reset button handlers."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":333,"cache_read_input_tokens":96352,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":333},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeFZzZTQUVdX7nfRcDJ","type":"assistant","uuid":"1d99219b-8785-40ba-9584-3f545840fd28","timestamp":"2026-01-28T23:27:54.339Z"}
{"parentUuid":"1d99219b-8785-40ba-9584-3f545840fd28","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_019VM7VCuGZwA1eZv2vdEySM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GFrK9GPLsrZ3eB5HQuMS2z","name":"Grep","input":{"pattern":"setAnalysisState\\('IDLE'\\)","path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","output_mode":"content","-n":true}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":333,"cache_read_input_tokens":96352,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":333},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeFZzZTQUVdX7nfRcDJ","type":"assistant","uuid":"96be671d-6a4f-47a9-8982-c2f87b57b9a3","timestamp":"2026-01-28T23:27:55.478Z"}
{"parentUuid":"96be671d-6a4f-47a9-8982-c2f87b57b9a3","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GFrK9GPLsrZ3eB5HQuMS2z","type":"tool_result","content":"2031:                      setAnalysisState('IDLE');\n2132:                    setAnalysisState('IDLE');\n2152:          setAnalysisState('IDLE');"}]},"uuid":"d4f07e66-e994-43dc-adb9-247ba47b7e09","timestamp":"2026-01-28T23:27:57.186Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"2031:                      setAnalysisState('IDLE');\n2132:                    setAnalysisState('IDLE');\n2152:          setAnalysisState('IDLE');","numLines":3},"sourceToolAssistantUUID":"96be671d-6a4f-47a9-8982-c2f87b57b9a3"}
{"parentUuid":"d4f07e66-e994-43dc-adb9-247ba47b7e09","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BFLrjafoQK9NgYUJ8CeesX","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me read the context around these lines to find the reset handlers.","signature":"Eu4BCkYICxgCKkBLFS24mYmtKyvsVwUXIjCVVmqx7roVtXf+7TOpIlaRp6J0vFgDxbkKAR0vMfDO7SoQzaxpHA2Csenv2wXx6WRCEgxhmSL09jS2s/JSF/IaDAPpGK5KN3PtB84QryIwPEaeOhVvQNg4dkmNVIXuM7BhYzyuJFhdjjH+H0fh1wmcoZ90ImfasfH7L1LML5o4KlaD5w0TkzOt09PtjtCvXIw1fNnUlMQujXZaaHJn7iwgPq6H4LZkPlskMwGQNYHzqGsOoOvnn0ygPGuCqGPbPkQ0FbHmsvSBPqh6M/0j6s4M9qxyR6U9QhgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":259,"cache_read_input_tokens":96685,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":259},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeG15BLQFE5UpdBj4Wf","type":"assistant","uuid":"7ffae89e-707e-41b7-9da9-800ad4765926","timestamp":"2026-01-28T23:27:59.840Z"}
{"parentUuid":"7ffae89e-707e-41b7-9da9-800ad4765926","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BFLrjafoQK9NgYUJ8CeesX","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017ur7PBRJUMJTK289AKMVLZ","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","offset":2015,"limit":30}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":259,"cache_read_input_tokens":96685,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":259},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeG15BLQFE5UpdBj4Wf","type":"assistant","uuid":"e7ecd31e-e536-41ff-99c1-1c7416c73a54","timestamp":"2026-01-28T23:28:00.573Z"}
{"parentUuid":"e7ecd31e-e536-41ff-99c1-1c7416c73a54","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017ur7PBRJUMJTK289AKMVLZ","type":"tool_result","content":"  2015→                )}\n  2016→\n  2017→                {/* Reset button */}\n  2018→                {videoUrl && !analyzing && (\n  2019→                  <button\n  2020→                    onClick={() => {\n  2021→                      setResult(null);\n  2022→                      setVideoUrl(null);\n  2023→                      setVideoFile(null);\n  2024→                      setIssues([]);\n  2025→                      setPoseData([]);\n  2026→                      setFrameAnalyses([]);\n  2027→                      setCurrentTime(0);\n  2028→                      setDuration(0);\n  2029→                      setAutoLevelResult(null);\n  2030→                      setGuidanceKeyframes([]);\n  2031→                      setAnalysisState('IDLE');\n  2032→                    }}\n  2033→                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n  2034→                  >\n  2035→                    Analyze Another Video\n  2036→                  </button>\n  2037→                )}\n  2038→              </div>\n  2039→            </div>\n  2040→          )}\n  2041→\n  2042→          {/* Results Section (legacy format without video) */}\n  2043→          {result && !videoUrl && (\n  2044→            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d5f7feca-2f70-4e15-bbe4-3ac9b590658b","timestamp":"2026-01-28T23:28:01.200Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","content":"                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">","numLines":30,"startLine":2015,"totalLines":2186}},"sourceToolAssistantUUID":"e7ecd31e-e536-41ff-99c1-1c7416c73a54"}
{"parentUuid":"d5f7feca-2f70-4e15-bbe4-3ac9b590658b","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0154UMVdLbjuPM3g8SAZK471","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to update this reset handler to also clear the V4 state:- ghostData- showGhost- computedSkill- mistakeEvents- selectedMistake\n\nLet me update this reset handler.","signature":"EtICCkYICxgCKkB55c2RWmQEP4rJ3gnhh5/PIw9QwC2XtRRAishmGful34B5CzxUy+RjXha4Vt2J9uMLgaMaCncLjsdqcyKS/b2/EgwJoalryGuOJh37k14aDKcFg4O+9lEk9syyIyIw1gB+wXY5GOumf64HmLKqLsuf84b55XACCi+mK746H49KmEmClFoX8A2f7VS/H8qAKrkB+Zl2I1sAi1/ctdhaiAGFsHMQ7TdBaskEuDxP70wXZ0WusC7t7OJQvyHEJb83BMgdt4rNGH8O0kMW8TMUOcZUT4cYsvfaUmlFgHjfk42w0z+aRtsZIrLcHytOLJBTU3rmqmH6qZ8/jOsL10/b5tLOaUl2YgZPeK65e808aBcjgvgsKMw5NwoSNFlR8mMTcakQGtBeuSfZEJsFWdIHuniT8blx56hzCefWIjNkktdus184vEYzGjVMDSQYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":627,"cache_read_input_tokens":96944,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":627},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXaeGHa7LKvy44j1r6amv","type":"assistant","uuid":"862bc491-30f6-4e2b-8b4d-406ab6a305ab","timestamp":"2026-01-28T23:28:04.134Z"}
{"parentUuid":"862bc491-30f6-4e2b-8b4d-406ab6a305ab","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0154UMVdLbjuPM3g8SAZK471","type":"message","role":"assistant","content":[{"type":"text","text":"Let me update the first reset handler."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":627,"cache_read_input_tokens":96944,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":627},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXaeGHa7LKvy44j1r6amv","type":"assistant","uuid":"15df6b77-5591-411b-a6c4-db91da3978ff","timestamp":"2026-01-28T23:28:04.486Z"}
{"parentUuid":"15df6b77-5591-411b-a6c4-db91da3978ff","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0154UMVdLbjuPM3g8SAZK471","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CpNHdQhL4CBjmueoS9J6VX","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}","new_string":"                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                      // V4 state reset\n                      setGhostData(null);\n                      setShowGhost(false);\n                      setComputedSkill(null);\n                      setMistakeEvents([]);\n                      setSelectedMistake(null);\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":627,"cache_read_input_tokens":96944,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":627},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXaeGHa7LKvy44j1r6amv","type":"assistant","uuid":"bdd1000f-7716-4c95-852f-bdce4dfa493b","timestamp":"2026-01-28T23:28:08.535Z"}
{"parentUuid":"bdd1000f-7716-4c95-852f-bdce4dfa493b","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CpNHdQhL4CBjmueoS9J6VX","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"b957662b-6c85-409e-8f44-44b9387a5ee5","timestamp":"2026-01-28T23:28:09.144Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}","newString":"                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                      // V4 state reset\n                      setGhostData(null);\n                      setShowGhost(false);\n                      setComputedSkill(null);\n                      setMistakeEvents([]);\n                      setSelectedMistake(null);\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame, GhostRivalData } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":2029,"oldLines":6,"newStart":2029,"newLines":12,"lines":["                       setAutoLevelResult(null);","                       setGuidanceKeyframes([]);","                       setAnalysisState('IDLE');","+                      // V4 state reset","+                      setGhostData(null);","+                      setShowGhost(false);","+                      setComputedSkill(null);","+                      setMistakeEvents([]);","+                      setSelectedMistake(null);","                     }}","                     className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"","                   >"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"bdd1000f-7716-4c95-852f-bdce4dfa493b"}
{"parentUuid":"b957662b-6c85-409e-8f44-44b9387a5ee5","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013b6f7T32KsiHN9JmYMBiA7","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me find and update the second reset handler around line 2132 (original).","signature":"EvgBCkYICxgCKkD1qiOPY8L5QY/mDHXOrqXhqfNQTB0tMA53U/Bm9jxbopo+MDXC0mRwWlUmzeKeytSkIym4FeBFd8E3KwQR5oF1EgxAlu1zOGyT1U+YO9gaDLSgqF32OlHs/cdbRiIwaU46jcKwm+z3VyMjoI9UDRDqXyAcUZPTWIRkRJ9jCjKFGYPx/5WSEO2tTedptPM6KmC2JVmQ0vSh6G9HwB2OWWEU13JhteQpq0rhxADOERxQd+lVyA+JkOzFvn3reebifar7jXnm863+pJC9Ja8zPyxMrGsR9AE8ZFa10bsvKTnqAraUl3wPi/gS7qzeVzeNvn8YAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":722,"cache_read_input_tokens":97571,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":722},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeGx6NGYqCGD7Bsov7Q","type":"assistant","uuid":"5f72e212-bd2f-4bc0-834d-448e0adbc7bc","timestamp":"2026-01-28T23:28:12.758Z"}
{"parentUuid":"5f72e212-bd2f-4bc0-834d-448e0adbc7bc","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013b6f7T32KsiHN9JmYMBiA7","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me update the second reset handler."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":722,"cache_read_input_tokens":97571,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":722},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeGx6NGYqCGD7Bsov7Q","type":"assistant","uuid":"750ebe53-341d-40af-bfac-b2ef0ce1784e","timestamp":"2026-01-28T23:28:13.041Z"}
{"parentUuid":"750ebe53-341d-40af-bfac-b2ef0ce1784e","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_013b6f7T32KsiHN9JmYMBiA7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WBL3mmVpZtmtRyca4tvET5","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","offset":2125,"limit":40}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":722,"cache_read_input_tokens":97571,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":722},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeGx6NGYqCGD7Bsov7Q","type":"assistant","uuid":"9cfe3166-8d7b-41b0-9fff-4531ed1390a8","timestamp":"2026-01-28T23:28:13.724Z"}
{"parentUuid":"9cfe3166-8d7b-41b0-9fff-4531ed1390a8","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WBL3mmVpZtmtRyca4tvET5","type":"tool_result","content":"  2125→                  </div>\n  2126→                )}\n  2127→\n  2128→                <button\n  2129→                  onClick={() => {\n  2130→                    setResult(null);\n  2131→                    setSelectedIssue(null);\n  2132→                    setSelectedDrill(null);\n  2133→                    setVideoUrl(null);\n  2134→                    setPoseData([]);\n  2135→                    setIssues([]);\n  2136→                    setAutoLevelResult(null);\n  2137→                    setGuidanceKeyframes([]);\n  2138→                    setAnalysisState('IDLE');\n  2139→                  }}\n  2140→                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n  2141→                >\n  2142→                  Analyze Another Video\n  2143→                </button>\n  2144→              </div>\n  2145→            </div>\n  2146→          )}\n  2147→        </div>\n  2148→      </main>\n  2149→\n  2150→      {/* Player Selection Modal */}\n  2151→      <PlayerSelectionModal\n  2152→        isOpen={showPlayerSelection}\n  2153→        onClose={() => {\n  2154→          setShowPlayerSelection(false);\n  2155→          setAnalyzing(false);\n  2156→          setVideoUrl(null);\n  2157→          setVideoFile(null);\n  2158→          setAnalysisState('IDLE');\n  2159→        }}\n  2160→        onConfirm={handlePlayerSelectionConfirm}\n  2161→        tracks={detectedTracks}\n  2162→        detectedFormat={detectedMatchFormat}\n  2163→      />\n  2164→    </div>\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"ac9d7c47-c7e9-4d3f-8070-b564dc2e5109","timestamp":"2026-01-28T23:28:14.339Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","content":"                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>","numLines":40,"startLine":2125,"totalLines":2192}},"sourceToolAssistantUUID":"9cfe3166-8d7b-41b0-9fff-4531ed1390a8"}
{"parentUuid":"ac9d7c47-c7e9-4d3f-8070-b564dc2e5109","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01ChwDBPC9PwLuWGYxBYyNky","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the second reset handler (legacy format) and the player selection modal onClose handler.","signature":"EpICCkYICxgCKkCIzZ9/anMYaqho3oBYtcnHW3MVpjccmL3tiiJSdKSzKViwRUVtT9iDpGff8VzvSi+MG4XAr56wb0fZURsY4pqdEgz7WNj4cyy7HYoH9IQaDG3iTHVKSeO6Ml6mvCIwFPwo32ke++eHyUsLcenyj5Ze16L04Y0OEPaiBnmOciI5UL4oWA0cUjvg+J8LRCGlKnosPjW6x7uPT0EyhKIbMYOCCuny0OJCYgTpmIUIio/li58Igfb/GVc8huAUjGGGwPhoXgWLdOndMBF0YGlKlXEb8MWH4O++sLy0hnNmE5hp0xlEX/WAaO2NOcPZgNRDfzjV43ZisbaGxtjiYKQzipJSYEWbSUiZ8EgPDBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":731,"cache_read_input_tokens":98293,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":731},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeHFjGG7RvZnk5F1cFA","type":"assistant","uuid":"7b1917e9-c068-4303-8a8e-5c9222522332","timestamp":"2026-01-28T23:28:17.378Z"}
{"parentUuid":"7b1917e9-c068-4303-8a8e-5c9222522332","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01ChwDBPC9PwLuWGYxBYyNky","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XJqM5DxfAP76ZSSqayGtF2","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>","new_string":"                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                    // V4 state reset\n                    setGhostData(null);\n                    setShowGhost(false);\n                    setComputedSkill(null);\n                    setMistakeEvents([]);\n                    setSelectedMistake(null);\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":731,"cache_read_input_tokens":98293,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":731},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeHFjGG7RvZnk5F1cFA","type":"assistant","uuid":"6dd8f842-c7ac-4e66-8d5b-4694da180e47","timestamp":"2026-01-28T23:28:20.735Z"}
{"parentUuid":"6dd8f842-c7ac-4e66-8d5b-4694da180e47","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XJqM5DxfAP76ZSSqayGtF2","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"6fa49acb-bfde-4f2a-97e8-9c02c6618d58","timestamp":"2026-01-28T23:28:21.283Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>","newString":"                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                    // V4 state reset\n                    setGhostData(null);\n                    setShowGhost(false);\n                    setComputedSkill(null);\n                    setMistakeEvents([]);\n                    setSelectedMistake(null);\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame, GhostRivalData } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                      // V4 state reset\n                      setGhostData(null);\n                      setShowGhost(false);\n                      setComputedSkill(null);\n                      setMistakeEvents([]);\n                      setSelectedMistake(null);\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":2136,"oldLines":6,"newStart":2136,"newLines":12,"lines":["                     setAutoLevelResult(null);","                     setGuidanceKeyframes([]);","                     setAnalysisState('IDLE');","+                    // V4 state reset","+                    setGhostData(null);","+                    setShowGhost(false);","+                    setComputedSkill(null);","+                    setMistakeEvents([]);","+                    setSelectedMistake(null);","                   }}","                   className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"","                 >"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"6dd8f842-c7ac-4e66-8d5b-4694da180e47"}
{"parentUuid":"6fa49acb-bfde-4f2a-97e8-9c02c6618d58","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0128ow4ak8TJ4iCFC5TxH643","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me also update the player selection modal onClose handler. Let me read around line 2150 to update it.","signature":"EpUCCkYICxgCKkCtn9PhGaLmRrCAhPAipnn9aDWjgl1Kht3fNMBQU9uAZyiBq3kHX0CFssDbzn/kIYj2tZHqHraQklV6NcgvdMm4EgwkoPXQfg/TPQw/jNEaDPycH5d2DVzy0ZaK/yIwX3M2kHkGxdd5bxS2OUX3Q+nOsyE2k4xZ3rcj+TcUit65+vOkQWzD4nzXcYQeKZHtKn1hkFwLte/OuwHQzFERIxxec2Ugyuc71twoLUuaTzgbE+KQn2a2yAcHYbB4+eYeDySaFhfd4htgxK5SsKMdmogqokWXwTfM3b2HaiKxaYpQYriULGeIK/0veF7uCfy01zSsb73bosrBQkdbC/le2PCkhxgk2uoIrAtcHF3oyhgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":604,"cache_read_input_tokens":99024,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":604},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeHqxo4SCWtkZJsq6us","type":"assistant","uuid":"4cb452f8-64d8-4f03-b309-d6fa739f06cc","timestamp":"2026-01-28T23:28:24.747Z"}
{"parentUuid":"4cb452f8-64d8-4f03-b309-d6fa739f06cc","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0128ow4ak8TJ4iCFC5TxH643","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013UmR7XvtBy7jtTEZSmme1x","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />","new_string":"      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n          // V4 state reset\n          setGhostData(null);\n          setShowGhost(false);\n          setComputedSkill(null);\n          setMistakeEvents([]);\n          setSelectedMistake(null);\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":604,"cache_read_input_tokens":99024,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":604},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeHqxo4SCWtkZJsq6us","type":"assistant","uuid":"6c3375f5-e786-4062-b1e9-0a944c2a087d","timestamp":"2026-01-28T23:28:27.640Z"}
{"parentUuid":"6c3375f5-e786-4062-b1e9-0a944c2a087d","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013UmR7XvtBy7jtTEZSmme1x","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"d50aaa3a-e598-4c2a-863e-5048c487fd9a","timestamp":"2026-01-28T23:28:28.230Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />","newString":"      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n          // V4 state reset\n          setGhostData(null);\n          setShowGhost(false);\n          setComputedSkill(null);\n          setMistakeEvents([]);\n          setSelectedMistake(null);\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame, GhostRivalData } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                      // V4 state reset\n                      setGhostData(null);\n                      setShowGhost(false);\n                      setComputedSkill(null);\n                      setMistakeEvents([]);\n                      setSelectedMistake(null);\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                    // V4 state reset\n                    setGhostData(null);\n                    setShowGhost(false);\n                    setComputedSkill(null);\n                    setMistakeEvents([]);\n                    setSelectedMistake(null);\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":2162,"oldLines":6,"newStart":2162,"newLines":12,"lines":["           setVideoUrl(null);","           setVideoFile(null);","           setAnalysisState('IDLE');","+          // V4 state reset","+          setGhostData(null);","+          setShowGhost(false);","+          setComputedSkill(null);","+          setMistakeEvents([]);","+          setSelectedMistake(null);","         }}","         onConfirm={handlePlayerSelectionConfirm}","         tracks={detectedTracks}"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"6c3375f5-e786-4062-b1e9-0a944c2a087d"}
{"parentUuid":"d50aaa3a-e598-4c2a-863e-5048c487fd9a","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_018GeAAeuRGVBSwSi9d8Ejw4","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me mark the task as completed and also update the handleFileSelect to reset V4 state when a new file is selected.","signature":"EqICCkYICxgCKkDTI4/DMbOvyVg3c7BGivDPqS83tsxC1qiBxq2PJcy6iFs5cp6fsGp/zcvxhGKcYkDt/ZyH0T0Rk3ZFtyrfYEkcEgwZzJkjE8cRDXvVsfkaDIFzE92jQgH2KZIoOyIwnnGijboP04cygFkiMiwQbkoHHTsFEGyvhvWhf+Dn64/CELLNIuqArmvaDQcxffWXKokBIfohzXmGiJt794YZo6iyEXjUgWFgb/0eQJ4Jlm6LSbIt2VtA+l+IQ6alm3JaUhoth+3Rtk92C+e2yTGlHxwzH6sGJsWXaKSqVtitw+UK9ME7JMxfiJKm8s9H12Gyuz/Bk9kq8/Yg1tpmWXPPHzgS1KX2sV6uknWFY03Lyxnogp510eNQnCDShOcYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":519,"cache_read_input_tokens":99628,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":519},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeJMdk8zx7yvxWuJc48","type":"assistant","uuid":"1fddefa0-8602-4ae4-a861-f3e9df0d64b1","timestamp":"2026-01-28T23:28:31.985Z"}
{"parentUuid":"1fddefa0-8602-4ae4-a861-f3e9df0d64b1","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_018GeAAeuRGVBSwSi9d8Ejw4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HLm1ThUZCT1JTmfQCpVdkE","name":"TodoWrite","input":{"todos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"completed","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"completed","activeForm":"Updating reset handlers"},{"content":"Verify no TypeScript errors","status":"in_progress","activeForm":"Verifying TypeScript errors"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":519,"cache_read_input_tokens":99628,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":519},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeJMdk8zx7yvxWuJc48","type":"assistant","uuid":"ee6e6e35-ebcb-4e10-acf2-31bcd0d98fc2","timestamp":"2026-01-28T23:28:34.120Z"}
{"parentUuid":"ee6e6e35-ebcb-4e10-acf2-31bcd0d98fc2","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HLm1ThUZCT1JTmfQCpVdkE","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"0c6ebc2a-fdc2-4940-a805-94ac043f475c","timestamp":"2026-01-28T23:28:34.161Z","toolUseResult":{"oldTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"completed","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"in_progress","activeForm":"Updating reset handlers"}],"newTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"completed","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"completed","activeForm":"Updating reset handlers"},{"content":"Verify no TypeScript errors","status":"in_progress","activeForm":"Verifying TypeScript errors"}]},"sourceToolAssistantUUID":"ee6e6e35-ebcb-4e10-acf2-31bcd0d98fc2"}
{"parentUuid":"0c6ebc2a-fdc2-4940-a805-94ac043f475c","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012YS4L2ebZBWJQs1JdA7auW","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me also update the handleFileSelect to clear V4 state when a new file is selected. Then verify there are no TypeScript errors.","signature":"EqsCCkYICxgCKkBPtBoaYMB2fOl858NSIncvP5fpdE5zvCIrlZ0o9RUDuO3HuNWS3gSOHowxPPAvl60eqwfVR/I7nFqFVSXumCAaEgzjQTLl7WNGRPpasx0aDAGzSFYWtHeVTumcXiIwwcdtMEYpCFpcf6hqZMRqjpXCVa/CN/GdMy4OeYFo/uqBUWRJ17zqaRNPD7FD5oCWKpIBtLJ0NBDmyETplAMJODfGuNqytOr3Vf7RWvCRcSOGFbTdK+gf8KR+spNgjbmS9AyuHBtOUlPmYKmbYSBmWPtxUlQmKPsHJL7DRPa2C+X0sHCh2Dptsd89Z/QLdRNYmWe1hS+rv6H9bj8Nb7dx4u879zJ+vGMqhgbQo9D3v7Bwpmd94egtERimkB4UbNwnPzT2qHUYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":377,"cache_read_input_tokens":100147,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":377},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeJih287zBdQzSRCcXG","type":"assistant","uuid":"3747da55-2ddc-4a70-9079-7f1349500b9e","timestamp":"2026-01-28T23:28:36.790Z"}
{"parentUuid":"3747da55-2ddc-4a70-9079-7f1349500b9e","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012YS4L2ebZBWJQs1JdA7auW","type":"message","role":"assistant","content":[{"type":"text","text":"Let me also update the handleFileSelect function to clear V4 state."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":377,"cache_read_input_tokens":100147,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":377},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeJih287zBdQzSRCcXG","type":"assistant","uuid":"321c7b9b-8c6d-4cce-8588-8eb77d374bd3","timestamp":"2026-01-28T23:28:37.161Z"}
{"parentUuid":"321c7b9b-8c6d-4cce-8588-8eb77d374bd3","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_012YS4L2ebZBWJQs1JdA7auW","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YaPKyVY1yxzk2oseCPiRhL","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","offset":737,"limit":35}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":377,"cache_read_input_tokens":100147,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":377},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeJih287zBdQzSRCcXG","type":"assistant","uuid":"bacced2b-de73-4fe5-b69c-668578c2bc34","timestamp":"2026-01-28T23:28:37.835Z"}
{"parentUuid":"bacced2b-de73-4fe5-b69c-668578c2bc34","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YaPKyVY1yxzk2oseCPiRhL","type":"tool_result","content":"   737→  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n   738→    const file = e.target.files?.[0];\n   739→    if (!file) return;\n   740→\n   741→    if (!file.type.startsWith('video/')) {\n   742→      setError('Please select a video file');\n   743→      return;\n   744→    }\n   745→\n   746→    if (file.size > 100 * 1024 * 1024) {\n   747→      setError('File size must be less than 100MB. Please compress your video before uploading.');\n   748→      return;\n   749→    }\n   750→\n   751→    setError(null);\n   752→    setVideoFile(file);\n   753→    setResult(null);\n   754→    setIssues([]);\n   755→    setPoseData([]);\n   756→    setFrameAnalyses([]);\n   757→    setAutoLevelResult(null);\n   758→    setGuidanceKeyframes([]);\n   759→\n   760→    // Create object URL for video preview\n   761→    const objectUrl = URL.createObjectURL(file);\n   762→    setVideoUrl(objectUrl);\n   763→\n   764→    // Start analysis\n   765→    await analyzeVideo(file, objectUrl);\n   766→  };\n   767→\n   768→  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n   769→  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n   770→    if (!poseLandmarkerRef.current) return [];\n   771→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"3b8d22cc-3086-4a8f-8a75-ea1fb6ee16d1","timestamp":"2026-01-28T23:28:38.479Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","content":"  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n","numLines":35,"startLine":737,"totalLines":2204}},"sourceToolAssistantUUID":"bacced2b-de73-4fe5-b69c-668578c2bc34"}
{"parentUuid":"3b8d22cc-3086-4a8f-8a75-ea1fb6ee16d1","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01L2Dwgn1vmwiU4D3xtTzi7H","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me update handleFileSelect to also clear V4 state when a new file is selected.","signature":"EvoBCkYICxgCKkC5GKFFXway1+5MlDMeQbkEkiNlu7S/Rt+Endb9ML5SoqqrTacvlWxQ7zrwkikMTBMssiNFgbrGFG3/T30O3KBbEgycbTsAVi/gtB9vV+UaDAgqwdYSfI5MCK7DvSIwmDHbZxRfRZQpD/RdJj/9lQcPr187LjATS29Pbu2UptTVoJ2wd+ix2X/inl9L7othKmLybfuis50xA/sC/zXKCK7Pkv0fSHhlUJU55sCVU8pGb84oEsRZdRaby21ihHqa8FiSI8KraGJHjsHPS2gzaetbiXY0RjlCHs/pDu6CvJ1qYLxvE6n7fG8MyOMNnar9BEnEXBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":694,"cache_read_input_tokens":100524,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":694},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeK2xcvv4qrmXfubFhN","type":"assistant","uuid":"03fba482-38d0-4396-9e2c-46b2808c19e8","timestamp":"2026-01-28T23:28:41.131Z"}
{"parentUuid":"03fba482-38d0-4396-9e2c-46b2808c19e8","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01L2Dwgn1vmwiU4D3xtTzi7H","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019BQoUWe6bepxxzJWuSs5nL","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","old_string":"    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview","new_string":"    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n    // V4 state reset\n    setGhostData(null);\n    setShowGhost(false);\n    setComputedSkill(null);\n    setMistakeEvents([]);\n    setSelectedMistake(null);\n\n    // Create object URL for video preview"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":694,"cache_read_input_tokens":100524,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":694},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeK2xcvv4qrmXfubFhN","type":"assistant","uuid":"3004bf16-e65b-4c84-b7e1-bfb4e9eb9f70","timestamp":"2026-01-28T23:28:43.622Z"}
{"parentUuid":"3004bf16-e65b-4c84-b7e1-bfb4e9eb9f70","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019BQoUWe6bepxxzJWuSs5nL","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx has been updated successfully."}]},"uuid":"4601f1ec-a136-4394-8ae1-17d2da19e382","timestamp":"2026-01-28T23:28:44.186Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\app\\analytics\\page.tsx","oldString":"    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview","newString":"    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n    // V4 state reset\n    setGhostData(null);\n    setShowGhost(false);\n    setComputedSkill(null);\n    setMistakeEvents([]);\n    setSelectedMistake(null);\n\n    // Create object URL for video preview","originalFile":"'use client';\n\nimport { useState, useEffect, useRef, useCallback, Suspense } from 'react';\nimport { useSearchParams } from 'next/navigation';\nimport Link from 'next/link';\nimport DashboardNav from '@/components/DashboardNav';\nimport DrillCard from '@/components/DrillCard';\nimport { TabbedDrillAnimation } from '@/components/Skeleton3D';\nimport PlayerSelectionModal from '@/components/PlayerSelectionModal';\nimport GuidanceAnimation from '@/components/GuidanceAnimation';\nimport { supabase, uploadVideo, getVideoUrl, getSignedVideoUrl } from '@/lib/supabase';\nimport {\n  drawSkeleton,\n  extractMetrics,\n  POSE_CONNECTIONS,\n  POSE_LANDMARKS\n} from '@/lib/pose-utils';\nimport {\n  DRILLS,\n  FORM_RULES,\n  evaluateForm,\n  findViolationTimestamps,\n  type EvaluationResult\n} from '@/lib/rules-engine';\nimport {\n  evaluateWithBands,\n  SCORING_LEGEND,\n  SKILL_LEVEL_DESCRIPTIONS,\n  validateSessionPoseData,\n} from '@/lib/scoring-rules';\nimport { computeSkillScore } from '@/lib/skill-scoring';\nimport { initializeGhostRival, getGhostPoseAtTime } from '@/lib/ghost-overlay';\nimport { detectMistakes, generateFixKeyframes } from '@/lib/mistake-detection';\nimport MistakeTimeline, { MistakeTimelineMini } from '@/components/MistakeTimeline';\nimport FixItCard from '@/components/FixItCard';\nimport SkillMeter, { SkillBadgeInline } from '@/components/SkillMeter';\nimport type { AnalysisResultJson, Issue, Drill, PoseLandmark, Session, PoseMetrics, PlayerTrackData, ComputedSkillScore, MistakeEvent, GhostPoseFrame, GhostRivalData } from '@/lib/types';\n\n// MediaPipe Types\ntype PoseLandmarker = any;\n\ninterface FrameAnalysis {\n  timestamp: number;\n  landmarks: PoseLandmark[] | null;\n  evaluation: EvaluationResult | null;\n  metrics: PoseMetrics | null;\n}\n\ninterface DetectedIssue {\n  code: string;\n  title: string;\n  severity: 'low' | 'medium' | 'high';\n  description?: string;\n  timestamps: number[];\n  drill?: any;\n}\n\n// PHASE 5: Analysis state machine\ntype AnalysisState = 'IDLE' | 'DETECTING_PLAYERS' | 'EXTRACTING_POSE' | 'GEMINI_SCORING' | 'DONE' | 'ERROR';\n\n// PHASE 3: Auto-level detection result from Gemini\ninterface AutoLevelResult {\n  level: 'Beginner' | 'Intermediate' | 'Advanced';\n  confidence: number;\n  rationaleBullets: string[];\n  guidanceKeyframes?: GuidanceKeyframe[];\n}\n\n// PHASE 4: Guidance keyframe for animation\ninterface GuidanceKeyframe {\n  name: string;\n  description: string;\n  landmarks: PoseLandmark[] | null;\n  targetLandmarks?: PoseLandmark[] | null;\n  correction?: string;\n}\n\nfunction AnalyticsContent() {\n  const searchParams = useSearchParams();\n  const sessionId = searchParams.get('session');\n\n  // State\n  const [uploading, setUploading] = useState(false);\n  const [analyzing, setAnalyzing] = useState(false);\n  const [analyzeProgress, setAnalyzeProgress] = useState(0);\n  const [analysisState, setAnalysisState] = useState<AnalysisState>('IDLE');\n  const [analysisId, setAnalysisId] = useState<string | null>(null);\n  const [result, setResult] = useState<AnalysisResultJson | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [selectedIssue, setSelectedIssue] = useState<Issue | null>(null);\n  const [selectedDrill, setSelectedDrill] = useState<Drill | null>(null);\n\n  // Multi-pose and player selection state\n  const [showPlayerSelection, setShowPlayerSelection] = useState(false);\n  const [detectedTracks, setDetectedTracks] = useState<PlayerTrackData[]>([]);\n  const [selectedTrackIds, setSelectedTrackIds] = useState<number[]>([]);\n  const [detectedMatchFormat, setDetectedMatchFormat] = useState<'singles' | 'doubles' | null>(null);\n  const [matchFormat, setMatchFormat] = useState<'singles' | 'doubles'>('singles');\n  const [eventType, setEventType] = useState<string>('');\n\n  // PHASE 3: Auto-level detection state (replaces manual skill level selector)\n  const [autoLevelResult, setAutoLevelResult] = useState<AutoLevelResult | null>(null);\n  const [currentBandedScore, setCurrentBandedScore] = useState<any>(null);\n\n  // PHASE 4: Guidance animation state\n  const [guidanceKeyframes, setGuidanceKeyframes] = useState<GuidanceKeyframe[]>([]);\n  const [showGuidance, setShowGuidance] = useState(false);\n\n  // V4 FEATURES: Ghost Rival, Skill Scoring, Mistake Timeline\n  const [ghostData, setGhostData] = useState<GhostRivalData | null>(null);\n  const [showGhost, setShowGhost] = useState(false);\n  const [computedSkill, setComputedSkill] = useState<ComputedSkillScore | null>(null);\n  const [mistakeEvents, setMistakeEvents] = useState<MistakeEvent[]>([]);\n  const [selectedMistake, setSelectedMistake] = useState<MistakeEvent | null>(null);\n\n  // Video playback state\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n  const [videoFile, setVideoFile] = useState<File | null>(null);\n  const [poseData, setPoseData] = useState<Array<PoseLandmark[] | null>>([]);\n  const [frameAnalyses, setFrameAnalyses] = useState<FrameAnalysis[]>([]);\n  const [issues, setIssues] = useState<DetectedIssue[]>([]);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [duration, setDuration] = useState(0);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [showSkeleton, setShowSkeleton] = useState(true);\n  const [fps, setFps] = useState(30);\n\n  // PHASE 2: Canvas overlay alignment state\n  const [videoRect, setVideoRect] = useState<DOMRect | null>(null);\n\n  // Pose detection\n  const [poseLandmarkerReady, setPoseLandmarkerReady] = useState(false);\n  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);\n\n  // PHASE 1: Timestamp tracking for monotonic enforcement\n  const lastTimestampMsRef = useRef<number>(-1);\n  const timestampBaseOffsetRef = useRef<number>(0);\n  const isProcessingRef = useRef<boolean>(false);\n\n  // Refs\n  const fileInputRef = useRef<HTMLInputElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const videoContainerRef = useRef<HTMLDivElement>(null);\n  const processVideoRef = useRef<HTMLVideoElement | null>(null);\n  const pollIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  // Initialize MediaPipe Pose Landmarker\n  useEffect(() => {\n    initializePoseLandmarker();\n    return () => {\n      cleanup();\n    };\n  }, []);\n\n  // Load session if ID provided\n  useEffect(() => {\n    if (sessionId) {\n      loadSession(sessionId);\n    }\n  }, [sessionId]);\n\n  // PHASE 2: Update canvas size on video resize\n  useEffect(() => {\n    const updateVideoRect = () => {\n      if (videoRef.current && videoContainerRef.current) {\n        const video = videoRef.current;\n        const container = videoContainerRef.current;\n\n        // Calculate the actual rendered video rectangle (accounting for object-contain)\n        const containerRect = container.getBoundingClientRect();\n        const videoAspect = video.videoWidth / video.videoHeight;\n        const containerAspect = containerRect.width / containerRect.height;\n\n        let renderWidth, renderHeight, offsetX, offsetY;\n\n        if (videoAspect > containerAspect) {\n          // Video is wider - letterbox top/bottom\n          renderWidth = containerRect.width;\n          renderHeight = containerRect.width / videoAspect;\n          offsetX = 0;\n          offsetY = (containerRect.height - renderHeight) / 2;\n        } else {\n          // Video is taller - letterbox left/right\n          renderHeight = containerRect.height;\n          renderWidth = containerRect.height * videoAspect;\n          offsetX = (containerRect.width - renderWidth) / 2;\n          offsetY = 0;\n        }\n\n        setVideoRect({\n          x: offsetX,\n          y: offsetY,\n          width: renderWidth,\n          height: renderHeight,\n          top: offsetY,\n          left: offsetX,\n          right: offsetX + renderWidth,\n          bottom: offsetY + renderHeight,\n          toJSON: () => ({})\n        } as DOMRect);\n      }\n    };\n\n    updateVideoRect();\n    window.addEventListener('resize', updateVideoRect);\n\n    return () => window.removeEventListener('resize', updateVideoRect);\n  }, [videoUrl]);\n\n  const initializePoseLandmarker = async () => {\n    try {\n      const vision = await import('@mediapipe/tasks-vision');\n      const { PoseLandmarker, FilesetResolver } = vision;\n\n      const filesetResolver = await FilesetResolver.forVisionTasks(\n        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n      );\n\n      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(filesetResolver, {\n        baseOptions: {\n          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 4, // Support up to 4 players for doubles\n        minPoseDetectionConfidence: 0.5,\n        minPosePresenceConfidence: 0.5,\n        minTrackingConfidence: 0.5,\n      });\n\n      setPoseLandmarkerReady(true);\n    } catch (error) {\n      console.error('Failed to load MediaPipe Pose:', error);\n      // Continue without pose detection - will use fallback\n    }\n  };\n\n  // PHASE 1: Recreate PoseLandmarker to reset timestamp tracking\n  const recreatePoseLandmarker = async () => {\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n    lastTimestampMsRef.current = -1;\n    timestampBaseOffsetRef.current = 0;\n    await initializePoseLandmarker();\n  };\n\n  const cleanup = () => {\n    if (pollIntervalRef.current) {\n      clearInterval(pollIntervalRef.current);\n    }\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    if (poseLandmarkerRef.current) {\n      poseLandmarkerRef.current.close();\n    }\n  };\n\n  const loadSession = async (id: string) => {\n    try {\n      setAnalyzing(true);\n      setAnalysisState('EXTRACTING_POSE');\n\n      // Try new sessions table first\n      const { data: sessionData, error: sessionError } = await supabase\n        .from('sessions')\n        .select('*')\n        .eq('id', id)\n        .single();\n\n      if (sessionError) {\n        // Try legacy table\n        const { data: legacyData, error: legacyError } = await supabase\n          .from('analysis_results')\n          .select('*')\n          .eq('id', id)\n          .single();\n\n        if (legacyError) throw legacyError;\n        if (legacyData?.result_json) {\n          setResult(legacyData.result_json);\n          if (legacyData.result_json.video_url) {\n            setVideoUrl(legacyData.result_json.video_url);\n          }\n        }\n      } else if (sessionData) {\n        // New session format\n        setVideoUrl(sessionData.video_url);\n\n        if (sessionData.pose_data) {\n          setPoseData(sessionData.pose_data);\n        }\n\n        // Fetch issues\n        const { data: issuesData } = await supabase\n          .from('issues')\n          .select('*')\n          .eq('session_id', id);\n\n        if (issuesData && issuesData.length > 0) {\n          setIssues(issuesData.map((issue: any) => ({\n            code: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description,\n            timestamps: issue.timestamps || [],\n            drill: issue.drill || DRILLS[issue.code?.toLowerCase().replace(/_/g, '-')],\n          })));\n        }\n\n        // Build result from session summary\n        const summary = sessionData.summary || {};\n        setResult({\n          top_issues: issuesData?.map((i: any) => ({\n            id: i.id,\n            title: i.title,\n            severity: i.severity,\n            description: i.description,\n            affected_metrics: [],\n          })) || [],\n          drills: issuesData?.map((i: any) => DRILLS[i.code?.toLowerCase().replace(/_/g, '-')]).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })) || [],\n          technique_summary: summary.feedback?.technique_summary || 'Analysis complete.',\n          strategy_summary: summary.feedback?.strategy_summary || '',\n          training_plan: [],\n        });\n      }\n      setAnalysisState('DONE');\n    } catch (err) {\n      console.error('Error loading session:', err);\n      setError('Failed to load session');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n    }\n  };\n\n  // PHASE 1 FIX: Process video with strictly monotonic timestamps\n  // Uses base offset approach to handle seeks without recreating PoseLandmarker\n  const processVideoWithPose = async (\n    videoElement: HTMLVideoElement,\n    selectedTracks: number[] = [0]\n  ): Promise<FrameAnalysis[]> => {\n    if (!poseLandmarkerRef.current) {\n      console.warn('Pose landmarker not ready');\n      return [];\n    }\n\n    // Prevent concurrent processing\n    if (isProcessingRef.current) {\n      console.warn('Already processing video, skipping');\n      return [];\n    }\n    isProcessingRef.current = true;\n\n    const analyses: FrameAnalysis[] = [];\n    const videoDuration = videoElement.duration;\n    const sampleRate = 10; // Process 10 frames per second\n    const totalFrames = Math.floor(videoDuration * sampleRate);\n\n    // PHASE 1: Reset timestamp tracking for fresh processing\n    // Use base offset approach so timestamps always increase even if we restart\n    timestampBaseOffsetRef.current = lastTimestampMsRef.current + 1000; // Add 1 second buffer\n    let localLastTimestamp = timestampBaseOffsetRef.current;\n\n    let validPoseFrames = 0;\n    let lowConfidenceFrames = 0;\n    let noPoseFrames = 0;\n\n    setAnalyzeProgress(10); // Start at 10% after track detection\n\n    for (let i = 0; i <= totalFrames; i++) {\n      const timestamp = i / sampleRate;\n      videoElement.currentTime = timestamp;\n\n      // Wait for video to seek\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      // Give the video a moment to render the frame\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure timestamp is strictly greater than last timestamp\n        // Use base offset + local timestamp to guarantee monotonic increase\n        const rawTimestampMs = Math.floor(timestamp * 1000);\n        const timestampMs = timestampBaseOffsetRef.current + rawTimestampMs;\n\n        // Double-check monotonicity\n        const safeTimestampMs = Math.max(localLastTimestamp + 1, timestampMs);\n        localLastTimestamp = safeTimestampMs;\n        lastTimestampMsRef.current = safeTimestampMs;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestampMs\n        );\n\n        let landmarks: PoseLandmark[] | null = null;\n        let evaluation: EvaluationResult | null = null;\n        let metrics: PoseMetrics | null = null;\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          // Only use the selected player's landmarks\n          const selectedPoseIdx = selectedTracks[0] < results.landmarks.length\n            ? selectedTracks[0]\n            : 0;\n\n          landmarks = results.landmarks[selectedPoseIdx].map((lm: any) => ({\n            x: lm.x,\n            y: lm.y,\n            z: lm.z,\n            visibility: lm.visibility ?? 1.0,\n          }));\n\n          if (landmarks && landmarks.length > 0) {\n            const avgVisibility = landmarks.reduce((sum, lm) => sum + lm.visibility, 0) / landmarks.length;\n\n            if (avgVisibility < 0.5) {\n              lowConfidenceFrames++;\n            } else {\n              validPoseFrames++;\n            }\n            metrics = extractMetrics(landmarks);\n\n            // Use intermediate level for initial processing (auto-level will adjust later)\n            const bandedResult = evaluateWithBands(landmarks, 'intermediate');\n            evaluation = {\n              passed: bandedResult.overall_band === 'green' || bandedResult.overall_band === 'yellow',\n              score: bandedResult.overall_score,\n              failedRules: bandedResult.overall_band === 'red' ? bandedResult.feedback.map(f => ({\n                rule: { code: 'FORM', name: f, description: f, severity: 'medium' as const } as any,\n                value: 0,\n                feedback: f,\n              })) : [],\n              passedRules: [],\n              highlightJoints: bandedResult.highlight_joints,\n              recommendedDrills: [],\n            };\n          }\n        } else {\n          noPoseFrames++;\n        }\n\n        analyses.push({\n          timestamp,\n          landmarks,\n          evaluation,\n          metrics,\n        });\n      } catch (err) {\n        const errorMsg = err instanceof Error ? err.message : String(err);\n        if (errorMsg.includes('timestamp') || errorMsg.includes('monotonic')) {\n          console.warn(`Frame ${i}: MediaPipe timestamp error - ${errorMsg}`);\n          // PHASE 1 FIX: On timestamp error, bump the base offset significantly\n          timestampBaseOffsetRef.current += 10000; // Add 10 seconds\n          localLastTimestamp = timestampBaseOffsetRef.current;\n        } else {\n          console.warn(`Frame ${i}: Error processing - ${errorMsg}`);\n        }\n        analyses.push({\n          timestamp,\n          landmarks: null,\n          evaluation: null,\n          metrics: null,\n        });\n      }\n\n      // Update progress (10-70%)\n      setAnalyzeProgress(10 + Math.round((i / totalFrames) * 60));\n    }\n\n    // PHASE 1: Log pose detection statistics\n    const totalProcessed = totalFrames + 1;\n    const validRatio = validPoseFrames / totalProcessed;\n    console.log(`Pose detection stats: ${validPoseFrames}/${totalProcessed} valid (${(validRatio * 100).toFixed(1)}%), ${lowConfidenceFrames} low-confidence, ${noPoseFrames} no-pose`);\n\n    if (validRatio < 0.3) {\n      console.warn('Low pose detection rate - video may have poor lighting or player not visible');\n    }\n\n    isProcessingRef.current = false;\n    return analyses;\n  };\n\n  // Detect issues from frame analyses\n  const detectIssuesFromAnalyses = (analyses: FrameAnalysis[]): DetectedIssue[] => {\n    const issueMap: Map<string, {\n      rule: any;\n      timestamps: number[];\n      count: number;\n    }> = new Map();\n\n    for (const frame of analyses) {\n      if (frame.evaluation && frame.evaluation.failedRules.length > 0) {\n        for (const failed of frame.evaluation.failedRules) {\n          const code = failed.rule.code;\n          if (!issueMap.has(code)) {\n            issueMap.set(code, {\n              rule: failed.rule,\n              timestamps: [],\n              count: 0,\n            });\n          }\n          const issue = issueMap.get(code)!;\n          issue.timestamps.push(frame.timestamp);\n          issue.count++;\n        }\n      }\n    }\n\n    // Convert to array and sort by count\n    const issues: DetectedIssue[] = Array.from(issueMap.entries())\n      .map(([code, data]) => ({\n        code,\n        title: data.rule.name,\n        severity: data.rule.severity,\n        description: data.rule.description,\n        timestamps: data.timestamps,\n        drill: DRILLS[data.rule.drillId],\n      }))\n      .sort((a, b) => b.timestamps.length - a.timestamps.length)\n      .slice(0, 5); // Top 5 issues\n\n    return issues;\n  };\n\n  // PHASE 3: Auto-detect skill level using Gemini\n  const detectSkillLevelWithGemini = async (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): Promise<AutoLevelResult> => {\n    setAnalysisState('GEMINI_SCORING');\n    setAnalyzeProgress(75);\n\n    try {\n      // Extract features for Gemini analysis\n      const validAnalyses = analyses.filter(a => a.metrics && a.landmarks);\n\n      if (validAnalyses.length < 5) {\n        // Fallback if not enough data\n        return {\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Insufficient pose data for accurate assessment'],\n        };\n      }\n\n      // Calculate aggregate metrics\n      const avgElbowAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.elbow_angle || 0), 0) / validAnalyses.length;\n      const avgKneeAngle = validAnalyses.reduce((sum, a) => sum + (a.metrics?.knee_angle || 0), 0) / validAnalyses.length;\n      const avgStanceWidth = validAnalyses.reduce((sum, a) => sum + (a.metrics?.stance_width_norm || 0), 0) / validAnalyses.length;\n      const avgRotation = validAnalyses.reduce((sum, a) => sum + (a.metrics?.shoulder_hip_rotation_proxy || 0), 0) / validAnalyses.length;\n\n      // Calculate consistency (standard deviation proxy)\n      const elbowVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.elbow_angle || 0) - avgElbowAngle, 2), 0) / validAnalyses.length;\n      const kneeVariance = validAnalyses.reduce((sum, a) => sum + Math.pow((a.metrics?.knee_angle || 0) - avgKneeAngle, 2), 0) / validAnalyses.length;\n\n      // Calculate movement intensity (velocity proxy from position changes)\n      let totalMovement = 0;\n      for (let i = 1; i < validAnalyses.length; i++) {\n        const prev = validAnalyses[i - 1].landmarks;\n        const curr = validAnalyses[i].landmarks;\n        if (prev && curr) {\n          const hipMovement = Math.sqrt(\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.x || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.x || 0), 2) +\n            Math.pow((curr[POSE_LANDMARKS.LEFT_HIP]?.y || 0) - (prev[POSE_LANDMARKS.LEFT_HIP]?.y || 0), 2)\n          );\n          totalMovement += hipMovement;\n        }\n      }\n      const avgMovement = totalMovement / (validAnalyses.length - 1);\n\n      // Issue frequency\n      const issueFrequency = detectedIssues.reduce((sum, i) => sum + i.timestamps.length, 0) / validAnalyses.length;\n\n      // Call Gemini API for skill level detection\n      const response = await fetch('/api/analysis/auto-level', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          metrics: {\n            avgElbowAngle,\n            avgKneeAngle,\n            avgStanceWidth,\n            avgRotation,\n            elbowConsistency: Math.sqrt(elbowVariance),\n            kneeConsistency: Math.sqrt(kneeVariance),\n            movementIntensity: avgMovement,\n            issueFrequency,\n            totalFrames: validAnalyses.length,\n            issueCount: detectedIssues.length,\n          },\n          issues: detectedIssues.map(i => ({\n            code: i.code,\n            title: i.title,\n            frequency: i.timestamps.length / validAnalyses.length,\n          })),\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        setAnalyzeProgress(90);\n        return {\n          level: result.level || 'Intermediate',\n          confidence: result.confidence || 0.7,\n          rationaleBullets: result.rationaleBullets || [],\n          guidanceKeyframes: result.guidanceKeyframes,\n        };\n      }\n    } catch (err) {\n      console.error('Gemini auto-level detection failed:', err);\n    }\n\n    // Fallback rule-based detection\n    setAnalyzeProgress(90);\n    return fallbackSkillLevelDetection(analyses, detectedIssues);\n  };\n\n  // Fallback rule-based skill level detection\n  const fallbackSkillLevelDetection = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): AutoLevelResult => {\n    const validAnalyses = analyses.filter(a => a.evaluation);\n    const passedFrames = validAnalyses.filter(a => a.evaluation?.passed).length;\n    const passRatio = validAnalyses.length > 0 ? passedFrames / validAnalyses.length : 0;\n    const highSeverityIssues = detectedIssues.filter(i => i.severity === 'high').length;\n\n    if (passRatio >= 0.7 && highSeverityIssues === 0) {\n      return {\n        level: 'Advanced',\n        confidence: 0.75,\n        rationaleBullets: [\n          'Consistent form across frames',\n          'No major technique issues detected',\n          'Good body mechanics observed',\n        ],\n      };\n    } else if (passRatio >= 0.4 || highSeverityIssues <= 1) {\n      return {\n        level: 'Intermediate',\n        confidence: 0.7,\n        rationaleBullets: [\n          'Moderate consistency in technique',\n          `${highSeverityIssues} area(s) need focused improvement`,\n          'Foundations are solid with room to refine',\n        ],\n      };\n    } else {\n      return {\n        level: 'Beginner',\n        confidence: 0.8,\n        rationaleBullets: [\n          'Multiple technique areas need development',\n          'Focus on fundamentals before advancing',\n          'Regular practice will show rapid improvement',\n        ],\n      };\n    }\n  };\n\n  // PHASE 4: Generate guidance keyframes from analysis\n  const generateGuidanceKeyframes = (\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[]\n  ): GuidanceKeyframe[] => {\n    const keyframes: GuidanceKeyframe[] = [];\n    const validAnalyses = analyses.filter(a => a.landmarks && a.landmarks.length > 0);\n\n    if (validAnalyses.length < 3) return keyframes;\n\n    // Find key moments: Setup, Contact/Action, Recovery\n    // Setup: Early stable frame\n    const setupIdx = Math.floor(validAnalyses.length * 0.1);\n    const contactIdx = Math.floor(validAnalyses.length * 0.5);\n    const recoveryIdx = Math.floor(validAnalyses.length * 0.85);\n\n    const setupFrame = validAnalyses[setupIdx];\n    const contactFrame = validAnalyses[contactIdx];\n    const recoveryFrame = validAnalyses[recoveryIdx];\n\n    // Determine primary issue for corrections\n    const primaryIssue = detectedIssues[0];\n    let correction = '';\n    if (primaryIssue) {\n      if (primaryIssue.code.includes('ELBOW')) {\n        correction = 'Extend elbow more at contact';\n      } else if (primaryIssue.code.includes('KNEE')) {\n        correction = 'Maintain athletic knee bend';\n      } else if (primaryIssue.code.includes('STANCE')) {\n        correction = 'Widen stance for stability';\n      } else if (primaryIssue.code.includes('ROTATION')) {\n        correction = 'Rotate hips before shoulders';\n      }\n    }\n\n    keyframes.push({\n      name: 'Setup',\n      description: 'Preparation phase',\n      landmarks: setupFrame?.landmarks || null,\n      correction: setupFrame?.evaluation?.passed ? undefined : 'Get into ready position earlier',\n    });\n\n    keyframes.push({\n      name: 'Contact',\n      description: 'Point of contact',\n      landmarks: contactFrame?.landmarks || null,\n      correction: correction || undefined,\n    });\n\n    keyframes.push({\n      name: 'Recovery',\n      description: 'Return to ready',\n      landmarks: recoveryFrame?.landmarks || null,\n      correction: recoveryFrame?.evaluation?.passed ? undefined : 'Recover to center faster',\n    });\n\n    return keyframes;\n  };\n\n  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {\n    const file = e.target.files?.[0];\n    if (!file) return;\n\n    if (!file.type.startsWith('video/')) {\n      setError('Please select a video file');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('File size must be less than 100MB. Please compress your video before uploading.');\n      return;\n    }\n\n    setError(null);\n    setVideoFile(file);\n    setResult(null);\n    setIssues([]);\n    setPoseData([]);\n    setFrameAnalyses([]);\n    setAutoLevelResult(null);\n    setGuidanceKeyframes([]);\n\n    // Create object URL for video preview\n    const objectUrl = URL.createObjectURL(file);\n    setVideoUrl(objectUrl);\n\n    // Start analysis\n    await analyzeVideo(file, objectUrl);\n  };\n\n  // PHASE 1 FIX: Detect player tracks with monotonic timestamps\n  const detectPlayerTracks = async (videoElement: HTMLVideoElement): Promise<PlayerTrackData[]> => {\n    if (!poseLandmarkerRef.current) return [];\n\n    const tracks: Map<number, PlayerTrackData> = new Map();\n    const sampleFrames = 5;\n    const duration = videoElement.duration;\n\n    // Use separate timestamp tracking for track detection\n    let trackDetectionTimestamp = lastTimestampMsRef.current + 1000;\n\n    for (let i = 0; i < sampleFrames; i++) {\n      const timestamp = (i / sampleFrames) * duration;\n      videoElement.currentTime = timestamp;\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n\n      await new Promise(resolve => setTimeout(resolve, 50));\n\n      try {\n        // PHASE 1 FIX: Ensure monotonic timestamp\n        trackDetectionTimestamp += 100; // 100ms between samples\n        const safeTimestamp = trackDetectionTimestamp;\n        lastTimestampMsRef.current = safeTimestamp;\n\n        const results = poseLandmarkerRef.current.detectForVideo(\n          videoElement,\n          safeTimestamp\n        );\n\n        if (results.landmarks && results.landmarks.length > 0) {\n          for (let poseIdx = 0; poseIdx < results.landmarks.length; poseIdx++) {\n            const landmarks = results.landmarks[poseIdx];\n            const bbox = calculateBoundingBox(landmarks);\n\n            if (!tracks.has(poseIdx)) {\n              tracks.set(poseIdx, {\n                track_id: poseIdx,\n                bbox_samples: [],\n                is_selected: false,\n                confidence_avg: 0,\n                frame_count: 0,\n                side: bbox.y < 0.5 ? 'far' : 'near',\n              });\n            }\n\n            const track = tracks.get(poseIdx)!;\n            track.bbox_samples.push({\n              frame: i,\n              x: bbox.x,\n              y: bbox.y,\n              w: bbox.w,\n              h: bbox.h,\n              confidence: landmarks[0].visibility || 0.5,\n            });\n            track.frame_count++;\n            track.confidence_avg =\n              (track.confidence_avg * (track.frame_count - 1) + (landmarks[0].visibility || 0.5)) /\n              track.frame_count;\n          }\n        }\n      } catch (err) {\n        console.warn('Error detecting poses in frame:', err);\n      }\n    }\n\n    // Generate thumbnails\n    const tracksArray = Array.from(tracks.values()).filter(t => t.frame_count >= 2);\n\n    if (tracksArray.length > 0) {\n      const bestFrameIdx = tracksArray[0].bbox_samples[0]?.frame || 0;\n      const bestTimestamp = (bestFrameIdx / sampleFrames) * duration;\n      videoElement.currentTime = Math.max(0.5, bestTimestamp);\n\n      await new Promise<void>((resolve) => {\n        const onSeeked = () => {\n          videoElement.removeEventListener('seeked', onSeeked);\n          resolve();\n        };\n        videoElement.addEventListener('seeked', onSeeked);\n      });\n      await new Promise(resolve => setTimeout(resolve, 100));\n\n      for (const track of tracksArray) {\n        if (track.bbox_samples.length > 0) {\n          const bestBbox = track.bbox_samples.reduce((best, current) =>\n            (current.confidence || 0) > (best.confidence || 0) ? current : best\n          );\n\n          const thumbnail = generateThumbnail(videoElement, {\n            x: bestBbox.x,\n            y: bestBbox.y,\n            w: bestBbox.w,\n            h: bestBbox.h,\n          });\n\n          if (thumbnail) {\n            track.thumbnail_url = thumbnail;\n          }\n        }\n      }\n    }\n\n    return tracksArray;\n  };\n\n  // Calculate bounding box from landmarks\n  const calculateBoundingBox = (landmarks: any[]): { x: number; y: number; w: number; h: number } => {\n    let minX = 1, minY = 1, maxX = 0, maxY = 0;\n    for (const lm of landmarks) {\n      if (lm.visibility > 0.5) {\n        minX = Math.min(minX, lm.x);\n        minY = Math.min(minY, lm.y);\n        maxX = Math.max(maxX, lm.x);\n        maxY = Math.max(maxY, lm.y);\n      }\n    }\n    return {\n      x: minX,\n      y: minY,\n      w: maxX - minX,\n      h: maxY - minY,\n    };\n  };\n\n  // Generate thumbnail from video at specific bounding box\n  const generateThumbnail = (\n    video: HTMLVideoElement,\n    bbox: { x: number; y: number; w: number; h: number },\n    padding: number = 0.1\n  ): string | null => {\n    try {\n      const canvas = document.createElement('canvas');\n      const ctx = canvas.getContext('2d');\n      if (!ctx) return null;\n\n      const vw = video.videoWidth;\n      const vh = video.videoHeight;\n\n      const padX = bbox.w * padding;\n      const padY = bbox.h * padding;\n\n      const cropX = Math.max(0, Math.floor((bbox.x - padX) * vw));\n      const cropY = Math.max(0, Math.floor((bbox.y - padY) * vh));\n      const cropW = Math.min(vw - cropX, Math.floor((bbox.w + padX * 2) * vw));\n      const cropH = Math.min(vh - cropY, Math.floor((bbox.h + padY * 2) * vh));\n\n      if (cropW <= 0 || cropH <= 0) return null;\n\n      const maxSize = 150;\n      const scale = Math.min(maxSize / cropW, maxSize / cropH);\n      canvas.width = Math.floor(cropW * scale);\n      canvas.height = Math.floor(cropH * scale);\n\n      ctx.drawImage(\n        video,\n        cropX, cropY, cropW, cropH,\n        0, 0, canvas.width, canvas.height\n      );\n\n      return canvas.toDataURL('image/jpeg', 0.8);\n    } catch (err) {\n      console.warn('Error generating thumbnail:', err);\n      return null;\n    }\n  };\n\n  // Handle player selection confirmation\n  const handlePlayerSelectionConfirm = (\n    selectedTracks: number[],\n    format: 'singles' | 'doubles',\n    event: string\n  ) => {\n    setSelectedTrackIds(selectedTracks);\n    setMatchFormat(format);\n    setEventType(event);\n    setShowPlayerSelection(false);\n\n    if (processVideoRef.current && videoFile) {\n      continueAnalysisWithSelection(processVideoRef.current, selectedTracks);\n    }\n  };\n\n  // Continue analysis after player selection\n  const continueAnalysisWithSelection = async (\n    processVideo: HTMLVideoElement,\n    selectedTracks: number[]\n  ) => {\n    setAnalysisState('EXTRACTING_POSE');\n    const analyses = await processVideoWithPose(processVideo, selectedTracks);\n    setFrameAnalyses(analyses);\n\n    const poseArray = analyses.map(a => a.landmarks);\n    setPoseData(poseArray);\n\n    const detectedIssues = detectIssuesFromAnalyses(analyses);\n    setIssues(detectedIssues);\n\n    // V4 FEATURE: Detect mistake events for timeline\n    const mistakes = detectMistakes(poseArray, 10);\n    setMistakeEvents(mistakes);\n\n    // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n    const metricsHistory = analyses.map(a => a.metrics);\n    const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n    setComputedSkill(skillResult);\n\n    // V4 FEATURE: Initialize ghost rival data\n    const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n    setGhostData(ghost);\n\n    // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n    const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n    // Override level with computed score\n    const finalLevel = {\n      ...levelResult,\n      level: skillResult.levelLabel,\n      confidence: skillResult.confidencePercent / 100,\n    };\n    setAutoLevelResult(finalLevel);\n\n    // PHASE 4: Generate guidance keyframes\n    const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n    setGuidanceKeyframes(guidance);\n\n    const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n    const totalFrames = analyses.filter(a => a.evaluation).length;\n\n    setResult({\n      top_issues: detectedIssues.map(issue => ({\n        id: issue.code,\n        title: issue.title,\n        severity: issue.severity,\n        description: issue.description || '',\n        affected_metrics: [],\n      })),\n      drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n        id: d.id,\n        name: d.name,\n        description: d.description,\n        duration_minutes: d.durationMinutes,\n        target_metrics: d.targetMetrics,\n        instructions: d.steps,\n      })),\n      technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n      strategy_summary: passedFrames > totalFrames * 0.7\n        ? 'Your form is generally good. Focus on the specific issues identified.'\n        : 'Work on maintaining consistent form throughout your movements.',\n      training_plan: [],\n    });\n\n    const saveResult = await saveAnalysisToDatabase(videoFile!, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n    if (!saveResult.success) {\n      setError(saveResult.error || 'Failed to save analysis');\n    }\n    setAnalyzing(false);\n    setAnalysisState('DONE');\n    setAnalyzeProgress(100);\n  };\n\n  const analyzeVideo = async (file: File, videoObjectUrl: string) => {\n    setAnalyzing(true);\n    setAnalyzeProgress(0);\n    setAnalysisState('DETECTING_PLAYERS');\n\n    try {\n      const processVideo = document.createElement('video');\n      processVideo.src = videoObjectUrl;\n      processVideo.muted = true;\n      processVideo.playsInline = true;\n      processVideoRef.current = processVideo;\n\n      await new Promise<void>((resolve, reject) => {\n        processVideo.onloadedmetadata = () => {\n          setDuration(processVideo.duration);\n          setFps(30);\n          resolve();\n        };\n        processVideo.onerror = () => reject(new Error('Failed to load video'));\n      });\n\n      await new Promise<void>((resolve) => {\n        if (processVideo.readyState >= 2) {\n          resolve();\n        } else {\n          processVideo.oncanplay = () => resolve();\n        }\n      });\n\n      // Detect player tracks first\n      setAnalyzeProgress(5);\n      const tracks = await detectPlayerTracks(processVideo);\n      setDetectedTracks(tracks);\n\n      const uniquePlayers = tracks.length;\n      const detectedFormat = uniquePlayers > 2 ? 'doubles' : 'singles';\n      setDetectedMatchFormat(detectedFormat);\n\n      if (tracks.length > 1) {\n        setShowPlayerSelection(true);\n        return;\n      }\n\n      if (tracks.length === 1) {\n        setSelectedTrackIds([tracks[0].track_id]);\n      }\n\n      // Process video with pose detection\n      let analyses: FrameAnalysis[] = [];\n\n      if (poseLandmarkerReady && poseLandmarkerRef.current) {\n        setAnalysisState('EXTRACTING_POSE');\n        analyses = await processVideoWithPose(processVideo, selectedTrackIds.length > 0 ? selectedTrackIds : [0]);\n        setFrameAnalyses(analyses);\n\n        const poseArray = analyses.map(a => a.landmarks);\n        setPoseData(poseArray);\n\n        const detectedIssues = detectIssuesFromAnalyses(analyses);\n        setIssues(detectedIssues);\n\n        // V4 FEATURE: Detect mistake events for timeline\n        const mistakes = detectMistakes(poseArray, 10);\n        setMistakeEvents(mistakes);\n\n        // V4 FEATURE: Compute skill score from REAL pose metrics (not Gemini alone)\n        const metricsHistory = analyses.map(a => a.metrics);\n        const skillResult = computeSkillScore(poseArray, metricsHistory, mistakes);\n        setComputedSkill(skillResult);\n\n        // V4 FEATURE: Initialize ghost rival data\n        const ghost = initializeGhostRival(poseArray, metricsHistory, 10);\n        setGhostData(ghost);\n\n        // PHASE 3: Also get Gemini feedback for narrative (but score comes from computed metrics)\n        const levelResult = await detectSkillLevelWithGemini(analyses, detectedIssues);\n        // Override level with computed score\n        const finalLevel = {\n          ...levelResult,\n          level: skillResult.levelLabel,\n          confidence: skillResult.confidencePercent / 100,\n        };\n        setAutoLevelResult(finalLevel);\n\n        // PHASE 4: Generate guidance keyframes\n        const guidance = levelResult.guidanceKeyframes || generateGuidanceKeyframes(analyses, detectedIssues);\n        setGuidanceKeyframes(guidance);\n\n        const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n        const totalFrames = analyses.filter(a => a.evaluation).length;\n\n        setResult({\n          top_issues: detectedIssues.map(issue => ({\n            id: issue.code,\n            title: issue.title,\n            severity: issue.severity,\n            description: issue.description || '',\n            affected_metrics: [],\n          })),\n          drills: detectedIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d.id,\n            name: d.name,\n            description: d.description,\n            duration_minutes: d.durationMinutes,\n            target_metrics: d.targetMetrics,\n            instructions: d.steps,\n          })),\n          technique_summary: `Analysis complete. Skill: ${skillResult.levelLabel} (${skillResult.skillScore}/100, ${skillResult.confidencePercent}% confidence). Found ${detectedIssues.length} areas and ${mistakes.length} mistake events.`,\n          strategy_summary: passedFrames > totalFrames * 0.7\n            ? 'Your form is generally good. Focus on the specific issues identified.'\n            : 'Work on maintaining consistent form throughout your movements.',\n          training_plan: [],\n        });\n\n        const saveResult = await saveAnalysisToDatabase(file, analyses, detectedIssues, skillResult.skillScore, finalLevel, mistakes, ghost.bestRepWindow);\n        if (!saveResult.success) {\n          setError(saveResult.error || 'Failed to save analysis. Video may not have uploaded correctly.');\n        }\n        setAnalysisState('DONE');\n      } else {\n        setError('Pose detection not available. Using demo mode.');\n        setAnalysisState('ERROR');\n\n        const demoIssues: DetectedIssue[] = [\n          {\n            code: 'ELBOW_ANGLE_OVERHEAD',\n            title: 'Elbow Extension (Overhead)',\n            severity: 'high',\n            description: 'Elbow should be nearly straight at contact point',\n            timestamps: [1.2, 3.5, 7.8],\n            drill: DRILLS['elbow-extension'],\n          },\n          {\n            code: 'KNEE_BEND',\n            title: 'Knee Bend',\n            severity: 'medium',\n            description: 'Bend knees more for power',\n            timestamps: [2.1, 5.3],\n            drill: DRILLS['lunge-practice'],\n          },\n        ];\n        setIssues(demoIssues);\n        setAutoLevelResult({\n          level: 'Intermediate',\n          confidence: 0.5,\n          rationaleBullets: ['Demo mode - upload video for real analysis'],\n        });\n        setResult({\n          top_issues: demoIssues.map(i => ({\n            id: i.code,\n            title: i.title,\n            severity: i.severity,\n            description: i.description || '',\n            affected_metrics: [],\n          })),\n          drills: demoIssues.map(i => i.drill).filter(Boolean).map(d => ({\n            id: d!.id,\n            name: d!.name,\n            description: d!.description,\n            duration_minutes: d!.durationMinutes,\n            target_metrics: d!.targetMetrics,\n            instructions: d!.steps,\n          })),\n          technique_summary: 'Demo analysis complete. Enable camera permissions for real-time pose detection.',\n          strategy_summary: '',\n          training_plan: [],\n        });\n      }\n\n    } catch (err) {\n      console.error('Analysis error:', err);\n      setError('Failed to analyze video. Please try again.');\n      setAnalysisState('ERROR');\n    } finally {\n      setAnalyzing(false);\n      setAnalyzeProgress(100);\n    }\n  };\n\n  const saveAnalysisToDatabase = async (\n    file: File,\n    analyses: FrameAnalysis[],\n    detectedIssues: DetectedIssue[],\n    avgScore: number,\n    levelResult?: AutoLevelResult,\n    mistakeEventsData?: MistakeEvent[],\n    bestRepWindowData?: { startTime: number; endTime: number; score: number; shotType?: string }\n  ): Promise<{ success: boolean; sessionId?: string; error?: string }> => {\n    try {\n      const { data: { user } } = await supabase.auth.getUser();\n      if (!user) {\n        return { success: false, error: 'Not authenticated' };\n      }\n\n      let videoPath: string | null = null;\n      let publicVideoUrl = '';\n\n      try {\n        videoPath = await uploadVideo(file, user.id, (progress) => {\n          setAnalyzeProgress(Math.min(95, 60 + Math.round(progress * 0.35)));\n        });\n\n        if (!videoPath) {\n          throw new Error('Upload returned empty path');\n        }\n\n        publicVideoUrl = getVideoUrl(videoPath);\n        console.log('Video uploaded successfully:', videoPath);\n\n      } catch (uploadError) {\n        console.error('Video upload failed:', uploadError);\n        const errorMessage = uploadError instanceof Error\n          ? uploadError.message\n          : 'Failed to upload video. Please try again.';\n        setError(errorMessage);\n        return { success: false, error: errorMessage };\n      }\n\n      const passedFrames = analyses.filter(a => a.evaluation?.passed).length;\n      const totalFrames = analyses.filter(a => a.evaluation).length;\n\n      const { data: session, error: sessionError } = await supabase\n        .from('sessions')\n        .insert({\n          user_id: user.id,\n          type: 'analytics',\n          video_path: videoPath,\n          video_url: publicVideoUrl,\n          filename: file.name,\n          frame_count: analyses.length,\n          overall_score: Math.round(avgScore),\n          pose_data: analyses.map(a => a.landmarks),\n          status: 'ready',\n          match_format: matchFormat,\n          event_type: eventType || null,\n          selected_tracks: selectedTrackIds,\n          skill_level: levelResult?.level.toLowerCase() || 'intermediate',\n          rules_version: 'v1',\n          // V4 FEATURES: Store computed skill metrics\n          skill_score: avgScore,\n          skill_confidence: levelResult?.confidence || 0.5,\n          best_rep_window: bestRepWindowData || null,\n          summary: {\n            total_frames: totalFrames,\n            green_frames: passedFrames,\n            red_frames: totalFrames - passedFrames,\n            green_ratio: totalFrames > 0 ? passedFrames / totalFrames : 0,\n            average_score: avgScore,\n            duration_seconds: duration,\n            auto_level: levelResult,\n          },\n        })\n        .select()\n        .single();\n\n      if (sessionError) {\n        console.error('Session save error:', sessionError);\n        return { success: false, error: 'Failed to save session data' };\n      }\n\n      if (session && detectedIssues.length > 0) {\n        const issueInserts = detectedIssues.map(issue => ({\n          session_id: session.id,\n          code: issue.code,\n          title: issue.title,\n          severity: issue.severity,\n          description: issue.description,\n          timestamps: issue.timestamps,\n          drill: issue.drill,\n        }));\n\n        const { error: issuesError } = await supabase.from('issues').insert(issueInserts);\n        if (issuesError) {\n          console.warn('Issues save warning:', issuesError);\n        }\n      }\n\n      // V4 FEATURE: Save mistake events for timeline\n      if (session && mistakeEventsData && mistakeEventsData.length > 0) {\n        const mistakeInserts = mistakeEventsData.map(mistake => ({\n          session_id: session.id,\n          type: mistake.type,\n          start_time_sec: mistake.startTimeSec,\n          end_time_sec: mistake.endTimeSec,\n          severity: mistake.severity,\n          confidence: mistake.confidence,\n          joints: mistake.joints,\n          summary_title: mistake.summaryTitle,\n        }));\n\n        const { error: mistakeError } = await supabase.from('mistake_events').insert(mistakeInserts);\n        if (mistakeError) {\n          console.warn('Mistake events save warning:', mistakeError);\n        }\n      }\n\n      setAnalyzeProgress(100);\n      return { success: true, sessionId: session.id };\n\n    } catch (err) {\n      console.error('Error saving to database:', err);\n      const errorMessage = err instanceof Error ? err.message : 'Failed to save analysis';\n      return { success: false, error: errorMessage };\n    }\n  };\n\n  // PHASE 2 FIX: Video frame rendering with proper canvas alignment\n  const renderFrame = useCallback(() => {\n    if (!videoRef.current || !canvasRef.current || !videoContainerRef.current) return;\n\n    const video = videoRef.current;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return;\n\n    // PHASE 2 FIX: Calculate actual rendered video dimensions (accounting for object-contain)\n    const container = videoContainerRef.current;\n    const containerRect = container.getBoundingClientRect();\n\n    if (video.videoWidth === 0 || video.videoHeight === 0) return;\n\n    const videoAspect = video.videoWidth / video.videoHeight;\n    const containerAspect = containerRect.width / containerRect.height;\n\n    let renderWidth, renderHeight, offsetX, offsetY;\n\n    if (videoAspect > containerAspect) {\n      // Video is wider - letterbox top/bottom\n      renderWidth = containerRect.width;\n      renderHeight = containerRect.width / videoAspect;\n      offsetX = 0;\n      offsetY = (containerRect.height - renderHeight) / 2;\n    } else {\n      // Video is taller - letterbox left/right\n      renderHeight = containerRect.height;\n      renderWidth = containerRect.height * videoAspect;\n      offsetX = (containerRect.width - renderWidth) / 2;\n      offsetY = 0;\n    }\n\n    // Set canvas to match container size\n    if (canvas.width !== containerRect.width || canvas.height !== containerRect.height) {\n      canvas.width = containerRect.width;\n      canvas.height = containerRect.height;\n    }\n\n    // Clear canvas\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (!showSkeleton) return;\n\n    // Find the closest frame analysis\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - video.currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    // Also check raw poseData array (for loaded sessions)\n    if (!closestFrame && poseData.length > 0) {\n      const frameIndex = Math.floor(video.currentTime * 10);\n      const landmarks = poseData[Math.min(frameIndex, poseData.length - 1)];\n      if (landmarks) {\n        closestFrame = {\n          timestamp: video.currentTime,\n          landmarks,\n          evaluation: evaluateForm(landmarks, 'general'),\n          metrics: extractMetrics(landmarks),\n        };\n      }\n    }\n\n    if (closestFrame?.landmarks) {\n      // Get skill level from auto-detection or default to intermediate\n      const skillLevel = (autoLevelResult?.level.toLowerCase() || 'intermediate') as 'beginner' | 'intermediate' | 'advanced';\n      const bandedResult = evaluateWithBands(closestFrame.landmarks, skillLevel);\n      setCurrentBandedScore(bandedResult);\n\n      const isGreen = bandedResult.overall_band === 'green';\n      const isYellow = bandedResult.overall_band === 'yellow';\n      const color = isGreen ? '#22c55e' : isYellow ? '#eab308' : '#ef4444';\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.fillStyle = color;\n\n      // PHASE 2 FIX: Draw skeleton with proper offset and scaling\n      for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n        const start = closestFrame.landmarks[startIdx];\n        const end = closestFrame.landmarks[endIdx];\n        if (start && end && start.visibility > 0.5 && end.visibility > 0.5) {\n          ctx.beginPath();\n          // Apply offset and scale to match actual video render position\n          ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n          ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n          ctx.stroke();\n        }\n      }\n\n      // Draw joints\n      for (const landmark of closestFrame.landmarks) {\n        if (landmark.visibility > 0.5) {\n          ctx.beginPath();\n          ctx.arc(\n            offsetX + landmark.x * renderWidth,\n            offsetY + landmark.y * renderHeight,\n            5,\n            0,\n            2 * Math.PI\n          );\n          ctx.fill();\n        }\n      }\n\n      // V4 FEATURE: Draw Ghost Overlay if enabled\n      if (showGhost && ghostData?.enabled && ghostData.poseSequence.length > 0) {\n        const ghostLandmarks = getGhostPoseAtTime(ghostData, video.currentTime);\n        if (ghostLandmarks) {\n          const ghostColor = 'rgba(100, 200, 255, 0.6)'; // Light blue with transparency\n\n          // Draw ghost connections\n          ctx.strokeStyle = ghostColor;\n          ctx.lineWidth = 2;\n\n          for (const [startIdx, endIdx] of POSE_CONNECTIONS) {\n            const start = ghostLandmarks[startIdx];\n            const end = ghostLandmarks[endIdx];\n            if (start && end && (start.visibility ?? 0) > 0.5 && (end.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.moveTo(offsetX + start.x * renderWidth, offsetY + start.y * renderHeight);\n              ctx.lineTo(offsetX + end.x * renderWidth, offsetY + end.y * renderHeight);\n              ctx.stroke();\n            }\n          }\n\n          // Draw ghost joints\n          ctx.fillStyle = ghostColor;\n          for (const landmark of ghostLandmarks) {\n            if ((landmark.visibility ?? 0) > 0.5) {\n              ctx.beginPath();\n              ctx.arc(\n                offsetX + landmark.x * renderWidth,\n                offsetY + landmark.y * renderHeight,\n                4,\n                0,\n                2 * Math.PI\n              );\n              ctx.fill();\n            }\n          }\n        }\n      }\n    }\n\n    if (!video.paused) {\n      animationRef.current = requestAnimationFrame(renderFrame);\n    }\n  }, [frameAnalyses, poseData, showSkeleton, autoLevelResult, showGhost, ghostData]);\n\n  // Trigger skeleton render when poseData is loaded\n  useEffect(() => {\n    if (poseData.length > 0 && videoRef.current) {\n      const tryRender = () => {\n        if (videoRef.current && videoRef.current.readyState >= 2) {\n          renderFrame();\n        } else {\n          setTimeout(tryRender, 100);\n        }\n      };\n      tryRender();\n    }\n  }, [poseData, renderFrame]);\n\n  // Handle video time updates\n  const handleTimeUpdate = useCallback(() => {\n    if (videoRef.current) {\n      setCurrentTime(videoRef.current.currentTime);\n      renderFrame();\n    }\n  }, [renderFrame]);\n\n  // Handle video play/pause\n  const togglePlayPause = useCallback(() => {\n    if (videoRef.current) {\n      if (videoRef.current.paused) {\n        videoRef.current.play();\n        setIsPlaying(true);\n        animationRef.current = requestAnimationFrame(renderFrame);\n      } else {\n        videoRef.current.pause();\n        setIsPlaying(false);\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n      }\n    }\n  }, [renderFrame]);\n\n  // Jump to timestamp\n  const jumpToTimestamp = useCallback((timestamp: number) => {\n    if (videoRef.current) {\n      videoRef.current.currentTime = timestamp;\n      videoRef.current.pause();\n      setIsPlaying(false);\n      setCurrentTime(timestamp);\n      setTimeout(renderFrame, 50);\n    }\n  }, [renderFrame]);\n\n  // Find next mistake\n  const goToNextMistake = useCallback(() => {\n    const allTimestamps = issues\n      .flatMap((i) => i.timestamps || [])\n      .sort((a, b) => a - b);\n\n    const nextTimestamp = allTimestamps.find((t) => t > currentTime + 0.5);\n    if (nextTimestamp !== undefined) {\n      jumpToTimestamp(nextTimestamp);\n    } else if (allTimestamps.length > 0) {\n      jumpToTimestamp(allTimestamps[0]);\n    }\n  }, [issues, currentTime, jumpToTimestamp]);\n\n  // Handle video metadata loaded\n  const handleLoadedMetadata = useCallback(() => {\n    if (videoRef.current) {\n      setDuration(videoRef.current.duration);\n      setTimeout(renderFrame, 100);\n    }\n  }, [renderFrame]);\n\n  const getSeverityColor = (severity: string) => {\n    switch (severity) {\n      case 'high':\n        return 'bg-red-50 border-red-200 text-red-800';\n      case 'medium':\n        return 'bg-yellow-50 border-yellow-200 text-yellow-800';\n      case 'low':\n        return 'bg-green-50 border-green-200 text-green-800';\n      default:\n        return 'bg-gray-50 border-gray-200 text-gray-800';\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Get current frame info for display\n  const getCurrentFrameInfo = () => {\n    if (frameAnalyses.length === 0) return null;\n\n    let closestFrame: FrameAnalysis | null = null;\n    let minDiff = Infinity;\n\n    for (const frame of frameAnalyses) {\n      const diff = Math.abs(frame.timestamp - currentTime);\n      if (diff < minDiff) {\n        minDiff = diff;\n        closestFrame = frame;\n      }\n    }\n\n    return closestFrame;\n  };\n\n  const currentFrameInfo = getCurrentFrameInfo();\n\n  // PHASE 5: Get analysis state message\n  const getAnalysisStateMessage = () => {\n    switch (analysisState) {\n      case 'DETECTING_PLAYERS':\n        return 'Detecting players in video...';\n      case 'EXTRACTING_POSE':\n        return 'Extracting pose data from frames...';\n      case 'GEMINI_SCORING':\n        return 'AI analyzing skill level...';\n      case 'DONE':\n        return 'Analysis complete!';\n      case 'ERROR':\n        return 'Analysis failed';\n      default:\n        return 'Ready to analyze';\n    }\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          {/* Header */}\n          <div className=\"mb-8\">\n            <h1 className=\"text-3xl font-bold text-gray-900\">Video Analytics</h1>\n            <p className=\"text-gray-600 mt-1\">\n              {sessionId ? 'Review your analysis results' : 'Upload a video for AI-powered technique analysis'}\n            </p>\n          </div>\n\n          {/* Upload Section */}\n          {!result && !videoUrl && (\n            <div className=\"bg-white rounded-xl p-8 shadow-sm mb-8\">\n              <div\n                className={`border-2 border-dashed rounded-xl p-12 text-center transition ${\n                  uploading || analyzing\n                    ? 'border-primary-300 bg-primary-50'\n                    : 'border-gray-300 hover:border-primary-400'\n                }`}\n              >\n                {uploading ? (\n                  <div className=\"space-y-4\">\n                    <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary-500 mx-auto\"></div>\n                    <p className=\"text-gray-600\">Uploading video...</p>\n                  </div>\n                ) : analyzing ? (\n                  // PHASE 5: Enhanced loading state with state machine\n                  <div className=\"space-y-4\">\n                    <div className=\"w-16 h-16 bg-primary-100 rounded-full flex items-center justify-center mx-auto relative\">\n                      <svg className=\"w-8 h-8 text-primary-500 animate-pulse\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z\" />\n                      </svg>\n                      {/* Spinning ring */}\n                      <div className=\"absolute inset-0 border-4 border-primary-200 border-t-primary-500 rounded-full animate-spin\"></div>\n                    </div>\n                    <p className=\"text-gray-900 font-medium\">{getAnalysisStateMessage()}</p>\n\n                    {/* Progress steps */}\n                    <div className=\"flex justify-center gap-2 mt-4\">\n                      {['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].map((state, idx) => (\n                        <div\n                          key={state}\n                          className={`w-3 h-3 rounded-full transition-colors ${\n                            analysisState === state\n                              ? 'bg-primary-500 animate-pulse'\n                              : ['DETECTING_PLAYERS', 'EXTRACTING_POSE', 'GEMINI_SCORING', 'DONE'].indexOf(analysisState) > idx\n                              ? 'bg-green-500'\n                              : 'bg-gray-300'\n                          }`}\n                        />\n                      ))}\n                    </div>\n                    <p className=\"text-gray-500 text-sm\">\n                      {analysisState === 'DETECTING_PLAYERS' && 'Finding players in the video...'}\n                      {analysisState === 'EXTRACTING_POSE' && 'Processing pose detection frame by frame'}\n                      {analysisState === 'GEMINI_SCORING' && 'AI is evaluating your technique'}\n                    </p>\n\n                    <div className=\"w-64 mx-auto bg-gray-200 rounded-full h-2\">\n                      <div\n                        className=\"bg-primary-500 h-2 rounded-full transition-all duration-300\"\n                        style={{ width: `${analyzeProgress}%` }}\n                      ></div>\n                    </div>\n                    <p className=\"text-sm text-gray-500\">{analyzeProgress}% complete</p>\n                  </div>\n                ) : (\n                  <>\n                    <div className=\"w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                      <svg className=\"w-8 h-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\" />\n                      </svg>\n                    </div>\n                    <h3 className=\"text-lg font-medium text-gray-900 mb-2\">Upload your badminton video</h3>\n                    <p className=\"text-gray-500 mb-4\">MP4, MOV, or WebM up to 100MB</p>\n                    {poseLandmarkerReady && (\n                      <p className=\"text-sm text-green-600 mb-4\">Pose detection ready</p>\n                    )}\n                    <input ref={fileInputRef} type=\"file\" accept=\"video/*\" onChange={handleFileSelect} className=\"hidden\" />\n                    <button onClick={() => fileInputRef.current?.click()} className=\"px-6 py-3 bg-primary-500 text-white rounded-lg font-medium hover:bg-primary-600 transition\">\n                      Select Video\n                    </button>\n                  </>\n                )}\n              </div>\n\n              {error && (\n                <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\">{error}</div>\n              )}\n            </div>\n          )}\n\n          {/* Video Player with Overlay */}\n          {videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-8 mb-8\">\n              <div className=\"lg:col-span-2\">\n                <div className=\"bg-gray-900 rounded-xl overflow-hidden\">\n                  {/* PHASE 2 FIX: Proper video container for canvas alignment */}\n                  <div ref={videoContainerRef} className=\"relative aspect-video\">\n                    <video\n                      ref={videoRef}\n                      src={videoUrl}\n                      className=\"absolute inset-0 w-full h-full object-contain\"\n                      onTimeUpdate={handleTimeUpdate}\n                      onLoadedMetadata={handleLoadedMetadata}\n                      onEnded={() => setIsPlaying(false)}\n                      playsInline\n                    />\n                    <canvas\n                      ref={canvasRef}\n                      className={`absolute inset-0 w-full h-full pointer-events-none ${\n                        showSkeleton ? '' : 'hidden'\n                      }`}\n                    />\n\n                    {/* Status indicator with auto-detected level */}\n                    {currentBandedScore && (\n                      <div className={`absolute top-4 left-4 px-3 py-1.5 rounded-full text-sm font-medium ${\n                        currentBandedScore.overall_band === 'green' ? 'bg-green-500 text-white' :\n                        currentBandedScore.overall_band === 'yellow' ? 'bg-yellow-500 text-white' :\n                        currentBandedScore.overall_band === 'red' ? 'bg-red-500 text-white' :\n                        'bg-gray-500 text-white'\n                      }`}>\n                        {SCORING_LEGEND[currentBandedScore.overall_band as keyof typeof SCORING_LEGEND]?.label || 'Unknown'}\n                        <span className=\"ml-2 opacity-75\">\n                          {Math.round(currentBandedScore.overall_score)}%\n                        </span>\n                      </div>\n                    )}\n\n                    {/* Time display */}\n                    <div className=\"absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm\">\n                      {formatTime(currentTime)} / {formatTime(duration)}\n                    </div>\n\n                    {/* Current metrics display */}\n                    {currentFrameInfo?.metrics && (\n                      <div className=\"absolute bottom-16 left-4 bg-black/70 text-white p-3 rounded-lg text-xs\">\n                        <p>Elbow: {currentFrameInfo.metrics.elbow_angle.toFixed(0)}deg</p>\n                        <p>Knee: {currentFrameInfo.metrics.knee_angle.toFixed(0)}deg</p>\n                        <p>Stance: {(currentFrameInfo.metrics.stance_width_norm * 100).toFixed(0)}%</p>\n                      </div>\n                    )}\n                  </div>\n\n                  {/* Controls - PHASE 3: Removed skill level dropdown */}\n                  <div className=\"p-4 flex items-center justify-between\">\n                    <div className=\"flex items-center gap-2\">\n                      <button\n                        onClick={togglePlayPause}\n                        className=\"p-2 bg-primary-500 text-white rounded-lg hover:bg-primary-600 transition\"\n                      >\n                        {isPlaying ? (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        ) : (\n                          <svg className=\"w-6 h-6\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z\" />\n                            <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth={2} d=\"M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n                          </svg>\n                        )}\n                      </button>\n\n                      <button\n                        onClick={goToNextMistake}\n                        disabled={issues.length === 0 || analyzing}\n                        className=\"px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition text-sm font-medium disabled:opacity-50\"\n                      >\n                        Next Mistake\n                      </button>\n                    </div>\n\n                    <div className=\"flex items-center gap-4\">\n                      {/* PHASE 3: Show auto-detected level instead of dropdown */}\n                      {autoLevelResult && (\n                        <div className=\"flex items-center gap-2 text-white text-sm\">\n                          <span className=\"px-2 py-1 bg-primary-600 rounded text-xs font-medium\">\n                            {autoLevelResult.level}\n                          </span>\n                          <span className=\"text-gray-400 text-xs\">\n                            {Math.round(autoLevelResult.confidence * 100)}% confidence\n                          </span>\n                        </div>\n                      )}\n\n                      <label className=\"flex items-center gap-2 text-white text-sm\">\n                        <input\n                          type=\"checkbox\"\n                          checked={showSkeleton}\n                          onChange={(e) => {\n                            setShowSkeleton(e.target.checked);\n                            if (e.target.checked) {\n                              setTimeout(renderFrame, 50);\n                            }\n                          }}\n                          className=\"rounded\"\n                        />\n                        Show Skeleton\n                      </label>\n\n                      {/* V4 FEATURE: Ghost overlay toggle */}\n                      {ghostData && ghostData.poseSequence.length > 0 && (\n                        <label className=\"flex items-center gap-2 text-white text-sm\">\n                          <input\n                            type=\"checkbox\"\n                            checked={showGhost}\n                            onChange={(e) => {\n                              setShowGhost(e.target.checked);\n                              if (e.target.checked) {\n                                setTimeout(renderFrame, 50);\n                              }\n                            }}\n                            className=\"rounded accent-cyan-400\"\n                          />\n                          <span className=\"text-cyan-400\">Ghost (Best Rep)</span>\n                        </label>\n                      )}\n                    </div>\n                  </div>\n\n                  {/* Timeline scrubber */}\n                  <div className=\"px-4 pb-4\">\n                    <input\n                      type=\"range\"\n                      min={0}\n                      max={duration || 100}\n                      step={0.1}\n                      value={currentTime}\n                      onChange={(e) => {\n                        const time = parseFloat(e.target.value);\n                        if (videoRef.current) {\n                          videoRef.current.currentTime = time;\n                          setCurrentTime(time);\n                          setTimeout(renderFrame, 50);\n                        }\n                      }}\n                      className=\"w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer\"\n                    />\n                  </div>\n\n                  {/* V4 FEATURE: Mistake Timeline */}\n                  {mistakeEvents.length > 0 && duration > 0 && (\n                    <div className=\"px-4 pb-4\">\n                      <MistakeTimeline\n                        mistakes={mistakeEvents}\n                        duration={duration}\n                        currentTime={currentTime}\n                        onSeek={(time) => {\n                          if (videoRef.current) {\n                            videoRef.current.currentTime = time;\n                            setCurrentTime(time);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        onSelectMistake={(mistake) => {\n                          setSelectedMistake(mistake);\n                          if (mistake && videoRef.current) {\n                            videoRef.current.currentTime = mistake.startTimeSec;\n                            setCurrentTime(mistake.startTimeSec);\n                            setTimeout(renderFrame, 50);\n                          }\n                        }}\n                        selectedMistakeId={selectedMistake?.id}\n                      />\n                    </div>\n                  )}\n                </div>\n\n                {/* V4 FEATURE: SkillMeter with computed metrics */}\n                {computedSkill && (\n                  <div className=\"mt-6\">\n                    <SkillMeter skillData={computedSkill} />\n                  </div>\n                )}\n\n                {/* V4 FEATURE: FixItCard for selected mistake */}\n                {selectedMistake && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-3\">\n                      <h3 className=\"font-semibold text-gray-900\">Fix This Mistake</h3>\n                      <button\n                        onClick={() => setSelectedMistake(null)}\n                        className=\"text-sm text-gray-500 hover:text-gray-700\"\n                      >\n                        Close\n                      </button>\n                    </div>\n                    <FixItCard\n                      mistake={selectedMistake}\n                      fixKeyframes={poseData.length > 0 ? generateFixKeyframes(selectedMistake, poseData, 10) : undefined}\n                      onClose={() => setSelectedMistake(null)}\n                    />\n                  </div>\n                )}\n\n                {/* PHASE 3: Auto-level detection result panel (Gemini rationale) */}\n                {autoLevelResult && autoLevelResult.rationaleBullets.length > 0 && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">AI Analysis Notes</h3>\n                      <span className={`px-3 py-1 rounded-full text-sm font-medium ${\n                        autoLevelResult.level === 'Advanced' ? 'bg-green-100 text-green-800' :\n                        autoLevelResult.level === 'Intermediate' ? 'bg-yellow-100 text-yellow-800' :\n                        'bg-blue-100 text-blue-800'\n                      }`}>\n                        {autoLevelResult.level}\n                      </span>\n                    </div>\n                    <div className=\"space-y-2\">\n                      {autoLevelResult.rationaleBullets.map((bullet, idx) => (\n                        <div key={idx} className=\"flex items-start gap-2 text-sm text-gray-600\">\n                          <svg className=\"w-4 h-4 text-primary-500 mt-0.5 flex-shrink-0\" fill=\"currentColor\" viewBox=\"0 0 20 20\">\n                            <path fillRule=\"evenodd\" d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\" clipRule=\"evenodd\" />\n                          </svg>\n                          <span>{bullet}</span>\n                        </div>\n                      ))}\n                    </div>\n                  </div>\n                )}\n\n                {/* PHASE 4: Guidance Animation */}\n                {guidanceKeyframes.length > 0 && (\n                  <div className=\"mt-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"font-semibold text-gray-900\">Movement Guidance</h3>\n                      <button\n                        onClick={() => setShowGuidance(!showGuidance)}\n                        className=\"text-sm text-primary-600 hover:text-primary-700\"\n                      >\n                        {showGuidance ? 'Hide' : 'Show'} Animation\n                      </button>\n                    </div>\n                    {showGuidance && (\n                      <GuidanceAnimation\n                        keyframes={guidanceKeyframes}\n                        primaryIssue={issues[0]}\n                      />\n                    )}\n                  </div>\n                )}\n\n                {/* Analysis Summary */}\n                {result && (\n                  <div className=\"mt-6 bg-white rounded-xl p-6 shadow-sm\">\n                    <h3 className=\"font-semibold text-gray-900 mb-3\">Analysis Summary</h3>\n                    <p className=\"text-gray-600\">{result.technique_summary}</p>\n                    {result.strategy_summary && (\n                      <p className=\"text-gray-500 mt-2 text-sm\">{result.strategy_summary}</p>\n                    )}\n                  </div>\n                )}\n              </div>\n\n              {/* Issues Panel */}\n              <div className=\"space-y-4\">\n                <h3 className=\"font-semibold text-gray-900\">Detected Issues</h3>\n                {analyzing ? (\n                  <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                    {/* Shimmer loading animation */}\n                    <div className=\"animate-pulse space-y-4\">\n                      <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-1/2\"></div>\n                      <div className=\"h-20 bg-gray-200 rounded\"></div>\n                      <div className=\"h-4 bg-gray-200 rounded w-2/3\"></div>\n                    </div>\n                  </div>\n                ) : issues.length > 0 ? (\n                  <div className=\"space-y-4 max-h-[600px] overflow-y-auto\">\n                    {issues.map((issue, index) => (\n                      <DrillCard\n                        key={index}\n                        issue={issue}\n                        onTimestampClick={jumpToTimestamp}\n                        currentTime={currentTime}\n                      />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"bg-green-50 border border-green-200 rounded-xl p-4 text-green-800\">\n                    <p className=\"font-medium\">Great form!</p>\n                    <p className=\"text-sm\">No major issues detected in this video.</p>\n                  </div>\n                )}\n\n                {/* Reset button */}\n                {videoUrl && !analyzing && (\n                  <button\n                    onClick={() => {\n                      setResult(null);\n                      setVideoUrl(null);\n                      setVideoFile(null);\n                      setIssues([]);\n                      setPoseData([]);\n                      setFrameAnalyses([]);\n                      setCurrentTime(0);\n                      setDuration(0);\n                      setAutoLevelResult(null);\n                      setGuidanceKeyframes([]);\n                      setAnalysisState('IDLE');\n                      // V4 state reset\n                      setGhostData(null);\n                      setShowGhost(false);\n                      setComputedSkill(null);\n                      setMistakeEvents([]);\n                      setSelectedMistake(null);\n                    }}\n                    className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                  >\n                    Analyze Another Video\n                  </button>\n                )}\n              </div>\n            </div>\n          )}\n\n          {/* Results Section (legacy format without video) */}\n          {result && !videoUrl && (\n            <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-8\">\n              {/* Left Column - Issues */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Areas to Improve</h2>\n                  <div className=\"space-y-3\">\n                    {result.top_issues.map((issue) => (\n                      <button\n                        key={issue.id}\n                        onClick={() => setSelectedIssue(issue)}\n                        className={`w-full text-left p-4 rounded-lg border transition ${\n                          selectedIssue?.id === issue.id ? 'ring-2 ring-primary-500' : ''\n                        } ${getSeverityColor(issue.severity)}`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium\">{issue.title}</span>\n                          <span className=\"text-xs uppercase font-semibold\">{issue.severity}</span>\n                        </div>\n                        <p className=\"text-sm opacity-80\">{issue.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-3\">Technique Summary</h2>\n                  <p className=\"text-gray-600\">{result.technique_summary}</p>\n                </div>\n              </div>\n\n              {/* Right Column - Drills */}\n              <div className=\"space-y-6\">\n                <div className=\"bg-white rounded-xl p-6 shadow-sm\">\n                  <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">Recommended Drills</h2>\n                  <div className=\"space-y-3\">\n                    {result.drills.map((drill) => (\n                      <button\n                        key={drill.id}\n                        onClick={() => setSelectedDrill(drill)}\n                        className={`w-full text-left p-4 rounded-lg border border-gray-200 hover:border-primary-300 transition ${\n                          selectedDrill?.id === drill.id ? 'ring-2 ring-primary-500 border-primary-300' : ''\n                        }`}\n                      >\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <span className=\"font-medium text-gray-900\">{drill.name}</span>\n                          <span className=\"text-sm text-gray-500\">{drill.duration_minutes} min</span>\n                        </div>\n                        <p className=\"text-sm text-gray-600\">{drill.description}</p>\n                      </button>\n                    ))}\n                  </div>\n                </div>\n\n                {selectedDrill && (\n                  <div className=\"bg-gradient-to-br from-primary-50 to-primary-100 rounded-xl p-6\">\n                    <div className=\"flex items-center justify-between mb-4\">\n                      <h3 className=\"text-lg font-semibold text-gray-900\">{selectedDrill.name}</h3>\n                      <Link\n                        href={`/practice?drill=${selectedDrill.id}`}\n                        className=\"px-4 py-2 bg-primary-500 text-white rounded-lg text-sm font-medium hover:bg-primary-600 transition\"\n                      >\n                        Let&apos;s Practice\n                      </Link>\n                    </div>\n                    <div className=\"space-y-3\">\n                      <p className=\"text-gray-700\">{selectedDrill.description}</p>\n                      <div>\n                        <p className=\"font-medium text-gray-900 mb-2\">Instructions:</p>\n                        <ol className=\"list-decimal list-inside space-y-1 text-gray-700\">\n                          {selectedDrill.instructions.map((instruction, i) => (\n                            <li key={i}>{instruction}</li>\n                          ))}\n                        </ol>\n                      </div>\n                    </div>\n                  </div>\n                )}\n\n                <button\n                  onClick={() => {\n                    setResult(null);\n                    setSelectedIssue(null);\n                    setSelectedDrill(null);\n                    setVideoUrl(null);\n                    setPoseData([]);\n                    setIssues([]);\n                    setAutoLevelResult(null);\n                    setGuidanceKeyframes([]);\n                    setAnalysisState('IDLE');\n                    // V4 state reset\n                    setGhostData(null);\n                    setShowGhost(false);\n                    setComputedSkill(null);\n                    setMistakeEvents([]);\n                    setSelectedMistake(null);\n                  }}\n                  className=\"w-full py-3 border border-gray-300 rounded-lg text-gray-700 font-medium hover:bg-gray-50 transition\"\n                >\n                  Analyze Another Video\n                </button>\n              </div>\n            </div>\n          )}\n        </div>\n      </main>\n\n      {/* Player Selection Modal */}\n      <PlayerSelectionModal\n        isOpen={showPlayerSelection}\n        onClose={() => {\n          setShowPlayerSelection(false);\n          setAnalyzing(false);\n          setVideoUrl(null);\n          setVideoFile(null);\n          setAnalysisState('IDLE');\n          // V4 state reset\n          setGhostData(null);\n          setShowGhost(false);\n          setComputedSkill(null);\n          setMistakeEvents([]);\n          setSelectedMistake(null);\n        }}\n        onConfirm={handlePlayerSelectionConfirm}\n        tracks={detectedTracks}\n        detectedFormat={detectedMatchFormat}\n      />\n    </div>\n  );\n}\n\nfunction AnalyticsLoading() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      <DashboardNav />\n      <main className=\"ml-64 p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"animate-pulse\">\n            <div className=\"h-8 bg-gray-200 rounded w-48 mb-4\"></div>\n            <div className=\"h-4 bg-gray-200 rounded w-96 mb-8\"></div>\n            <div className=\"bg-gray-200 rounded-xl h-96\"></div>\n          </div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nexport default function AnalyticsPage() {\n  return (\n    <Suspense fallback={<AnalyticsLoading />}>\n      <AnalyticsContent />\n    </Suspense>\n  );\n}\n","structuredPatch":[{"oldStart":756,"oldLines":6,"newStart":756,"newLines":12,"lines":["     setFrameAnalyses([]);","     setAutoLevelResult(null);","     setGuidanceKeyframes([]);","+    // V4 state reset","+    setGhostData(null);","+    setShowGhost(false);","+    setComputedSkill(null);","+    setMistakeEvents([]);","+    setSelectedMistake(null);"," ","     // Create object URL for video preview","     const objectUrl = URL.createObjectURL(file);"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"3004bf16-e65b-4c84-b7e1-bfb4e9eb9f70"}
{"parentUuid":"4601f1ec-a136-4394-8ae1-17d2da19e382","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_015X3jgxxkXUbH4ubKkYGEpe","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me run a TypeScript check to ensure there are no errors.","signature":"EugBCkYICxgCKkAOyxCkWapvSAKQTvXbEOZH6rV3VW13mAsKL8u7weMOw+JFjl5lk9cIICF3rdW2hf81giaMSSZ2A1gNNW630pjaEgxVibzrOvt3d7hDkEMaDCwfvDPfyravW9zxGCIw4Pcblw3D0CtDiiWPyIHZ0RgR68Voop9DVgIjfvXEgGWI060eHO8nk7BQOdfApBuAKlBM1yQCtzNMcjLDPNMkOESljXv3BgnGNl0Eh9LDLcLeDur7v1JNFqhTyS36z2aVcJDCeLbSAhQlFuOYYeDaiNJYS/Tiyq9zdHe/uq0FL8NPehgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":431,"cache_read_input_tokens":101218,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":431},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeKXph8S847dYtL8uVX","type":"assistant","uuid":"a6546c17-3e12-449f-81a6-fd36b3bdc1ef","timestamp":"2026-01-28T23:28:47.511Z"}
{"parentUuid":"a6546c17-3e12-449f-81a6-fd36b3bdc1ef","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_015X3jgxxkXUbH4ubKkYGEpe","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me run TypeScript to verify there are no errors."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":431,"cache_read_input_tokens":101218,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":431},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeKXph8S847dYtL8uVX","type":"assistant","uuid":"3b7e3566-b186-4886-8b39-2c31d6814aba","timestamp":"2026-01-28T23:28:47.887Z"}
{"parentUuid":"3b7e3566-b186-4886-8b39-2c31d6814aba","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_015X3jgxxkXUbH4ubKkYGEpe","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LQFj2HQiCpYgMyq1dKnjB5","name":"Bash","input":{"command":"cd \"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\" && npx tsc --noEmit 2>&1 | head -50","description":"Run TypeScript check","timeout":60000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":431,"cache_read_input_tokens":101218,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":431},"output_tokens":4,"service_tier":"standard"}},"requestId":"req_011CXaeKXph8S847dYtL8uVX","type":"assistant","uuid":"77eb1daa-acb9-441e-8fe6-4ea159e44e03","timestamp":"2026-01-28T23:28:48.941Z"}
{"parentUuid":"77eb1daa-acb9-441e-8fe6-4ea159e44e03","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LQFj2HQiCpYgMyq1dKnjB5","type":"tool_result","content":"src/lib/mistake-detection.ts(459,31): error TS2802: Type 'Map<string, { startFrame: number; frames: number; confidence: number; }>' can only be iterated through when using the '--downlevelIteration' flag or with a '--target' of 'es2015' or higher.","is_error":false}]},"uuid":"2c2aa253-a033-4dd6-af1b-898a81b62ed7","timestamp":"2026-01-28T23:28:54.889Z","toolUseResult":{"stdout":"src/lib/mistake-detection.ts(459,31): error TS2802: Type 'Map<string, { startFrame: number; frames: number; confidence: number; }>' can only be iterated through when using the '--downlevelIteration' flag or with a '--target' of 'es2015' or higher.\r","stderr":"","interrupted":false,"isImage":false},"sourceToolAssistantUUID":"77eb1daa-acb9-441e-8fe6-4ea159e44e03"}
{"parentUuid":"2c2aa253-a033-4dd6-af1b-898a81b62ed7","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01P5qyyhf6EHjERWr2K1M3vA","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"There's a TypeScript error in mistake-detection.ts related to iterating over a Map. This is an existing issue not related to my changes. The analytics page should be fine. Let me specifically check if there are any errors in the analytics page.","signature":"Ep0DCkYICxgCKkB32hzskbM9ilBj63cyCFlMlpEuMs3F/O5PKzjeQAONR310nx3dJo+WISYBRp584qZtnO9REPZoPI8wrAqesB9VEgyiiWizS0HKKfPqXYAaDKwuYhDKcsAQssJsZSIwsc/+e8N/9Een+n1xcuu9oyl9ZxbTlF+VXowlo6+MIgWXdpOiDJrfuMDAd9Jke6VdKoQCdIxzdHFiHTeb8wBLcCx4HbPR/QPqXtKx5oTPK02dm2iogVoUi3mVJGf/bc1vY8Bvz7yExzDb4WN+v47PQk2zb49LcwRO2qgJCD2/YMDlXEaySGQ7zd8/xXrESyuseviH7ol58hPcylPTi3aP71BunR0QpOlpsRkZ5ujwyD6AOWXJiYHUqLOBQzJXkzJ5Qqet592FVXfkKYuZLgsmAd8mzxKk/J6a7/Lo//3oBkL8J8fA/Uq81CTZM0zpFwr3+SnY+W1o0T/0rfd1U/6pF7Iz/W9eRjeJ1JdhHDRYYl0+Y9cYrGAhwgoh4bThc50h0cH+kMDztPnow/qV/opwnTlCc113qxUYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":263,"cache_read_input_tokens":101649,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":263},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeLFJYoP5nWgqZvqSAb","type":"assistant","uuid":"ac82e652-fddd-4013-ad2b-4c16b92c92d1","timestamp":"2026-01-28T23:28:57.821Z"}
{"parentUuid":"ac82e652-fddd-4013-ad2b-4c16b92c92d1","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01P5qyyhf6EHjERWr2K1M3vA","type":"message","role":"assistant","content":[{"type":"text","text":"The error is in mistake-detection.ts (pre-existing). Let me check specifically for analytics page errors."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":263,"cache_read_input_tokens":101649,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":263},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeLFJYoP5nWgqZvqSAb","type":"assistant","uuid":"be8f1ca5-ba89-429d-acd9-087d1b2cd771","timestamp":"2026-01-28T23:28:58.400Z"}
{"parentUuid":"be8f1ca5-ba89-429d-acd9-087d1b2cd771","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01P5qyyhf6EHjERWr2K1M3vA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XXYf6q1PA4xgJ4uftmKLZt","name":"Bash","input":{"command":"cd \"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\" && npx tsc --noEmit 2>&1 | grep -E \"analytics/page|types.ts|ghost-overlay|skill-scoring\" || echo \"No errors in target files\"","description":"Check for errors in target files","timeout":60000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":263,"cache_read_input_tokens":101649,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":263},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeLFJYoP5nWgqZvqSAb","type":"assistant","uuid":"2549da27-70ca-495c-80bc-14b057347f31","timestamp":"2026-01-28T23:29:00.000Z"}
{"parentUuid":"2549da27-70ca-495c-80bc-14b057347f31","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XXYf6q1PA4xgJ4uftmKLZt","type":"tool_result","content":"No errors in target files","is_error":false}]},"uuid":"5dbbc830-955e-47c1-ac9b-89749b571cc7","timestamp":"2026-01-28T23:29:02.695Z","toolUseResult":{"stdout":"No errors in target files\r","stderr":"","interrupted":false,"isImage":false},"sourceToolAssistantUUID":"2549da27-70ca-495c-80bc-14b057347f31"}
{"parentUuid":"5dbbc830-955e-47c1-ac9b-89749b571cc7","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_011ZCjJzhMUtr5c64qcbKijW","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The analytics page and related files have no TypeScript errors. Let me fix the mistake-detection.ts issue since it's part of the V4 features I was implementing.","signature":"EskCCkYICxgCKkAseBMuYbt+ehig6xvf2w+26Q8bUwj9NGRQvTBe14fnFyQ3UxaiUXg4QzT3TEK2rSu8MgyKGGg1TfNFEnV6iBKZEgxOdld84IzqJyNn6EAaDB2s0pLRHXNmOhfBfSIwVaSuPlXIRM3FFQjgCQYze9+J/xz4XDrrYA5zF6H5T1555HCvBpwCQTI3GLBYySuwKrABF7PFDTq9kOhvJUbiNXpXj7fBbCFSXTafi9bA2H2WR+Vdsjpq3KknEmtE6QTYm79wM+RZkEEav2Zh8bWBHEuvobALGH+5e/o9F4ZHvqkbV1SMCMul94xd/nMqrbyFiZwMT7S9IFkdUSJplEQNjLn6MyDpBJt25Re9ioBYbAL7SoPl2MXAmpucMTCWa0V16wy7D7gRSayvH1f13lqSNgMSMTr1HyPOFqgQuV4EE1IxMMoYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":268,"cache_read_input_tokens":101912,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":268},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeLpgV9m2heA7TbJktA","type":"assistant","uuid":"cdbf547a-fc7d-4fa3-a7db-fe0e2f850e99","timestamp":"2026-01-28T23:29:05.346Z"}
{"parentUuid":"cdbf547a-fc7d-4fa3-a7db-fe0e2f850e99","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_011ZCjJzhMUtr5c64qcbKijW","type":"message","role":"assistant","content":[{"type":"text","text":"Let me fix the mistake-detection.ts issue as well since it's part of the V4 features."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":268,"cache_read_input_tokens":101912,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":268},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeLpgV9m2heA7TbJktA","type":"assistant","uuid":"9a45d6f1-e585-40e3-b6c0-315f874745e1","timestamp":"2026-01-28T23:29:05.823Z"}
{"parentUuid":"9a45d6f1-e585-40e3-b6c0-315f874745e1","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_011ZCjJzhMUtr5c64qcbKijW","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BDESSnRF3CuGSrKRRQK6DK","name":"Read","input":{"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","offset":455,"limit":15}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":268,"cache_read_input_tokens":101912,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":268},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXaeLpgV9m2heA7TbJktA","type":"assistant","uuid":"688e3c2c-7ea1-4325-b408-8aa9a200fad5","timestamp":"2026-01-28T23:29:06.497Z"}
{"parentUuid":"688e3c2c-7ea1-4325-b408-8aa9a200fad5","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BDESSnRF3CuGSrKRRQK6DK","type":"tool_result","content":"   455→    }\n   456→  }\n   457→\n   458→  // Close any remaining active issues\n   459→  for (const [code, issue] of activeIssues) {\n   460→    if (issue.frames >= MIN_PERSISTENCE_FRAMES) {\n   461→      const mistakeType = MISTAKE_TYPES[code as keyof typeof MISTAKE_TYPES];\n   462→      if (mistakeType) {\n   463→        mistakes.push({\n   464→          id: `${code}-${issue.startFrame}`,\n   465→          type: code,\n   466→          startTimeSec: issue.startFrame / fps,\n   467→          endTimeSec: poseData.length / fps,\n   468→          severity: mistakeType.severity,\n   469→          confidence: issue.confidence,\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"dab7860b-68c0-46eb-a098-0d5380a8e5f6","timestamp":"2026-01-28T23:29:07.138Z","toolUseResult":{"type":"text","file":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","content":"    }\n  }\n\n  // Close any remaining active issues\n  for (const [code, issue] of activeIssues) {\n    if (issue.frames >= MIN_PERSISTENCE_FRAMES) {\n      const mistakeType = MISTAKE_TYPES[code as keyof typeof MISTAKE_TYPES];\n      if (mistakeType) {\n        mistakes.push({\n          id: `${code}-${issue.startFrame}`,\n          type: code,\n          startTimeSec: issue.startFrame / fps,\n          endTimeSec: poseData.length / fps,\n          severity: mistakeType.severity,\n          confidence: issue.confidence,","numLines":15,"startLine":455,"totalLines":652}},"sourceToolAssistantUUID":"688e3c2c-7ea1-4325-b408-8aa9a200fad5"}
{"parentUuid":"dab7860b-68c0-46eb-a098-0d5380a8e5f6","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0131jiHdNLdRyE1PhDY1J8D4","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The issue is iterating over a Map. I can fix this by converting the Map to an array first, or by using Array.from. Let me fix it by using Array.from.","signature":"Er4CCkYICxgCKkCxkKLFnUdV5nKKN9p+J1DnHHvwFphce7R/GBgfdXtsTVRnmkXp4zHJekcYZyf7xkAPDcTqoQKd+MfgIhVKJx6MEgxhdYqpl3mGSoETy7oaDI28y44kexJMRbixdSIwEQ7LHheorFpu7jWJVMszLQGiBEjtb6o1QKHTe8EKHJlTVP7izwHJCrI8zChCn6IqKqUBpRToQF4nClDkkOO0ICgjcEgRsFW8FYjhom/7aKotwVFk9459QxH7HxwQt5gTGrjvfpvFtL2jBEWz5mn0ZoZzfKwVIH4RcIVoj6G3hWl04bW23M4WjREd+UTD4pczR2qbsTXoOQtJ1EIo26fKaIc8nJw02YOYbvllN7RxQUK50oSJzhunTxiK6y+rsLw/T4iGDrjmWtcWLrwX1lBgtvQ03gX8vzNgGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":485,"cache_read_input_tokens":102180,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":485},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeM9eG18dpEDixe2Fhp","type":"assistant","uuid":"4c9568a8-ba7b-4427-bdfb-ac353ac76b36","timestamp":"2026-01-28T23:29:10.180Z"}
{"parentUuid":"4c9568a8-ba7b-4427-bdfb-ac353ac76b36","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_0131jiHdNLdRyE1PhDY1J8D4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015n1VudtfR4sdUtEBNpChKz","name":"Edit","input":{"replace_all":false,"file_path":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","old_string":"  // Close any remaining active issues\n  for (const [code, issue] of activeIssues) {","new_string":"  // Close any remaining active issues\n  for (const [code, issue] of Array.from(activeIssues.entries())) {"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":485,"cache_read_input_tokens":102180,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":485},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeM9eG18dpEDixe2Fhp","type":"assistant","uuid":"73fc250c-1c6f-4645-8ff6-7b966c3761d6","timestamp":"2026-01-28T23:29:11.341Z"}
{"type":"file-history-snapshot","messageId":"73fc250c-1c6f-4645-8ff6-7b966c3761d6","snapshot":{"messageId":"fe658491-c683-4132-8e78-4cc3f12bf5ba","trackedFileBackups":{"rallycoach\\src\\app\\analytics\\page.tsx":{"backupFileName":"3f45345577d2b22e@v1","version":1,"backupTime":"2026-01-28T23:24:20.053Z"},"rallycoach\\src\\lib\\mistake-detection.ts":{"backupFileName":"ca351c545110e9df@v1","version":1,"backupTime":"2026-01-28T23:29:11.922Z"}},"timestamp":"2026-01-28T23:23:50.394Z"},"isSnapshotUpdate":true}
{"parentUuid":"73fc250c-1c6f-4645-8ff6-7b966c3761d6","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015n1VudtfR4sdUtEBNpChKz","type":"tool_result","content":"The file c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts has been updated successfully."}]},"uuid":"24cb45f3-3905-4203-93fc-e7dacc250312","timestamp":"2026-01-28T23:29:11.930Z","toolUseResult":{"filePath":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\\src\\lib\\mistake-detection.ts","oldString":"  // Close any remaining active issues\n  for (const [code, issue] of activeIssues) {","newString":"  // Close any remaining active issues\n  for (const [code, issue] of Array.from(activeIssues.entries())) {","originalFile":"/**\n * Mistake Detection Module\n *\n * Detects specific mistake types from pose data:\n * 1. Overhead contact too low\n * 2. Late/missing split-step\n * 3. Poor lunge recovery\n * 4. Insufficient body rotation\n * 5. Stance too narrow/wide\n *\n * Each mistake includes:\n * - Time range (startTimeSec, endTimeSec)\n * - Severity (0-1)\n * - Confidence (derived from visibility)\n * - Affected joints\n */\n\nimport type {\n  PoseLandmark,\n  PoseMetrics,\n  MistakeEvent,\n  FixKeyframe,\n  TimelineSegment\n} from './types';\nimport { POSE_LANDMARKS, calculateAngle, calculateDistance } from './pose-utils';\n\n// Minimum frames to persist an issue before reporting\nconst MIN_PERSISTENCE_FRAMES = 3;\n// Minimum confidence to report a mistake\nconst MIN_CONFIDENCE_THRESHOLD = 0.4;\n\n/**\n * Mistake type definitions with thresholds and feedback\n */\nconst MISTAKE_TYPES = {\n  OVERHEAD_CONTACT_LOW: {\n    code: 'OVERHEAD_CONTACT_LOW',\n    title: 'Contact Point Too Low',\n    description: 'Raise your contact point for better power and angle',\n    severity: 0.8,\n    joints: [\n      POSE_LANDMARKS.RIGHT_WRIST,\n      POSE_LANDMARKS.RIGHT_ELBOW,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n    ],\n  },\n  LATE_SPLIT_STEP: {\n    code: 'LATE_SPLIT_STEP',\n    title: 'Late or Missing Split-Step',\n    description: 'Time your split-step with opponent\\'s contact',\n    severity: 0.6,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n      POSE_LANDMARKS.LEFT_KNEE,\n      POSE_LANDMARKS.RIGHT_KNEE,\n    ],\n  },\n  POOR_LUNGE_RECOVERY: {\n    code: 'POOR_LUNGE_RECOVERY',\n    title: 'Slow Lunge Recovery',\n    description: 'Push off your front foot faster to recover',\n    severity: 0.7,\n    joints: [\n      POSE_LANDMARKS.RIGHT_KNEE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n      POSE_LANDMARKS.LEFT_HIP,\n      POSE_LANDMARKS.RIGHT_HIP,\n    ],\n  },\n  INSUFFICIENT_ROTATION: {\n    code: 'INSUFFICIENT_ROTATION',\n    title: 'Insufficient Body Rotation',\n    description: 'Rotate hips before shoulders for more power',\n    severity: 0.5,\n    joints: [\n      POSE_LANDMARKS.LEFT_SHOULDER,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n      POSE_LANDMARKS.LEFT_HIP,\n      POSE_LANDMARKS.RIGHT_HIP,\n    ],\n  },\n  STANCE_TOO_NARROW: {\n    code: 'STANCE_TOO_NARROW',\n    title: 'Stance Too Narrow',\n    description: 'Widen your stance for better stability',\n    severity: 0.4,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n    ],\n  },\n  STANCE_TOO_WIDE: {\n    code: 'STANCE_TOO_WIDE',\n    title: 'Stance Too Wide',\n    description: 'Narrow your stance for quicker movement',\n    severity: 0.4,\n    joints: [\n      POSE_LANDMARKS.LEFT_ANKLE,\n      POSE_LANDMARKS.RIGHT_ANKLE,\n    ],\n  },\n  ELBOW_TOO_BENT: {\n    code: 'ELBOW_TOO_BENT',\n    title: 'Elbow Too Bent at Contact',\n    description: 'Extend your elbow more at contact point',\n    severity: 0.7,\n    joints: [\n      POSE_LANDMARKS.RIGHT_ELBOW,\n      POSE_LANDMARKS.RIGHT_WRIST,\n      POSE_LANDMARKS.RIGHT_SHOULDER,\n    ],\n  },\n};\n\n/**\n * Calculate confidence for a mistake based on joint visibility\n */\nfunction calculateMistakeConfidence(\n  landmarks: PoseLandmark[],\n  jointIndices: number[]\n): number {\n  if (!landmarks || jointIndices.length === 0) return 0;\n\n  let totalVisibility = 0;\n  let count = 0;\n\n  for (const idx of jointIndices) {\n    const landmark = landmarks[idx];\n    if (landmark) {\n      totalVisibility += landmark.visibility ?? 0;\n      count++;\n    }\n  }\n\n  return count > 0 ? totalVisibility / count : 0;\n}\n\n/**\n * Detect overhead contact too low\n */\nfunction detectOverheadContactLow(\n  landmarks: PoseLandmark[]\n): { detected: boolean; confidence: number } {\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const head = landmarks[POSE_LANDMARKS.NOSE];\n\n  if (!rightWrist || !rightShoulder || !head) {\n    return { detected: false, confidence: 0 };\n  }\n\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.OVERHEAD_CONTACT_LOW.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  // Check if wrist is raised (overhead position) but not high enough\n  const isOverheadPosition = rightWrist.y < rightShoulder.y;\n  const isTooLow = isOverheadPosition && rightWrist.y > head.y - 0.05;\n\n  return { detected: isOverheadPosition && isTooLow, confidence };\n}\n\n/**\n * Detect late or missing split-step\n * Checks for stance width changes that indicate split-step\n */\nfunction detectLateSplitStep(\n  currentLandmarks: PoseLandmark[],\n  prevLandmarks: PoseLandmark[] | null,\n  prev2Landmarks: PoseLandmark[] | null\n): { detected: boolean; confidence: number } {\n  if (!prevLandmarks || !prev2Landmarks) {\n    return { detected: false, confidence: 0 };\n  }\n\n  const confidence = calculateMistakeConfidence(currentLandmarks, MISTAKE_TYPES.LATE_SPLIT_STEP.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  // Calculate stance widths\n  const currentStance = calculateStanceWidth(currentLandmarks);\n  const prevStance = calculateStanceWidth(prevLandmarks);\n  const prev2Stance = calculateStanceWidth(prev2Landmarks);\n\n  if (currentStance === 0 || prevStance === 0 || prev2Stance === 0) {\n    return { detected: false, confidence };\n  }\n\n  // Detect if there's a significant movement without split-step\n  // Split-step: quick widening then return\n  const stanceChange = Math.abs(currentStance - prevStance);\n  const prevChange = Math.abs(prevStance - prev2Stance);\n\n  // If there's big movement but no stance change, split-step might be missing\n  const movementWithoutSplitStep = stanceChange < 0.1 && prevChange < 0.1;\n\n  // Check if body is moving (hip position change)\n  const currentHip = currentLandmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const prevHip = prevLandmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const prev2Hip = prev2Landmarks[POSE_LANDMARKS.RIGHT_HIP];\n\n  if (!currentHip || !prevHip || !prev2Hip) {\n    return { detected: false, confidence };\n  }\n\n  const hipMovement = Math.sqrt(\n    Math.pow(currentHip.x - prev2Hip.x, 2) + Math.pow(currentHip.y - prev2Hip.y, 2)\n  );\n\n  // Significant movement without split-step\n  const detected = hipMovement > 0.05 && movementWithoutSplitStep;\n\n  return { detected, confidence };\n}\n\n/**\n * Detect poor lunge recovery\n */\nfunction detectPoorLungeRecovery(\n  currentLandmarks: PoseLandmark[],\n  prevLandmarks: PoseLandmark[] | null,\n  isInLunge: boolean,\n  lungeStartFrame: number,\n  currentFrame: number,\n  fps: number\n): { detected: boolean; confidence: number; isInLunge: boolean; lungeStartFrame: number } {\n  const confidence = calculateMistakeConfidence(currentLandmarks, MISTAKE_TYPES.POOR_LUNGE_RECOVERY.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence, isInLunge, lungeStartFrame };\n  }\n\n  const rightHip = currentLandmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const rightKnee = currentLandmarks[POSE_LANDMARKS.RIGHT_KNEE];\n  const rightAnkle = currentLandmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n\n  if (!rightHip || !rightKnee || !rightAnkle) {\n    return { detected: false, confidence, isInLunge, lungeStartFrame };\n  }\n\n  const kneeAngle = calculateAngle(rightHip, rightKnee, rightAnkle);\n\n  // Detect lunge entry (knee angle < 110)\n  if (!isInLunge && kneeAngle < 110) {\n    return { detected: false, confidence, isInLunge: true, lungeStartFrame: currentFrame };\n  }\n\n  // Check recovery (knee angle back > 145)\n  if (isInLunge && kneeAngle > 145) {\n    const recoveryFrames = currentFrame - lungeStartFrame;\n    const recoveryTime = recoveryFrames / fps;\n\n    // Poor recovery if > 0.8 seconds\n    const isPoorRecovery = recoveryTime > 0.8;\n\n    return { detected: isPoorRecovery, confidence, isInLunge: false, lungeStartFrame: 0 };\n  }\n\n  // Still in lunge\n  if (isInLunge) {\n    const lungeTime = (currentFrame - lungeStartFrame) / fps;\n    // Very poor if in lunge > 1.5 seconds\n    return { detected: lungeTime > 1.5, confidence, isInLunge: true, lungeStartFrame };\n  }\n\n  return { detected: false, confidence, isInLunge, lungeStartFrame };\n}\n\n/**\n * Detect insufficient body rotation\n */\nfunction detectInsufficientRotation(\n  landmarks: PoseLandmark[]\n): { detected: boolean; confidence: number } {\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.INSUFFICIENT_ROTATION.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const leftHip = landmarks[POSE_LANDMARKS.LEFT_HIP];\n  const rightHip = landmarks[POSE_LANDMARKS.RIGHT_HIP];\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n\n  if (!leftShoulder || !rightShoulder || !leftHip || !rightHip || !rightWrist) {\n    return { detected: false, confidence };\n  }\n\n  // Only check rotation during overhead shots\n  if (rightWrist.y > rightShoulder.y) {\n    return { detected: false, confidence };\n  }\n\n  // Calculate rotation angle\n  const shoulderAngle = Math.atan2(\n    rightShoulder.y - leftShoulder.y,\n    rightShoulder.x - leftShoulder.x\n  );\n  const hipAngle = Math.atan2(\n    rightHip.y - leftHip.y,\n    rightHip.x - leftHip.x\n  );\n  const rotationDeg = Math.abs(shoulderAngle - hipAngle) * (180 / Math.PI);\n\n  // Insufficient rotation if < 10 degrees during overhead\n  return { detected: rotationDeg < 10, confidence };\n}\n\n/**\n * Detect stance issues\n */\nfunction detectStanceIssues(\n  landmarks: PoseLandmark[]\n): { tooNarrow: boolean; tooWide: boolean; confidence: number } {\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.STANCE_TOO_NARROW.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { tooNarrow: false, tooWide: false, confidence };\n  }\n\n  const stanceWidth = calculateStanceWidth(landmarks);\n  if (stanceWidth === 0) {\n    return { tooNarrow: false, tooWide: false, confidence };\n  }\n\n  return {\n    tooNarrow: stanceWidth < 0.5,\n    tooWide: stanceWidth > 2.0,\n    confidence,\n  };\n}\n\n/**\n * Detect elbow too bent at contact\n */\nfunction detectElbowTooBent(\n  landmarks: PoseLandmark[]\n): { detected: boolean; confidence: number } {\n  const confidence = calculateMistakeConfidence(landmarks, MISTAKE_TYPES.ELBOW_TOO_BENT.joints);\n  if (confidence < MIN_CONFIDENCE_THRESHOLD) {\n    return { detected: false, confidence };\n  }\n\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n  const rightElbow = landmarks[POSE_LANDMARKS.RIGHT_ELBOW];\n  const rightWrist = landmarks[POSE_LANDMARKS.RIGHT_WRIST];\n\n  if (!rightShoulder || !rightElbow || !rightWrist) {\n    return { detected: false, confidence };\n  }\n\n  // Only check during overhead\n  if (rightWrist.y > rightShoulder.y) {\n    return { detected: false, confidence };\n  }\n\n  const elbowAngle = calculateAngle(rightShoulder, rightElbow, rightWrist);\n\n  // Elbow too bent if < 130 degrees during overhead contact\n  return { detected: elbowAngle < 130, confidence };\n}\n\n/**\n * Main function: Detect all mistakes from pose data\n */\nexport function detectMistakes(\n  poseData: (PoseLandmark[] | null)[],\n  fps: number = 10\n): MistakeEvent[] {\n  const mistakes: MistakeEvent[] = [];\n  const activeIssues: Map<string, { startFrame: number; frames: number; confidence: number }> = new Map();\n\n  // State for lunge tracking\n  let isInLunge = false;\n  let lungeStartFrame = 0;\n\n  for (let i = 0; i < poseData.length; i++) {\n    const landmarks = poseData[i];\n    if (!landmarks) continue;\n\n    const prevLandmarks = i > 0 ? poseData[i - 1] : null;\n    const prev2Landmarks = i > 1 ? poseData[i - 2] : null;\n\n    // Check each mistake type\n    const detections: { code: string; detected: boolean; confidence: number }[] = [];\n\n    // Overhead contact too low\n    const overhead = detectOverheadContactLow(landmarks);\n    detections.push({ code: 'OVERHEAD_CONTACT_LOW', ...overhead });\n\n    // Late split-step\n    const splitStep = detectLateSplitStep(landmarks, prevLandmarks, prev2Landmarks);\n    detections.push({ code: 'LATE_SPLIT_STEP', ...splitStep });\n\n    // Poor lunge recovery\n    const lungeResult = detectPoorLungeRecovery(\n      landmarks, prevLandmarks, isInLunge, lungeStartFrame, i, fps\n    );\n    isInLunge = lungeResult.isInLunge;\n    lungeStartFrame = lungeResult.lungeStartFrame;\n    detections.push({ code: 'POOR_LUNGE_RECOVERY', detected: lungeResult.detected, confidence: lungeResult.confidence });\n\n    // Insufficient rotation\n    const rotation = detectInsufficientRotation(landmarks);\n    detections.push({ code: 'INSUFFICIENT_ROTATION', ...rotation });\n\n    // Stance issues\n    const stance = detectStanceIssues(landmarks);\n    if (stance.tooNarrow) {\n      detections.push({ code: 'STANCE_TOO_NARROW', detected: true, confidence: stance.confidence });\n    }\n    if (stance.tooWide) {\n      detections.push({ code: 'STANCE_TOO_WIDE', detected: true, confidence: stance.confidence });\n    }\n\n    // Elbow too bent\n    const elbow = detectElbowTooBent(landmarks);\n    detections.push({ code: 'ELBOW_TOO_BENT', ...elbow });\n\n    // Process detections\n    for (const { code, detected, confidence } of detections) {\n      const issue = activeIssues.get(code);\n\n      if (detected) {\n        if (issue) {\n          // Continue existing issue\n          issue.frames++;\n          issue.confidence = Math.max(issue.confidence, confidence);\n        } else {\n          // Start new issue\n          activeIssues.set(code, { startFrame: i, frames: 1, confidence });\n        }\n      } else if (issue) {\n        // Issue ended - check if it persisted long enough\n        if (issue.frames >= MIN_PERSISTENCE_FRAMES) {\n          const mistakeType = MISTAKE_TYPES[code as keyof typeof MISTAKE_TYPES];\n          if (mistakeType) {\n            mistakes.push({\n              id: `${code}-${issue.startFrame}`,\n              type: code,\n              startTimeSec: issue.startFrame / fps,\n              endTimeSec: i / fps,\n              severity: mistakeType.severity,\n              confidence: issue.confidence,\n              joints: mistakeType.joints,\n              summaryTitle: mistakeType.title,\n              description: mistakeType.description,\n            });\n          }\n        }\n        activeIssues.delete(code);\n      }\n    }\n  }\n\n  // Close any remaining active issues\n  for (const [code, issue] of activeIssues) {\n    if (issue.frames >= MIN_PERSISTENCE_FRAMES) {\n      const mistakeType = MISTAKE_TYPES[code as keyof typeof MISTAKE_TYPES];\n      if (mistakeType) {\n        mistakes.push({\n          id: `${code}-${issue.startFrame}`,\n          type: code,\n          startTimeSec: issue.startFrame / fps,\n          endTimeSec: poseData.length / fps,\n          severity: mistakeType.severity,\n          confidence: issue.confidence,\n          joints: mistakeType.joints,\n          summaryTitle: mistakeType.title,\n          description: mistakeType.description,\n        });\n      }\n    }\n  }\n\n  // Sort by time and merge overlapping segments of same type\n  return mergeMistakes(mistakes);\n}\n\n/**\n * Merge overlapping or adjacent mistakes of the same type\n */\nfunction mergeMistakes(mistakes: MistakeEvent[]): MistakeEvent[] {\n  if (mistakes.length === 0) return [];\n\n  // Sort by type then by start time\n  mistakes.sort((a, b) => {\n    if (a.type !== b.type) return a.type.localeCompare(b.type);\n    return a.startTimeSec - b.startTimeSec;\n  });\n\n  const merged: MistakeEvent[] = [];\n  let current = { ...mistakes[0] };\n\n  for (let i = 1; i < mistakes.length; i++) {\n    const next = mistakes[i];\n\n    if (next.type === current.type && next.startTimeSec <= current.endTimeSec + 0.5) {\n      // Merge\n      current.endTimeSec = Math.max(current.endTimeSec, next.endTimeSec);\n      current.confidence = Math.max(current.confidence, next.confidence);\n    } else {\n      merged.push(current);\n      current = { ...next };\n    }\n  }\n\n  merged.push(current);\n\n  // Sort final result by start time\n  merged.sort((a, b) => a.startTimeSec - b.startTimeSec);\n\n  return merged;\n}\n\n/**\n * Convert mistakes to timeline segments for rendering\n */\nexport function mistakesToTimelineSegments(\n  mistakes: MistakeEvent[],\n  totalDuration: number\n): TimelineSegment[] {\n  if (totalDuration <= 0) return [];\n\n  return mistakes.map(event => ({\n    id: event.id,\n    startPercent: (event.startTimeSec / totalDuration) * 100,\n    widthPercent: ((event.endTimeSec - event.startTimeSec) / totalDuration) * 100,\n    color: getSeverityColor(event.severity),\n    event,\n  }));\n}\n\n/**\n * Get color based on severity\n */\nfunction getSeverityColor(severity: number): string {\n  if (severity >= 0.7) return '#ef4444'; // Red\n  if (severity >= 0.4) return '#f97316'; // Orange\n  return '#eab308'; // Yellow\n}\n\n/**\n * Generate fix keyframes for a mistake\n */\nexport function generateFixKeyframes(\n  mistake: MistakeEvent,\n  poseData: (PoseLandmark[] | null)[],\n  fps: number = 10\n): FixKeyframe[] {\n  const startFrame = Math.floor(mistake.startTimeSec * fps);\n  const endFrame = Math.floor(mistake.endTimeSec * fps);\n\n  const keyframes: FixKeyframe[] = [];\n\n  // Setup phase - frame before mistake\n  const setupFrame = Math.max(0, startFrame - Math.floor(fps * 0.3));\n  if (poseData[setupFrame]) {\n    keyframes.push({\n      phase: 'setup',\n      landmarks: poseData[setupFrame]!,\n      label: 'Setup',\n      correction: getSetupCorrection(mistake.type),\n    });\n  }\n\n  // Contact phase - middle of mistake\n  const contactFrame = Math.floor((startFrame + endFrame) / 2);\n  if (poseData[contactFrame]) {\n    keyframes.push({\n      phase: 'contact',\n      landmarks: poseData[contactFrame]!,\n      label: 'Contact',\n      correction: getContactCorrection(mistake.type),\n    });\n  }\n\n  // Recovery phase - frame after mistake\n  const recoveryFrame = Math.min(poseData.length - 1, endFrame + Math.floor(fps * 0.3));\n  if (poseData[recoveryFrame]) {\n    keyframes.push({\n      phase: 'recover',\n      landmarks: poseData[recoveryFrame]!,\n      label: 'Recovery',\n      correction: getRecoveryCorrection(mistake.type),\n    });\n  }\n\n  return keyframes;\n}\n\nfunction getSetupCorrection(mistakeType: string): string {\n  switch (mistakeType) {\n    case 'OVERHEAD_CONTACT_LOW':\n      return 'Position yourself under the shuttle early';\n    case 'LATE_SPLIT_STEP':\n      return 'Watch opponent\\'s racket for timing';\n    case 'POOR_LUNGE_RECOVERY':\n      return 'Prepare to push off front foot';\n    case 'INSUFFICIENT_ROTATION':\n      return 'Turn sideways to the net';\n    default:\n      return 'Ready position';\n  }\n}\n\nfunction getContactCorrection(mistakeType: string): string {\n  switch (mistakeType) {\n    case 'OVERHEAD_CONTACT_LOW':\n      return 'Hit at the highest point above your head';\n    case 'LATE_SPLIT_STEP':\n      return 'Land with both feet as opponent hits';\n    case 'POOR_LUNGE_RECOVERY':\n      return 'Push through heel immediately';\n    case 'INSUFFICIENT_ROTATION':\n      return 'Rotate hips then shoulders';\n    case 'ELBOW_TOO_BENT':\n      return 'Extend elbow fully at contact';\n    default:\n      return 'Contact point';\n  }\n}\n\nfunction getRecoveryCorrection(mistakeType: string): string {\n  switch (mistakeType) {\n    case 'POOR_LUNGE_RECOVERY':\n      return 'Return to center quickly';\n    case 'LATE_SPLIT_STEP':\n      return 'Move explosively after landing';\n    default:\n      return 'Return to ready position';\n  }\n}\n\n// Helper function\nfunction calculateStanceWidth(landmarks: PoseLandmark[]): number {\n  const leftAnkle = landmarks[POSE_LANDMARKS.LEFT_ANKLE];\n  const rightAnkle = landmarks[POSE_LANDMARKS.RIGHT_ANKLE];\n  const leftShoulder = landmarks[POSE_LANDMARKS.LEFT_SHOULDER];\n  const rightShoulder = landmarks[POSE_LANDMARKS.RIGHT_SHOULDER];\n\n  if (!leftAnkle || !rightAnkle || !leftShoulder || !rightShoulder) return 0;\n  if ((leftAnkle.visibility ?? 0) < 0.5 || (rightAnkle.visibility ?? 0) < 0.5) return 0;\n\n  const shoulderWidth = calculateDistance(leftShoulder, rightShoulder);\n  const ankleWidth = calculateDistance(leftAnkle, rightAnkle);\n\n  return shoulderWidth > 0 ? ankleWidth / shoulderWidth : 0;\n}\n","structuredPatch":[{"oldStart":456,"oldLines":7,"newStart":456,"newLines":7,"lines":["   }"," ","   // Close any remaining active issues","-  for (const [code, issue] of activeIssues) {","+  for (const [code, issue] of Array.from(activeIssues.entries())) {","     if (issue.frames >= MIN_PERSISTENCE_FRAMES) {","       const mistakeType = MISTAKE_TYPES[code as keyof typeof MISTAKE_TYPES];","       if (mistakeType) {"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"73fc250c-1c6f-4645-8ff6-7b966c3761d6"}
{"parentUuid":"24cb45f3-3905-4203-93fc-e7dacc250312","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01SakAv6oNZ3X9RQzZGBhTMc","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me run TypeScript check again to verify the fix.","signature":"EtwBCkYICxgCKkA56ZuotHbeCOdHFFO36YInb48tmP2MkdnXP+XANdJFgKySyHLY4/G8SHfOUaUW68UdBAkNh2AeMt7gbnS5eacEEgwDSlPI4elREAAnjckaDOlnuuDMUPdaWiQIECIwn7TUnHsP6Q0iMrXyJp83nU3CZoZE05seZECfv3fe504nnDACH8ktew9qsc1EajoMKkQKgXLpUwcFFOkBUYagJaVwQAhZfROhrtvCO29AKtmwt/+acPk/G140+0UOLq/JzZMc1GDnLN7PBmbE4fwSKjB8r4T2dRgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":524,"cache_read_input_tokens":102665,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":524},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeMaqpYpg4eWcwGmLCU","type":"assistant","uuid":"0418089a-b327-4eab-86f9-1bbee8a417f8","timestamp":"2026-01-28T23:29:16.385Z"}
{"parentUuid":"0418089a-b327-4eab-86f9-1bbee8a417f8","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01SakAv6oNZ3X9RQzZGBhTMc","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01RZiWWLcPHavLuTxRmehVs7","name":"Bash","input":{"command":"cd \"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\" && npx tsc --noEmit 2>&1 | head -20","description":"Verify TypeScript check passes","timeout":60000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":524,"cache_read_input_tokens":102665,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":524},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeMaqpYpg4eWcwGmLCU","type":"assistant","uuid":"a8fb4ffc-0ebd-489f-b64f-a85d6f88a371","timestamp":"2026-01-28T23:29:17.306Z"}
{"parentUuid":"a8fb4ffc-0ebd-489f-b64f-a85d6f88a371","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RZiWWLcPHavLuTxRmehVs7","type":"tool_result","content":"","is_error":false}]},"uuid":"a4d3611e-5bdd-473e-b235-a4ceb78aae90","timestamp":"2026-01-28T23:29:20.134Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false},"sourceToolAssistantUUID":"a8fb4ffc-0ebd-489f-b64f-a85d6f88a371"}
{"parentUuid":"a4d3611e-5bdd-473e-b235-a4ceb78aae90","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01UF4WUmA3EiGLBwX6oS6yeq","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"TypeScript check passes. Let me now mark the task as completed and do a summary of what was implemented.","signature":"EpACCkYICxgCKkAnibRQWfOxS1WaYnmr+tSIBF6Y71zEoNlVqzepF4o3ascPaxOtlDvtZlBQHUUOkqtmKFvyBCeFNRFPZMCSVrusEgxA4DQQPf0jOd3F+ZkaDN4Go7FCHrQ+tNE4TyIw9wiKiKMQvh69jlRR8vabzf3kfczypvLTRT+nfduaItWmNcM8V+0DpdbxI4GH4kPQKngFvTFqYYvwlk6qej3/r3aeX7rCCxcYAizB53BH4g6IOg76IfBcZaF3+VdfDfW/x4Slkq5dve85lECrmHVP0xGWaTFINsUb+9aEJf6jgSMKIpzfen1nAI6fasejbH76HbXh98PbiQ1KbiaS4soJK8OqsBecbaqyfkoYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":187,"cache_read_input_tokens":103189,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":187},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeN7Ms96H37sSgVqGfU","type":"assistant","uuid":"06a43644-33f1-4b4f-9aad-c4bf49ada587","timestamp":"2026-01-28T23:29:22.683Z"}
{"parentUuid":"06a43644-33f1-4b4f-9aad-c4bf49ada587","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01UF4WUmA3EiGLBwX6oS6yeq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JEE791CQDBAnRU8sFYwH5u","name":"TodoWrite","input":{"todos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"completed","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"completed","activeForm":"Updating reset handlers"},{"content":"Verify no TypeScript errors","status":"completed","activeForm":"Verifying TypeScript errors"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":187,"cache_read_input_tokens":103189,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":187},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXaeN7Ms96H37sSgVqGfU","type":"assistant","uuid":"71a478f2-7b24-4104-b5f3-6c4cfb563383","timestamp":"2026-01-28T23:29:24.915Z"}
{"parentUuid":"71a478f2-7b24-4104-b5f3-6c4cfb563383","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JEE791CQDBAnRU8sFYwH5u","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"177fc57e-4293-4654-809a-a6338d0cd03c","timestamp":"2026-01-28T23:29:25.004Z","toolUseResult":{"oldTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"completed","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"completed","activeForm":"Updating reset handlers"},{"content":"Verify no TypeScript errors","status":"in_progress","activeForm":"Verifying TypeScript errors"}],"newTodos":[{"content":"Update saveAnalysisToDatabase signature for V4 params","status":"completed","activeForm":"Updating saveAnalysisToDatabase signature"},{"content":"Update analyzeVideo function with V4 features","status":"completed","activeForm":"Updating analyzeVideo function"},{"content":"Add MistakeTimeline component to UI","status":"completed","activeForm":"Adding MistakeTimeline component"},{"content":"Add SkillMeter component to UI","status":"completed","activeForm":"Adding SkillMeter component"},{"content":"Add ghost toggle and FixItCard to UI","status":"completed","activeForm":"Adding ghost toggle and FixItCard"},{"content":"Update reset handlers for V4 state","status":"completed","activeForm":"Updating reset handlers"},{"content":"Verify no TypeScript errors","status":"completed","activeForm":"Verifying TypeScript errors"}]},"sourceToolAssistantUUID":"71a478f2-7b24-4104-b5f3-6c4cfb563383"}
{"parentUuid":"177fc57e-4293-4654-809a-a6338d0cd03c","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01C7Fmrk2zxDStbFPrZffPbx","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me verify the build works by running the Next.js build.","signature":"EuMBCkYICxgCKkAu/L8u2ssFGmXuVybypJ1M5KwNDeWIRD5ZG4BRGF+EqC/VTTsCvnIHWXsF04iTIfFMD3ee03Yeapip4uMpW73UEgxFklflUH13JTRUNVsaDILTRjqcmWCf6T3w3CIwBbm4izEvHK6VVwje0n2kzBOX2IgyNUigbITX8lcIbG0AB9f4lMjao8FwP7BlQ9g+Kkv+ZAvOBDDAv3s9ejwM8H2mkQUcRLpP9Zh9wnd0pH77FrOo0b+atEV67ekTb1+Ud9y04Wpe3T57gMxlZBmvt8iWNg43GEKcXKxnQ18YAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":369,"cache_read_input_tokens":103376,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":369},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeNUGDdmKm1JREm2gKM","type":"assistant","uuid":"db34dae5-b726-42c1-8086-e40c7a87e57d","timestamp":"2026-01-28T23:29:27.859Z"}
{"parentUuid":"db34dae5-b726-42c1-8086-e40c7a87e57d","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01C7Fmrk2zxDStbFPrZffPbx","type":"message","role":"assistant","content":[{"type":"text","text":"Let me verify the build works."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":369,"cache_read_input_tokens":103376,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":369},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeNUGDdmKm1JREm2gKM","type":"assistant","uuid":"543faf7e-9b1e-4039-9022-7310149e4e99","timestamp":"2026-01-28T23:29:28.134Z"}
{"parentUuid":"543faf7e-9b1e-4039-9022-7310149e4e99","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01C7Fmrk2zxDStbFPrZffPbx","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Mx4RKLDPHeT6HyZErR6eT6","name":"Bash","input":{"command":"cd \"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack\\rallycoach\" && npm run build 2>&1 | tail -30","description":"Verify Next.js build","timeout":180000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":369,"cache_read_input_tokens":103376,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":369},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaeNUGDdmKm1JREm2gKM","type":"assistant","uuid":"3577534a-5f19-4126-931e-fcc0196247cc","timestamp":"2026-01-28T23:29:28.946Z"}
{"parentUuid":"3577534a-5f19-4126-931e-fcc0196247cc","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Mx4RKLDPHeT6HyZErR6eT6","type":"tool_result","content":"   Collecting build traces ...\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    5.85 kB         164 kB\n├ ○ /_not-found                          875 B          88.3 kB\n├ ○ /analytics                           21.5 kB         197 kB\n├ ƒ /api/analysis/[id]                   0 B                0 B\n├ ƒ /api/analysis/auto-level             0 B                0 B\n├ ƒ /api/analysis/start                  0 B                0 B\n├ ƒ /api/practice/tick                   0 B                0 B\n├ ƒ /api/racket/recommend                0 B                0 B\n├ ƒ /api/strategy/recommend              0 B                0 B\n├ ○ /dashboard                           110 kB          272 kB\n├ ○ /history                             2.66 kB         167 kB\n├ ƒ /history/[sessionId]                 5.76 kB         182 kB\n├ ○ /icon.svg                            0 B                0 B\n├ ○ /login                               3.66 kB         162 kB\n├ ○ /practice                            5.97 kB         172 kB\n├ ○ /racket                              8.68 kB         170 kB\n├ ○ /signup                              3.92 kB         162 kB\n└ ○ /strategy                            15.5 kB         177 kB\n+ First Load JS shared by all            87.5 kB\n  ├ chunks/23-2e80f9b872582632.js        31.7 kB\n  ├ chunks/fd9d1056-14f562504cf252d7.js  53.6 kB\n  └ other shared chunks (total)          2.13 kB\n\n\n○  (Static)   prerendered as static content\nƒ  (Dynamic)  server-rendered on demand","is_error":false}]},"uuid":"400a1942-883e-4a23-a6c4-38f6eb1f1b73","timestamp":"2026-01-28T23:29:45.628Z","toolUseResult":{"stdout":"   Collecting build traces ...\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    5.85 kB         164 kB\n├ ○ /_not-found                          875 B          88.3 kB\n├ ○ /analytics                           21.5 kB         197 kB\n├ ƒ /api/analysis/[id]                   0 B                0 B\n├ ƒ /api/analysis/auto-level             0 B                0 B\n├ ƒ /api/analysis/start                  0 B                0 B\n├ ƒ /api/practice/tick                   0 B                0 B\n├ ƒ /api/racket/recommend                0 B                0 B\n├ ƒ /api/strategy/recommend              0 B                0 B\n├ ○ /dashboard                           110 kB          272 kB\n├ ○ /history                             2.66 kB         167 kB\n├ ƒ /history/[sessionId]                 5.76 kB         182 kB\n├ ○ /icon.svg                            0 B                0 B\n├ ○ /login                               3.66 kB         162 kB\n├ ○ /practice                            5.97 kB         172 kB\n├ ○ /racket                              8.68 kB         170 kB\n├ ○ /signup                              3.92 kB         162 kB\n└ ○ /strategy                            15.5 kB         177 kB\n+ First Load JS shared by all            87.5 kB\n  ├ chunks/23-2e80f9b872582632.js        31.7 kB\n  ├ chunks/fd9d1056-14f562504cf252d7.js  53.6 kB\n  └ other shared chunks (total)          2.13 kB\n\n\n○  (Static)   prerendered as static content\nƒ  (Dynamic)  server-rendered on demand\r","stderr":"","interrupted":false,"isImage":false},"sourceToolAssistantUUID":"3577534a-5f19-4126-931e-fcc0196247cc"}
{"parentUuid":"400a1942-883e-4a23-a6c4-38f6eb1f1b73","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01A74cyq56pcwUfutsBvLvsi","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The build succeeded. All V4 features have been integrated into the analytics page. Let me provide a summary of the completed implementation.","signature":"ErUCCkYICxgCKkB01zgvMDONWUCCa1EFA7L1bTa1i7wXQCFxdWjapxiYGON9jGg3rbTAxxafqGqbcH6A8H4Vrsvuhu6GaNqp780zEgwWl9mAVscdSzaxCMwaDC5mkzdcJFx+WVzsGCIwJgEVrAvKeA6Xb3JMycdQLoX1gOzPRGj4NffLk4tRn3ttGbWRA+zHMWbb2FnkKvpUKpwBe927ih9cdAiIHt6/5dZqbuYlisi3w3Ixxu5GzTbTGloH4ifzD8nj4GCYxqMUgNQ4hAMYG7OeX3ZpQ6RcDa9t4Jlbq4iSV89SAAGiagrV1XTHVVaKqWYD+98RZTi+xaJ58TIKh6EKaWpfbmXDeXRrC5PSEN5fr7KvOBJFUCdf5joslGT8Nq9wGJOoPlGtZCHSzcpDc4zSiuGxDTN1GAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":705,"cache_read_input_tokens":103745,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":705},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaePzUBaFd3AzRhc18Xv","type":"assistant","uuid":"7436dd09-79e3-4a47-b329-3b8ccbb59cb2","timestamp":"2026-01-28T23:29:48.001Z"}
{"parentUuid":"7436dd09-79e3-4a47-b329-3b8ccbb59cb2","isSidechain":false,"userType":"external","cwd":"c:\\Users\\ASUS\\Desktop\\Gemini 3 hack","sessionId":"d33a5d5e-2558-4393-affc-97df18cc3930","version":"2.1.21","gitBranch":"","slug":"synthetic-tinkering-falcon","message":{"model":"claude-opus-4-5-20251101","id":"msg_01A74cyq56pcwUfutsBvLvsi","type":"message","role":"assistant","content":[{"type":"text","text":"The build succeeded. Here's a summary of the V4 features implementation that was completed:\n\n## Implementation Summary\n\n### Files Modified:\n- [analytics/page.tsx](rallycoach/src/app/analytics/page.tsx) - Main analytics page with all V4 features integrated\n- [mistake-detection.ts](rallycoach/src/lib/mistake-detection.ts) - Fixed TypeScript iteration issue\n\n### V4 Features Integrated:\n\n1. **Ghost Rival Overlay** ✅\n   - Toggle checkbox added to video controls (cyan \"Ghost (Best Rep)\" label)\n   - Ghost skeleton rendered on canvas with translucent blue color\n   - Syncs with video playhead using `getGhostPoseAtTime()`\n\n2. **Mistake Timeline** ✅\n   - `MistakeTimeline` component added below video scrubber\n   - Color-coded segments by severity (red/orange/yellow)\n   - Click-to-seek functionality\n   - Playhead tracking\n   - Selected mistake indicator\n\n3. **FixItCard** ✅\n   - Shows when a mistake is selected from timeline\n   - Animated stick-figure correction phases\n   - Generated keyframes from pose data when available\n\n4. **SkillMeter** ✅\n   - Displays computed skill score (0-100) and level (Beginner/Intermediate/Advanced)\n   - Confidence meter derived from MediaPipe visibility values\n   - Score breakdown with form quality, consistency, recovery speed metrics\n\n5. **Auto Skill Estimation** ✅\n   - `computeSkillScore()` computes skill from REAL pose metrics\n   - Confidence derived from actual landmark visibility values\n   - Gemini provides narrative rationale, but score comes from computed metrics\n\n6. **Database Integration** ✅\n   - `saveAnalysisToDatabase` updated with V4 params (mistakes, bestRepWindow)\n   - Mistake events saved to `mistake_events` table\n   - Skill score and confidence stored in sessions table\n\n7. **State Management** ✅\n   - All reset handlers updated to clear V4 state\n   - File selection clears V4 state\n   - Both analysis paths (single player and player selection) include V4 features"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":705,"cache_read_input_tokens":103745,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":705},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CXaePzUBaFd3AzRhc18Xv","type":"assistant","uuid":"697d0710-bf35-4fc2-93e4-89972920c46c","timestamp":"2026-01-28T23:29:58.767Z"}
{"type":"summary","summary":"RallyCoach V4 Features: Ghost Overlay, Mistake Timeline, Skill Scoring","leafUuid":"697d0710-bf35-4fc2-93e4-89972920c46c"}
